<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 235]
- [cs.AI](#cs.AI) [Total: 92]
- [cs.LG](#cs.LG) [Total: 106]
- [cs.CG](#cs.CG) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.CY](#cs.CY) [Total: 21]
- [eess.AS](#eess.AS) [Total: 4]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.NE](#cs.NE) [Total: 3]
- [q-bio.NC](#q-bio.NC) [Total: 3]
- [q-bio.OT](#q-bio.OT) [Total: 1]
- [eess.SP](#eess.SP) [Total: 2]
- [q-bio.GN](#q-bio.GN) [Total: 2]
- [math.AP](#math.AP) [Total: 1]
- [cs.RO](#cs.RO) [Total: 16]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.SD](#cs.SD) [Total: 11]
- [quant-ph](#quant-ph) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.CR](#cs.CR) [Total: 14]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 9]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.CV](#cs.CV) [Total: 42]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.SE](#cs.SE) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Amadeus-Verbo Technical Report: The powerful Qwen2.5 family models trained in Portuguese](https://arxiv.org/abs/2506.00019)
*William Alberto Cruz-Castañeda,Marcellus Amadeus*

Main category: cs.CL

TL;DR: 介绍了开发针对巴西葡萄牙语的大语言模型Amadeus Verbo的经验，包括不同参数规模的模型，旨在展示如何轻松微调基础模型以推动巴西葡萄牙语LLM的开源发展。


<details>
  <summary>Details</summary>
Motivation: 为了满足多样化的用例需求，并推动巴西葡萄牙语大语言模型的开源发展。

Method: 开发了包括基础调优、合并和指令调优的模型，参数规模从0.5B到72B不等。

Result: Amadeus Verbo系列模型已在HuggingFace上公开。

Conclusion: 展示了在数据和资源可用时，微调基础模型以推动巴西葡萄牙语LLM开源开发的可行性。

Abstract: This report introduces the experience of developing Amadeus Verbo, a family
of large language models for Brazilian Portuguese. To handle diverse use cases,
Amadeus Verbo includes base-tuned, merged, and instruction-tuned models in
sizes of 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B parameters. Thus, the main
objective is to show how easy it is to fine-tune foundation models to
democratize the open-source development of Brazilian Portuguese LLMs when data
and resources are available. Amadeus-Verbo family models are all available at
HuggingFace at
https://huggingface.co/collections/amadeusai/amadeus-verbo-qwen25-67cf2e7aae69ce2b3bcdcfda.

</details>


### [2] [Scaling Physical Reasoning with the PHYSICS Dataset](https://arxiv.org/abs/2506.00022)
*Shenghe Zheng,Qianjia Cheng,Junchi Yao,Mengsong Wu,haonan he,Ning Ding,Yu Cheng,Shuyue Hu,Lei Bai,Dongzhan Zhou,Ganqu Cui,Peng Ye*

Main category: cs.CL

TL;DR: PHYSICS是一个包含16,568个高质量物理问题的数据集，旨在提升大语言模型在物理领域的推理能力。


<details>
  <summary>Details</summary>
Motivation: 物理作为推理密集型且对现实世界理解至关重要的学科，目前在大语言模型研究中关注较少。

Method: 通过精心设计的流程从100多本教科书中筛选问题，涵盖五大物理领域和不同难度级别，并提供训练数据的推理路径。同时提出Rule+Model评估框架以解决现有评估方法的偏差问题。

Result: 评估显示当前最先进的开源和专有模型在处理物理任务时存在局限性。

Conclusion: PHYSICS数据集和评估方法有望共同推动大语言模型在物理领域的发展。

Abstract: Large Language Models (LLMs) have achieved remarkable progress on advanced
reasoning tasks such as mathematics and coding competitions. Meanwhile,
physics, despite being both reasoning-intensive and essential to real-world
understanding, received limited academic and industrial attention. This paper
introduces PHYSICS, a dataset containing 16,568 high-quality physics problems
spanning subjects and difficulty levels, to facilitate this issue.
Specifically, PHYSICS is curated with exercises from over 100 textbooks through
a carefully designed pipeline for quality control. It covers five major physics
domains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern
Physics. It also spans a wide range of difficulty levels, from high school to
graduate-level physics courses. To utilize the data for improving and
evaluating the model's physical reasoning capabilities, we split the dataset
into training and test sets, and provide reasoning paths generated by powerful
reasoning models for the training data to facilitate model training. In
addition, for the evaluation part, we find that existing evaluation frameworks
exhibit biases in aspects such as units, simplification, and precision in
physics domain. To balance efficiency and accuracy, we introduce a Rule+Model
evaluation framework tailored to physics problems. Our evaluations on current
state-of-the-art open-source and proprietary models highlight the limitations
of current models in handling physics-related tasks. We hope that our dataset
and evaluation methodology will jointly advance the development of LLMs in the
field of physics.

</details>


### [3] [From Mathematical Reasoning to Code: Generalization of Process Reward Models in Test-Time Scaling](https://arxiv.org/abs/2506.00027)
*Zhengyu Chen,Yudong Wang,Teng Xiao,Ruochen Zhou,Xuesheng Yang,Wei Wang,Zhifang Sui,Jingang Wang*

Main category: cs.CL

TL;DR: 研究分析了过程奖励模型（PRMs）在提升大语言模型推理能力中的作用，发现模型规模和计算成本需平衡，数据多样性对性能至关重要，并提出了不同资源条件下的优化策略。


<details>
  <summary>Details</summary>
Motivation: 探索PRMs在解决中间错误和提升推理能力中的有效性，以及其在训练、扩展和泛化方面的表现。

Method: 从训练方法、可扩展性和泛化能力多角度分析PRMs，研究预训练与奖励模型训练FLOPs的关系，并评估不同测试时扩展策略。

Result: 发现模型规模增加时性能回报递减，数据多样性显著影响性能；蒙特卡洛树搜索在资源充足时最优，Best-of-N采样适用于资源有限场景；PRMs在数学和代码生成任务中表现相似。

Conclusion: PRMs在推理任务中表现出色，但需平衡规模与成本，数据多样性和优化策略对其性能至关重要，且具备跨领域泛化能力。

Abstract: Recent advancements in improving the reasoning capabilities of Large Language
Models have underscored the efficacy of Process Reward Models (PRMs) in
addressing intermediate errors through structured feedback mechanisms. This
study analyzes PRMs from multiple perspectives, including training
methodologies, scalability, and generalization capabilities. We investigate the
interplay between pre-training and reward model training FLOPs to assess their
influence on PRM efficiency and accuracy in complex reasoning tasks. Our
analysis reveals a pattern of diminishing returns in performance with
increasing PRM scale, highlighting the importance of balancing model size and
computational cost. Furthermore, the diversity of training datasets
significantly impacts PRM performance, emphasizing the importance of diverse
data to enhance both accuracy and efficiency. We further examine test-time
scaling strategies, identifying Monte Carlo Tree Search as the most effective
method when computational resources are abundant, while Best-of-N Sampling
serves as a practical alternative under resource-limited conditions. Notably,
our findings indicate that PRMs trained on mathematical datasets exhibit
performance comparable to those tailored for code generation, suggesting robust
cross-domain generalization. Employing a gradient-based metric, we observe that
PRMs exhibit a preference for selecting responses with similar underlying
patterns, further informing their optimization.

</details>


### [4] [Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists](https://arxiv.org/abs/2506.00042)
*Yue Cui,Liuyi Yao,Shuchang Tao,Weijie Shi,Yaliang Li,Bolin Ding,Xiaofang Zhou*

Main category: cs.CL

TL;DR: 论文提出HiTEC框架，通过分层错误检查表诊断和缓解工具调用错误，包含全局和局部检查表，并部署了HiTEC-ICL和HiTEC-KTO两种方法，显著提升了参数填充准确性和工具调用成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在工具调用中常因参数填充错误而受限，需要一种无需依赖大量实际交互的系统性解决方案。

Method: 提出HiTEC框架，包含全局和局部错误检查表，并开发了HiTEC-ICL（上下文学习）和HiTEC-KTO（偏好优化）两种部署方法。

Result: 在五个公共数据集上的实验表明，HiTEC显著提高了参数填充准确性和工具调用成功率。

Conclusion: HiTEC框架有效解决了工具调用中的参数错误问题，为LLMs的实用化提供了可靠支持。

Abstract: Large language models (LLMs) have significantly advanced natural language
processing, particularly through the integration of external tools and APIs.
However, their effectiveness is frequently hampered by parameter mis-filling
during tool calling. In this paper, we propose the Hierarchical Tool Error
Checklist (HiTEC) framework to systematically diagnose and mitigate
tool-calling errors without relying on extensive real-world interactions. HiTEC
introduces a two-tiered approach: a global error checklist that identifies
common, cross-tool issues, and a local error checklist that targets
tool-specific and contextual failures. Building on this structure, we propose
two deployments: HiTEC-In Context Learning (HiTEC-ICL) and
HiTEC-Kahneman-Tversky Optimization (HiTEC-KTO). HiTEC-ICL embeds the global
checklist in the initial prompts and leverages a two-round conversational
interaction to dynamically refine parameter handling, while HiTEC-KTO generates
high-quality negative examples to drive fine-tuning via preference-based
optimization. Extensive experiments across five public datasets demonstrate
that our framework significantly improves parameter-filling accuracy and
tool-calling success rates compared to baseline methods.

</details>


### [5] [Unraveling SITT: Social Influence Technique Taxonomy and Detection with LLMs](https://arxiv.org/abs/2506.00061)
*Wiktoria Mieleszczenko-Kowszewicz,Beata Bajcar,Aleksander Szczęsny,Maciej Markiewicz,Jolanta Babiak,Berenika Dyczek,Przemysław Kazienko*

Main category: cs.CL

TL;DR: 本文提出了Social Influence Technique Taxonomy (SITT)框架，包含58种社会影响技术，并评估了LLMs识别这些技术的能力。结果表明，现有模型表现有限，尤其是对上下文敏感的技术。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs识别社会影响技术的能力，填补现有研究空白，并提供一个标注数据集。

Method: 构建SITT数据集（746个对话），采用分层多标签分类方法，评估5种LLMs（如GPT-4o、Claude 3.5等）。

Result: Claude 3.5表现最佳（F1=0.45），但整体模型表现有限，尤其是对上下文敏感技术。

Conclusion: LLMs在识别社会影响技术方面仍有局限，需领域特定微调。本文为相关研究提供了新资源和评估范例。

Abstract: In this work we present the Social Influence Technique Taxonomy (SITT), a
comprehensive framework of 58 empirically grounded techniques organized into
nine categories, designed to detect subtle forms of social influence in textual
content. We also investigate the LLMs ability to identify various forms of
social influence. Building on interdisciplinary foundations, we construct the
SITT dataset -- a 746-dialogue corpus annotated by 11 experts in Polish and
translated into English -- to evaluate the ability of LLMs to identify these
techniques. Using a hierarchical multi-label classification setup, we benchmark
five LLMs, including GPT-4o, Claude 3.5, Llama-3.1, Mixtral, and PLLuM. Our
results show that while some models, notably Claude 3.5, achieved moderate
success (F1 score = 0.45 for categories), overall performance of models remains
limited, particularly for context-sensitive techniques. The findings
demonstrate key limitations in current LLMs' sensitivity to nuanced linguistic
cues and underscore the importance of domain-specific fine-tuning. This work
contributes a novel resource and evaluation example for understanding how LLMs
detect, classify, and potentially replicate strategies of social influence in
natural dialogues.

</details>


### [6] [Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling](https://arxiv.org/abs/2506.00064)
*Jiayi Zeng,Yizhe Feng,Mengliang He,Wenhui Lei,Wei Zhang,Zeming Liu,Xiaoming Shi,Aimin Zhou*

Main category: cs.CL

TL;DR: 论文提出了一种主动错误处理方法，无需显式错误处理指令，并引入了一个名为Mis-prompt的新基准，用于评估LLMs在主动错误处理中的表现。


<details>
  <summary>Details</summary>
Motivation: 现实场景中通常缺乏显式错误处理指令，当前LLMs的被动错误处理方法存在局限性，需要研究主动错误处理。

Method: 提出了Mis-prompt基准，包含四个评估任务、错误分类法和新数据集，并分析了LLMs在基准上的表现。

Result: 实验表明当前LLMs在主动错误处理上表现不佳，但通过错误处理实例的SFT可以提升其能力。

Conclusion: 论文为主动错误处理研究提供了新基准和数据集，并展示了SFT对提升LLMs能力的潜力。

Abstract: Large language models (LLMs) have demonstrated significant advancements in
error handling. Current error-handling works are performed in a passive manner,
with explicit error-handling instructions. However, in real-world scenarios,
explicit error-handling instructions are usually unavailable. In this paper,
our work identifies this challenge as how to conduct proactive error handling
without explicit error handling instructions. To promote further research, this
work introduces a new benchmark, termed Mis-prompt, consisting of four
evaluation tasks, an error category taxonomy, and a new evaluation dataset.
Furthermore, this work analyzes current LLMs' performance on the benchmark, and
the experimental results reveal that current LLMs show poor performance on
proactive error handling, and SFT on error handling instances improves LLMs'
proactive error handling capabilities. The dataset will be publicly available.

</details>


### [7] [You Prefer This One, I Prefer Yours: Using Reference Words is Harder Than Vocabulary Words for Humans and Multimodal Language Models](https://arxiv.org/abs/2506.00065)
*Dota Tianai Dong,Yifan Luo,Po-Ya Angela Wang,Asli Ozyurek,Paula Rubio-Fernandez*

Main category: cs.CL

TL;DR: 论文研究了多模态语言模型（MLMs）在代词使用上的表现，发现其在需要社会认知和空间推理的代词任务上表现较差，尤其是所有格代词和指示代词。


<details>
  <summary>Details</summary>
Motivation: 尽管MLMs在人类交流中越来越像人类，但其使用代词的能力尚未被充分研究，尤其是需要社会认知和空间推理的代词。

Method: 通过比较人类和七种先进MLMs在词汇任务、所有格代词和指示代词上的表现，分析了MLMs的局限性。

Result: MLMs在词汇任务上接近人类水平，但在所有格和指示代词上表现较差，尤其是后者。提示工程仅部分改善了所有格代词的表现。

Conclusion: 当前NLP系统在处理需要语用学和社会认知的语法形式时仍面临挑战。

Abstract: Multimodal language models (MLMs) increasingly communicate in human-like
ways, yet their ability to use reference words remains largely overlooked
despite their ubiquity in everyday communication. Our study addresses this gap
by comparing human and MLM use of three word classes with increasing cognitive
demands: vocabulary words, possessive pronouns (`mine' vs `yours'), and
demonstrative pronouns (`this one' vs `that one'). Evaluating seven
state-of-the-art MLMs against human participants, we observe a clear difficulty
hierarchy: while MLMs approach human-level performance on the vocabulary task,
they show substantial deficits with possessives and demonstratives. Our
analysis reveals these difficulties stem from limitations in perspective-taking
and spatial reasoning. Although prompt engineering improved model performance
on possessive use, demonstrative use remained well below human-level
competence. These findings provide theoretical and empirical evidence that
producing grammatical forms requiring pragmatics and social cognition remains a
clear challenge in current NLP systems.

</details>


### [8] [Probing Politico-Economic Bias in Multilingual Large Language Models: A Cultural Analysis of Low-Resource Pakistani Languages](https://arxiv.org/abs/2506.00068)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文系统分析了13种最先进的大型语言模型（LLMs）在巴基斯坦五种低资源语言中的政治偏见，揭示了其受西方训练数据影响偏向自由左翼，但在区域语言中表现出威权倾向。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在非西方和低资源多语言环境中的政治经济偏见，填补现有研究的空白。

Method: 结合定量的政治取向评估（经济和社会轴）与定性的框架分析（内容、风格和重点），并针对巴基斯坦社会的11个关键社会政治主题设计提示。

Result: LLMs主要偏向自由左翼价值观，但在区域语言中表现出威权倾向，且存在模型特定的偏见特征和语言条件化的意识形态表达差异。

Conclusion: 研究强调了建立基于文化的多语言偏见审计框架的紧迫性。

Abstract: Large Language Models (LLMs) are increasingly shaping public discourse, yet
their politico-economic biases remain underexamined in non-Western and
low-resource multilingual contexts. This paper presents a systematic analysis
of political bias in 13 state-of-the-art LLMs across five low-resource
languages spoken in Pakistan: Urdu, Punjabi, Sindhi, Balochi, and Pashto. We
propose a novel framework that integrates an adapted Political Compass Test
(PCT) with a multi-level framing analysis. Our method combines quantitative
assessment of political orientation across economic (left-right) and social
(libertarian-authoritarian) axes with qualitative analysis of framing through
content, style, and emphasis. We further contextualize this analysis by
aligning prompts with 11 key socio-political themes relevant to Pakistani
society. Our results reveal that LLMs predominantly align with liberal-left
values, echoing Western training data influences, but exhibit notable shifts
toward authoritarian framing in regional languages, suggesting strong cultural
modulation effects. We also identify consistent model-specific bias signatures
and language-conditioned variations in ideological expression. These findings
show the urgent need for culturally grounded, multilingual bias auditing
frameworks.

</details>


### [9] [Evaluating the Sensitivity of LLMs to Prior Context](https://arxiv.org/abs/2506.00069)
*Robert Hankache,Kingsley Nketia Acheampong,Liang Song,Marek Brynda,Raad Khraishi,Greig A. Cowan*

Main category: cs.CL

TL;DR: 论文研究了多轮对话中大型语言模型（LLM）的性能变化，发现多轮交互会导致性能显著下降，并提出任务描述的合理放置可以缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单轮问答任务，无法捕捉多轮交互对LLM性能的影响，因此需要新的评估方法。

Method: 引入一组新的基准测试，系统性地改变上下文的数量和性质，并评估多种LLM（如GPT、Claude和Gemini）的性能变化。

Result: 多轮交互中，LLM在选择题上的性能可能大幅下降（某些模型下降73%），但任务描述的合理放置可将准确性提高3.5倍。

Conclusion: 需要设计更鲁棒的策略来评估和缓解LLM对上下文的敏感性。

Abstract: As large language models (LLMs) are increasingly deployed in multi-turn
dialogue and other sustained interactive scenarios, it is essential to
understand how extended context affects their performance. Popular benchmarks,
focusing primarily on single-turn question answering (QA) tasks, fail to
capture the effects of multi-turn exchanges. To address this gap, we introduce
a novel set of benchmarks that systematically vary the volume and nature of
prior context. We evaluate multiple conventional LLMs, including GPT, Claude,
and Gemini, across these benchmarks to measure their sensitivity to contextual
variations. Our findings reveal that LLM performance on multiple-choice
questions can degrade dramatically in multi-turn interactions, with performance
drops as large as 73% for certain models. Even highly capable models such as
GPT-4o exhibit up to a 32% decrease in accuracy. Notably, the relative
performance of larger versus smaller models is not always predictable.
Moreover, the strategic placement of the task description within the context
can substantially mitigate performance drops, improving the accuracy by as much
as a factor of 3.5. These findings underscore the need for robust strategies to
design, evaluate, and mitigate context-related sensitivity in LLMs.

</details>


### [10] [Gaussian mixture models as a proxy for interacting language models](https://arxiv.org/abs/2506.00077)
*Edward Wang,Tianyu Wang,Avanti Athreya,Vince Lyzinski,Carey E. Priebe*

Main category: cs.CL

TL;DR: 论文提出用交互高斯混合模型（GMMs）替代复杂的大语言模型（LLMs）来研究社会科学中的人类行为，发现GMMs能捕捉LLMs的动态特征。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然强大但计算成本高，而GMMs可能提供更高效的替代方案。

Method: 比较简化的GMMs模型与LLMs在交互反馈下的实验模拟。

Result: 交互GMMs能捕捉LLMs动态的重要特征，并分析了二者的异同。

Conclusion: GMMs具有优势，未来可进一步优化和研究。

Abstract: Large language models (LLMs) are a powerful tool with the ability to match
human capabilities and behavior in many settings. Retrieval-augmented
generation (RAG) further allows LLMs to generate diverse output depending on
the contents of their RAG database. This motivates their use in the social
sciences to study human behavior between individuals when large-scale
experiments are infeasible. However, LLMs depend on complex, computationally
expensive algorithms. In this paper, we introduce interacting Gaussian mixture
models (GMMs) as an alternative to similar frameworks using LLMs. We compare a
simplified model of GMMs to select experimental simulations of LLMs whose
updating and response depend on feedback from other LLMs. We find that
interacting GMMs capture important features of the dynamics in interacting
LLMs, and we investigate key similarities and differences between interacting
LLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture
models, potential modifications, and future research directions.

</details>


### [11] [COSMIC: Generalized Refusal Direction Identification in LLM Activations](https://arxiv.org/abs/2506.00085)
*Vincent Siu,Nicholas Crispino,Zihao Yu,Sam Pan,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.CL

TL;DR: COSMIC是一种自动框架，通过余弦相似度选择方向，无需依赖模型输出或预设模板，即可识别拒绝行为并引导模型向更安全行为转变。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预设模板或人工分析，难以全面识别LLMs中的拒绝行为。

Method: 使用余弦相似度指标（COSMIC）自动选择方向和目标层，独立于模型输出。

Result: 在对抗性环境和弱对齐模型中可靠识别拒绝方向，引导模型行为更安全，且误拒绝率低。

Conclusion: COSMIC在多种对齐条件下表现稳健，无需预设假设即可实现高效行为引导。

Abstract: Large Language Models (LLMs) encode behaviors such as refusal within their
activation space, yet identifying these behaviors remains a significant
challenge. Existing methods often rely on predefined refusal templates
detectable in output tokens or require manual analysis. We introduce
\textbf{COSMIC} (Cosine Similarity Metrics for Inversion of Concepts), an
automated framework for direction selection that identifies viable steering
directions and target layers using cosine similarity - entirely independent of
model outputs. COSMIC achieves steering performance comparable to prior methods
without requiring assumptions about a model's refusal behavior, such as the
presence of specific refusal tokens. It reliably identifies refusal directions
in adversarial settings and weakly aligned models, and is capable of steering
such models toward safer behavior with minimal increase in false refusals,
demonstrating robustness across a wide range of alignment conditions.

</details>


### [12] [SwitchLingua: The First Large-Scale Multilingual and Multi-Ethnic Code-Switching Dataset](https://arxiv.org/abs/2506.00087)
*Peng Xie,Xingyuan Liu,Tsz Wai Chan,Yequan Bie,Yangqiu Song,Yang Wang,Hao Chen,Kani Chen*

Main category: cs.CL

TL;DR: 论文介绍了LinguaMaster框架和SwitchLingua数据集，填补了多语言代码转换数据集的空白，并提出了新的评估指标SAER。


<details>
  <summary>Details</summary>
Motivation: 现有代码转换数据集规模小且单一，无法满足多语言应用需求，亟需大规模多样化数据集。

Method: 提出LinguaMaster框架，用于高效合成多语言数据，并构建SwitchLingua数据集，包含42万文本样本和80小时音频。

Result: SwitchLingua数据集覆盖12种语言和63种民族背景，SAER指标能更准确评估代码转换场景下的ASR性能。

Conclusion: LinguaMaster和SwitchLingua为多语言研究提供了基础资源，SAER提升了评估准确性。

Abstract: Code-switching (CS) is the alternating use of two or more languages within a
conversation or utterance, often influenced by social context and speaker
identity. This linguistic phenomenon poses challenges for Automatic Speech
Recognition (ASR) systems, which are typically designed for a single language
and struggle to handle multilingual inputs. The growing global demand for
multilingual applications, including Code-Switching ASR (CSASR), Text-to-Speech
(CSTTS), and Cross-Lingual Information Retrieval (CLIR), highlights the
inadequacy of existing monolingual datasets.
  Although some code-switching datasets exist, most are limited to bilingual
mixing within homogeneous ethnic groups, leaving a critical need for a
large-scale, diverse benchmark akin to ImageNet in computer vision.
  To bridge this gap, we introduce \textbf{LinguaMaster}, a multi-agent
collaboration framework specifically designed for efficient and scalable
multilingual data synthesis. Leveraging this framework, we curate
\textbf{SwitchLingua}, the first large-scale multilingual and multi-ethnic
code-switching dataset, including: (1) 420K CS textual samples across 12
languages, and (2) over 80 hours of audio recordings from 174 speakers
representing 18 countries/regions and 63 racial/ethnic backgrounds, based on
the textual data. This dataset captures rich linguistic and cultural diversity,
offering a foundational resource for advancing multilingual and multicultural
research. Furthermore, to address the issue that existing ASR evaluation
metrics lack sensitivity to code-switching scenarios, we propose the
\textbf{Semantic-Aware Error Rate (SAER)}, a novel evaluation metric that
incorporates semantic information, providing a more accurate and context-aware
assessment of system performance.

</details>


### [13] [HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs](https://arxiv.org/abs/2506.00088)
*Qing Li,Jiahui Geng,Zongxiong Chen,Derui Zhu,Yuxia Wang,Congbo Ma,Chenyang Lyu,Fakhri Karray*

Main category: cs.CL

TL;DR: 论文提出了一种名为HD-NDEs的新方法，通过神经微分方程在LLMs的潜在空间中系统性评估陈述的真实性，显著提升了幻觉检测的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成内容时存在幻觉问题，现有分类方法（如SAPLMA）在输出序列早期或中期出现非事实信息时效果不佳。

Method: 采用神经微分方程（Neural DEs）建模LLMs潜在空间的动态系统，并将潜在空间序列映射到分类空间进行真实性评估。

Result: 在五个数据集和六种常用LLMs上的实验表明，HD-NDEs显著优于现有技术，尤其在True-False数据集上AUC-ROC提升了14%以上。

Conclusion: HD-NDEs通过动态建模潜在空间，有效解决了LLMs的幻觉问题，为实际部署提供了更可靠的解决方案。

Abstract: In recent years, large language models (LLMs) have made remarkable
advancements, yet hallucination, where models produce inaccurate or non-factual
statements, remains a significant challenge for real-world deployment. Although
current classification-based methods, such as SAPLMA, are highly efficient in
mitigating hallucinations, they struggle when non-factual information arises in
the early or mid-sequence of outputs, reducing their reliability. To address
these issues, we propose Hallucination Detection-Neural Differential Equations
(HD-NDEs), a novel method that systematically assesses the truthfulness of
statements by capturing the full dynamics of LLMs within their latent space.
Our approaches apply neural differential equations (Neural DEs) to model the
dynamic system in the latent space of LLMs. Then, the sequence in the latent
space is mapped to the classification space for truth assessment. The extensive
experiments across five datasets and six widely used LLMs demonstrate the
effectiveness of HD-NDEs, especially, achieving over 14% improvement in AUC-ROC
on the True-False dataset compared to state-of-the-art techniques.

</details>


### [14] [Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards](https://arxiv.org/abs/2506.00103)
*Xun Lu*

Main category: cs.CL

TL;DR: 论文提出了一种基于可验证奖励的强化学习（RLVR）方法，通过生成式奖励模型（GenRM）和自举相对策略优化（BRPO）算法，解决了非可验证任务（如创意写作）中的奖励建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在非可验证任务中依赖人类偏好的标量奖励模型，存在泛化能力有限和奖励欺骗问题，需要一种更可靠的奖励建模方法。

Method: 提出写作原则驱动的成对生成式奖励模型（GenRM）和自举相对策略优化（BRPO）算法，将主观评估转化为可验证奖励。

Result: 方法在写作任务中表现出持续改进和抗奖励欺骗能力，并在多个基准测试中取得竞争性结果。

Conclusion: 研究展示了RLVR框架在统一规则、参考和无参考奖励建模方面的潜力，为语言任务的全面强化学习训练范式铺平了道路。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has enabled large
language models (LLMs) to achieve remarkable breakthroughs in reasoning tasks
with objective ground-truth answers, such as mathematics and code generation.
However, a significant gap remains for non-verifiable tasks, like creative
writing and open-ended dialogue, where quality assessment is inherently
subjective and lacks definitive references. Existing approaches for these
domains often rely on scalar reward models trained with human preferences,
which suffer from limited generalization and are prone to reward hacking, such
as over-explanation and length bias. In this work, we propose a unified
RLVR-based training paradigm that bridges the gap between non-verifiable tasks
and verifiable rewards. We introduce a writing-principle-based pairwise
Generative Reward Model (GenRM) and a novel Bootstrapped Relative Policy
Optimization (BRPO) algorithm. The pairwise writing GenRM leverages
self-principled critique to transform subjective assessments into reliable,
verifiable rewards, while BRPO enables dynamic, reference-free pairwise
comparison by leveraging a bootstrapped response as temporary reference from
within group rollouts during RL training. Our approach empowers LLMs to develop
robust writing capabilities without supervised fine-tuning, as demonstrated by
Writing-Zero, which shows consistent improvement and strong resistance to
reward hacking compared to scalar reward baselines. Furthermore, our method
achieves competitive results on both in-house and open-source writing
benchmarks. Our findings suggest the potential to unify rule-based,
reference-based, and reference-free reward modeling under the RLVR framework,
thus paving the way for a comprehensive and scalable RL training paradigm
applicable across all language tasks.

</details>


### [15] [Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models](https://arxiv.org/abs/2506.00134)
*Fardin Ahsan Sakib,Ziwei Zhu,Karen Trister Grace,Meliha Yetisgen,Ozlem Uzuner*

Main category: cs.CL

TL;DR: 论文研究了从临床文本中提取社会健康决定因素（SDOH）时，大型语言模型（LLM）可能因依赖表面线索而产生错误预测的问题，并提出缓解策略。


<details>
  <summary>Details</summary>
Motivation: SDOH提取对医疗分析至关重要，但LLM可能因依赖表面线索（如提及酒精或吸烟）而错误预测药物使用状态，同时发现模型性能中存在性别差异。

Method: 使用SHAC数据集中的MIMIC部分，以药物状态提取为例，分析LLM的错误预测，并评估提示工程和链式推理等缓解策略。

Result: 研究发现提及酒精或吸烟会误导模型预测当前/过去药物使用，且模型性能存在性别差异。缓解策略能减少假阳性。

Conclusion: 通过提示工程和链式推理等策略，可以提升LLM在健康领域的可靠性。

Abstract: Social determinants of health (SDOH) extraction from clinical text is
critical for downstream healthcare analytics. Although large language models
(LLMs) have shown promise, they may rely on superficial cues leading to
spurious predictions. Using the MIMIC portion of the SHAC (Social History
Annotation Corpus) dataset and focusing on drug status extraction as a case
study, we demonstrate that mentions of alcohol or smoking can falsely induce
models to predict current/past drug use where none is present, while also
uncovering concerning gender disparities in model performance. We further
evaluate mitigation strategies - such as prompt engineering and
chain-of-thought reasoning - to reduce these false positives, providing
insights into enhancing LLM reliability in health domains.

</details>


### [16] [LaMP-QA: A Benchmark for Personalized Long-form Question Answering](https://arxiv.org/abs/2506.00137)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: 论文介绍了LaMP-QA基准，用于评估个性化长答案生成，填补了资源不足的空白，并通过实验证明个性化上下文可提升性能达39%。


<details>
  <summary>Details</summary>
Motivation: 个性化在问答系统中至关重要，但相关研究和资源匮乏，因此需要建立基准以推动研究。

Method: 提出LaMP-QA基准，涵盖三大类问题，通过人工和自动评估比较策略，并测试多种非个性化和个性化方法。

Result: 实验显示，引入个性化上下文可使性能提升达39%。

Conclusion: LaMP-QA基准为个性化问答研究提供了重要资源，并证明了其有效性。

Abstract: Personalization is essential for question answering systems that are
user-centric. Despite its importance, personalization in answer generation has
been relatively underexplored. This is mainly due to lack of resources for
training and evaluating personalized question answering systems. We address
this gap by introducing LaMP-QA -- a benchmark designed for evaluating
personalized long-form answer generation. The benchmark covers questions from
three major categories: (1) Arts & Entertainment, (2) Lifestyle & Personal
Development, and (3) Society & Culture, encompassing over 45 subcategories in
total. To assess the quality and potential impact of the LaMP-QA benchmark for
personalized question answering, we conduct comprehensive human and automatic
evaluations, to compare multiple evaluation strategies for evaluating generated
personalized responses and measure their alignment with human preferences.
Furthermore, we benchmark a number of non-personalized and personalized
approaches based on open-source and proprietary large language models (LLMs).
Our results show that incorporating the personalized context provided leads to
performance improvements of up to 39%. The benchmark is publicly released to
support future research in this area.

</details>


### [17] [Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry](https://arxiv.org/abs/2506.00145)
*Sujeet Kumar,Pretam Ray,Abhinay Beerukuri,Shrey Kamoji,Manoj Balaji Jagadeeshan,Pawan Goyal*

Main category: cs.CL

TL;DR: 本文介绍了Vedavani，首个专注于梵语吠陀诗歌的自动语音识别（ASR）研究，提出了一个54小时的梵语ASR数据集，并测试了多种多语言语音模型。


<details>
  <summary>Details</summary>
Motivation: 梵语的音位复杂性和语音转换特性使其在ASR研究中具有挑战性，尤其是在诗歌形式中。本文旨在填补这一研究空白。

Method: 构建了一个包含30,779个标记音频样本的梵语ASR数据集，并测试了多种多语言语音模型。

Result: 实验表明，IndicWhisper在测试的模型中表现最佳。

Conclusion: Vedavani为梵语ASR研究提供了首个全面数据集，并验证了IndicWhisper的有效性。

Abstract: Sanskrit, an ancient language with a rich linguistic heritage, presents
unique challenges for automatic speech recognition (ASR) due to its phonemic
complexity and the phonetic transformations that occur at word junctures,
similar to the connected speech found in natural conversations. Due to these
complexities, there has been limited exploration of ASR in Sanskrit,
particularly in the context of its poetic verses, which are characterized by
intricate prosodic and rhythmic patterns. This gap in research raises the
question: How can we develop an effective ASR system for Sanskrit, particularly
one that captures the nuanced features of its poetic form? In this study, we
introduce Vedavani, the first comprehensive ASR study focused on Sanskrit Vedic
poetry. We present a 54-hour Sanskrit ASR dataset, consisting of 30,779
labelled audio samples from the Rig Veda and Atharva Veda. This dataset
captures the precise prosodic and rhythmic features that define the language.
We also benchmark the dataset on various state-of-the-art multilingual speech
models.$^{1}$ Experimentation revealed that IndicWhisper performed the best
among the SOTA models.

</details>


### [18] [Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement](https://arxiv.org/abs/2506.00160)
*Qihui Fan,Enfu Nan,Wenbo Li,Lei Lu,Pu Zhao,Yanzhi Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的狼人杀游戏系统，通过优化的TTS模型提升兼容性和用户体验，认为随着LLM推理能力的增强，额外组件将变得不必要。


<details>
  <summary>Details</summary>
Motivation: 随着LLM推理和说服能力的提升，结合社交推理游戏的流行，研究如何利用LLM（如DeepSeek R1和V3）提升狼人杀游戏的用户体验。

Method: 提出了一种基于LLM的狼人杀系统，结合优化的TTS模型，无需额外组件（如微调或经验池）。

Result: 系统能够提供更兼容和更具吸引力的游戏体验。

Conclusion: 随着LLM推理能力的持续增强，未来在狼人杀等游戏中，额外组件可能不再需要。

Abstract: The growing popularity of social deduction game systems for both business
applications and AI research has greatly benefited from the rapid advancements
in Large Language Models (LLMs), which now demonstrate stronger reasoning and
persuasion capabilities. Especially with the raise of DeepSeek R1 and V3
models, LLMs should enable a more engaging experience for human players in
LLM-agent-based social deduction games like Werewolf. Previous works either
fine-tuning, advanced prompting engineering, or additional experience pool to
achieve engaging text-format Werewolf game experience. We propose a novel yet
straightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)
models designed for enhanced compatibility with various LLM models, and
improved user engagement. We argue with ever enhancing LLM reasoning, extra
components will be unnecessary in the case of Werewolf.

</details>


### [19] [Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences](https://arxiv.org/abs/2506.00195)
*Mingqian Zheng,Wenjia Hu,Patrick Zhao,Motahhare Eslami,Jena D. Hwang,Faeze Brahman,Carolyn Rose,Maarten Sap*

Main category: cs.CL

TL;DR: 研究表明，部分遵从（提供一般信息但不含可操作细节）是最优的拒绝策略，能显著减少用户负面感知，而现有LLMs和奖励模型未能充分利用此策略。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs对所有潜在有害查询一概拒绝，导致安全性与用户体验的权衡问题。

Method: 通过480名参与者评估3,840个查询-响应对，研究不同拒绝策略对用户感知的影响，并分析9个先进LLMs的响应模式和6个奖励模型的评分。

Result: 部分遵从策略能将负面用户感知降低50%以上，但现有模型和奖励模型未能自然采用或充分评估此策略。

Conclusion: 有效的安全机制应注重设计深思熟虑的拒绝策略，而非仅依赖意图检测，以实现安全性与用户持续参与的双赢。

Abstract: Current LLMs are trained to refuse potentially harmful input queries
regardless of whether users actually had harmful intents, causing a tradeoff
between safety and user experience. Through a study of 480 participants
evaluating 3,840 query-response pairs, we examine how different refusal
strategies affect user perceptions across varying motivations. Our findings
reveal that response strategy largely shapes user experience, while actual user
motivation has negligible impact. Partial compliance -- providing general
information without actionable details -- emerges as the optimal strategy,
reducing negative user perceptions by over 50% to flat-out refusals.
Complementing this, we analyze response patterns of 9 state-of-the-art LLMs and
evaluate how 6 reward models score different refusal strategies, demonstrating
that models rarely deploy partial compliance naturally and reward models
currently undervalue it. This work demonstrates that effective guardrails
require focusing on crafting thoughtful refusals rather than detecting intent,
offering a path toward AI safety mechanisms that ensure both safety and
sustained user engagement.

</details>


### [20] [Structuring Radiology Reports: Challenging LLMs with Lightweight Models](https://arxiv.org/abs/2506.00200)
*Johannes Moll,Louisa Fay,Asfandyar Azhar,Sophie Ostmeier,Tim Lueth,Sergios Gatidis,Curtis Langlotz,Jean-Benoit Delbrouck*

Main category: cs.CL

TL;DR: 论文探讨了轻量级编码器-解码器模型（如T5和BERT2BERT）在结构化放射学报告中的表现，相比大型语言模型（LLMs），轻量级模型在性能和资源消耗上更具优势。


<details>
  <summary>Details</summary>
Motivation: 放射学报告缺乏标准化格式，限制了人类解读和机器学习应用。尽管大型语言模型（LLMs）在临床文本重构中表现优异，但其高计算需求、不透明性和数据隐私问题阻碍了实际部署。

Method: 研究比较了轻量级模型（<300M参数）与八种开源LLMs（1B-70B）在MIMIC-CXR和CheXpert Plus数据集上的表现，采用了前缀提示、上下文学习和LoRA微调等技术。

Result: 轻量级模型在人类标注测试集上表现优于基于提示技术的LLMs。虽然部分LoRA微调的LLMs在Findings部分略有提升，但计算资源消耗显著增加。

Conclusion: 轻量级模型是资源受限医疗环境中结构化临床文本的可持续且隐私保护的解决方案。

Abstract: Radiology reports are critical for clinical decision-making but often lack a
standardized format, limiting both human interpretability and machine learning
(ML) applications. While large language models (LLMs) have shown strong
capabilities in reformatting clinical text, their high computational
requirements, lack of transparency, and data privacy concerns hinder practical
deployment. To address these challenges, we explore lightweight encoder-decoder
models (<300M parameters)-specifically T5 and BERT2BERT-for structuring
radiology reports from the MIMIC-CXR and CheXpert Plus datasets. We benchmark
these models against eight open-source LLMs (1B-70B), adapted using prefix
prompting, in-context learning (ICL), and low-rank adaptation (LoRA)
finetuning. Our best-performing lightweight model outperforms all LLMs adapted
using prompt-based techniques on a human-annotated test set. While some
LoRA-finetuned LLMs achieve modest gains over the lightweight model on the
Findings section (BLEU 6.4%, ROUGE-L 4.8%, BERTScore 3.6%, F1-RadGraph 1.1%,
GREEN 3.6%, and F1-SRR-BERT 4.3%), these improvements come at the cost of
substantially greater computational resources. For example, LLaMA-3-70B
incurred more than 400 times the inference time, cost, and carbon emissions
compared to the lightweight model. These results underscore the potential of
lightweight, task-specific models as sustainable and privacy-preserving
solutions for structuring clinical text in resource-constrained healthcare
settings.

</details>


### [21] [Structure-Aware Fill-in-the-Middle Pretraining for Code](https://arxiv.org/abs/2506.00204)
*Linyuan Gong,Alvin Cheung,Mostafa Elhoushi,Sida Wang*

Main category: cs.CL

TL;DR: AST-FIM是一种利用抽象语法树（AST）进行代码LLM预训练的方法，比传统随机字符掩码方法更有效。


<details>
  <summary>Details</summary>
Motivation: 现有LLM将代码视为纯文本并随机掩码字符，忽略了代码的语法结构，导致训练示例不连贯。

Method: 提出AST-FIM，通过AST掩码完整语法结构，生成更符合代码编辑模式的训练示例。

Result: 在1B和8B参数模型上，AST-FIM在标准FIM基准测试中比随机字符FIM高出5分。

Conclusion: AST-FIM能更好地适应实际代码编辑任务，提升模型性能。

Abstract: Fill-in-the-Middle (FIM) is a common pretraining method for code LLMs, where
models complete code segments given surrounding context. However, existing LLMs
treat code as plain text and mask random character spans. We propose and
evaluate AST-FIM, a pretraining strategy that leverages Abstract Syntax Trees
(ASTs) to mask complete syntactic structures at scale, ensuring coherent
training examples better aligned with universal code structures and common code
editing patterns such as blocks, expressions, or functions. To evaluate
real-world fill-in-the-middle (FIM) programming tasks, we introduce
Real-FIM-Eval, a benchmark derived from 30,000+ GitHub commits across 12
languages. On infilling tasks, experiments on 1B and 8B parameter models show
that AST-FIM is particularly beneficial for real-world code editing as it
outperforms standard random-character FIM by up to 5 pts on standard FIM
benchmarks. Our code is publicly available at
https://github.com/gonglinyuan/ast_fim.

</details>


### [22] [REIC: RAG-Enhanced Intent Classification at Scale](https://arxiv.org/abs/2506.00210)
*Ziji Zhang,Michael Yang,Zhiyu Chen,Yingying Zhuang,Shu-Ting Pi,Qun Liu,Rajashekar Maragoud,Vy Nguyen,Anurag Beniwal*

Main category: cs.CL

TL;DR: REIC是一种基于检索增强生成的意图分类方法，解决了传统方法在大规模客户服务中的扩展性问题，无需频繁重新训练即可实现精确分类。


<details>
  <summary>Details</summary>
Motivation: 随着公司产品线的扩展，意图分类面临意图数量增加和分类体系跨垂直领域变化的可扩展性挑战。

Method: REIC利用检索增强生成（RAG）动态整合相关知识，实现精确分类。

Result: 在真实数据集上的实验表明，REIC在大型客户服务场景中优于传统的微调、零样本和少样本方法。

Conclusion: REIC在领域内和跨领域场景中均表现出色，适合实际部署于自适应和大规模意图分类系统。

Abstract: Accurate intent classification is critical for efficient routing in customer
service, ensuring customers are connected with the most suitable agents while
reducing handling times and operational costs. However, as companies expand
their product lines, intent classification faces scalability challenges due to
the increasing number of intents and variations in taxonomy across different
verticals. In this paper, we introduce REIC, a Retrieval-augmented generation
Enhanced Intent Classification approach, which addresses these challenges
effectively. REIC leverages retrieval-augmented generation (RAG) to dynamically
incorporate relevant knowledge, enabling precise classification without the
need for frequent retraining. Through extensive experiments on real-world
datasets, we demonstrate that REIC outperforms traditional fine-tuning,
zero-shot, and few-shot methods in large-scale customer service settings. Our
results highlight its effectiveness in both in-domain and out-of-domain
scenarios, demonstrating its potential for real-world deployment in adaptive
and large-scale intent classification systems.

</details>


### [23] [ComposeRAG: A Modular and Composable RAG for Corpus-Grounded Multi-Hop Question Answering](https://arxiv.org/abs/2506.00232)
*Ruofan Wu,Youngwon Lee,Fan Shu,Danmei Xu,Seung-won Hwang,Zhewei Yao,Yuxiong He,Feng Yan*

Main category: cs.CL

TL;DR: ComposeRAG提出了一种模块化的RAG系统设计，通过分解核心功能为独立模块，提升了多跳问答的准确性、可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统设计过于单一，核心功能耦合度高，限制了可解释性、系统评估和针对性改进，尤其是在复杂多跳问答任务中。

Method: ComposeRAG将RAG流程分解为原子化、可组合的模块（如问题分解、查询重写、检索决策和答案验证），并引入自反机制以增强鲁棒性。

Result: 在四个多跳问答基准测试中，ComposeRAG在准确性和答案可靠性上均优于基线方法，最高提升15%的准确率，并显著减少未接地答案。

Conclusion: ComposeRAG展示了模块化设计在多跳推理中的优势，提供了灵活、透明、可扩展且高性能的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems are increasingly diverse, yet
many suffer from monolithic designs that tightly couple core functions like
query reformulation, retrieval, reasoning, and verification. This limits their
interpretability, systematic evaluation, and targeted improvement, especially
for complex multi-hop question answering. We introduce ComposeRAG, a novel
modular abstraction that decomposes RAG pipelines into atomic, composable
modules. Each module, such as Question Decomposition, Query Rewriting,
Retrieval Decision, and Answer Verification, acts as a parameterized
transformation on structured inputs/outputs, allowing independent
implementation, upgrade, and analysis. To enhance robustness against errors in
multi-step reasoning, ComposeRAG incorporates a self-reflection mechanism that
iteratively revisits and refines earlier steps upon verification failure.
Evaluated on four challenging multi-hop QA benchmarks, ComposeRAG consistently
outperforms strong baselines in both accuracy and grounding fidelity.
Specifically, it achieves up to a 15% accuracy improvement over
fine-tuning-based methods and up to a 5% gain over reasoning-specialized
pipelines under identical retrieval conditions. Crucially, ComposeRAG
significantly enhances grounding: its verification-first design reduces
ungrounded answers by over 10% in low-quality retrieval settings, and by
approximately 3% even with strong corpora. Comprehensive ablation studies
validate the modular architecture, demonstrating distinct and additive
contributions from each component. These findings underscore ComposeRAG's
capacity to deliver flexible, transparent, scalable, and high-performing
multi-hop reasoning with improved grounding and interpretability.

</details>


### [24] [MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility](https://arxiv.org/abs/2506.00235)
*Yexiao He,Ang Li,Boyi Liu,Zhewei Yao,Yuxiong He*

Main category: cs.CL

TL;DR: MedOrch是一个新型的医疗决策支持框架，通过整合多个专业工具和推理代理，提供全面的医疗决策支持，并在多个医疗任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在医疗决策中要么依赖任务特定模型（适应性有限），要么依赖未与专业知识工具结合的语言模型，无法满足复杂需求。

Method: MedOrch采用模块化、基于代理的架构，灵活整合领域特定工具，同时确保透明和可追溯的推理过程。

Result: 在阿尔茨海默病诊断、胸部X光解读和医学视觉问答等任务中，MedOrch表现优异，准确率显著提升。

Conclusion: MedOrch通过推理驱动的工具利用，支持多模态医疗数据处理和复杂临床决策任务，具有推动医疗AI发展的潜力。

Abstract: Healthcare decision-making represents one of the most challenging domains for
Artificial Intelligence (AI), requiring the integration of diverse knowledge
sources, complex reasoning, and various external analytical tools. Current AI
systems often rely on either task-specific models, which offer limited
adaptability, or general language models without grounding with specialized
external knowledge and tools. We introduce MedOrch, a novel framework that
orchestrates multiple specialized tools and reasoning agents to provide
comprehensive medical decision support. MedOrch employs a modular, agent-based
architecture that facilitates the flexible integration of domain-specific tools
without altering the core system. Furthermore, it ensures transparent and
traceable reasoning processes, enabling clinicians to meticulously verify each
intermediate step underlying the system's recommendations. We evaluate MedOrch
across three distinct medical applications: Alzheimer's disease diagnosis,
chest X-ray interpretation, and medical visual question answering, using
authentic clinical datasets. The results demonstrate MedOrch's competitive
performance across these diverse medical tasks. Notably, in Alzheimer's disease
diagnosis, MedOrch achieves an accuracy of 93.26%, surpassing the
state-of-the-art baseline by over four percentage points. For predicting
Alzheimer's disease progression, it attains a 50.35% accuracy, marking a
significant improvement. In chest X-ray analysis, MedOrch exhibits superior
performance with a Macro AUC of 61.2% and a Macro F1-score of 25.5%. Moreover,
in complex multimodal visual question answering (Image+Table), MedOrch achieves
an accuracy of 54.47%. These findings underscore MedOrch's potential to advance
healthcare AI by enabling reasoning-driven tool utilization for multimodal
medical data processing and supporting intricate cognitive tasks in clinical
decision-making.

</details>


### [25] [PersianMedQA: Language-Centric Evaluation of LLMs in the Persian Medical Domain](https://arxiv.org/abs/2506.00250)
*Mohammad Javad Ranjbar Kalahroodi,Amirhossein Sheikholselami,Sepehr Karimi,Sepideh Ranjbar Kalahroodi,Heshaam Faili,Azadeh Shakery*

Main category: cs.CL

TL;DR: 论文介绍了PersianMedQA数据集，用于评估大语言模型（LLM）在波斯语和英语医学问答中的表现，结果显示闭源通用模型（如GPT-4.1）表现最佳，而波斯语微调模型表现较差。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在高风险领域（如医学）和低资源语言（如波斯语）中的可靠性。

Method: 构建PersianMedQA数据集，并在零样本和思维链（CoT）设置下对40多种最先进的模型进行基准测试。

Result: 闭源通用模型表现最佳（波斯语83.3%，英语80.7%），波斯语微调模型表现较差（如Dorna在波斯语中仅35.9%）。翻译对性能有影响，模型大小不足以保证性能。

Conclusion: PersianMedQA为评估LLM的多语言和文化背景医学推理提供了基础，强调领域和语言适应的重要性。

Abstract: Large Language Models (LLMs) have achieved remarkable performance on a wide
range of NLP benchmarks, often surpassing human-level accuracy. However, their
reliability in high-stakes domains such as medicine, particularly in
low-resource languages, remains underexplored. In this work, we introduce
PersianMedQA, a large-scale, expert-validated dataset of multiple-choice
Persian medical questions, designed to evaluate LLMs across both Persian and
English. We benchmark over 40 state-of-the-art models, including
general-purpose, Persian fine-tuned, and medical LLMs, in zero-shot and
chain-of-thought (CoT) settings. Our results show that closed-source general
models (e.g., GPT-4.1) consistently outperform all other categories, achieving
83.3% accuracy in Persian and 80.7% in English, while Persian fine-tuned models
such as Dorna underperform significantly (e.g., 35.9% in Persian), often
struggling with both instruction-following and domain reasoning. We also
analyze the impact of translation, showing that while English performance is
generally higher, Persian responses are sometimes more accurate due to cultural
and clinical contextual cues. Finally, we demonstrate that model size alone is
insufficient for robust performance without strong domain or language
adaptation. PersianMedQA provides a foundation for evaluating multilingual and
culturally grounded medical reasoning in LLMs. The PersianMedQA dataset can be
accessed at:
https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA](https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA

</details>


### [26] [Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race](https://arxiv.org/abs/2506.00253)
*Lihao Sun,Chengzhi Mao,Valentin Hofmann,Xuechunzi Bai*

Main category: cs.CL

TL;DR: 研究发现，尽管对齐的语言模型在显式偏见评估中表现无偏，但在隐式任务中仍存在刻板印象，原因是早期内部表征忽略种族概念，导致安全机制失效。提出新策略，通过激励早期层表征种族概念来缓解隐式偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨对齐语言模型在显式和隐式偏见评估中的不一致现象，揭示其机制并提出改进方法。

Method: 分析对齐与未对齐模型在内部表征中的差异，提出通过激励早期层表征种族概念的新策略。

Result: 对齐模型在早期层忽略种族概念，导致隐式偏见放大；新策略能有效缓解这种偏见。

Conclusion: 忽略种族概念会无意中放大隐式偏见，激励早期表征种族概念是一种有效的缓解方法。

Abstract: Although value-aligned language models (LMs) appear unbiased in explicit bias
evaluations, they often exhibit stereotypes in implicit word association tasks,
raising concerns about their fair usage. We investigate the mechanisms behind
this discrepancy and find that alignment surprisingly amplifies implicit bias
in model outputs. Specifically, we show that aligned LMs, unlike their
unaligned counterparts, overlook racial concepts in early internal
representations when the context is ambiguous. Not representing race likely
fails to activate safety guardrails, leading to unintended biases. Inspired by
this insight, we propose a new bias mitigation strategy that works by
incentivizing the representation of racial concepts in the early model layers.
In contrast to conventional mitigation methods of machine unlearning, our
interventions find that steering the model to be more aware of racial concepts
effectively mitigates implicit bias. Similar to race blindness in humans,
ignoring racial nuances can inadvertently perpetuate subtle biases in LMs.

</details>


### [27] [The Impact of Disability Disclosure on Fairness and Bias in LLM-Driven Candidate Selection](https://arxiv.org/abs/2506.00256)
*Mahammed Kamruzzaman,Gene Louis Kim*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在招聘过程中倾向于选择未披露残疾的候选人，即使候选人未披露残疾状态，其被选中的概率仍低于明确表示无残疾的候选人。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在招聘过程中对自愿披露残疾信息的候选人的选择偏好，填补现有研究空白。

Method: 通过对比具有相同性别、种族、资历和背景的候选人，分析LLMs在残疾信息披露与否情况下的选择差异。

Result: LLMs更倾向于选择未披露残疾的候选人，即使未披露残疾状态的候选人也比明确表示无残疾的候选人更少被选中。

Conclusion: 研究揭示了LLMs在招聘中可能存在的残疾偏见，需进一步优化模型以减少不公平现象。

Abstract: As large language models (LLMs) become increasingly integrated into hiring
processes, concerns about fairness have gained prominence. When applying for
jobs, companies often request/require demographic information, including
gender, race, and disability or veteran status. This data is collected to
support diversity and inclusion initiatives, but when provided to LLMs,
especially disability-related information, it raises concerns about potential
biases in candidate selection outcomes. Many studies have highlighted how
disability can impact CV screening, yet little research has explored the
specific effect of voluntarily disclosed information on LLM-driven candidate
selection. This study seeks to bridge that gap. When candidates shared
identical gender, race, qualifications, experience, and backgrounds, and sought
jobs with minimal employment rate gaps between individuals with and without
disabilities (e.g., Cashier, Software Developer), LLMs consistently favored
candidates who disclosed that they had no disability. Even in cases where
candidates chose not to disclose their disability status, the LLMs were less
likely to select them compared to those who explicitly stated they did not have
a disability.

</details>


### [28] [MultiHoax: A Dataset of Multi-hop False-Premise Questions](https://arxiv.org/abs/2506.00264)
*Mohammadamin Shafiei,Hamidreza Saffari,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 论文提出了MultiHoax基准，用于评估大语言模型在复杂多步推理任务中处理错误前提的能力，发现现有模型在多国家、多知识类别和多跳推理中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在高风险领域部署时，检测错误假设和进行批判性推理的能力对确保可靠输出至关重要。现有基准仅关注单跳错误前提问题，而现实推理需要多跳推理。

Method: 引入MultiHoax基准，涵盖七个国家和十个知识类别，利用维基百科作为知识源，评估模型在多步推理中检测错误前提的能力。

Result: 实验表明，现有先进大语言模型在不同国家、知识类别和多跳推理类型中难以检测错误前提。

Conclusion: 研究强调了大语言模型在错误前提检测和多跳推理能力上的不足，需进一步改进。

Abstract: As Large Language Models are increasingly deployed in high-stakes domains,
their ability to detect false assumptions and reason critically is crucial for
ensuring reliable outputs. False-premise questions (FPQs) serve as an important
evaluation method by exposing cases where flawed assumptions lead to incorrect
responses. While existing benchmarks focus on single-hop FPQs, real-world
reasoning often requires multi-hop inference, where models must verify
consistency across multiple reasoning steps rather than relying on
surface-level cues. To address this gap, we introduce MultiHoax, a benchmark
for evaluating LLMs' ability to handle false premises in complex, multi-step
reasoning tasks. Our dataset spans seven countries and ten diverse knowledge
categories, using Wikipedia as the primary knowledge source to enable factual
reasoning across regions. Experiments reveal that state-of-the-art LLMs
struggle to detect false premises across different countries, knowledge
categories, and multi-hop reasoning types, highlighting the need for improved
false premise detection and more robust multi-hop reasoning capabilities in
LLMs.

</details>


### [29] [CASPER: A Large Scale Spontaneous Speech Dataset](https://arxiv.org/abs/2506.00267)
*Cihan Xiao,Ruixing Liang,Xiangyu Zhang,Mehmet Emre Tiryaki,Veronica Bae,Lavanya Shankar,Rong Yang,Ethan Poon,Emmanuel Dupoux,Sanjeev Khudanpur,Leibny Paola Garcia Perera*

Main category: cs.CL

TL;DR: 提出了一种新方法收集自然对话数据，发布了一个200+小时的自发语音数据集，解决了现有数据集中脚本对话为主的问题。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型的成功激发了开发类似语音处理能力的兴趣，但高质量自发语音数据的稀缺是主要挑战。

Method: 设计了一种新颖的管道，用于引发和记录自然对话，并发布了第一阶段数据集。

Result: 成功收集了200+小时的自发语音数据，为研究社区提供了可扩展的资源。

Conclusion: 该数据集和方法为未来自发语音数据收集奠定了基础，并计划进一步扩展数据集。

Abstract: The success of large language models has driven interest in developing
similar speech processing capabilities. However, a key challenge is the
scarcity of high-quality spontaneous speech data, as most existing datasets
contain scripted dialogues. To address this, we present a novel pipeline for
eliciting and recording natural dialogues and release our Stage 1 dataset with
200+ hours of spontaneous speech. Our approach fosters fluid, natural
conversations while encouraging a diverse range of topics and interactive
exchanges. Unlike traditional methods, it facilitates genuine interactions,
providing a reproducible framework for future data collection. This paper
introduces our dataset and methodology, laying the groundwork for addressing
the shortage of spontaneous speech data. We plan to expand this dataset in
future stages, offering a growing resource for the research community.

</details>


### [30] [Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings](https://arxiv.org/abs/2506.00277)
*Hans W. A. Hanley,Zakir Durumeric*

Main category: cs.CL

TL;DR: 提出了一种新颖、可扩展、可解释且多语言的层次化聚类方法，用于新闻和社交媒体数据，通过多语言Matryoshka嵌入实现不同粒度的相似性度量。


<details>
  <summary>Details</summary>
Motivation: 当前方法在扩展性、相似性度量透明度和多语言处理上存在不足，需要改进。

Method: 训练多语言Matryoshka嵌入模型，开发高效层次聚类算法。

Result: 嵌入模型在SemEval 2022 Task 8测试集上达到最优性能（Pearson ρ = 0.816）。

Conclusion: 该方法能有效识别和聚类新闻数据中的故事、叙事和主题。

Abstract: Contextual large language model embeddings are increasingly utilized for
topic modeling and clustering. However, current methods often scale poorly,
rely on opaque similarity metrics, and struggle in multilingual settings. In
this work, we present a novel, scalable, interpretable, hierarchical, and
multilingual approach to clustering news articles and social media data. To do
this, we first train multilingual Matryoshka embeddings that can determine
story similarity at varying levels of granularity based on which subset of the
dimensions of the embeddings is examined. This embedding model achieves
state-of-the-art performance on the SemEval 2022 Task 8 test dataset (Pearson
$\rho$ = 0.816). Once trained, we develop an efficient hierarchical clustering
algorithm that leverages the hierarchical nature of Matryoshka embeddings to
identify unique news stories, narratives, and themes. We conclude by
illustrating how our approach can identify and cluster stories, narratives, and
overarching themes within real-world news datasets.

</details>


### [31] [Emergent Abilities of Large Language Models under Continued Pretraining for Language Adaptation](https://arxiv.org/abs/2506.00288)
*Ahmed Elhady,Eneko Agirre,Mikel Artetxe*

Main category: cs.CL

TL;DR: 研究发现，在持续预训练（CPT）中加入英语数据对验证困惑度无影响，但对目标语言的下游能力至关重要。未加入英语会导致灾难性遗忘，影响模型泛化能力。提出课程学习和权重指数移动平均（EMA）作为替代方案。


<details>
  <summary>Details</summary>
Motivation: 探索在持续预训练中加入英语数据的作用及其对目标语言能力的影响。

Method: 引入语言无关的上下文学习（ICL）基准，分析英语数据的作用，并提出课程学习和EMA作为替代方案。

Result: 未加入英语会导致灾难性遗忘和模型参数大幅变化，影响下游能力。课程学习和EMA能有效缓解问题。

Conclusion: 研究揭示了CPT中涌现能力的动态机制，为未来设计更有效的方法提供了基础。

Abstract: Continued pretraining (CPT) is a popular approach to adapt existing large
language models (LLMs) to new languages. When doing so, it is common practice
to include a portion of English data in the mixture, but its role has not been
carefully studied to date. In this work, we show that including English does
not impact validation perplexity, yet it is critical for the emergence of
downstream capabilities in the target language. We introduce a
language-agnostic benchmark for in-context learning (ICL), which reveals
catastrophic forgetting early on CPT when English is not included. This in turn
damages the ability of the model to generalize to downstream prompts in the
target language as measured by perplexity, even if it does not manifest in
terms of accuracy until later in training, and can be tied to a big shift in
the model parameters. Based on these insights, we introduce curriculum learning
and exponential moving average (EMA) of weights as effective alternatives to
mitigate the need for English. All in all, our work sheds light into the
dynamics by which emergent abilities arise when doing CPT for language
adaptation, and can serve as a foundation to design more effective methods in
the future.

</details>


### [32] [DLM-One: Diffusion Language Models for One-Step Sequence Generation](https://arxiv.org/abs/2506.00290)
*Tianqi Chen,Shujian Zhang,Mingyuan Zhou*

Main category: cs.CL

TL;DR: DLM-One是一种基于分数蒸馏的框架，用于一步生成序列，通过连续扩散语言模型（DLMs）实现。它避免了迭代优化，显著提升了采样效率，实验显示推理时间可加速约500倍，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过一步生成序列提高扩散语言模型的采样效率，同时保持生成质量。

Method: 通过将学生模型在连续词嵌入空间中的输出分数与预训练教师DLM的分数函数对齐，实现一步生成。

Result: 在DiffuSeq上实验表明，DLM-One推理时间加速约500倍，且在基准文本生成任务中性能接近教师模型。

Conclusion: 一步扩散为高效高质量语言生成提供了新方向，并推动了连续扩散模型在自然语言处理中的广泛应用。

Abstract: This paper introduces DLM-One, a score-distillation-based framework for
one-step sequence generation with continuous diffusion language models (DLMs).
DLM-One eliminates the need for iterative refinement by aligning the scores of
a student model's outputs in the continuous token embedding space with the
score function of a pretrained teacher DLM. We investigate whether DLM-One can
achieve substantial gains in sampling efficiency for language modeling. Through
comprehensive experiments on DiffuSeq -- a representative continuous DLM -- we
show that DLM-One achieves up to ~500x speedup in inference time while
maintaining competitive performance on benchmark text generation tasks used to
evaluate the teacher models. We further analyze the method's empirical behavior
across multiple datasets, providing initial insights into its generality and
practical applicability. Our findings position one-step diffusion as a
promising direction for efficient, high-quality language generation and broader
adoption of continuous diffusion models operating in embedding space for
natural language processing.

</details>


### [33] [Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs](https://arxiv.org/abs/2506.00304)
*Payal Mohapatra,Akash Pandey,Xiaoyuan Zhang,Qi Zhu*

Main category: cs.CL

TL;DR: 论文提出了一种新的EMG适配器模块，将无声EMG信号映射到大型语言模型（LLM）的输入空间，实现了在无声EMG到文本任务中0.49的平均词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 无声EMG是一种有效的沟通工具，但现有方法依赖有声和无声EMG信号配对数据，对无法发声的个体不实用。

Method: 提出EMG适配器模块，将EMG特征映射到LLM输入空间，利用LLM理解无声EMG信号。

Result: 在无声EMG到文本任务中，平均WER为0.49，数据量仅六分钟时性能提升近20%。

Conclusion: 该研究为LLM理解无声EMG信号迈出了重要一步，展示了其在无声语音识别中的潜力。

Abstract: Unvoiced electromyography (EMG) is an effective communication tool for
individuals unable to produce vocal speech. However, most prior methods rely on
paired voiced and unvoiced EMG signals, along with speech data, for EMG-to-text
conversion, which is not practical for such individuals. Given the rise of
large language models (LLMs) in speech recognition, we explore their potential
to understand unvoiced speech. To this end, we address the challenge of
learning from unvoiced EMG alone and propose a novel EMG adaptor module that
maps EMG features into an LLM's input space, achieving an average word error
rate (WER) of 0.49 on a closed-vocabulary unvoiced EMG-to-text task. Even with
a conservative data availability of just six minutes, our approach improves
performance over specialized models by nearly 20%. While LLMs have been shown
to be extendable to new language modalities -- such as audio -- understanding
articulatory biosignals like unvoiced EMG remains more challenging. This work
takes a crucial first step toward enabling LLMs to comprehend unvoiced speech
using surface EMG.

</details>


### [34] [Lossless Token Sequence Compression via Meta-Tokens](https://arxiv.org/abs/2506.00307)
*John Harvill,Ziwei Fan,Hao Wang,Yizhou Sun,Hao Ding,Luke Huan,Anoop Deoras*

Main category: cs.CL

TL;DR: 本文提出了一种任务无关的无损压缩技术，用于减少大型语言模型的输入序列长度，平均减少27%和18%，同时不丢失语义信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为有损压缩，可能丢失语义信息，而本文旨在开发一种无损压缩技术，确保语义完整性。

Method: 采用类似LZ77的无损压缩技术，显著减少输入序列长度，同时易于反向恢复。

Result: 在两项评估任务中，输入序列长度平均减少27%和18%，计算量分别减少47%和33%。

Conclusion: 无损压缩技术性能接近未压缩输入，未来更大模型和计算资源可能完全消除性能差距。

Abstract: Existing work on prompt compression for Large Language Models (LLM) focuses
on lossy methods that try to maximize the retention of semantic information
that is relevant to downstream tasks while significantly reducing the sequence
length. In this paper, we introduce a task-agnostic lossless compression
technique similar to LZ77 that makes it possible to reduce the input token
sequence length on average by 27\% and 18\% for the two evaluation tasks
explored here. Given that we use transformer-based LLMs, this equates to 47\%
and 33\% less encoding computation, respectively, due to the quadratic nature
of attention. The token sequence transformation is trivial to reverse and
highlights that no semantic information is lost in the process. We evaluate our
proposed approach on two tasks that require strict preservation of
semantics/syntax and demonstrate that existing lossy compression methods
perform poorly in this setting. We find that our lossless compression technique
produces only a small gap in performance compared to using the uncompressed
input and posit that larger models and an expanded computing budget would
likely erase the gap entirely.

</details>


### [35] [An evaluation of LLMs for generating movie reviews: GPT-4o, Gemini-2.0 and DeepSeek-V3](https://arxiv.org/abs/2506.00312)
*Brendan Sands,Yining Wang,Chenhao Xu,Yuxuan Zhou,Lai Wei,Rohitash Chandra*

Main category: cs.CL

TL;DR: 该研究提出了一种利用GPT-4o、DeepSeek-V3和Gemini-2.0三种大语言模型（LLMs）生成电影评论的框架，并通过与IMDb用户评论的对比评估其性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在电影评论生成任务中的适用性，并比较不同模型的表现。

Method: 使用电影字幕和剧本作为输入，生成评论，并从词汇、情感极性、相似性和主题一致性等方面与IMDb用户评论进行比较。

Result: LLMs能生成语法流畅、结构完整的评论，但在情感丰富度和风格一致性上与IMDb评论仍有差距。DeepSeek-V3表现最平衡，GPT-4o偏向积极情感，Gemini-2.0更擅长捕捉负面情感但情感强度过高。

Conclusion: LLMs在电影评论生成任务中表现出潜力，但需进一步优化以提升情感和风格的质量。

Abstract: Large language models (LLMs) have been prominent in various tasks, including
text generation and summarisation. The applicability of LLMs to the generation
of product reviews is gaining momentum, paving the way for the generation of
movie reviews. In this study, we propose a framework that generates movie
reviews using three LLMs (GPT-4o, DeepSeek-V3, and Gemini-2.0), and evaluate
their performance by comparing the generated outputs with IMDb user reviews. We
use movie subtitles and screenplays as input to the LLMs and investigate how
they affect the quality of reviews generated. We review the LLM-based movie
reviews in terms of vocabulary, sentiment polarity, similarity, and thematic
consistency in comparison to IMDB user reviews. The results demonstrate that
LLMs are capable of generating syntactically fluent and structurally complete
movie reviews. Nevertheless, there is still a noticeable gap in emotional
richness and stylistic coherence between LLM-generated and IMDb reviews,
suggesting that further refinement is needed to improve the overall quality of
movie review generation. We provided a survey-based analysis where participants
were told to distinguish between LLM and IMDb user reviews. The results show
that LLM-generated reviews are difficult to distinguish from IMDB user reviews.
We found that DeepSeek-V3 produced the most balanced reviews, closely matching
IMDb reviews. GPT-4o overemphasised positive emotions, while Gemini-2.0
captured negative emotions better but showed excessive emotional intensity.

</details>


### [36] [SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation](https://arxiv.org/abs/2506.00319)
*Yufei Tian,Jiao Sun,Nanyun Peng,Zizhao Zhang*

Main category: cs.CL

TL;DR: SkillVerse是一种无监督的树状诊断框架，用于评估语言模型在特定能力上的熟练度，并通过树搜索算法和预测模型弱点提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型处理复杂任务的能力增强，需要更精细的评估方法来理解模型的具体能力，以指导模型开发。

Method: SkillVerse利用LLM作为评判者，对模型响应进行批评，并将其组织成层次化的树状结构（dendrogram），从而灵活分析模型能力。

Result: SkillVerse在两项下游任务中表现优异：1）通过树搜索算法提升少样本学习性能25%；2）预测模型弱点的成功率提高22%，达到55%。

Conclusion: SkillVerse提供了一种灵活且有效的方法，能够深入分析语言模型的能力，并为模型优化提供实用指导。

Abstract: As language models evolve to tackle complex, multifaceted tasks, their
evaluation must adapt to capture this intricacy. A granular, skill-specific
understanding of model capabilities can empower researchers to make informed
model development plans. In this paper, we introduce SkillVerse, an
unsupervised tree-structured diagnosis framework for understanding model
proficiency in specific abilities. With LLM as a judge, SkillVerse first
critiques the model responses, and then organizes them into a hierarchical
structure termed dendrogram. Given proficiency at arbitrary levels of
granularity, SkillVerse is flexible to produce insights of behaviors of modern
large models. We also demonstrate its efficacy in two downstream tasks: 1)
improving model in-context learning by 25% using a tree-search algorithm to
select more informative few-shot demonstrations, and 2) accurately predicting
new model weaknesses with a 55% success rate, 22% higher than without
SkillVerse.

</details>


### [37] [TreeRare: Syntax Tree-Guided Retrieval and Reasoning for Knowledge-Intensive Question Answering](https://arxiv.org/abs/2506.00331)
*Boyi Zhang,Zhuo Liu,Hangfeng He*

Main category: cs.CL

TL;DR: TreeRare是一种基于语法树的信息检索和推理框架，用于解决复杂知识密集型问题，通过分步检索和合成证据显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有检索框架中推理错误和检索结果不匹配的问题，提升复杂问题的解答能力。

Method: 利用语法树自底向上遍历，生成子组件查询并检索相关段落，合成证据后聚合形成最终答案。

Result: 在五个问答数据集上，TreeRare显著优于现有最先进方法。

Conclusion: TreeRare通过语法树引导的检索和推理，有效解决了复杂问题解答中的局限性。

Abstract: In real practice, questions are typically complex and knowledge-intensive,
requiring Large Language Models (LLMs) to recognize the multifaceted nature of
the question and reason across multiple information sources. Iterative and
adaptive retrieval, where LLMs decide when and what to retrieve based on their
reasoning, has been shown to be a promising approach to resolve complex,
knowledge-intensive questions. However, the performance of such retrieval
frameworks is limited by the accumulation of reasoning errors and misaligned
retrieval results. To overcome these limitations, we propose TreeRare (Syntax
Tree-Guided Retrieval and Reasoning), a framework that utilizes syntax trees to
guide information retrieval and reasoning for question answering. Following the
principle of compositionality, TreeRare traverses the syntax tree in a
bottom-up fashion, and in each node, it generates subcomponent-based queries
and retrieves relevant passages to resolve localized uncertainty. A
subcomponent question answering module then synthesizes these passages into
concise, context-aware evidence. Finally, TreeRare aggregates the evidence
across the tree to form a final answer. Experiments across five question
answering datasets involving ambiguous or multi-hop reasoning demonstrate that
TreeRare achieves substantial improvements over existing state-of-the-art
methods.

</details>


### [38] [Disentangling Codemixing in Chats: The NUS ABC Codemixed Corpus](https://arxiv.org/abs/2506.00332)
*Svetlana Churina,Akshat Gupta,Insyirah Mujtahid,Kokil Jaidka*

Main category: cs.CL

TL;DR: 该研究提出了首个标注的通用语码混合语料库，旨在支持计算语言学、社会语言学和自然语言处理研究。


<details>
  <summary>Details</summary>
Motivation: 尽管语码混合在社交媒体等非正式交流中普遍存在，但缺乏公开可用的标注语料库来模拟人类对话和关系。

Method: 通过持续收集、验证和整合语码混合消息，构建结构化数据集，并以JSON格式发布，附带详细元数据和语言统计信息。

Result: 目前已包含超过355,641条涵盖多种语码混合模式的消息，主要关注英语、普通话和其他语言。

Conclusion: Codemix Corpus预计将成为计算语言学、社会语言学和NLP应用研究的基础数据集。

Abstract: Code-mixing involves the seamless integration of linguistic elements from
multiple languages within a single discourse, reflecting natural multilingual
communication patterns. Despite its prominence in informal interactions such as
social media, chat messages and instant-messaging exchanges, there has been a
lack of publicly available corpora that are author-labeled and suitable for
modeling human conversations and relationships. This study introduces the first
labeled and general-purpose corpus for understanding code-mixing in context
while maintaining rigorous privacy and ethical standards. Our live project will
continuously gather, verify, and integrate code-mixed messages into a
structured dataset released in JSON format, accompanied by detailed metadata
and linguistic statistics. To date, it includes over 355,641 messages spanning
various code-mixing patterns, with a primary focus on English, Mandarin, and
other languages. We expect the Codemix Corpus to serve as a foundational
dataset for research in computational linguistics, sociolinguistics, and NLP
applications.

</details>


### [39] [Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models](https://arxiv.org/abs/2506.00334)
*Gerard Christopher Yeo,Kokil Jaidka*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLMs）如何利用上下文信息推理他人情绪状态，基于心理理论（ToM）框架，并揭示了LLMs在情绪推理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有情绪识别数据集通常依赖显性线索，而忽略了隐性上下文线索对情绪推理的重要性。研究旨在探索LLMs如何利用这些隐性线索进行情绪推理。

Method: 基于认知评估理论，构建了一个专门的ToM评估数据集，评估LLMs在正向（从上下文到情绪）和反向（从情绪到上下文）推理中的表现。

Result: LLMs具备一定程度的推理能力，但在将情境结果和评估与特定情绪关联方面表现较差。

Conclusion: 研究强调了在LLMs的情绪推理训练和评估中融入心理学理论的必要性。

Abstract: Datasets used for emotion recognition tasks typically contain overt cues that
can be used in predicting the emotions expressed in a text. However, one
challenge is that texts sometimes contain covert contextual cues that are rich
in affective semantics, which warrant higher-order reasoning abilities to infer
emotional states, not simply the emotions conveyed. This study advances beyond
surface-level perceptual features to investigate how large language models
(LLMs) reason about others' emotional states using contextual information,
within a Theory-of-Mind (ToM) framework. Grounded in Cognitive Appraisal
Theory, we curate a specialized ToM evaluation dataset1 to assess both forward
reasoning - from context to emotion- and backward reasoning - from emotion to
inferred context. We showed that LLMs can reason to a certain extent, although
they are poor at associating situational outcomes and appraisals with specific
emotions. Our work highlights the need for psychological theories in the
training and evaluation of LLMs in the context of emotion reasoning.

</details>


### [40] [OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning](https://arxiv.org/abs/2506.00338)
*Yifan Peng,Shakeel Muhammad,Yui Sudo,William Chen,Jinchuan Tian,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: cs.CL

TL;DR: OWSM项目通过整合YODAS数据集和开发数据清洗流程，显著提升了语音模型的性能，并在多语言任务中超越或匹配工业前沿模型。


<details>
  <summary>Details</summary>
Motivation: OWSM项目的训练数据不足，需要扩展数据规模以提升模型性能。

Method: 整合YODAS数据集，开发可扩展的数据清洗流程，处理语言标签错误和音频-文本不对齐问题。

Result: 清洗后数据集包含166,000小时语音，覆盖75种语言；OWSM v4模型在多语言任务中表现优于前代，甚至媲美工业前沿模型。

Conclusion: 通过数据扩展和清洗，OWSM v4模型性能显著提升，相关数据和工具将公开。

Abstract: The Open Whisper-style Speech Models (OWSM) project has developed a series of
fully open speech foundation models using academic-scale resources, but their
training data remains insufficient. This work enhances OWSM by integrating
YODAS, a large-scale web-crawled dataset with a Creative Commons license.
However, incorporating YODAS is nontrivial due to its wild nature, which
introduces challenges such as incorrect language labels and audio-text
misalignments. To address this, we develop a scalable data-cleaning pipeline
using public toolkits, yielding a dataset with 166,000 hours of speech across
75 languages. Our new series of OWSM v4 models, trained on this curated dataset
alongside existing OWSM data, significantly outperform previous versions on
multilingual benchmarks. Our models even match or surpass frontier industrial
models like Whisper and MMS in multiple scenarios. We will publicly release the
cleaned YODAS data, pre-trained models, and all associated scripts via the
ESPnet toolkit.

</details>


### [41] [Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs](https://arxiv.org/abs/2506.00344)
*Sungjae Lee,Hoyoung Kim,Jeongyeon Hwang,Eunhyeok Park,Jungseul Ok*

Main category: cs.CL

TL;DR: 提出了一种轻量级且上下文敏感的潜在语义聚类（LSC）方法，利用生成LLM的内部隐藏状态进行聚类，显著提高了测试时计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有语义聚类方法依赖外部模型，计算开销大且难以捕捉上下文语义。

Method: 提出LSC方法，利用生成LLM的内部隐藏状态进行聚类，避免使用外部模型。

Result: 实验表明，LSC在多种LLM和数据集上显著提高计算效率，性能优于现有方法。

Conclusion: LSC是一种高效且性能优越的语义聚类方法，适用于测试时计算扩展。

Abstract: Scaling test-time computation--generating and analyzing multiple or
sequential outputs for a single input--has become a promising strategy for
improving the reliability and quality of large language models (LLMs), as
evidenced by advances in uncertainty quantification and multi-step reasoning. A
key shared component is semantic clustering, which groups outputs that differ
in form but convey the same meaning. Semantic clustering enables estimation of
the distribution over the semantics of outputs and helps avoid redundant
exploration of reasoning paths. However, existing approaches typically rely on
external models, which introduce substantial computational overhead and often
fail to capture context-aware semantics. We propose Latent Semantic Clustering
(LSC), a lightweight and context-sensitive method that leverages the generator
LLM's internal hidden states for clustering, eliminating the need for external
models. Our extensive experiment across various LLMs and datasets shows that
LSC significantly improves the computational efficiency of test-time scaling
while maintaining or exceeding the performance of existing methods.

</details>


### [42] [Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG](https://arxiv.org/abs/2506.00381)
*Siavash Shams,Richard Antonello,Gavin Mischler,Stephan Bickel,Ashesh Mehta,Nima Mesgarani*

Main category: cs.CL

TL;DR: Neuro2Semantic是一种新框架，通过iEEG记录重建感知语音的语义内容，采用LSTM适配器和校正模块实现无约束文本生成，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决神经信号解码连续语言的挑战，推动脑机接口和神经解码技术的实际应用。

Method: 分两阶段：LSTM适配器对齐神经信号与文本嵌入，校正模块生成连续自然文本。

Result: 仅需30分钟神经数据即表现优异，在低数据场景下超越现有方法。

Conclusion: Neuro2Semantic展示了在脑机接口和神经解码技术中的实用潜力。

Abstract: Decoding continuous language from neural signals remains a significant
challenge in the intersection of neuroscience and artificial intelligence. We
introduce Neuro2Semantic, a novel framework that reconstructs the semantic
content of perceived speech from intracranial EEG (iEEG) recordings. Our
approach consists of two phases: first, an LSTM-based adapter aligns neural
signals with pre-trained text embeddings; second, a corrector module generates
continuous, natural text directly from these aligned embeddings. This flexible
method overcomes the limitations of previous decoding approaches and enables
unconstrained text generation. Neuro2Semantic achieves strong performance with
as little as 30 minutes of neural data, outperforming a recent state-of-the-art
method in low-data settings. These results highlight the potential for
practical applications in brain-computer interfaces and neural decoding
technologies.

</details>


### [43] [Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees' Dialogue to Facilitate Nurse Communication Training](https://arxiv.org/abs/2506.00386)
*Keyeun Lee,Seolhee Lee,Esther Hehsun Kim,Yena Ko,Jinsu Eun,Dahee Kim,Hyewon Cho,Haiyi Zhu,Robert E. Kraut,Eunyoung Suh,Eun-mee Kim,Hajin Lim*

Main category: cs.CL

TL;DR: Adaptive-VP是一个基于大型语言模型的虚拟患者对话生成框架，能够动态调整虚拟患者行为以提升护士沟通培训效果。


<details>
  <summary>Details</summary>
Motivation: 标准化患者模拟成本高且缺乏灵活性，现有虚拟患者系统无法根据学员沟通技能动态调整行为。

Method: 利用大型语言模型动态生成虚拟患者对话，构建临床场景并实时评估学员沟通技能。

Result: 自动评估显示框架能反映真实沟通水平，专家确认其交互更自然、真实。

Conclusion: Adaptive-VP是一种可扩展且有效的护士沟通培训工具。

Abstract: Effective communication training is essential to preparing nurses for
high-quality patient care. While standardized patient (SP) simulations provide
valuable experiential learning, they are often costly and inflexible. Virtual
patient (VP) systems offer a scalable alternative, but most fail to adapt to
the varying communication skills of trainees. In particular, when trainees
respond ineffectively, VPs should escalate in hostility or become
uncooperative--yet this level of adaptive interaction remains largely
unsupported. To address this gap, we introduce Adaptive-VP, a VP dialogue
generation framework that leverages large language models (LLMs) to dynamically
adapt VP behavior based on trainee input. The framework features a pipeline for
constructing clinically grounded yet flexible VP scenarios and a modular system
for assessing trainee communication and adjusting VP responses in real time,
while ensuring learner safety. We validated Adaptive-VP by simulating
challenging patient conversations. Automated evaluation using a corpus from
practicing nurses showed that our communication skill evaluation mechanism
reflected real-world proficiency levels. Expert nurses further confirmed that
Adaptive-VP produced more natural and realistic interactions than existing
approaches, demonstrating its potential as a scalable and effective tool for
nursing communication training.

</details>


### [44] [SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL](https://arxiv.org/abs/2506.00391)
*Ge Qu,Jinyang Li,Bowen Qin,Xiaolong Li,Nan Huo,Chenhao Ma,Reynold Cheng*

Main category: cs.CL

TL;DR: SHARE是一种基于SLM的分层动作校正助手，通过将SQL查询转换为逐步动作轨迹并分两阶段细化，解决了传统自校正方法的计算开销大和错误检测能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统自校正方法依赖LLM的递归调用，计算开销大，且LLM难以有效检测和修正SQL查询的错误。

Method: SHARE采用三个小型语言模型（SLM）的流水线，将SQL查询转换为动作轨迹，并进行两阶段细化，同时提出分层自进化策略进行高效训练。

Result: 实验表明，SHARE显著提升了自校正能力，并在低资源训练环境下保持强鲁棒性。

Conclusion: SHARE为文本到SQL应用提供了一种高效且数据隐私友好的自校正解决方案。

Abstract: Current self-correction approaches in text-to-SQL face two critical
limitations: 1) Conventional self-correction methods rely on recursive
self-calls of LLMs, resulting in multiplicative computational overhead, and 2)
LLMs struggle to implement effective error detection and correction for
declarative SQL queries, as they fail to demonstrate the underlying reasoning
path. In this work, we propose SHARE, an SLM-based Hierarchical Action
corREction assistant that enables LLMs to perform more precise error
localization and efficient correction. SHARE orchestrates three specialized
Small Language Models (SLMs) in a sequential pipeline, where it first
transforms declarative SQL queries into stepwise action trajectories that
reveal underlying reasoning, followed by a two-phase granular refinement. We
further propose a novel hierarchical self-evolution strategy for data-efficient
training. Experimental results demonstrate that SHARE effectively enhances
self-correction capabilities while proving robust across various LLMs.
Furthermore, our comprehensive analysis shows that SHARE maintains strong
performance even in low-resource training settings, which is particularly
valuable for text-to-SQL applications with data privacy constraints.

</details>


### [45] [Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively](https://arxiv.org/abs/2506.00396)
*Jiawei Gu,Shangsong Liang*

Main category: cs.CL

TL;DR: 论文提出了一种名为SRM的框架，通过外部奖励分配器和推测验证机制，在保持效果的同时显著降低LLM决策的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LLM决策中往往忽视效率与性能的平衡，导致高计算成本换取微小性能提升。

Method: 引入3E标准评估搜索策略的成本效益，并提出SRM框架，结合外部奖励分配器和推测验证机制优化决策过程。

Result: 实验表明，SRM在数学推理、规划和专业领域数值推理等任务中，将成本降至原框架的1/10，同时保持效果。

Conclusion: SRM为LLM决策提供了一种高效且有效的解决方案，平衡了性能与计算成本。

Abstract: Effective decision-making in Large Language Models (LLMs) is essential for
handling intricate tasks. However, existing approaches prioritize performance
but often overlook the balance between effectiveness and computational cost. To
address this, we first introduce the 3E Criteria to systematically assess the
cost-effectiveness of search strategies, revealing that existing methods often
trade significant efficiency for marginal performance gains. To improve LLM
decision-making while maintaining efficiency, we propose the Speculative Reward
Model (SRM), a plug-and-play framework that seamlessly integrates with existing
search strategies. Specifically, SRM employs an external reward assigner to
predict optimal actions, reducing reliance on LLMs' internal self-evaluation.
And a speculative verification mechanism is used to prune suboptimal choices
and guide the search toward more promising steps. We evaluate SRM on several
complex decision-making tasks including mathematical reasoning, planning and
numerical reasoning in specialized domains. Experimental results show that SRM
reduces costs to 1/10 of the original search framework on average while
maintaining effectiveness.

</details>


### [46] [Scaling Textual Gradients via Sampling-Based Momentum](https://arxiv.org/abs/2506.00400)
*Zixin Ding,Junyuan Hong,Jiachen T. Wang,Zinan Lin,Zhangyang Wang,Yuxin Chen*

Main category: cs.CL

TL;DR: 论文研究了文本提示优化在大型语言模型中的重要性，提出了一种改进的文本随机梯度下降方法（TSGD-M），通过重新加权采样提高性能并减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 随着文本提示在大型语言模型中的作用日益重要，优化文本提示成为关键挑战。传统方法（如TGD）在数据规模增加时性能下降且计算成本高。

Method: 提出TSGD-M方法，借鉴数值梯度下降的动量思想，通过基于历史批次分布重新加权采样，实现可扩展的上下文学习。

Result: 在九个NLP任务中，TSGD-M显著优于未采用重新加权采样的TGD基线，同时减少了大多数任务的方差。

Conclusion: TSGD-M是一种高效且可扩展的文本提示优化方法，能够提升性能并降低计算成本。

Abstract: As prompts play an increasingly critical role in large language models
(LLMs), optimizing textual prompts has become a crucial challenge. The Textual
Gradient Descent (TGD) framework has emerged as a promising data-driven
approach that iteratively refines textual prompts using LLM - suggested updates
(or textual gradients) over minibatches of training samples. In this paper, we
empirically demonstrate that scaling the number of training examples initially
improves but later degrades TGD's performance across multiple downstream NLP
tasks. However, while data scaling improves results for most tasks, it also
significantly increases the computational cost when leveraging LLMs. To address
this, we draw inspiration from numerical gradient descent and propose Textual
Stochastic Gradient Descent with Momentum (TSGD-M) - a method that facilitates
scalable in-context learning by reweighting prompt sampling based on past batch
distributions. Across nine NLP tasks spanning three domains - including
BIG-Bench Hard (BBH), natural language understanding tasks, and reasoning tasks
- TSGD-M significantly outperforms TGD baselines that do not incorporate
reweighted sampling, while also reducing variance in most tasks.

</details>


### [47] [Causal Structure Discovery for Error Diagnostics of Children's ASR](https://arxiv.org/abs/2506.00402)
*Vishwanath Pratap Singh,Md. Sahidullah,Tomi Kinnunen*

Main category: cs.CL

TL;DR: 该论文提出了一种因果结构发现方法，用于分析儿童自动语音识别（ASR）表现不佳的多因素相互依赖关系，并通过因果量化测量各因素的影响。


<details>
  <summary>Details</summary>
Motivation: 儿童ASR表现通常不如成人，现有方法忽略了生理、认知和外部因素之间的相互依赖关系。

Method: 引入因果结构发现方法，量化各因素对ASR的影响，并分析微调模型对这些因素的缓解效果。

Result: 实验表明，该方法在不同ASR系统（如Whisper和Wav2Vec2.0）中具有普适性。

Conclusion: 研究揭示了儿童ASR表现的多因素相互依赖关系，为改进ASR系统提供了新视角。

Abstract: Children's automatic speech recognition (ASR) often underperforms compared to
that of adults due to a confluence of interdependent factors: physiological
(e.g., smaller vocal tracts), cognitive (e.g., underdeveloped pronunciation),
and extrinsic (e.g., vocabulary limitations, background noise). Existing
analysis methods examine the impact of these factors in isolation, neglecting
interdependencies-such as age affecting ASR accuracy both directly and
indirectly via pronunciation skills. In this paper, we introduce a causal
structure discovery to unravel these interdependent relationships among
physiology, cognition, extrinsic factors, and ASR errors. Then, we employ
causal quantification to measure each factor's impact on children's ASR. We
extend the analysis to fine-tuned models to identify which factors are
mitigated by fine-tuning and which remain largely unaffected. Experiments on
Whisper and Wav2Vec2.0 demonstrate the generalizability of our findings across
different ASR systems.

</details>


### [48] [Accelerating Diffusion LLMs via Adaptive Parallel Decoding](https://arxiv.org/abs/2506.00413)
*Daniel Israel,Guy Van den Broeck,Aditya Grover*

Main category: cs.CL

TL;DR: 论文提出了一种自适应并行解码（APD）方法，通过动态调整并行采样的令牌数量，解决了扩散大语言模型（dLLMs）在并行生成令牌时速度与质量的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前自回归解码（LLMs）的生成速度受限于逐令牌预测，而扩散大语言模型（dLLMs）理论上支持并行生成，但实践中难以在不牺牲质量的情况下达到自回归模型的速度。

Method: APD通过定义dLLM边际概率与小型辅助自回归模型序列联合概率的乘积混合，动态调整并行采样的令牌数量，并优化了KV缓存和掩码输入大小。

Result: APD在下游基准测试中显著提高了吞吐量，同时质量下降极小。

Conclusion: APD通过三个可调参数灵活权衡吞吐量与质量，为并行解码提供了一种高效解决方案。

Abstract: The generation speed of LLMs are bottlenecked by autoregressive decoding,
where tokens are predicted sequentially one by one. Alternatively, diffusion
large language models (dLLMs) theoretically allow for parallel token
generation, but in practice struggle to achieve the speed of autoregressive
models without significantly sacrificing quality. We therefore introduce
adaptive parallel decoding (APD), a novel method that dynamically adjusts the
number of tokens sampled in parallel. We achieve this by defining a
multiplicative mixture between the dLLM marginal probabilities and the joint
probability of sequences under a small auxiliary autoregressive model. This
inverts the standard setup of speculative decoding, where the goal is to sample
from a large autoregressive verifier by drafting from a smaller model. We
further optimize APD by enabling KV caching and limiting the size of the masked
input. Altogether, our method puts forward three tunable parameters to flexibly
tradeoff throughput and quality. We show that APD provides markedly higher
throughput with minimal quality degradations on downstream benchmarks.

</details>


### [49] [Dual Debiasing for Noisy In-Context Learning for Text Generation](https://arxiv.org/abs/2506.00418)
*Siqi Liang,Sumyeong Ahn,Paramveer S. Dhillon,Jiayu Zhou*

Main category: cs.CL

TL;DR: 论文提出了一种双去偏框架，通过合成邻居修正困惑度估计，生成鲁棒的样本清洁度评分，有效检测高噪声比下的噪声标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高噪声比下假设噪声样本困惑度更高会失效，论文重新审视困惑度在噪声标注文本生成中的偏差问题。

Method: 引入双去偏框架，利用合成邻居显式修正困惑度估计，生成样本清洁度评分。

Result: 实验表明该方法噪声检测能力强，最终ICL性能接近完全清洁演示语料库，且在高噪声比下仍鲁棒。

Conclusion: 双去偏框架能有效解决困惑度偏差问题，提升噪声标注下的文本生成质量。

Abstract: In context learning (ICL) relies heavily on high quality demonstrations drawn
from large annotated corpora. Existing approaches detect noisy annotations by
ranking local perplexities, presuming that noisy samples yield higher
perplexities than their clean counterparts. However, this assumption breaks
down when the noise ratio is high and many demonstrations are flawed. We
reexamine the perplexity based paradigm for text generation under noisy
annotations, highlighting two sources of bias in perplexity: the annotation
itself and the domain specific knowledge inherent in large language models
(LLMs). To overcome these biases, we introduce a dual debiasing framework that
uses synthesized neighbors to explicitly correct perplexity estimates, yielding
a robust Sample Cleanliness Score. This metric uncovers absolute sample
cleanliness regardless of the overall corpus noise level. Extensive experiments
demonstrate our method's superior noise detection capabilities and show that
its final ICL performance is comparable to that of a fully clean demonstration
corpus. Moreover, our approach remains robust even when noise ratios are
extremely high.

</details>


### [50] [Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions](https://arxiv.org/abs/2506.00421)
*Jihyoung Jang,Minwook Bae,Minji Kim,Dilek Hakkani-Tur,Hyounghun Kim*

Main category: cs.CL

TL;DR: 该研究旨在提升聊天机器人的多模态交互能力，特别是视觉和听觉的结合，以支持更沉浸式的对话。通过引入新的数据集$M^3C$和提出多模态记忆检索模型，实现了在复杂场景下的长期多会话交互。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦于视觉任务，忽视了听觉模态，且交互多为静态。本研究旨在填补这一空白，实现更自然的动态多模态对话。

Method: 提出多模态记忆检索模型，并基于新数据集$M^3C$进行训练，支持视觉和听觉输入的处理。

Result: 模型在复杂场景下能有效处理多模态输入，保持连贯动态的对话，人类评估表现优异。

Conclusion: 该模型展示了在多模态对话中的潜力，为未来高级多模态聊天机器人提供了方向。

Abstract: As chatbots continue to evolve toward human-like, real-world, interactions,
multimodality remains an active area of research and exploration. So far,
efforts to integrate multimodality into chatbots have primarily focused on
image-centric tasks, such as visual dialogue and image-based instructions,
placing emphasis on the "eyes" of human perception while neglecting the "ears",
namely auditory aspects. Moreover, these studies often center around static
interactions that focus on discussing the modality rather than naturally
incorporating it into the conversation, which limits the richness of
simultaneous, dynamic engagement. Furthermore, while multimodality has been
explored in multi-party and multi-session conversations, task-specific
constraints have hindered its seamless integration into dynamic, natural
conversations. To address these challenges, this study aims to equip chatbots
with "eyes and ears" capable of more immersive interactions with humans. As
part of this effort, we introduce a new multimodal conversation dataset,
Multimodal Multi-Session Multi-Party Conversation ($M^3C$), and propose a novel
multimodal conversation model featuring multimodal memory retrieval. Our model,
trained on the $M^3C$, demonstrates the ability to seamlessly engage in
long-term conversations with multiple speakers in complex, real-world-like
settings, effectively processing visual and auditory inputs to understand and
respond appropriately. Human evaluations highlight the model's strong
performance in maintaining coherent and dynamic interactions, demonstrating its
potential for advanced multimodal conversational agents.

</details>


### [51] [DYNAC: Dynamic Vocabulary based Non-Autoregressive Contextualization for Speech Recognition](https://arxiv.org/abs/2506.00422)
*Yui Sudo,Yosuke Fukumoto,Muhammad Shakeel,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: cs.CL

TL;DR: DYNAC是一种基于动态词汇的非自回归上下文化方法，通过自条件CTC减少实时因子，同时保持较低的词错误率。


<details>
  <summary>Details</summary>
Motivation: 动态词汇在自回归模型中虽能提高准确性，但推理速度慢；而在非自回归模型中，条件独立性假设无法捕捉静态与动态词汇间的依赖关系。

Method: 提出DYNAC，通过将动态词汇集成到中间层，利用自条件CTC方法捕捉依赖关系并降低实时因子。

Result: 在LibriSpeech 960测试集上，DYNAC将实时因子降低81%，词错误率仅增加0.1个百分点。

Conclusion: DYNAC在保持高准确性的同时显著提升了推理速度，为非自回归模型中的上下文偏置提供了有效解决方案。

Abstract: Contextual biasing (CB) improves automatic speech recognition for rare and
unseen phrases. Recent studies have introduced dynamic vocabulary, which
represents context phrases as expandable tokens in autoregressive (AR) models.
This method improves CB accuracy but with slow inference speed. While dynamic
vocabulary can be applied to non-autoregressive (NAR) models, such as
connectionist temporal classification (CTC), the conditional independence
assumption fails to capture dependencies between static and dynamic tokens.
This paper proposes DYNAC (Dynamic Vocabulary-based NAR Contextualization), a
self-conditioned CTC method that integrates dynamic vocabulary into
intermediate layers. Conditioning the encoder on dynamic vocabulary, DYNAC
effectively captures dependencies between static and dynamic tokens while
reducing the real-time factor (RTF). Experimental results show that DYNAC
reduces RTF by 81% with a 0.1-point degradation in word error rate on the
LibriSpeech 960 test-clean set.

</details>


### [52] [Inter-Passage Verification for Multi-evidence Multi-answer QA](https://arxiv.org/abs/2506.00425)
*Bingsen Chen,Shengjie Wang,Xi Ye,Chen Zhao*

Main category: cs.CL

TL;DR: 提出了一种新的多答案问答框架RI$^2$VER，通过独立阅读和跨段落验证解决多答案QA的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成QA系统难以处理多答案问题，需要高效检索和合成大量证据段落。

Method: RI$^2$VER框架包括检索大量段落、独立处理生成初始答案集，以及跨段落验证流程（验证问题生成、收集额外证据、跨段落合成验证）。

Result: 在QAMPARI和RoMQA数据集上显著优于基线，平均F1分数提升11.17%。

Conclusion: 跨段落验证流程使框架在多证据合成问题上表现优异。

Abstract: Multi-answer question answering (QA), where questions can have many valid
answers, presents a significant challenge for existing retrieval-augmented
generation-based QA systems, as these systems struggle to retrieve and then
synthesize a large number of evidence passages. To tackle these challenges, we
propose a new multi-answer QA framework -- Retrieval-augmented Independent
Reading with Inter-passage Verification (RI$^2$VER). Our framework retrieves a
large set of passages and processes each passage individually to generate an
initial high-recall but noisy answer set. Then we propose a new inter-passage
verification pipeline that validates every candidate answer through (1)
Verification Question Generation, (2) Gathering Additional Evidence, and (3)
Verification with inter-passage synthesis. Evaluations on the QAMPARI and RoMQA
datasets demonstrate that our framework significantly outperforms existing
baselines across various model sizes, achieving an average F1 score improvement
of 11.17%. Further analysis validates that our inter-passage verification
pipeline enables our framework to be particularly beneficial for questions
requiring multi-evidence synthesis.

</details>


### [53] [G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models](https://arxiv.org/abs/2506.00445)
*Long Bai,Zixuan Li,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 论文提出了一种名为G2S的学习框架，通过分离通用模式和场景信息的学习过程，提升大型语言模型在时序知识图谱预测任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时序知识图谱预测任务中同时学习通用模式和场景信息，导致两种知识的学习过程相互干扰，影响模型的泛化能力。

Method: G2S框架分为两个阶段：通用学习阶段通过屏蔽场景信息学习通用模式；特定学习阶段通过上下文学习或微调注入场景信息。

Result: 实验结果表明，G2S显著提升了大型语言模型的泛化能力。

Conclusion: G2S框架通过分离通用和特定知识的学习过程，有效提升了模型在时序知识图谱预测任务中的性能。

Abstract: Forecasting over Temporal Knowledge Graphs (TKGs) which predicts future facts
based on historical ones has received much attention. Recent studies have
introduced Large Language Models (LLMs) for this task to enhance the models'
generalization abilities. However, these models perform forecasting via
simultaneously learning two kinds of entangled knowledge in the TKG: (1)
general patterns, i.e., invariant temporal structures shared across different
scenarios; and (2) scenario information, i.e., factual knowledge engaged in
specific scenario, such as entities and relations. As a result, the learning
processes of these two kinds of knowledge may interfere with each other, which
potentially impact the generalization abilities of the models. To enhance the
generalization ability of LLMs on this task, in this paper, we propose a
General-to-Specific learning framework (G2S) that disentangles the learning
processes of the above two kinds of knowledge. In the general learning stage,
we mask the scenario information in different TKGs and convert it into
anonymous temporal structures. After training on these structures, the model is
able to capture the general patterns across different TKGs. In the specific
learning stage, we inject the scenario information into the structures via
either in-context learning or fine-tuning modes. Experimental results show that
G2S effectively improves the generalization abilities of LLMs.

</details>


### [54] [Fact-Controlled Diagnosis of Hallucinations in Medical Text Summarization](https://arxiv.org/abs/2506.00448)
*Suhas BN,Han-Chin Shing,Lei Xu,Mitch Strong,Jon Burnsky,Jessica Ofor,Jordan R. Mason,Susan Chen,Sundararajan Srinivasan,Chaitanya Shivade,Jack Moriarty,Joseph Paul Cohen*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）在临床对话摘要中的幻觉问题，评估了检测方法，并构建了两个数据集。研究发现通用检测器效果不佳，提出了基于事实的新方法，效果显著。


<details>
  <summary>Details</summary>
Motivation: 临床对话摘要中的幻觉问题对患者护理和决策有重大风险，但相关研究不足，且通用检测器效果不确定。

Method: 构建了两个数据集（事实控制数据集和自然幻觉数据集），评估了通用检测器，并开发了基于事实的新方法。

Result: 通用检测器效果不佳，基于事实的新方法在检测真实临床幻觉中表现良好。

Conclusion: 研究提出了专门指标和数据集，推动了临床摘要系统的可信度提升。

Abstract: Hallucinations in large language models (LLMs) during summarization of
patient-clinician dialogues pose significant risks to patient care and clinical
decision-making. However, the phenomenon remains understudied in the clinical
domain, with uncertainty surrounding the applicability of general-domain
hallucination detectors. The rarity and randomness of hallucinations further
complicate their investigation. In this paper, we conduct an evaluation of
hallucination detection methods in the medical domain, and construct two
datasets for the purpose: A fact-controlled Leave-N-out dataset -- generated by
systematically removing facts from source dialogues to induce hallucinated
content in summaries; and a natural hallucination dataset -- arising
organically during LLM-based medical summarization. We show that general-domain
detectors struggle to detect clinical hallucinations, and that performance on
fact-controlled hallucinations does not reliably predict effectiveness on
natural hallucinations. We then develop fact-based approaches that count
hallucinations, offering explainability not available with existing methods.
Notably, our LLM-based detectors, which we developed using fact-controlled
hallucinations, generalize well to detecting real-world clinical
hallucinations. This research contributes a suite of specialized metrics
supported by expert-annotated datasets to advance faithful clinical
summarization systems.

</details>


### [55] [Massively Multilingual Adaptation of Large Language Models Using Bilingual Translation Data](https://arxiv.org/abs/2506.00469)
*Shaoxiong Ji,Zihao Li,Jaakko Paavola,Indraneil Paul,Hengyu Luo,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 研究了在大规模多语言持续预训练中是否包含平行数据的影响，发现双语翻译数据能提升低资源语言的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨在大规模多语言持续预训练中，双语翻译数据的作用及其对语言适应性的影响。

Method: 构建了MaLA双语翻译语料库，包含2500多种语言对，并基于Llama3模型开发了EMMA-500套件，通过671B token的数据混合进行持续预训练。

Result: 双语数据显著提升了语言迁移和性能，尤其是低资源语言。

Conclusion: 双语翻译数据对大规模多语言模型的持续预训练具有积极影响，尤其是在低资源语言上表现突出。

Abstract: This paper investigates a critical design decision in the practice of
massively multilingual continual pre-training -- the inclusion of parallel
data. Specifically, we study the impact of bilingual translation data for
massively multilingual language adaptation of the Llama3 family of models to
500 languages. To this end, we construct the MaLA bilingual translation corpus,
containing data from more than 2,500 language pairs. Subsequently, we develop
the EMMA-500 Llama 3 suite of four massively multilingual models -- continually
pre-trained from the Llama 3 family of base models extensively on diverse data
mixes up to 671B tokens -- and explore the effect of continual pre-training
with or without bilingual translation data. Comprehensive evaluation across 7
tasks and 12 benchmarks demonstrates that bilingual data tends to enhance
language transfer and performance, particularly for low-resource languages. We
open-source the MaLA corpus, EMMA-500 Llama 3 suite artefacts, code, and model
generations.

</details>


### [56] [EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models](https://arxiv.org/abs/2506.00479)
*Zekun Wang,Minghua Ma,Zexin Wang,Rongchuan Mu,Liping Shan,Ming Liu,Bing Qin*

Main category: cs.CL

TL;DR: 本文系统评估了大型视觉语言模型（LVLMs）的主流加速技术，提出了EffiVLM-Bench框架，并开源代码以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 尽管LVLMs取得了显著成功，但其高计算需求限制了实际部署，现有方法缺乏全面的评估。

Method: 通过分类为令牌和参数压缩，系统评估主流加速技术，并引入EffiVLM-Bench框架进行多维度评估。

Result: 实验和分析提供了加速LVLMs的最优策略，并探索了Pareto最优权衡。

Conclusion: 开源EffiVLM-Bench代码和方案，为未来研究提供支持。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable success, yet
their significant computational demands hinder practical deployment. While
efforts to improve LVLM efficiency are growing, existing methods lack
comprehensive evaluation across diverse backbones, benchmarks, and metrics. In
this work, we systematically evaluate mainstream acceleration techniques for
LVLMs, categorized into token and parameter compression. We introduce
EffiVLM-Bench, a unified framework for assessing not only absolute performance
but also generalization and loyalty, while exploring Pareto-optimal trade-offs.
Our extensive experiments and in-depth analyses offer insights into optimal
strategies for accelerating LVLMs. We open-source code and recipes for
EffiVLM-Bench to foster future research.

</details>


### [57] [PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings](https://arxiv.org/abs/2506.00481)
*Junseo Kim,Jongwook Han,Dongmin Choi,Jongwook Yoon,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 论文提出了一个个性化视觉说服（PVP）数据集，包含28,454张说服性图像，并提供了2,521名标注者的评价分数及其心理特征，用于推动个性化视觉说服技术的发展。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏连接图像说服力与个人信息的综合数据集，阻碍了AI在个性化视觉说服领域的发展。

Method: 发布PVP数据集，包含图像、标注者的评价分数及其心理特征，并开发了说服性图像生成器和自动评估器。

Result: 实验表明，结合心理特征能提升说服性图像的生成和评估效果。

Conclusion: PVP数据集为个性化视觉说服技术提供了重要资源，心理特征的引入具有显著价值。

Abstract: Visual persuasion, which uses visual elements to influence cognition and
behaviors, is crucial in fields such as advertising and political
communication. With recent advancements in artificial intelligence, there is
growing potential to develop persuasive systems that automatically generate
persuasive images tailored to individuals. However, a significant bottleneck in
this area is the lack of comprehensive datasets that connect the persuasiveness
of images with the personal information about those who evaluated the images.
To address this gap and facilitate technological advancements in personalized
visual persuasion, we release the Personalized Visual Persuasion (PVP) dataset,
comprising 28,454 persuasive images across 596 messages and 9 persuasion
strategies. Importantly, the PVP dataset provides persuasiveness scores of
images evaluated by 2,521 human annotators, along with their demographic and
psychological characteristics (personality traits and values). We demonstrate
the utility of our dataset by developing a persuasive image generator and an
automated evaluator, and establish benchmark baselines. Our experiments reveal
that incorporating psychological characteristics enhances the generation and
evaluation of persuasive images, providing valuable insights for personalized
visual persuasion.

</details>


### [58] [Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models](https://arxiv.org/abs/2506.00483)
*Aviv Jan,Dean Tahory,Omer Talmi,Omar Abo Mokh*

Main category: cs.CL

TL;DR: Auto-Patch通过动态修改隐藏状态提升大语言模型的多跳推理能力，在MuSiQue数据集上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 多跳问题对大语言模型仍具挑战性，现有方法难以跨多步推理链接信息。

Method: 基于PatchScopes框架，Auto-Patch利用学习到的分类器选择性修改内部表示。

Result: 在MuSiQue数据集上，Auto-Patch将解决率从18.45%提升至23.63±0.7%，接近Chain-of-Thought的27.44%。

Conclusion: 动态隐藏状态干预有望推动大语言模型的复杂推理能力。

Abstract: Multi-hop questions still stump large language models (LLMs), which struggle
to link information across multiple reasoning steps. We introduce Auto-Patch, a
novel method that dynamically patches hidden states during inference to enhance
multi-hop reasoning in LLMs. Building on the PatchScopes framework, Auto-Patch
selectively modifies internal representations using a learned classifier.
Evaluated on the MuSiQue dataset, Auto-Patch improves the solve rate from
18.45\% (baseline) to 23.63~$\pm$~0.7\% (3 runs), narrowing the gap to
Chain-of-Thought prompting (27.44\%). Our results highlight the potential of
dynamic hidden state interventions for advancing complex reasoning in LLMs.

</details>


### [59] [Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection](https://arxiv.org/abs/2506.00488)
*Shuguo Hu,Jun Hu,Huaiwen Zhang*

Main category: cs.CL

TL;DR: 论文提出GLPN-LLM模型，结合LLM生成的伪标签和全局标签传播技术，提升多模态假新闻检测性能。


<details>
  <summary>Details</summary>
Motivation: LLM生成的伪标签单独使用时性能较差，需要有效整合以提升检测效果。

Method: 提出GLPN-LLM模型，通过全局标签传播技术整合LLM生成的伪标签，并设计掩码机制防止标签泄漏。

Result: 实验表明，模型在基准数据集上优于现有方法。

Conclusion: 结合LLM和标签传播技术可显著提升多模态假新闻检测性能。

Abstract: Large Language Models (LLMs) can assist multimodal fake news detection by
predicting pseudo labels. However, LLM-generated pseudo labels alone
demonstrate poor performance compared to traditional detection methods, making
their effective integration non-trivial. In this paper, we propose Global Label
Propagation Network with LLM-based Pseudo Labeling (GLPN-LLM) for multimodal
fake news detection, which integrates LLM capabilities via label propagation
techniques. The global label propagation can utilize LLM-generated pseudo
labels, enhancing prediction accuracy by propagating label information among
all samples. For label propagation, a mask-based mechanism is designed to
prevent label leakage during training by ensuring that training nodes do not
propagate their own labels back to themselves. Experimental results on
benchmark datasets show that by synergizing LLMs with label propagation, our
model achieves superior performance over state-of-the-art baselines.

</details>


### [60] [Exploring In-context Example Generation for Machine Translation](https://arxiv.org/abs/2506.00507)
*Dohyun Lee,Seungil Chad Lee,Chanwoo Yang,Yujin Baek,Jaegul Choo*

Main category: cs.CL

TL;DR: 本文提出了一种无需依赖外部资源的上下文示例生成方法（DAT），用于低资源语言的机器翻译，通过实验验证其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设存在人工标注的示例池，这在低资源语言中难以实现，因此探索无需外部资源的示例生成方法。

Method: 提出DAT方法，基于相关性和多样性生成示例对，无需外部资源支持。

Result: 在低资源语言上，DAT的翻译质量优于基线方法，并探索了逐步积累生成示例的潜力。

Conclusion: DAT为低资源语言的机器翻译提供了一种简单有效的解决方案，且代码已开源。

Abstract: Large language models (LLMs) have demonstrated strong performance across
various tasks, leveraging their exceptional in-context learning ability with
only a few examples. Accordingly, the selection of optimal in-context examples
has been actively studied in the field of machine translation. However, these
studies presuppose the presence of a demonstration pool with human-annotated
pairs, making them less applicable to low-resource languages where such an
assumption is challenging to meet. To overcome this limitation, this paper
explores the research direction of in-context example generation for machine
translation. Specifically, we propose Demonstration Augmentation for
Translation (DAT), a simple yet effective approach that generates example pairs
without relying on any external resources. This method builds upon two prior
criteria, relevance and diversity, which have been highlighted in previous work
as key factors for in-context example selection. Through experiments and
analysis on low-resource languages where human-annotated pairs are scarce, we
show that DAT achieves superior translation quality compared to the baselines.
Furthermore, we investigate the potential of progressively accumulating
generated pairs during test time to build and reuse a demonstration pool. Our
implementation is publicly available at https://github.com/aiclaudev/DAT.

</details>


### [61] [Goal-Aware Identification and Rectification of Misinformation in Multi-Agent Systems](https://arxiv.org/abs/2506.00509)
*Zherui Li,Yan Mi,Zhenhong Zhou,Houcheng Jiang,Guibin Zhang,Kun Wang,Junfeng Fang*

Main category: cs.CL

TL;DR: 论文提出ARGUS框架，用于防御多智能体系统中的错误信息注入，实验显示其显著降低错误信息毒性并提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统易受错误信息注入攻击，需深入研究其传播动态并开发有效防御方法。

Method: 提出ARGUS框架，基于目标感知推理的两阶段无训练防御方法，并使用MisinfoTask数据集进行评估。

Result: ARGUS平均降低错误信息毒性约28.17%，任务成功率提高约10.33%。

Conclusion: ARGUS能有效防御多智能体系统中的错误信息攻击，提升系统鲁棒性。

Abstract: Large Language Model-based Multi-Agent Systems (MASs) have demonstrated
strong advantages in addressing complex real-world tasks. However, due to the
introduction of additional attack surfaces, MASs are particularly vulnerable to
misinformation injection. To facilitate a deeper understanding of
misinformation propagation dynamics within these systems, we introduce
MisinfoTask, a novel dataset featuring complex, realistic tasks designed to
evaluate MAS robustness against such threats. Building upon this, we propose
ARGUS, a two-stage, training-free defense framework leveraging goal-aware
reasoning for precise misinformation rectification within information flows.
Our experiments demonstrate that in challenging misinformation scenarios, ARGUS
exhibits significant efficacy across various injection attacks, achieving an
average reduction in misinformation toxicity of approximately 28.17% and
improving task success rates under attack by approximately 10.33%. Our code and
dataset is available at: https://github.com/zhrli324/ARGUS.

</details>


### [62] [Evaluating the Evaluation of Diversity in Commonsense Generation](https://arxiv.org/abs/2506.00514)
*Tianhui Zhang,Bei Peng,Danushka Bollegala*

Main category: cs.CL

TL;DR: 本文通过系统评估常识生成中的多样性指标，发现基于形式的指标高估多样性，而基于内容的指标与LLM评分高度相关，建议未来研究采用基于内容的指标。


<details>
  <summary>Details</summary>
Motivation: 现有常识生成任务中多样性评估指标的有效性不明确，需系统评估以确定最佳指标。

Method: 通过LLM创建标注数据集，对现有多样性指标进行元评估。

Result: 基于内容的多样性指标优于基于形式的指标，与LLM评分高度相关。

Conclusion: 建议未来常识生成研究采用基于内容的多样性评估指标。

Abstract: In commonsense generation, given a set of input concepts, a model must
generate a response that is not only commonsense bearing, but also capturing
multiple diverse viewpoints. Numerous evaluation metrics based on form- and
content-level overlap have been proposed in prior work for evaluating the
diversity of a commonsense generation model. However, it remains unclear as to
which metrics are best suited for evaluating the diversity in commonsense
generation. To address this gap, we conduct a systematic meta-evaluation of
diversity metrics for commonsense generation. We find that form-based diversity
metrics tend to consistently overestimate the diversity in sentence sets, where
even randomly generated sentences are assigned overly high diversity scores. We
then use an Large Language Model (LLM) to create a novel dataset annotated for
the diversity of sentences generated for a commonsense generation task, and use
it to conduct a meta-evaluation of the existing diversity evaluation metrics.
Our experimental results show that content-based diversity evaluation metrics
consistently outperform the form-based counterparts, showing high correlations
with the LLM-based ratings. We recommend that future work on commonsense
generation should use content-based metrics for evaluating the diversity of
their outputs.

</details>


### [63] [CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention](https://arxiv.org/abs/2506.00519)
*Yuxi Sun,Aoqi Zuo,Wei Gao,Jing Ma*

Main category: cs.CL

TL;DR: 论文提出了一种名为CausalAbstain的方法，通过因果视角帮助LLMs在多语言场景中更有效地选择反馈并提升弃权决策的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在不同语言中存在知识差异，当前的多语言弃权策略依赖生成反馈和自省，但可能受到反馈中的不准确性和偏见影响。

Method: 从因果视角出发，提出CausalAbstain方法，帮助LLMs决定是否使用多个生成的反馈，并识别最有用的反馈。

Result: 在两种基准数据集（百科和常识知识QA任务）上，CausalAbstain在原生语言和多语言设置中均优于基线方法，且具有可解释性。

Conclusion: CausalAbstain能有效选择有用反馈并提升弃权决策，为多语言场景中的LLMs提供了一种更可靠的解决方案。

Abstract: Large Language Models (LLMs) often exhibit knowledge disparities across
languages. Encouraging LLMs to \textit{abstain} when faced with knowledge gaps
is a promising strategy to reduce hallucinations in multilingual settings.
Current abstention strategies for multilingual scenarios primarily rely on
generating feedback in various languages using LLMs and performing
self-reflection. However, these methods can be adversely impacted by
inaccuracies and biases in the generated feedback. To address this, from a
causal perspective, we introduce \textit{CausalAbstain}, a method that helps
LLMs determine whether to utilize multiple generated feedback responses and how
to identify the most useful ones. Extensive experiments demonstrate that
\textit{CausalAbstain} effectively selects helpful feedback and enhances
abstention decisions with interpretability in both native language
(\textsc{Casual-native}) and multilingual (\textsc{Causal-multi}) settings,
outperforming strong baselines on two benchmark datasets covering encyclopedic
and commonsense knowledge QA tasks. Our code and data are open-sourced at
https://github.com/peachch/CausalAbstain.

</details>


### [64] [Retrieval-Augmented Generation Systems for Intellectual Property via Synthetic Multi-Angle Fine-tuning](https://arxiv.org/abs/2506.00527)
*Runtao Ren,Jian Ma,Jianxi Luo*

Main category: cs.CL

TL;DR: MQG-RFM通过多角度问题生成和检索微调方法，提升IP领域RAG系统对多样化用户查询的响应能力，显著提高检索准确性和生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决IP领域RAG系统因用户查询多样性（如口语化表达、拼写错误和模糊术语）导致的检索不准确和响应不佳问题。

Method: 采用轻量级Data-to-Tune范式，结合提示工程化查询生成和硬负样本挖掘，优化检索模型以对齐语义等效但语言多样的问题。

Result: 在台湾专利Q&A数据集上，检索准确性分别提升185.62%和262.26%，生成质量提升14.22%和53.58%。

Conclusion: MQG-RFM通过语义感知的检索优化，为中小型机构提供了一种实用、可扩展的专利情报解决方案，并已在ScholarMate平台实际应用。

Abstract: Retrieval-Augmented Generation (RAG) systems in the Intellectual Property
(IP) field often struggle with diverse user queries, including colloquial
expressions, spelling errors, and ambiguous terminology, leading to inaccurate
retrieval and suboptimal responses. To address this challenge, we propose
Multi-Angle Question Generation and Retrieval Fine-Tuning Method (MQG-RFM), a
novel framework that leverages large language models (LLMs) to simulate varied
user inquiries and fine-tunes retrieval models to align semantically equivalent
but linguistically diverse questions. Unlike complex architectural
modifications, MQG-RFM adopts a lightweight Data-to-Tune paradigm, combining
prompt-engineered query generation with hard negative mining to enhance
retrieval robustness without costly infrastructure changes. Experimental
results on a Taiwan patent Q&A dataset show 185.62% improvement in retrieval
accuracy on the Patent Consultation dataset and 262.26% improvement on the
Novel Patent Technology Report dataset, with 14.22% and 53.58% improvements in
generation quality over the baselines, respectively. By bridging the gap
between user intent and system comprehension through semantic-aware retrieval
optimization, MQG-RFM offers a practical, scalable approach for rapid,
cost-effective deployment among small and medium-sized agencies seeking
reliable patent intelligence solutions. Additionally, our proposed method has
already been adopted by ScholarMate, the largest professional research social
networking platform in China, to support real-world development and deployment.
A demo version of the instantiated is available at
https://github.com/renruntao/patent_rag.

</details>


### [65] [Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing](https://arxiv.org/abs/2506.00536)
*Changyue Wang,Weihang Su,Qingyao Ai,Yujia Zhou,Yiqun Liu*

Main category: cs.CL

TL;DR: DecKER是一个新的知识编辑框架，通过解耦推理与知识编辑，显著提升了多跳问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有上下文知识编辑方法未明确分离新注入知识与模型原始推理过程，导致知识冲突和推理路径不一致。

Method: 提出DecKER框架，生成掩码推理路径，并通过混合检索和基于模型的验证解决知识编辑问题。

Result: 在多跳问答基准测试中，DecKER显著优于现有方法，减少了知识冲突并保持了推理一致性。

Conclusion: DecKER通过解耦推理与知识编辑，为轻量级知识更新提供了更有效的解决方案。

Abstract: Knowledge editing aims to efficiently update Large Language Models (LLMs) by
modifying specific knowledge without retraining the entire model. Among
knowledge editing approaches, in-context editing (ICE) offers a lightweight
solution by injecting new knowledge directly into the input context, leaving
model parameters unchanged. However, existing ICE approaches do not explicitly
separate the newly injected knowledge from the model's original reasoning
process. This entanglement often results in conflicts between external updates
and internal parametric knowledge, undermining the consistency and accuracy of
the reasoning path.In this work, we conduct preliminary experiments to examine
how parametric knowledge influences reasoning path planning. We find that the
model's reasoning is tightly coupled with its internal knowledge, and that
naively injecting new information without adapting the reasoning path often
leads to performance degradation, particularly in multi-hop tasks. To this end,
we propose DecKER, a novel ICE framework that decouples reasoning from
knowledge editing by generating a masked reasoning path and then resolving
knowledge edits via hybrid retrieval and model-based validation. Experiments on
multi-hop QA benchmarks show that DecKER significantly outperforms existing ICE
methods by mitigating knowledge conflicts and preserving reasoning consistency.
Our code is available at: https://github.com/bebr2/DecKER .

</details>


### [66] [ARIA: Training Language Agents with Intention-Driven Reward Aggregation](https://arxiv.org/abs/2506.00539)
*Ruihan Yang,Yikai Zhang,Aili Chen,Xintao Wang,Siyu Yuan,Jiangjie Chen,Deqing Yang,Yanghua Xiao*

Main category: cs.CL

TL;DR: 论文提出ARIA方法，通过将自然语言动作从高维空间映射到低维意图空间，聚合奖励以减少方差，提升强化学习效果。


<details>
  <summary>Details</summary>
Motivation: 在开放语言动作环境中，动作空间的高维性导致奖励稀疏和方差大，阻碍有效强化学习。

Method: ARIA方法将动作投影到低维意图空间，聚类语义相似动作并共享奖励，从而减少方差。

Result: 实验显示ARIA显著降低策略梯度方差，并在四个下游任务中平均提升9.95%性能。

Conclusion: ARIA通过意图空间奖励聚合，有效解决了高维动作空间中的奖励稀疏问题，提升了语言代理的训练效果。

Abstract: Large language models (LLMs) have enabled agents to perform complex reasoning
and decision-making through free-form language interactions. However, in
open-ended language action environments (e.g., negotiation or question-asking
games), the action space can be formulated as a joint distribution over tokens,
resulting in an exponentially large action space. Sampling actions in such a
space can lead to extreme reward sparsity, which brings large reward variance,
hindering effective reinforcement learning (RL). To address this, we propose
ARIA, a method that Aggregates Rewards in Intention space to enable efficient
and effective language Agents training. ARIA aims to project natural language
actions from the high-dimensional joint token distribution space into a
low-dimensional intention space, where semantically similar actions are
clustered and assigned shared rewards. This intention-aware reward aggregation
reduces reward variance by densifying reward signals, fostering better policy
optimization. Extensive experiments demonstrate that ARIA not only
significantly reduces policy gradient variance, but also delivers substantial
performance gains of an average of 9.95% across four downstream tasks,
consistently outperforming offline and online RL baselines.

</details>


### [67] [Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages](https://arxiv.org/abs/2506.00549)
*Hyangsuk Min,Yuho Lee,Minjeong Ban,Jiaqi Deng,Nicole Hee-Yeon Kim,Taewon Yun,Hang Su,Jason Cai,Hwanjun Song*

Main category: cs.CL

TL;DR: MSumBench是一个多维、多领域的文本摘要评估框架，支持中英文，提供领域特定评估标准，并利用多代理辩论系统提升标注质量。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架缺乏领域特定标准，以英语为主，且人工标注因推理复杂性面临挑战。

Method: 引入MSumBench，包含多维评估、多领域覆盖、领域特定标准，以及多代理辩论系统。

Result: 评估了八种现代摘要模型，发现跨领域和语言的性能差异，并分析了大语言模型作为摘要评估者的偏见。

Conclusion: MSumBench为文本摘要提供了更全面的评估工具，揭示了模型性能差异和评估偏见。

Abstract: Evaluation frameworks for text summarization have evolved in terms of both
domain coverage and metrics. However, existing benchmarks still lack
domain-specific assessment criteria, remain predominantly English-centric, and
face challenges with human annotation due to the complexity of reasoning. To
address these, we introduce MSumBench, which provides a multi-dimensional,
multi-domain evaluation of summarization in English and Chinese. It also
incorporates specialized assessment criteria for each domain and leverages a
multi-agent debate system to enhance annotation quality. By evaluating eight
modern summarization models, we discover distinct performance patterns across
domains and languages. We further examine large language models as summary
evaluators, analyzing the correlation between their evaluation and
summarization capabilities, and uncovering systematic bias in their assessment
of self-generated summaries. Our benchmark dataset is publicly available at
https://github.com/DISL-Lab/MSumBench.

</details>


### [68] [AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation](https://arxiv.org/abs/2506.00551)
*Ming Wang,Peidong Wang,Lin Wu,Xiaocui Yang,Daling Wang,Shi Feng,Yuxin Chen,Bixuan Wang,Yifei Zhang*

Main category: cs.CL

TL;DR: 论文提出了AnnaAgent，一种动态情感和认知代理系统，用于模拟心理咨询中的求助者，解决了动态演化和多会话记忆两大挑战。


<details>
  <summary>Details</summary>
Motivation: 由于成本和伦理问题，AI驱动的心理健康研究中难以使用真实求助者，因此需要更真实的模拟代理。

Method: 提出AnnaAgent，配备情绪调节器和抱怨引发器，并采用三级记忆机制整合短期和长期记忆。

Result: 评估结果显示，AnnaAgent在心理咨询中比现有基线更真实地模拟求助者。

Conclusion: AnnaAgent为心理健康研究提供了更真实的模拟工具，代码已通过伦理审查并开源。

Abstract: Constrained by the cost and ethical concerns of involving real seekers in
AI-driven mental health, researchers develop LLM-based conversational agents
(CAs) with tailored configurations, such as profiles, symptoms, and scenarios,
to simulate seekers. While these efforts advance AI in mental health, achieving
more realistic seeker simulation remains hindered by two key challenges:
dynamic evolution and multi-session memory. Seekers' mental states often
fluctuate during counseling, which typically spans multiple sessions. To
address this, we propose AnnaAgent, an emotional and cognitive dynamic agent
system equipped with tertiary memory. AnnaAgent incorporates an emotion
modulator and a complaint elicitor trained on real counseling dialogues,
enabling dynamic control of the simulator's configurations. Additionally, its
tertiary memory mechanism effectively integrates short-term and long-term
memory across sessions. Evaluation results, both automated and manual,
demonstrate that AnnaAgent achieves more realistic seeker simulation in
psychological counseling compared to existing baselines. The ethically reviewed
and screened code can be found on https://github.com/sci-m-wang/AnnaAgent.

</details>


### [69] [The Hidden Language of Harm: Examining the Role of Emojis in Harmful Online Communication and Content Moderation](https://arxiv.org/abs/2506.00583)
*Yuhang Zhou,Yimin Xiao,Wei Ai,Ge Gao*

Main category: cs.CL

TL;DR: 论文研究了社交媒体中表情符号在冒犯性内容中的作用，并提出了一个基于LLM的多步审核流程，以减少冒犯性同时保留语义。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中冒犯性内容普遍存在，但表情符号的作用尚未被充分研究，尤其是在其通过符号关联、讽刺或上下文滥用时可能产生有害含义。

Method: 系统分析了表情符号在冒犯性推文中的分布及其模糊性利用，提出了一种基于LLM的多步审核流程，选择性替换有害表情符号。

Result: 人类评估证实该方法能有效减少冒犯性感知，同时保留推文的语义意图。分析还揭示了不同冒犯类型中的异质性效果。

Conclusion: 研究为在线交流和表情符号审核提供了细致见解，提出的方法在减少冒犯性方面具有实际应用价值。

Abstract: Social media platforms have become central to modern communication, yet they
also harbor offensive content that challenges platform safety and inclusivity.
While prior research has primarily focused on textual indicators of offense,
the role of emojis, ubiquitous visual elements in online discourse, remains
underexplored. Emojis, despite being rarely offensive in isolation, can acquire
harmful meanings through symbolic associations, sarcasm, and contextual misuse.
In this work, we systematically examine emoji contributions to offensive
Twitter messages, analyzing their distribution across offense categories and
how users exploit emoji ambiguity. To address this, we propose an LLM-powered,
multi-step moderation pipeline that selectively replaces harmful emojis while
preserving the tweet's semantic intent. Human evaluations confirm our approach
effectively reduces perceived offensiveness without sacrificing meaning. Our
analysis also reveals heterogeneous effects across offense types, offering
nuanced insights for online communication and emoji moderation.

</details>


### [70] [Entriever: Energy-based Retriever for Knowledge-Grounded Dialog Systems](https://arxiv.org/abs/2506.00585)
*Yucheng Cai,Ke Li,Yi Huang,Junlan Feng,Zhijian Ou*

Main category: cs.CL

TL;DR: Entriever是一种基于能量的检索器，通过能量函数直接建模候选检索结果，解决了现有检索器中知识片段条件独立假设的问题，显著提升了知识检索和对话系统的性能。


<details>
  <summary>Details</summary>
Motivation: 在知识驱动的对话系统中，现有检索器通常假设知识片段条件独立，而实际上可能存在多个相关且相互依赖的知识片段。

Method: 提出Entriever，通过能量函数定义相关性分数，直接建模候选检索结果整体，探索了多种能量函数架构和训练方法。

Result: Entriever在知识检索任务中显著优于强基线模型，并在半监督训练中显著提升对话系统的端到端性能。

Conclusion: Entriever通过整体建模知识片段的相关性，有效解决了现有检索器的局限性，提升了知识检索和对话系统的性能。

Abstract: A retriever, which retrieves relevant knowledge pieces from a knowledge base
given a context, is an important component in many natural language processing
(NLP) tasks. Retrievers have been introduced in knowledge-grounded dialog
systems to improve knowledge acquisition. In knowledge-grounded dialog systems,
when conditioning on a given context, there may be multiple relevant and
correlated knowledge pieces. However, knowledge pieces are usually assumed to
be conditionally independent in current retriever models. To address this
issue, we propose Entriever, an energy-based retriever. Entriever directly
models the candidate retrieval results as a whole instead of modeling the
knowledge pieces separately, with the relevance score defined by an energy
function. We explore various architectures of energy functions and different
training methods for Entriever, and show that Entriever substantially
outperforms the strong cross-encoder baseline in knowledge retrieval tasks.
Furthermore, we show that in semi-supervised training of knowledge-grounded
dialog systems, Entriever enables effective scoring of retrieved knowledge
pieces and significantly improves end-to-end performance of dialog systems.

</details>


### [71] [PAKTON: A Multi-Agent Framework for Question Answering in Long Legal Agreements](https://arxiv.org/abs/2506.00608)
*Petros Raptopoulos,Giorgos Filandrianos,Maria Lymperaiou,Giorgos Stamou*

Main category: cs.CL

TL;DR: PAKTON是一个开源的多智能体框架，旨在通过协作工作流和检索增强生成技术，实现自动化合同审查，提升可访问性、适应性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 合同审查复杂且耗时，通常需要法律专业知识，对非专业人士不友好；同时合同内容通常保密，限制了专有模型的使用。

Method: PAKTON采用多智能体协作工作流和检索增强生成（RAG）技术，实现端到端的自动化合同分析。

Result: 实验表明，PAKTON在预测准确性、检索性能、可解释性、完整性和合理性方面优于通用和预训练模型。

Conclusion: PAKTON为合同审查提供了一种更高效、隐私保护的解决方案，尤其适合非专业人士使用。

Abstract: Contract review is a complex and time-intensive task that typically demands
specialized legal expertise, rendering it largely inaccessible to non-experts.
Moreover, legal interpretation is rarely straightforward-ambiguity is
pervasive, and judgments often hinge on subjective assessments. Compounding
these challenges, contracts are usually confidential, restricting their use
with proprietary models and necessitating reliance on open-source alternatives.
To address these challenges, we introduce PAKTON: a fully open-source,
end-to-end, multi-agent framework with plug-and-play capabilities. PAKTON is
designed to handle the complexities of contract analysis through collaborative
agent workflows and a novel retrieval-augmented generation (RAG) component,
enabling automated legal document review that is more accessible, adaptable,
and privacy-preserving. Experiments demonstrate that PAKTON outperforms both
general-purpose and pretrained models in predictive accuracy, retrieval
performance, explainability, completeness, and grounded justifications as
evaluated through a human study and validated with automated metrics.

</details>


### [72] [Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation](https://arxiv.org/abs/2506.00612)
*Running Yang,Wenlong Deng,Minghui Chen,Yuyin Zhou,Xiaoxiao Li*

Main category: cs.CL

TL;DR: 论文提出了一种知识引导的数据增强框架（KGGDG），通过生成具有临床合理性和误导性的干扰项，提升临床多选题数据集的难度，从而更严格评估大型语言模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 临床任务（如诊断和治疗）需要强大的决策能力，因此需要严格的评估基准来测试大型语言模型（LLMs）的可靠性。

Method: 采用基于知识图谱的多步语义路径搜索，生成医学相关但事实错误的干扰项，并通过LLM进一步优化这些干扰项。

Result: 在六个广泛使用的医学QA基准测试中，KGGDG显著降低了最先进LLMs的准确率。

Conclusion: KGGDG是一种强大的工具，能够更严格地评估医学LLMs的鲁棒性和诊断能力。

Abstract: Clinical tasks such as diagnosis and treatment require strong decision-making
abilities, highlighting the importance of rigorous evaluation benchmarks to
assess the reliability of large language models (LLMs). In this work, we
introduce a knowledge-guided data augmentation framework that enhances the
difficulty of clinical multiple-choice question (MCQ) datasets by generating
distractors (i.e., incorrect choices that are similar to the correct one and
may confuse existing LLMs). Using our KG-based pipeline, the generated choices
are both clinically plausible and deliberately misleading. Our approach
involves multi-step, semantically informed walks on a medical knowledge graph
to identify distractor paths-associations that are medically relevant but
factually incorrect-which then guide the LLM in crafting more deceptive
distractors. We apply the designed knowledge graph guided distractor generation
(KGGDG) pipline, to six widely used medical QA benchmarks and show that it
consistently reduces the accuracy of state-of-the-art LLMs. These findings
establish KGGDG as a powerful tool for enabling more robust and diagnostic
evaluations of medical LLMs.

</details>


### [73] [Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples](https://arxiv.org/abs/2506.00622)
*Haesung Pyun,Yoonah Park,Yohan Jo*

Main category: cs.CL

TL;DR: CombiSearch是一种用于对话状态跟踪（DST）的方法，通过评估上下文示例的组合影响来优化检索器训练，显著提升性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有检索器训练方法存在三个主要问题：未考虑示例的协同效应、未充分融入查询的语言特征、评分未直接优化DST性能，导致检索效果不佳。

Method: 提出CombiSearch方法，基于上下文示例对DST性能的组合影响进行评分，优化检索器训练。

Result: 在MultiWOZ上的评估显示，CombiSearch实现了20倍的数据效率提升，并在SGD数据集上表现良好，DST性能上限提升12%。

Conclusion: CombiSearch显著提升了DST性能上限，表明现有方法依赖次优数据训练检索器。

Abstract: In dialogue state tracking (DST), in-context learning comprises a retriever
that selects labeled dialogues as in-context examples and a DST model that uses
these examples to infer the dialogue state of the query dialogue. Existing
methods for constructing training data for retrievers suffer from three key
limitations: (1) the synergistic effect of examples is not considered, (2) the
linguistic characteristics of the query are not sufficiently factored in, and
(3) scoring is not directly optimized for DST performance. Consequently, the
retriever can fail to retrieve examples that would substantially improve DST
performance. To address these issues, we present CombiSearch, a method that
scores effective in-context examples based on their combinatorial impact on DST
performance. Our evaluation on MultiWOZ shows that retrievers trained with
CombiSearch surpass state-of-the-art models, achieving a 20x gain in data
efficiency and generalizing well to the SGD dataset. Moreover, CombiSearch
attains a 12% absolute improvement in the upper bound DST performance over
traditional approaches when no retrieval errors are assumed. This significantly
increases the headroom for practical DST performance while demonstrating that
existing methods rely on suboptimal data for retriever training.

</details>


### [74] [LID Models are Actually Accent Classifiers: Implications and Solutions for LID on Accented Speech](https://arxiv.org/abs/2506.00628)
*Niyati Bafna,Matthew Wiesner*

Main category: cs.CL

TL;DR: 本文探讨了LID模型在带口音语音上的性能下降问题，分析了错误原因，并提出了一种增强模型鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，LID模型在带口音语音上表现显著下降，但具体原因和错误特征尚未充分探索。

Method: (i) 识别L2口音语音的常见错误模式；(ii) 分析模型对短语音段的排列不变性；(iii) 提出一种整合序列级信息的方法。

Result: 通过输入分块增强模型鲁棒性，减少口音与语言的混淆，显著提升带口音语音上的性能。

Conclusion: 提出的方法在不依赖单语ASR系统的情况下，显著提升了LID模型在带口音语音上的表现。

Abstract: Prior research indicates that LID model performance significantly declines on
accented speech; however, the specific causes, extent, and characterization of
these errors remain under-explored. (i) We identify a common failure mode on
accented speech whereby LID systems often misclassify L2 accented speech as the
speaker's native language or a related language. (ii) We present evidence
suggesting that state-of-the-art models are invariant to permutations of short
spans of speech, implying they classify on the basis of short phonotactic
features indicative of accent rather than language. Our analysis reveals a
simple method to enhance model robustness to accents through input chunking.
(iii) We present an approach that integrates sequence-level information into
our model without relying on monolingual ASR systems; this reduces
accent-language confusion and significantly enhances performance on accented
speech while maintaining comparable results on standard LID.

</details>


### [75] [Social Construction of Urban Space: Understanding Neighborhood Boundaries Using Rental Listings](https://arxiv.org/abs/2506.00634)
*Adam Visokay,Ruth Bagley,Ian Kennedy,Chris Hess,Kyle Crowder,Rob Voigt,Denis Peskoff*

Main category: cs.CL

TL;DR: 通过分析芝加哥Craigslist租房广告（2018-2024），研究揭示了语言如何塑造城市空间的社会定义，发现邻里边界与广告宣称的差异。


<details>
  <summary>Details</summary>
Motivation: 探讨租房广告如何通过语言反映城市空间的社会构建，揭示传统方法忽略的空间定义争议。

Method: 结合人工和大语言模型标注，对Craigslist非结构化广告进行分类，并通过地理空间分析和主题建模识别模式。

Result: 发现三类空间模式：邻里定义冲突的房产、边界房产和“声誉洗白”现象；主题建模显示位置与广告内容的相关性。

Conclusion: 自然语言处理技术能揭示传统方法忽略的城市空间定义争议。

Abstract: Rental listings offer a unique window into how urban space is socially
constructed through language. We analyze Chicago Craigslist rental
advertisements from 2018 to 2024 to examine how listing agents characterize
neighborhoods, identifying mismatches between institutional boundaries and
neighborhood claims. Through manual and large language model annotation, we
classify unstructured listings from Craigslist according to their neighborhood.
Geospatial analysis reveals three distinct patterns: properties with
conflicting neighborhood designations due to competing spatial definitions,
border properties with valid claims to adjacent neighborhoods, and ``reputation
laundering" where listings claim association with distant, desirable
neighborhoods. Through topic modeling, we identify patterns that correlate with
spatial positioning: listings further from neighborhood centers emphasize
different amenities than centrally-located units. Our findings demonstrate that
natural language processing techniques can reveal how definitions of urban
spaces are contested in ways that traditional methods overlook.

</details>


### [76] [ViToSA: Audio-Based Toxic Spans Detection on Vietnamese Speech Utterances](https://arxiv.org/abs/2506.00636)
*Huy Ba Do,Vy Le-Phuong Huynh,Luan Thanh Nguyen*

Main category: cs.CL

TL;DR: 论文提出了首个越南语语音毒性检测数据集ViToSA，并开发了一个结合ASR和毒性检测的流程，显著降低了毒性语音的转录错误率。


<details>
  <summary>Details</summary>
Motivation: 在线平台上的毒性语音问题日益严重，但目前对低资源语言（如越南语）的音频毒性检测研究较少。

Method: 提出了ViToSA数据集（11,000个音频样本），并开发了一个结合ASR和毒性检测的流程。

Result: 实验表明，在ViToSA上微调的ASR模型显著降低了毒性语音的WER，文本毒性检测模型优于现有基线。

Conclusion: ViToSA为越南语语音毒性检测设立了新基准，推动了语音内容审核的未来研究。

Abstract: Toxic speech on online platforms is a growing concern, impacting user
experience and online safety. While text-based toxicity detection is
well-studied, audio-based approaches remain underexplored, especially for
low-resource languages like Vietnamese. This paper introduces ViToSA
(Vietnamese Toxic Spans Audio), the first dataset for toxic spans detection in
Vietnamese speech, comprising 11,000 audio samples (25 hours) with accurate
human-annotated transcripts. We propose a pipeline that combines ASR and toxic
spans detection for fine-grained identification of toxic content. Our
experiments show that fine-tuning ASR models on ViToSA significantly reduces
WER when transcribing toxic speech, while the text-based toxic spans detection
(TSD) models outperform existing baselines. These findings establish a novel
benchmark for Vietnamese audio-based toxic spans detection, paving the way for
future research in speech content moderation.

</details>


### [77] [Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution's Characteristics](https://arxiv.org/abs/2506.00637)
*Lorenzo Jaime Yu Flores,Ori Ernst,Jackie Chi Kit Cheung*

Main category: cs.CL

TL;DR: 论文提出了一种任务无关的置信度度量方法，用于改进文本生成模型的校准，无需额外微调或启发式方法。


<details>
  <summary>Details</summary>
Motivation: 模型置信度分数在文本生成中校准不佳，可能导致低质量或危险预测。现有方法未充分考虑生成任务中多个有效答案的情况。

Method: 提出基于模型输出概率的任务无关置信度度量方法，适用于生成任务。

Result: 在BART和Flan-T5模型上，该方法在摘要、翻译和问答任务中改进了置信度校准。

Conclusion: 任务无关的置信度度量方法能有效提升文本生成模型的校准效果。

Abstract: Well-calibrated model confidence scores can improve the usefulness of text
generation models. For example, users can be prompted to review predictions
with low confidence scores, to prevent models from returning bad or potentially
dangerous predictions. However, confidence metrics are not always well
calibrated in text generation. One reason is that in generation, there can be
many valid answers, which previous methods do not always account for. Hence, a
confident model could distribute its output probability among multiple
sequences because they are all valid. We propose task-agnostic confidence
metrics suited to generation, which rely solely on the probabilities associated
with the model outputs without the need for further fine-tuning or heuristics.
Using these, we are able to improve the calibration of BART and Flan-T5 on
summarization, translation, and QA datasets.

</details>


### [78] [SATA-BENCH: Select All That Apply Benchmark for Multiple Choice Questions](https://arxiv.org/abs/2506.00643)
*Weijie Xu,Shixian Cui,Xi Fang,Chi Xue,Stephanie Eckman,Chandan Reddy*

Main category: cs.CL

TL;DR: 论文介绍了SATA-BENCH，首个用于评估大语言模型（LLMs）在多选任务（SATA）中表现的基准测试，揭示了LLMs在此类任务中的显著不足，并提出了一种名为Choice Funnel的解码策略以提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实问题常需从多个选项中识别所有正确答案，但LLMs在此类任务中的能力尚未充分研究。

Method: 提出了SATA-BENCH基准测试，评估了27种开源和专有模型，并开发了Choice Funnel解码策略，结合去偏和自适应阈值技术。

Result: 最强模型在多选任务中仅达到41.8%的精确匹配率，Choice Funnel将性能提升29%，同时降低64%的推理成本。

Conclusion: 研究揭示了LLMs在多选任务中的核心挑战，并提出了改进框架，为实际应用中的多答案推理提供了新方向。

Abstract: Large language models (LLMs) are increasingly evaluated on single-answer
multiple-choice tasks, yet many real-world problems require identifying all
correct answers from a set of options. This capability remains underexplored.
We introduce SATA-BENCH, the first dedicated benchmark for evaluating LLMs on
Select All That Apply (SATA) questions across diverse domains, including
reading comprehension, law, and biomedicine. Our evaluation of 27 open-source
and proprietary models reveals a significant gap: even the strongest model
achieves only 41.8% exact match, exposing LLMs' inability to reliably identify
all correct answers. We find that this weakness stems from two core challenges:
selection bias - models favor certain choices regardless of content, and count
bias - models fail to predict the correct number of answers. To address these
issues, we propose Choice Funnel, a decoding strategy that combines token
debiasing with adaptive thresholding to guide models toward complete and
accurate selections. Choice Funnel achieves up to 29% higher exact match than
competitive baselines while reducing inference cost by over 64%. Our findings
expose fundamental limitations in current LLMs and introduce a new framework
for diagnosing and improving multi-answer reasoning. We release SATA-BENCH and
Choice Funnel to promote LLM development for robust decision-making in
realistic, multi-answer applications.

</details>


### [79] [Clinical Annotations for Automatic Stuttering Severity Assessment](https://arxiv.org/abs/2506.00644)
*Ana Rita Valente,Rufael Marew,Hawau Olamide Toyin,Hamdan Al-Ali,Anelise Bohnen,Inma Becerra,Elsa Marta Soares,Goncalo Leal,Hanan Aldarmaki*

Main category: cs.CL

TL;DR: 本文提出了一种基于临床标准的新口吃标注方案，用于增强FluencyBank数据集，并通过专家标注和多模态特征提高标注质量。


<details>
  <summary>Details</summary>
Motivation: 口吃是一种复杂障碍，需要专业评估和治疗，现有数据集需要更高质量的标注以反映临床实践。

Method: 聘请临床专家标注数据，采用多模态特征（视听）检测和分类口吃时刻、次要行为及紧张评分，并提供基于专家共识的高可靠性测试集。

Result: 实验和分析表明，口吃评估模型的训练和验证需要广泛的临床专业知识。

Conclusion: 新标注方案和高质量数据集为口吃评估模型的开发提供了可靠基础。

Abstract: Stuttering is a complex disorder that requires specialized expertise for
effective assessment and treatment. This paper presents an effort to enhance
the FluencyBank dataset with a new stuttering annotation scheme based on
established clinical standards. To achieve high-quality annotations, we hired
expert clinicians to label the data, ensuring that the resulting annotations
mirror real-world clinical expertise. The annotations are multi-modal,
incorporating audiovisual features for the detection and classification of
stuttering moments, secondary behaviors, and tension scores. In addition to
individual annotations, we additionally provide a test set with highly reliable
annotations based on expert consensus for assessing individual annotators and
machine learning models. Our experiments and analysis illustrate the complexity
of this task that necessitates extensive clinical expertise for valid training
and evaluation of stuttering assessment models.

</details>


### [80] [GuideX: Guided Synthetic Data Generation for Zero-Shot Information Extraction](https://arxiv.org/abs/2506.00649)
*Neil De La Fuente,Oscar Sainz,Iker García-Ferrero,Eneko Agirre*

Main category: cs.CL

TL;DR: GUIDEX是一种新方法，通过自动定义领域特定模式、推断指南并生成合成标记实例，提升了零样本信息抽取的性能。


<details>
  <summary>Details</summary>
Motivation: 传统信息抽取系统需要领域专家设计模式、标注数据和训练模型，成本高昂。大语言模型在零样本信息抽取中表现良好，但在未见领域性能下降。

Method: GUIDEX自动生成领域特定模式、指南和合成标记实例，结合Llama 3.1微调。

Result: GUIDEX在七个零样本命名实体识别基准上达到新SOTA，比之前方法提升7 F1点（无标注数据时），结合标注数据时提升近2 F1点。

Conclusion: GUIDEX显著提升了模型对复杂领域特定模式的理解能力，代码、模型和合成数据集已开源。

Abstract: Information Extraction (IE) systems are traditionally domain-specific,
requiring costly adaptation that involves expert schema design, data
annotation, and model training. While Large Language Models have shown promise
in zero-shot IE, performance degrades significantly in unseen domains where
label definitions differ. This paper introduces GUIDEX, a novel method that
automatically defines domain-specific schemas, infers guidelines, and generates
synthetically labeled instances, allowing for better out-of-domain
generalization. Fine-tuning Llama 3.1 with GUIDEX sets a new state-of-the-art
across seven zeroshot Named Entity Recognition benchmarks. Models trained with
GUIDEX gain up to 7 F1 points over previous methods without humanlabeled data,
and nearly 2 F1 points higher when combined with it. Models trained on GUIDEX
demonstrate enhanced comprehension of complex, domain-specific annotation
schemas. Code, models, and synthetic datasets are available at
neilus03.github.io/guidex.com

</details>


### [81] [Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques](https://arxiv.org/abs/2506.00658)
*Lang Xiong,Raina Gao,Alyssa Jeong,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 论文提出了Sarc7基准，用于分类7种讽刺类型，并开发了一种基于情感的生成方法。实验表明，基于情感提示的Gemini 2.5模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 讽刺因其微妙性对计算模型构成挑战，分类和生成讽刺对理解人类交流至关重要。

Method: 通过标注MUStARD数据集构建Sarc7基准，评估零样本、少样本、思维链（CoT）及新型基于情感提示的分类方法，并提出基于情感的生成方法。

Result: Gemini 2.5模型在基于情感提示下F1分数为0.3664，优于其他设置；人类评估显示其生成成功率比零样本提示高38.46%。

Conclusion: 基于情感的提示方法在讽刺分类和生成中表现优异，为理解讽刺提供了有效工具。

Abstract: Sarcasm is a form of humor where expressions convey meanings opposite to
their literal interpretations. Classifying and generating sarcasm using large
language models is vital for interpreting human communication. Sarcasm poses
challenges for computational models, due to its nuanced nature. We introduce
Sarc7, a benchmark that classifies 7 types of sarcasm: self-deprecating,
brooding, deadpan, polite, obnoxious, raging, and manic by annotating entries
of the MUStARD dataset. Classification was evaluated using zero-shot, few-shot,
chain-of-thought (CoT), and a novel emotion-based prompting technique. We
propose an emotion-based generation method developed by identifying key
components of sarcasm-incongruity, shock value, and context dependency. Our
classification experiments show that Gemini 2.5, using emotion-based prompting,
outperforms other setups with an F1 score of 0.3664. Human evaluators preferred
our emotion-based prompting, with 38.46% more successful generations than
zero-shot prompting.

</details>


### [82] [SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues](https://arxiv.org/abs/2506.00668)
*Martin Kuo,Jianyi Zhang,Aolin Ding,Louis DiValentin,Amin Hass,Benjamin F Morris,Isaac Jacobson,Randolph Linderman,James Kiessling,Nicolas Ramos,Bhavna Gopal,Maziyar Baran Pouyan,Changwei Liu,Hai Li,Yiran Chen*

Main category: cs.CL

TL;DR: STREAM是一种防御机制，通过安全推理对齐技术保护大型语言模型免受多轮对话攻击，同时保持其功能。


<details>
  <summary>Details</summary>
Motivation: 恶意攻击者可能通过多轮对话利用大型语言模型实现有害目标，对社会安全构成威胁。

Method: 构建人工标注的安全推理多轮对话数据集，并微调一个即插即用的安全推理调节器，用于识别多轮对话中的恶意意图。

Result: STREAM显著优于现有防御技术，将攻击成功率降低51.2%，同时保持模型功能。

Conclusion: STREAM是一种有效的防御多轮对话攻击的方法，兼顾安全性和功能性。

Abstract: Malicious attackers can exploit large language models (LLMs) by engaging them
in multi-turn dialogues to achieve harmful objectives, posing significant
safety risks to society. To address this challenge, we propose a novel defense
mechanism: SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues
(STREAM). STREAM defends LLMs against multi-turn attacks while preserving their
functional capabilities. Our approach involves constructing a human-annotated
dataset, the Safety Reasoning Multi-turn Dialogues dataset, which is used to
fine-tune a plug-and-play safety reasoning moderator. This model is designed to
identify malicious intent hidden within multi-turn conversations and alert the
target LLM of potential risks. We evaluate STREAM across multiple LLMs against
prevalent multi-turn attack strategies. Experimental results demonstrate that
our method significantly outperforms existing defense techniques, reducing the
Attack Success Rate (ASR) by 51.2%, all while maintaining comparable LLM
capability.

</details>


### [83] [DeepRAG: Integrating Hierarchical Reasoning and Process Supervision for Biomedical Multi-Hop QA](https://arxiv.org/abs/2506.00671)
*Yuelyu Ji,Hang Zhang,Shiven Verma,Hui Ji,Chun Li,Yushui Han,Yanshan Wang*

Main category: cs.CL

TL;DR: DeepRAG结合DeepSeek和RAG Gym，通过层次化问题分解和检索增强生成优化，显著提升MedHopQA生物医学问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 针对MedHopQA生物医学问答任务的复杂性，提出一种能系统分解复杂查询并提升生物医学准确性的框架。

Method: 集成DeepSeek的层次化问题分解能力和RAG Gym的检索增强生成优化，利用UMLS本体提供概念级奖励信号。

Result: 在MedHopQA数据集上，DeepRAG显著优于基线模型，包括独立的DeepSeek和RAG Gym，在精确匹配和概念级准确性上均有显著提升。

Conclusion: DeepRAG通过结合层次化分解和检索增强生成优化，有效提升了生物医学问答任务的性能。

Abstract: We propose DeepRAG, a novel framework that integrates DeepSeek hierarchical
question decomposition capabilities with RAG Gym unified retrieval-augmented
generation optimization using process level supervision. Targeting the
challenging MedHopQA biomedical question answering task, DeepRAG systematically
decomposes complex queries into precise sub-queries and employs concept level
reward signals informed by the UMLS ontology to enhance biomedical accuracy.
Preliminary evaluations on the MedHopQA dataset indicate that DeepRAG
significantly outperforms baseline models, including standalone DeepSeek and
RAG Gym, achieving notable improvements in both Exact Match and concept level
accuracy.

</details>


### [84] [Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments](https://arxiv.org/abs/2506.00694)
*Li Zhang,Morgan Gray,Jaromir Savelka,Kevin D. Ashley*

Main category: cs.CL

TL;DR: 该论文提出了一种自动化评估大型语言模型（LLM）在生成法律论证任务中表现的方法，重点关注真实性、因素利用和适当弃权。研究发现LLM在避免幻觉方面表现良好，但在因素利用和弃权能力上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在法律任务中的可靠性，特别是在生成法律论证时的真实性、因素利用和弃权能力。

Method: 设计自动化管道，使用外部LLM提取生成论证中的因素，并与输入案例的真实因素对比。测试了八种LLM在三种难度递增的任务上的表现。

Result: LLM在避免幻觉方面准确率超过90%，但未能充分利用相关因素，且在缺乏共同因素时无法有效弃权。

Conclusion: 自动化评估方法揭示了LLM在法律任务中的局限性，强调了改进因素利用和弃权能力的必要性。

Abstract: Large Language Models (LLMs) demonstrate potential in complex legal tasks
like argument generation, yet their reliability remains a concern. Building
upon pilot work assessing LLM generation of 3-ply legal arguments using human
evaluation, this paper introduces an automated pipeline to evaluate LLM
performance on this task, specifically focusing on faithfulness (absence of
hallucination), factor utilization, and appropriate abstention. We define
hallucination as the generation of factors not present in the input case
materials and abstention as the model's ability to refrain from generating
arguments when instructed and no factual basis exists. Our automated method
employs an external LLM to extract factors from generated arguments and
compares them against the ground-truth factors provided in the input case
triples (current case and two precedent cases). We evaluated eight distinct
LLMs on three tests of increasing difficulty: 1) generating a standard 3-ply
argument, 2) generating an argument with swapped precedent roles, and 3)
recognizing the impossibility of argument generation due to lack of shared
factors and abstaining. Our findings indicate that while current LLMs achieve
high accuracy (over 90%) in avoiding hallucination on viable argument
generation tests (Tests 1 & 2), they often fail to utilize the full set of
relevant factors present in the cases. Critically, on the abstention test (Test
3), most models failed to follow instructions to stop, instead generating
spurious arguments despite the lack of common factors. This automated pipeline
provides a scalable method for assessing these crucial LLM behaviors,
highlighting the need for improvements in factor utilization and robust
abstention capabilities before reliable deployment in legal settings. Project
page:
https://github.com/lizhang-AIandLaw/Measuring-Faithfulness-and-Abstention.

</details>


### [85] [From Argumentative Text to Argument Knowledge Graph: A New Framework for Structured Argumentation](https://arxiv.org/abs/2506.00713)
*Debarati Bhattacharjee,Ashish Anand*

Main category: cs.CL

TL;DR: 该论文提出了一种将论证文本转换为论证知识图（AKG）的框架，通过构建知识库图和推理规则，生成具有丰富属性的AKG，以支持未来的推理任务。


<details>
  <summary>Details</summary>
Motivation: 现有的论证数据集难以检测隐含的间接关系和削弱攻击，因此需要一种更直观且支持推理的图形化表示方法。

Method: 通过标注论证组件和关系，构建知识库图，应用假言推理形成论证，并生成AKG。同时识别缺失的推理规则以发现隐含关系。

Result: 生成的AKG能够直观展示论证结构，并支持检测隐含的间接关系和削弱攻击，为未来推理任务奠定基础。

Conclusion: AKG框架为论证分析提供了更直观的图形化表示，并支持隐含关系的推理，未来可用于论证一致性和修订机会的检查。

Abstract: This paper presents a framework to convert argumentative texts into argument
knowledge graphs (AKG). Starting with basic annotations of argumentative
components (ACs) and argumentative relations (ARs), we enrich the information
by constructing a knowledge base (KB) graph with metadata attributes for nodes.
Next, we use premises and inference rules from the KB to form arguments by
applying modus ponens. From these arguments, we create an AKG. The nodes and
edges of the AKG have attributes that capture important argumentative features.
We also find missing inference rules by identifying markers. This makes it
possible to identify undercut attacks that were previously undetectable in
existing datasets. The AKG gives a graphical view of the argumentative
structure that is easier to understand than theoretical formats. It also
prepares the ground for future reasoning tasks, including checking the
coherence of arguments and identifying opportunities for revision. For this, it
is important to find indirect relations, many of which are implicit. Our
proposed AKG format, with annotated inference rules and modus ponens, will help
reasoning models learn the implicit indirect relations that require inference
over arguments and the relations between them.

</details>


### [86] [Chain-of-Thought Training for Open E2E Spoken Dialogue Systems](https://arxiv.org/abs/2506.00722)
*Siddhant Arora,Jinchuan Tian,Hayato Futami,Jee-weon Jung,Jiatong Shi,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe*

Main category: cs.CL

TL;DR: 提出了一种基于思维链（CoT）的端到端（E2E）语音对话系统训练方法，解决了现有方法需要大量数据且生成语义不连贯的问题，并在小规模公开数据集上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 传统级联式语音对话系统缺乏端到端的可微性，而现有E2E方法需要大量训练数据且生成结果语义不连贯。本文旨在解决这些问题。

Method: 采用思维链（CoT）策略，将对话数据训练与多模态语言模型的预训练任务（如语音识别、文本生成等）紧密结合。

Result: 在公开的人类对话数据集（如Switchboard）上，仅需300小时数据即可训练，ROUGE-1分数比基线提高1.5以上。

Conclusion: 该方法简单高效，适用于小规模数据训练，并计划公开模型和训练代码。

Abstract: Unlike traditional cascaded pipelines, end-to-end (E2E) spoken dialogue
systems preserve full differentiability and capture non-phonemic information,
making them well-suited for modeling spoken interactions. However, existing E2E
approaches often require large-scale training data and generates responses
lacking semantic coherence. We propose a simple yet effective strategy
leveraging a chain-of-thought (CoT) formulation, ensuring that training on
conversational data remains closely aligned with the multimodal language model
(LM)'s pre-training on speech recognition~(ASR), text-to-speech synthesis
(TTS), and text LM tasks. Our method achieves over 1.5 ROUGE-1 improvement over
the baseline, successfully training spoken dialogue systems on publicly
available human-human conversation datasets, while being compute-efficient
enough to train on just 300 hours of public human-human conversation data, such
as the Switchboard. We will publicly release our models and training code.

</details>


### [87] [Structured Gradient Guidance for Few-Shot Adaptation in Large Language Models](https://arxiv.org/abs/2506.00726)
*Hongye Zheng,Yichen Wang,Ray Pan,Guiran Liu,Binrong Zhu,Hanlu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种梯度感知的微调方法，用于少样本条件下的大语言模型，旨在提升任务适应性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 在数据有限的情况下，如何增强大语言模型的任务适应性和训练稳定性是研究的核心动机。

Method: 基于基础损失函数，引入两个梯度相关的正则项：梯度方向一致性和梯度幅度控制，并结合梯度对齐机制提升跨任务泛化能力。

Result: 在多种自然语言理解任务中，该方法在平均准确率、梯度稳定性和方向对齐方面优于现有微调策略。

Conclusion: 梯度感知的微调框架能有效利用大语言模型的表示能力，确保训练稳定性并减少对大量标注数据的依赖。

Abstract: This paper presents a gradient-informed fine-tuning method for large language
models under few-shot conditions. The goal is to enhance task adaptability and
training stability when data is limited. The method builds on a base loss
function and introduces two gradient-related regularization terms. The first
enforces gradient direction consistency to guide parameter updates along
task-relevant directions and prevent drift. The second controls gradient
magnitude to avoid abnormal updates. Together, these components support a more
efficient and stable optimization path. To further improve cross-task
generalization, the method incorporates a gradient alignment mechanism. This
mechanism measures the consistency between optimization directions of the
source and target tasks. It enhances fine-tuning performance in multi-task and
cross-domain scenarios. Across various natural language understanding tasks,
the method outperforms existing fine-tuning strategies in average accuracy,
gradient stability, and directional alignment. Empirical evaluations under
different sample sizes and domain-specific tasks confirm the method's
robustness and broad applicability in low-resource environments. In particular,
the method shows clear advantages in controlling parameter update paths. The
results demonstrate that a gradient-based fine-tuning framework can effectively
leverage the representational power of large language models. It ensures
training stability while reducing dependence on large volumes of labeled data.

</details>


### [88] [Narrative Media Framing in Political Discourse](https://arxiv.org/abs/2506.00737)
*Yulia Otmakhova,Lea Frermann*

Main category: cs.CL

TL;DR: 论文提出了一种将叙事框架与基本框架要素结合的方法，并开发了一个形式化框架，用于自动分析叙事框架。通过标注气候变化的新闻数据集，分析了叙事框架在不同政治倾向中的分布，并测试了LLMs预测叙事框架的能力。最后，该方法在COVID-19领域的无监督应用中验证了其普适性。


<details>
  <summary>Details</summary>
Motivation: 叙事框架是传达复杂争议性观点的有效工具，但目前自动化框架分析大多忽略了这一工具。

Method: 将叙事性与框架要素结合，提出形式化框架；标注气候变化新闻数据集，分析叙事框架组件的政治倾向分布；测试LLMs预测能力；在COVID-19领域进行无监督应用验证。

Result: 叙事框架组件在不同政治倾向中存在差异；LLMs能有效预测叙事框架；COVID-19领域的无监督应用结果与理论一致。

Conclusion: 提出的框架能有效形式化和操作化叙事框架，具有跨领域的普适性。

Abstract: Narrative frames are a powerful way of conceptualizing and communicating
complex, controversial ideas, however automated frame analysis to date has
mostly overlooked this framing device. In this paper, we connect elements of
narrativity with fundamental aspects of framing, and present a framework which
formalizes and operationalizes such aspects. We annotate and release a data set
of news articles in the climate change domain, analyze the dominance of
narrative frame components across political leanings, and test LLMs in their
ability to predict narrative frames and their components. Finally, we apply our
framework in an unsupervised way to elicit components of narrative framing in a
second domain, the COVID-19 crisis, where our predictions are congruent with
prior theoretical work showing the generalizability of our approach.

</details>


### [89] [DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments](https://arxiv.org/abs/2506.00739)
*Chiyu Zhang,Marc-Alexandre Cote,Michael Albada,Anush Sankaran,Jack W. Stokes,Tong Wang,Amir Abdi,William Blum,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: DefenderBench是一个开源工具包，用于评估语言模型在网络安全任务中的表现，包括入侵检测、恶意内容分析和漏洞分析等。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在网络安全领域的潜力，并提供一种公平、严谨且易于使用的评估工具。

Method: 设计了模块化的DefenderBench工具包，支持标准化评估框架，测试了多种先进语言模型。

Result: Claude-3.7-sonnet表现最佳（得分81.65），开源模型Llama 3.3 70B紧随其后（得分71.81）。

Conclusion: DefenderBench为研究社区提供了一个可扩展、公平的评估平台，促进了语言模型在网络安全领域的应用。

Abstract: Large language model (LLM) agents have shown impressive capabilities in human
language comprehension and reasoning, yet their potential in cybersecurity
remains underexplored. We introduce DefenderBench, a practical, open-source
toolkit for evaluating language agents across offense, defense, and
cybersecurity knowledge-based tasks. DefenderBench includes environments for
network intrusion, malicious content detection, code vulnerability analysis,
and cybersecurity knowledge assessment. It is intentionally designed to be
affordable and easily accessible for researchers while providing fair and
rigorous assessment. We benchmark several state-of-the-art (SoTA) and popular
LLMs, including both open- and closed-weight models, using a standardized
agentic framework. Our results show that Claude-3.7-sonnet performs best with a
DefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40,
while the best open-weight model, Llama 3.3 70B, is not far behind with a
DefenderBench score of 71.81. DefenderBench's modular design allows seamless
integration of custom LLMs and tasks, promoting reproducibility and fair
comparisons. An anonymized version of DefenderBench is available at
https://github.com/microsoft/DefenderBench.

</details>


### [90] [Length Aware Speech Translation for Video Dubbing](https://arxiv.org/abs/2506.00740)
*Harveen Singh Chadha,Aswin Shanmugam Subramanian,Vikas Joshi,Shubham Bansal,Jian Xue,Rupeshkumar Mehta,Jinyu Li*

Main category: cs.CL

TL;DR: 提出了一种基于音素的端到端长度敏感语音翻译模型（LSST）和长度感知束搜索（LABS），用于实时视频配音，显著提升了源音频与目标音频的同步质量。


<details>
  <summary>Details</summary>
Motivation: 解决视频配音中翻译音频与源音频对齐的挑战，特别是在实时、设备端场景下的需求。

Method: 开发了LSST模型，通过预定义标签生成不同长度的翻译，并引入LABS方法在单次解码中生成多种长度的翻译。

Result: 在保持BLEU分数可比性的同时，显著提升了同步质量，西班牙语和韩语的MOS分别提高了0.34和0.65。

Conclusion: LSST和LABS方法有效解决了视频配音中的同步问题，适用于实时场景。

Abstract: In video dubbing, aligning translated audio with the source audio is a
significant challenge. Our focus is on achieving this efficiently, tailored for
real-time, on-device video dubbing scenarios. We developed a phoneme-based
end-to-end length-sensitive speech translation (LSST) model, which generates
translations of varying lengths short, normal, and long using predefined tags.
Additionally, we introduced length-aware beam search (LABS), an efficient
approach to generate translations of different lengths in a single decoding
pass. This approach maintained comparable BLEU scores compared to a baseline
without length awareness while significantly enhancing synchronization quality
between source and target audio, achieving a mean opinion score (MOS) gain of
0.34 for Spanish and 0.65 for Korean, respectively.

</details>


### [91] [Data Swarms: Optimizable Generation of Synthetic Evaluation Data](https://arxiv.org/abs/2506.00741)
*Shangbin Feng,Yike Wang,Weijia Shi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: Data Swarms算法通过粒子群优化生成合成评估数据，提升LLM评估的定量目标。Adversarial Swarms进一步实现数据生成与模型学习的协同进化。


<details>
  <summary>Details</summary>
Motivation: 优化合成评估数据的生成，以更好地满足LLM评估的定量需求，如生成更具挑战性的问题。

Method: 1. 训练初始数据生成器群；2. 定义评估目标；3. 使用粒子群优化优化生成器群；4. 扩展为对抗性群，实现数据与模型的协同进化。

Result: Data Swarms在五个评估目标上优于八种基线方法，Adversarial Swarms提升了数据的鲁棒性和模型的泛化能力。

Conclusion: Data Swarms能有效优化多目标组合，并泛化至未见的LLM，为评估数据生成提供了新方法。

Abstract: We propose Data Swarms, an algorithm to optimize the generation of synthetic
evaluation data and advance quantitative desiderata of LLM evaluation. We first
train a swarm of initial data generators using existing data, and define
various evaluation objectives to reflect the desired properties of evaluation
(e.g., generate more difficult problems for the evaluated models) and
quantitatively evaluate data generators. We then employ particle swarm
optimization to optimize the swarm of data generators, where they
collaboratively search through the model parameter space to find new generators
that advance these objectives. We further extend it to Adversarial Swarms,
where the data generator swarm generates harder data while the test taker model
swarm learns from such data, co-evolving dynamically for better data and models
simultaneously. Extensive experiments demonstrate that Data Swarms outperforms
eight data generation baselines across five evaluation objectives, while
Adversarial Swarms produce more robust learning of synthetic data and stronger
generalization. Further analysis reveals that Data Swarms successfully
optimizes compositions of multiple evaluation objectives and generalizes to new
off-the-shelf LLMs, unseen at optimization time.

</details>


### [92] [Assortment of Attention Heads: Accelerating Federated PEFT with Head Pruning and Strategic Client Selection](https://arxiv.org/abs/2506.00743)
*Yeshwanth Venkatesha,Souvik Kundu,Priyadarshini Panda*

Main category: cs.CL

TL;DR: 本文提出了一种在联邦学习框架中高效执行参数高效微调（PEFT）的方法，通过头剪枝、加权聚合机制和客户端选择策略解决资源受限和数据分布多样化的挑战。


<details>
  <summary>Details</summary>
Motivation: 在隐私保护的分布式学习框架（如联邦学习）中，参数高效微调（PEFT）的应用仍有限，主要由于资源受限设备和客户端数据分布多样化的挑战。

Method: 采用头剪枝降低训练复杂度，基于注意力头的重要性评分；提出头特定的加权聚合机制和客户端选择策略，确保全局模型捕获关键更新。

Result: 在MultiNLI等数据集上，使用T5-small模型和LoRA方法，实现了90%的稀疏度，通信优势达1.8倍，训练操作减少3.9倍，精度下降控制在2%以内。

Conclusion: 该方法在联邦学习中高效实现了PEFT，显著降低了通信和计算成本，同时保持了模型性能。

Abstract: Parameter Efficient Fine-Tuning (PEFT) has become the de-facto approach in
adapting Large Language Models (LLMs) for downstream tasks in Natural Language
Processing. However, its adoption in privacy-preserving distributed learning
frameworks, such as Federated Learning (FL), remains relatively limited. This
is mainly due to challenges specific to FL, such as resource-constrained
devices and diverse data distributions among clients. In this paper, we propose
an efficient method to perform PEFT within the FL framework for Multi-Head
Attention (MHA) based language models. We address the challenges through head
pruning, a novel head-specific weighted aggregation mechanism, and a client
selection strategy. Head pruning minimizes training complexity within the
clients, guided by the importance score computed based on the confidence of the
attention head. Weighted aggregation of heads ensures the global model captures
crucial updates from diverse clients complementing our client selection
strategy. We show results on the MultiNLI benchmark along with 20 Newsgroups,
XL-Sum, and E2E NLG datasets. We use the MultiNLI dataset and T5-small model
with LoRA as our PEFT method, attaining sparsity levels of up to 90%, resulting
in a communication advantage of up to 1.8x and a reduction in training OPs of
3.9x while maintaining the accuracy drop under 2%.

</details>


### [93] [Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in Large Language Model Translations](https://arxiv.org/abs/2506.00748)
*Pardis Sadat Zahraei,Ali Emami*

Main category: cs.CL

TL;DR: 论文介绍了Translate-with-Care (TWC)数据集，用于评估机器翻译系统在性别偏见和逻辑一致性方面的表现，发现现有模型普遍存在性别刻板印象和推理错误，并提出通过微调mBART-50显著改善这些问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器翻译中的性别偏见和逻辑一致性问题，特别是在自然性别语言（如英语）与无性别语言（如波斯语、印尼语、芬兰语）之间的翻译。

Method: 引入TWC数据集（3,950个挑战性场景），评估多种技术（如GPT-4、mBART-50、NLLB-200、Google Translate），并通过微调mBART-50优化性能。

Result: 所有模型在翻译无性别内容时表现不佳，倾向于使用男性代词，尤其是Google Translate和GPT-4。微调mBART-50显著减少了偏见和错误，并超越了专有模型。

Conclusion: 研究强调需要针对性别和语义一致性的方法，特别是在无性别语言中，以构建更公平和准确的翻译系统。

Abstract: Addressing gender bias and maintaining logical coherence in machine
translation remains challenging, particularly when translating between natural
gender languages, like English, and genderless languages, such as Persian,
Indonesian, and Finnish. We introduce the Translate-with-Care (TWC) dataset,
comprising 3,950 challenging scenarios across six low- to mid-resource
languages, to assess translation systems' performance. Our analysis of diverse
technologies, including GPT-4, mBART-50, NLLB-200, and Google Translate,
reveals a universal struggle in translating genderless content, resulting in
gender stereotyping and reasoning errors. All models preferred masculine
pronouns when gender stereotypes could influence choices. Google Translate and
GPT-4 showed particularly strong bias, favoring male pronouns 4-6 times more
than feminine ones in leadership and professional success contexts. Fine-tuning
mBART-50 on TWC substantially resolved these biases and errors, led to strong
generalization, and surpassed proprietary LLMs while remaining open-source.
This work emphasizes the need for targeted approaches to gender and semantic
coherence in machine translation, particularly for genderless languages,
contributing to more equitable and accurate translation systems.

</details>


### [94] [Understanding and Mitigating Cross-lingual Privacy Leakage via Language-specific and Universal Privacy Neurons](https://arxiv.org/abs/2506.00759)
*Wenshuo Dong,Qingsong Yang,Shu Yang,Lijie Hu,Meng Ding,Wanyu Lin,Tianhang Zheng,Di Wang*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLM）在多语言环境下的隐私泄露风险，并提出通过识别和停用隐私通用神经元和语言特定隐私神经元来降低风险。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究通过隐私神经元等方法缓解隐私泄露风险，但这些方法仅适用于英语环境。论文旨在解决跨语言场景下的隐私泄露问题。

Method: 研究分析了跨语言隐私泄露的信息流，发现隐私信息主要在中间层处理，并在后期层转换为语言特定空间时风险最高。通过识别隐私通用神经元和语言特定隐私神经元，并停用它们来降低风险。

Result: 停用这些神经元后，跨语言隐私泄露风险降低了23.3%-31.6%。

Conclusion: 论文揭示了跨语言隐私泄露的机制，并提出了一种有效的缓解方法，为多语言环境下的隐私保护提供了新思路。

Abstract: Large Language Models (LLMs) trained on massive data capture rich information
embedded in the training data. However, this also introduces the risk of
privacy leakage, particularly involving personally identifiable information
(PII). Although previous studies have shown that this risk can be mitigated
through methods such as privacy neurons, they all assume that both the
(sensitive) training data and user queries are in English. We show that they
cannot defend against the privacy leakage in cross-lingual contexts: even if
the training data is exclusively in one language, these (private) models may
still reveal private information when queried in another language. In this
work, we first investigate the information flow of cross-lingual privacy
leakage to give a better understanding. We find that LLMs process private
information in the middle layers, where representations are largely shared
across languages. The risk of leakage peaks when converted to a
language-specific space in later layers. Based on this, we identify
privacy-universal neurons and language-specific privacy neurons.
Privacy-universal neurons influence privacy leakage across all languages, while
language-specific privacy neurons are only related to specific languages. By
deactivating these neurons, the cross-lingual privacy leakage risk is reduced
by 23.3%-31.6%.

</details>


### [95] [Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models](https://arxiv.org/abs/2506.00773)
*Boheng Sheng,Jiacheng Yao,Meicong Zhang,Guoxiu He*

Main category: cs.CL

TL;DR: 提出了一种动态分割长文本的方法，通过计算相邻句子的语义相似度来划分可变长度块，并结合问题感知分类器选择关键块，显著提升了LLMs对长文本的理解能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理长文本时，固定长度的截断方法可能导致语义相关内容的分离，影响理解准确性。

Method: 计算相邻句子的语义相似度，动态分割长文本为可变长度块；训练问题感知分类器选择关键块。

Result: 在单跳和多跳问答基准测试中表现优于基线方法，支持长达256k token的输入。

Conclusion: 动态分割和选择方法有效提升了LLMs对长文本的理解能力，具有广泛适用性。

Abstract: Large language models (LLMs) often struggle to accurately read and comprehend
extremely long texts. Current methods for improvement typically rely on
splitting long contexts into fixed-length chunks. However, fixed truncation
risks separating semantically relevant content, leading to ambiguity and
compromising accurate understanding. To overcome this limitation, we propose a
straightforward approach for dynamically separating and selecting chunks of
long context, facilitating a more streamlined input for LLMs. In particular, we
compute semantic similarities between adjacent sentences, using lower
similarities to adaptively divide long contexts into variable-length chunks. We
further train a question-aware classifier to select sensitive chunks that are
critical for answering specific questions. Experimental results on both
single-hop and multi-hop question-answering benchmarks show that the proposed
approach consistently outperforms strong baselines. Notably, it maintains
robustness across a wide range of input lengths, handling sequences of up to
256k tokens. Our datasets and code are available at the following link:
https://github.com/ECNU-Text-Computing/DCS

</details>


### [96] [Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge](https://arxiv.org/abs/2506.00777)
*Md Tahmid Rahman Laskar,Israt Jahan,Elham Dolatabadi,Chun Peng,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TL;DR: 论文探讨了使用LLMs作为评估者（LLM-as-the-Judge）在生物医学关系抽取任务中的可行性，发现其表现较差（通常低于50%准确率），并提出结构化输出格式和领域适应技术以提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动评估指标在生物医学关系抽取任务中不可靠，而人工评估成本高且耗时。因此，研究LLMs作为替代评估方法的有效性。

Method: 对8个LLMs作为评估者进行基准测试，评估5个LLMs在3个生物医学关系抽取数据集上的表现，并提出结构化输出格式和领域适应技术。

Result: LLM-based评估者在生物医学关系抽取任务中表现较差，结构化输出格式使其性能平均提升15%，领域适应技术进一步优化了结果。

Conclusion: 结构化输出格式和领域适应技术可显著提升LLM-based评估者在生物医学关系抽取任务中的性能，为实际应用提供了可行方案。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance in
biomedical relation extraction, even in zero-shot scenarios. However,
evaluating LLMs in this task remains challenging due to their ability to
generate human-like text, often producing synonyms or abbreviations of
gold-standard answers, making traditional automatic evaluation metrics
unreliable. On the other hand, while human evaluation is more reliable, it is
costly and time-consuming, making it impractical for real-world applications.
This paper investigates the use of LLMs-as-the-Judge as an alternative
evaluation method for biomedical relation extraction. We benchmark 8 LLMs as
judges to evaluate the responses generated by 5 other LLMs across 3 biomedical
relation extraction datasets. Unlike other text-generation tasks, we observe
that LLM-based judges perform quite poorly (usually below 50% accuracy) in the
biomedical relation extraction task. Our findings reveal that it happens mainly
because relations extracted by LLMs do not adhere to any standard format. To
address this, we propose structured output formatting for LLM-generated
responses that helps LLM-Judges to improve their performance by about 15% (on
average). We also introduce a domain adaptation technique to further enhance
LLM-Judge performance by effectively transferring knowledge between datasets.
We release both our human-annotated and LLM-annotated judgment data (36k
samples in total) for public use here:
https://github.com/tahmedge/llm_judge_biomedical_re.

</details>


### [97] [KG-TRACES: Enhancing Large Language Models with Knowledge Graph-constrained Trajectory Reasoning and Attribution Supervision](https://arxiv.org/abs/2506.00783)
*Rong Wu,Pinlong Cai,Jianbiao Mei,Licheng Wen,Tao Hu,Xuemeng Yang,Daocheng Fu,Botian Shi*

Main category: cs.CL

TL;DR: KG-TRACES框架通过显式监督推理路径和过程，提升大语言模型在复杂推理任务中的表现，同时增强其可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中表现不佳，缺乏可解释性和可信度，限制了其应用。

Method: 提出KG-TRACES框架，联合监督模型预测符号关系路径、完整三元组推理路径，并生成基于推理路径的归因感知推理过程。

Result: 在WebQSP和CWQ任务中显著优于现有方法，Hits@1和F1分数均有提升，并展示了在医学等领域的迁移能力。

Conclusion: KG-TRACES通过显式监督实现了更稳定、目标明确的推理过程，显著提升了模型的可解释性和性能。

Abstract: Large language models (LLMs) have made remarkable strides in various natural
language processing tasks, but their performance on complex reasoning problems
remains hindered by a lack of explainability and trustworthiness. This issue,
often manifesting as hallucinations or unattributable reasoning processes,
limits their applicability in complex reasoning scenarios. To address this, we
propose Knowledge Graph-constrained Trajectory Reasoning Attribution and Chain
Explanation Supervision (KG-TRACES), a novel framework that enhances the
reasoning ability of LLMs through explicit supervision over reasoning paths and
processes. KG-TRACES jointly supervises the model to: (1) predict symbolic
relation paths, (2) predict full triple-level reasoning paths, and (3) generate
attribution-aware reasoning processes grounded in the reasoning paths. At
inference phase, the model adapts to both KG-available and KG-unavailable
scenarios, retrieving reasoning paths from a KG when possible or predicting
plausible reasoning paths with only intrinsic knowledge when not. This design
enables the model to reason in an explainable and source-attributable pattern.
Through extensive experiments on complex reasoning tasks, we demonstrate that
KG-TRACES significantly outperforms existing SOTA: it improves Hits@1 by 1.6%
and F1 by 4.7% on WebQSP, and achieves improvements of 4.8% in Hits@1 and 2.1%
in F1 on CWQ. Moreover, we show its transferability to specialized domains such
as medicine. By visualizing the intermediate steps of reasoning processes, we
further show that the explicit supervision introduced by KG-TRACES leads to
more stable and goal-directed reasoning processes, aligning closely with
correct answers. Code is available at https://github.com/Edaizi/KG-TRACES.

</details>


### [98] [Research Borderlands: Analysing Writing Across Research Cultures](https://arxiv.org/abs/2506.00784)
*Shaily Bhatt,Tal August,Maria Antoniak*

Main category: cs.CL

TL;DR: 本文提出了一种以人为中心的方法，通过访谈跨学科研究人员，构建了一个框架来衡量语言技术中的文化能力，并揭示了LLM在文化适应性上的不足。


<details>
  <summary>Details</summary>
Motivation: 提升语言技术的文化能力，但现有研究多依赖合成设置和不完美的文化代理，缺乏与社区的互动。

Method: 通过访谈跨学科研究人员，构建了结构、风格、修辞和引用规范的框架，并用计算指标量化这些特征。

Result: 揭示了人类研究论文中的潜在文化规范，并指出LLM在文化适应性上的不足和写作同质化倾向。

Conclusion: 以人为中心的方法能有效衡量人类和LLM生成文本中的文化规范。

Abstract: Improving cultural competence of language technologies is important. However
most recent works rarely engage with the communities they study, and instead
rely on synthetic setups and imperfect proxies of culture. In this work, we
take a human-centered approach to discover and measure language-based cultural
norms, and cultural competence of LLMs. We focus on a single kind of culture,
research cultures, and a single task, adapting writing across research
cultures. Through a set of interviews with interdisciplinary researchers, who
are experts at moving between cultures, we create a framework of structural,
stylistic, rhetorical, and citational norms that vary across research cultures.
We operationalise these features with a suite of computational metrics and use
them for (a) surfacing latent cultural norms in human-written research papers
at scale; and (b) highlighting the lack of cultural competence of LLMs, and
their tendency to homogenise writing. Overall, our work illustrates the
efficacy of a human-centered approach to measuring cultural norms in
human-written and LLM-generated texts.

</details>


### [99] [RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2506.00789)
*Yixiao Zeng,Tianyu Cao,Danqing Wang,Xinran Zhao,Zimeng Qiu,Morteza Ziyadi,Tongshuang Wu,Lei Li*

Main category: cs.CL

TL;DR: RARE框架通过知识图谱驱动的合成管道（RARE-Get）生成多级问题集，测试RAG系统在动态、时间敏感语料库中的鲁棒性，发现RAG系统对扰动表现出明显脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有评估很少测试RAG系统如何应对现实世界噪声、内部与外部检索上下文冲突或快速变化的事实。

Method: 引入RARE框架，包括知识图谱驱动的合成管道（RARE-Get）生成问题集，构建数据集（RARE-Set），并定义检索条件鲁棒性指标（RARE-Met）。

Result: RAG系统对扰动表现出明显脆弱性，文档鲁棒性是最薄弱环节，多跳查询的鲁棒性普遍低于单跳查询。

Conclusion: RARE为RAG系统鲁棒性评估提供了统一框架，揭示了其在动态环境中的不足。

Abstract: Retrieval-Augmented Generation (RAG) enhances recency and factuality in
answers. However, existing evaluations rarely test how well these systems cope
with real-world noise, conflicting between internal and external retrieved
contexts, or fast-changing facts. We introduce Retrieval-Aware Robustness
Evaluation (RARE), a unified framework and large-scale benchmark that jointly
stress-tests query and document perturbations over dynamic, time-sensitive
corpora. One of the central features of RARE is a knowledge-graph-driven
synthesis pipeline (RARE-Get) that automatically extracts single and multi-hop
relations from the customized corpus and generates multi-level question sets
without manual intervention. Leveraging this pipeline, we construct a dataset
(RARE-Set) spanning 400 expert-level time-sensitive finance, economics, and
policy documents and 48,322 questions whose distribution evolves as the
underlying sources change. To quantify resilience, we formalize
retrieval-conditioned robustness metrics (RARE-Met) that capture a model's
ability to remain correct or recover when queries, documents, or real-world
retrieval results are systematically altered. Our results show that RAG systems
exhibit surprising vulnerability to perturbations, with document robustness
consistently being the weakest point regardless of generator size or
architecture. RAG systems consistently show lower robustness on multi-hop
queries than single-hop queries across all domains.

</details>


### [100] [Fast or Slow? Integrating Fast Intuition and Deliberate Thinking for Enhancing Visual Question Answering](https://arxiv.org/abs/2506.00806)
*Songtao Jiang,Chenyi Zhou,Yan Zhang,Yeying Jin,Zuozhu Liu*

Main category: cs.CL

TL;DR: FOCUS是一种动态适应问题复杂度的插件方法，结合直觉与深度分析推理，提升多模态大语言模型在视觉问答中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉问答中不加区分地标注所有对象，导致性能下降，缺乏对关键视觉元素的关注。

Method: 基于双过程理论，FOCUS动态结合快速直觉判断与深度分析推理，对简单问题支持零样本推理，复杂问题则采用先概念化再观察的策略。

Result: 在四个基准测试中，FOCUS显著提升了开源和黑盒模型的性能。

Conclusion: FOCUS通过结合多样化认知策略和精细化视觉信息，显著提升了视觉问答任务的性能。

Abstract: Multimodal large language models (MLLMs) still struggle with complex
reasoning tasks in Visual Question Answering (VQA). While current methods have
advanced by incorporating visual prompts, our study uncovers critical
limitations: these approaches indiscriminately annotate all detected objects
for every visual question, generating excessive visual markers that degrade
task performance. This issue stems primarily from a lack of focus on key visual
elements, raising two important questions: Are all objects equally important,
and do all questions require visual prompts? Motivated by Dual Process Theory,
which distinguishes between instinctive and deliberate cognitive modes in human
reasoning, we propose FOCUS, a plug-and-play approach that dynamically adapts
to the complexity of questions, combining fast intuitive judgments with
deliberate analytical reasoning to enhance the vision-language reasoning
capability of the MLLM. For straightforward questions, FOCUS supports efficient
zero-shot reasoning. For more complex tasks, it employs the conceptualizing
before observation strategy to highlight critical elements. Extensive
experiments on four benchmarks, ScienceQA, TextQA, VizWiz, and MME, demonstrate
that FOCUS consistently improves the performance of both open-source and
black-box MLLMs, achieving significant gains across all datasets. Ablation
studies further validate the importance of combining diverse cognitive
strategies with refined visual information for superior performance. Code will
be released.

</details>


### [101] [GuessBench: Sensemaking Multimodal Creativity in the Wild](https://arxiv.org/abs/2506.00814)
*Zifeng Zhu,Shangbin Feng,Herun Wan,Ningnan Wang,Minnan Luo,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: GuessBench是一个评估视觉语言模型（VLMs）在建模人类创造力方面的新基准，基于Minecraft游戏数据，展示了其在创造力建模中的挑战性。


<details>
  <summary>Details</summary>
Motivation: 研究人类创造力的建模，尤其是在噪声和多样性环境下，VLMs的表现。

Method: 从Minecraft游戏中收集1500张图像并设计2000个问题，测试六种VLMs和五种推理增强方法。

Result: GPT-4o错误率为34%，开源与API模型性能差距显著（13.87% vs. 53.93%）。微调后视觉感知任务提升15.36%。

Conclusion: GuessBench揭示了VLMs在创造力建模中的局限性，尤其是在文化背景和低资源语言中的表现差异。

Abstract: We propose GuessBench, a novel benchmark that evaluates Vision Language
Models (VLMs) on modeling the pervasive, noisy, and pluralistic human
creativity. GuessBench sources data from "Guess the Build", an online
multiplayer Minecraft minigame where one player constructs a Minecraft build
given a concept (e.g. caterpillar) and others try to guess it with natural
language hints, presenting a pristine testbed for sensemaking creativity in the
wild with VLMs acting as guessers. We curate 1500 images from the actual
gameplay and design 2000 problems spanning static and dynamic image settings,
natural language hints of varying completeness, and more. Extensive experiments
with six open/API VLMs and five reasoning enhancement approaches demonstrate
that GuessBench presents a uniquely challenging task in creativity modeling:
even the start-of-the-art GPT-4o is incorrect on 34% of instances, while we
observe a huge performance gap (13.87% vs. 53.93% on average) between open and
API models. When used as a resource to improve VLMs, fine-tuning on the
reasoning traces for GuessBench problems improves visual perception tasks by
15.36% on average. Further analysis reveals that VLM performance in creativity
sensemaking correlates with the frequency of the concept in training data,
while the accuracy drops sharply for concepts in underrepresented cultural
contexts and low-resource languages.

</details>


### [102] [From Plain Text to Poetic Form: Generating Metrically-Constrained Sanskrit Verses](https://arxiv.org/abs/2506.00815)
*Manoj Balaji Jagadeeshan,Samarth Bhatia,Pretam Ray,Harshul Raj Surana,Akhil Rajeev P,Priya Mishra,Annarao Kulkarni,Ganesh Ramakrishnan,Prathosh AP,Pawan Goyal*

Main category: cs.CL

TL;DR: 本文探讨了如何将大型语言模型（LLMs）应用于低资源、形态丰富的语言（如梵语）中的结构化诗歌生成，并提出了一个数据集和多种生成模型评估方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决LLMs在高资源语言中的进展未能惠及低资源语言（如梵语）的问题，特别是在结构化诗歌生成领域。

Method: 方法包括构建一个用于英译梵语诗歌的数据集，评估多种生成模型（开源和专有），并探索约束解码策略和基于指令的微调。

Result: 结果显示，约束解码策略在生成符合语法的诗歌形式上达到99%以上的准确率，而指令微调模型在语义和风格对齐上表现更好，但牺牲了少量韵律精度。

Conclusion: 结论表明，LLMs可以通过特定策略成功适应低资源语言的诗歌生成，但需在韵律精度和语义对齐之间权衡。

Abstract: Recent advances in large language models (LLMs) have significantly improved
natural language generation, including creative tasks like poetry composition.
However, most progress remains concentrated in high-resource languages. This
raises an important question: Can LLMs be adapted for structured poetic
generation in a low-resource, morphologically rich language such as Sanskrit?
In this work, we introduce a dataset designed for translating English prose
into structured Sanskrit verse, with strict adherence to classical metrical
patterns, particularly the Anushtub meter. We evaluate a range of generative
models-both open-source and proprietary-under multiple settings. Specifically,
we explore constrained decoding strategies and instruction-based fine-tuning
tailored to metrical and semantic fidelity. Our decoding approach achieves over
99% accuracy in producing syntactically valid poetic forms, substantially
outperforming general-purpose models in meter conformity. Meanwhile,
instruction-tuned variants show improved alignment with source meaning and
poetic style, as supported by human assessments, albeit with marginal
trade-offs in metrical precision.

</details>


### [103] [One for All: Update Parameterized Knowledge Across Multiple Models](https://arxiv.org/abs/2506.00817)
*Weitao Ma,Xiyuan Du,Xiaocheng Feng,Lei Huang,Yichong Huang,Huiyi Zhang,Xiaoliang Yang,Baohang Li,Xiachong Feng,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: OnceEdit是一种基于集成的新方法，通过插件模型实现多模型的知识编辑，解决了现有方法在更新多模型时的效率问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）难以保持知识更新，导致错误和幻觉。知识编辑是一种高效替代重训练的方法，但现有方法主要针对单个模型，难以适应多模型场景。

Method: OnceEdit采用插件模型作为编辑模块，引入动态权重机制和集成增强机制，优化知识编辑在多模型中的效果。

Result: 实验表明，OnceEdit在多种LLMs上表现优于现有方法，编辑效率更高，且在多模型编辑场景中表现出适应性和稳定性。

Conclusion: OnceEdit为多模型知识编辑提供了一种高效、稳定的解决方案，具有广泛的应用潜力。

Abstract: Large language models (LLMs) encode vast world knowledge but struggle to stay
up-to-date, often leading to errors and hallucinations. Knowledge editing
offers an efficient alternative to retraining, enabling targeted modifications
by updating specific model parameters. However, existing methods primarily
focus on individual models, posing challenges in efficiently updating multiple
models and adapting to new models. To address this, we propose OnceEdit, a
novel ensemble-based approach that employs a plug-in model as the editing
module, enabling stable knowledge updates across multiple models. Building on
the model ensemble, OnceEdit introduces two key mechanisms to enhance its
effectiveness. First, we introduce a dynamic weight mechanism through a \weight
token for distinguishing between edit-related and non-edit-related instances,
ensuring the appropriate utilization of knowledge from integrated models.
Second, we incorporate an ensemble enhancement mechanism to mitigate the
excessive reliance on the central model inherent in the model ensemble
technique, making it more suitable for knowledge editing. Extensive experiments
on diverse LLMs demonstrate that OnceEdit consistently outperforms existing
methods while achieving superior editing efficiency. Further analysis confirms
its adaptability and stability in multi-model editing scenarios. Our code will
be available.

</details>


### [104] [Probing the Geometry of Truth: Consistency and Generalization of Truth Directions in LLMs Across Logical Transformations and Question Answering Tasks](https://arxiv.org/abs/2506.00823)
*Yuntai Bao,Xuhong Zhang,Tianyu Du,Xinkui Zhao,Zhengwen Feng,Hao Peng,Jianwei Yin*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）的“真实性方向”并非在所有模型中一致，且更强大的模型表现更好。真实性探针能有效泛化到多种任务，并提升用户对LLM输出的信任。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs中“真实性方向”的普遍性、识别方法及其在不同上下文中的泛化能力。

Method: 通过实验分析LLMs的真实性方向，训练探针并测试其在逻辑转换、问答任务等中的泛化能力。

Result: 发现真实性方向在更强大的模型中表现更一致，探针能有效泛化到多种任务，提升用户信任。

Conclusion: 研究深化了对LLMs内部表示的理解，并为提升模型输出的可信度提供了新方法。

Abstract: Large language models (LLMs) are trained on extensive datasets that
encapsulate substantial world knowledge. However, their outputs often include
confidently stated inaccuracies. Earlier works suggest that LLMs encode
truthfulness as a distinct linear feature, termed the "truth direction", which
can classify truthfulness reliably. We address several open questions about the
truth direction: (i) whether LLMs universally exhibit consistent truth
directions; (ii) whether sophisticated probing techniques are necessary to
identify truth directions; and (iii) how the truth direction generalizes across
diverse contexts. Our findings reveal that not all LLMs exhibit consistent
truth directions, with stronger representations observed in more capable
models, particularly in the context of logical negation. Additionally, we
demonstrate that truthfulness probes trained on declarative atomic statements
can generalize effectively to logical transformations, question-answering
tasks, in-context learning, and external knowledge sources. Finally, we explore
the practical application of truthfulness probes in selective
question-answering, illustrating their potential to improve user trust in LLM
outputs. These results advance our understanding of truth directions and
provide new insights into the internal representations of LLM beliefs. Our code
is public at https://github.com/colored-dye/truthfulness_probe_generalization

</details>


### [105] [HERGC: Heterogeneous Experts Representation and Generative Completion for Multimodal Knowledge Graphs](https://arxiv.org/abs/2506.00826)
*Yongkang Xiao,Rui Zhang*

Main category: cs.CL

TL;DR: HERGC是一个用于多模态知识图谱补全的框架，通过结合异构专家表示和生成式LLM预测器，显著提升了补全性能。


<details>
  <summary>Details</summary>
Motivation: 现有MMKGC方法在封闭世界假设下仅利用MMKG中的信息，限制了推理能力，而生成式方法在单模态KG补全中表现优异，但在MMKGC中尚未充分探索。

Method: HERGC首先通过异构专家表示检索器融合多模态信息并检索候选集，然后利用微调的生成式LLM预测器从候选集中识别正确答案。

Result: 在三个标准MMKG基准测试中，HERGC表现出色，达到了最先进的性能。

Conclusion: HERGC通过结合异构专家表示和生成式LLM预测器，有效解决了MMKGC问题，展示了其强大潜力。

Abstract: Multimodal knowledge graphs (MMKGs) enrich traditional knowledge graphs (KGs)
by incorporating diverse modalities such as images and text. Multi-modal
knowledge graph completion (MMKGC) seeks to exploit these heterogeneous signals
to infer missing facts, thereby mitigating the intrinsic incompleteness of
MMKGs. Existing MMKGC methods typically leverage only the information contained
in the MMKGs under the closed-world assumption and adopt discriminative
training objectives, which limits their reasoning capacity during completion.
Recent generative completion approaches powered by advanced large language
models (LLMs) have shown strong reasoning abilities in unimodal knowledge graph
completion, but their potential in MMKGC remains largely unexplored. To bridge
this gap, we propose HERGC, a Heterogeneous Experts Representation and
Generative Completion framework for MMKGs. HERGC first deploys a Heterogeneous
Experts Representation Retriever that enriches and fuses multimodal information
and retrieves a compact candidate set for each incomplete triple. It then uses
a Generative LLM Predictor fine-tuned on minimal instruction data to accurately
identify the correct answer from these candidates. Extensive experiments on
three standard MMKG benchmarks demonstrate HERGC's effectiveness and
robustness, achieving state-of-the-art performance.

</details>


### [106] [COMPKE: Complex Question Answering under Knowledge Editing](https://arxiv.org/abs/2506.00829)
*Keyuan Cheng,Zijian Kan,Zhixian He,Zhuoran Zhang,Muhammad Asif Ali,Ke Xu,Lijie Hu,Di Wang*

Main category: cs.CL

TL;DR: COMPKE是一个新的知识编辑基准，用于评估模型在复杂推理和现实场景中的表现，填补了现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准在多跳问答中评估知识编辑效果，但未能有效反映模型在复杂推理和现实场景中的应用能力。

Method: 引入了包含11,924个复杂问题的COMPKE基准，并对四种知识编辑方法进行了广泛评估。

Result: 不同模型在COMPKE上的表现差异显著，例如MeLLo在GPT-4O-MINI上准确率为39.47，而在QWEN2.5-3B上仅为3.83。

Conclusion: COMPKE揭示了知识编辑方法在不同模型中的效果差异，为未来研究提供了新的评估工具。

Abstract: Knowledge Editing, which efficiently modifies the knowledge in large language
models, has gathered great attention. Current benchmarks primarily use
multi-hop question answering to assess and analyze newly injected or updated
knowledge. However, we argue that these benchmarks fail to effectively evaluate
how well the updated models apply this knowledge in real-life scenarios,
particularly when questions require complex reasoning, involving one-to-many
relationships or multi-step logical intersections. To fill in this gap, we
introduce a new benchmark, COMPKE: Complex Question Answering under Knowledge
Editing, which includes 11,924 complex questions that reflect real-life
situations. We conduct an extensive evaluation of four knowledge editing
methods on COMPKE, revealing that their effectiveness varies notably across
different models. For instance, MeLLo attains an accuracy of 39.47 on
GPT-4O-MINI, but this drops sharply to 3.83 on QWEN2.5-3B. We further
investigate the underlying causes of these disparities from both methodological
and model-specific perspectives. The datasets are available at
https://github.com/kzjkzj666/CompKE.

</details>


### [107] [Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](https://arxiv.org/abs/2506.00842)
*Jiawei Gu,Ziting Xian,Yuanzhen Xie,Ye Liu,Enjie Liu,Ruichao Zhong,Mochi Gao,Yunzhi Tan,Bo Hu,Zang Li*

Main category: cs.CL

TL;DR: 论文提出CoRE框架，通过对比检索增强生成和上下文学习，提升LLMs在结构化数据上的表现，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在结构化数据（如表格和数据库）上表现不佳，主要因其预训练中缺乏相关经验和僵化的文本到结构转换机制。

Method: 引入CoRE框架，结合对比检索增强生成和上下文学习，模拟人类知识迁移，并使用MCTS生成经验记忆扩展训练数据。

Result: 在Text-to-SQL和TableQA任务中，平均性能提升3.44%和4.24%，部分任务提升高达17.2%。

Conclusion: CoRE框架无需额外训练，持续提升LLMs在结构化数据上的能力，填补了认知差距。

Abstract: Large language models (LLMs) achieve strong performance on plain text tasks
but underperform on structured data like tables and databases. Potential
challenges arise from their underexposure during pre-training and rigid
text-to-structure transfer mechanisms. Unlike humans who seamlessly apply
learned patterns across data modalities, LLMs struggle to infer implicit
relationships embedded in tabular formats, especially in the absence of
explicit structural guidance. To bridge this cognitive gap, we introduce
Contrastive Retrieval-Augmented Generation on Experience (CoRE), a framework
that builds experience memory representations and enhances generalization
through contrastive In-Context Learning (ICL) to simulate human-like knowledge
transfer. Experiments on Text-to-SQL and TableQA show CoRE significantly
improves performance, achieving average gains of 3.44% and 4.24%, with up to
17.2% on challenging tasks. Our Monte Carlo Tree Search (MCTS)-generated
Experience Memory expands training data 8-9x, enhancing diversity and domain
coverage. This training-free and continual method propels LLMs toward
structured knowledge expertise.

</details>


### [108] [EEG2TEXT-CN: An Exploratory Study of Open-Vocabulary Chinese Text-EEG Alignment via Large Language Model and Contrastive Learning on ChineseEEG](https://arxiv.org/abs/2506.00854)
*Jacky Tai-Yu Lu,Jung Chiang,Chi-Sheng Chen,Anna Nai-Yun Tung,Hsiang Wei Hu,Yuan Chiao Cheng*

Main category: cs.CL

TL;DR: EEG2TEXT-CN是一个针对中文的开源词汇EEG到文本生成框架，结合生物启发的EEG编码器和预训练语言模型，通过掩码预训练和对比学习实现脑信号与语言对齐。


<details>
  <summary>Details</summary>
Motivation: 探索非语音、跨模态的脑信号解码为中文文本的可行性，为多语言脑-文本研究开辟新方向。

Method: 使用NICE-EEG编码器和MiniLM语言模型，通过掩码预训练和对比学习对齐脑信号与语言表示，采用教师强制和填充掩码训练解码器。

Result: 在1,500个训练验证句子和300个测试样本上，最佳BLEU-1得分为6.38%，显示词汇对齐的潜力，但句法流畅性仍需改进。

Conclusion: EEG2TEXT-CN证明了从EEG解码中文文本的可行性，为未来中文认知语言接口奠定了基础。

Abstract: We propose EEG2TEXT-CN, which, to the best of our knowledge, represents one
of the earliest open-vocabulary EEG-to-text generation frameworks tailored for
Chinese. Built on a biologically grounded EEG encoder (NICE-EEG) and a compact
pretrained language model (MiniLM), our architecture aligns multichannel brain
signals with natural language representations via masked pretraining and
contrastive learning. Using a subset of the ChineseEEG dataset, where each
sentence contains approximately ten Chinese characters aligned with 128-channel
EEG recorded at 256 Hz, we segment EEG into per-character embeddings and
predict full sentences in a zero-shot setting. The decoder is trained with
teacher forcing and padding masks to accommodate variable-length sequences.
Evaluation on over 1,500 training-validation sentences and 300 held-out test
samples shows promising lexical alignment, with a best BLEU-1 score of 6.38\%.
While syntactic fluency remains a challenge, our findings demonstrate the
feasibility of non-phonetic, cross-modal language decoding from EEG. This work
opens a new direction in multilingual brain-to-text research and lays the
foundation for future cognitive-language interfaces in Chinese.

</details>


### [109] [How Bidirectionality Helps Language Models Learn Better via Dynamic Bottleneck Estimation](https://arxiv.org/abs/2506.00859)
*Md Kowsher,Nusrat Jahan Prottasha,Shiyun Xu,Shetu Mohanto,Chen Chen,Niloofar Yousefi,Ozlem Garibay*

Main category: cs.CL

TL;DR: 本文通过信息瓶颈（IB）原则研究了双向语言模型优于单向模型的原因，提出了一种动态可扩展的方法FlowNIB，证明了双向模型保留更多互信息且具有更高有效维度。


<details>
  <summary>Details</summary>
Motivation: 探索双向语言模型在自然语言理解任务中优于单向模型的理论原因。

Method: 提出FlowNIB方法，动态估计训练中的互信息，并设计框架衡量表示复杂性。

Result: 双向模型在温和条件下保留更多互信息且表示更丰富，实验验证了信息编码和压缩的动态过程。

Conclusion: 研究为双向架构的有效性提供了理论解释，并提供了分析深度语言模型中信息流的实用工具。

Abstract: Bidirectional language models have better context understanding and perform
better than unidirectional models on natural language understanding tasks, yet
the theoretical reasons behind this advantage remain unclear. In this work, we
investigate this disparity through the lens of the Information Bottleneck (IB)
principle, which formalizes a trade-off between compressing input information
and preserving task-relevant content. We propose FlowNIB, a dynamic and
scalable method for estimating mutual information during training that
addresses key limitations of classical IB approaches, including computational
intractability and fixed trade-off schedules. Theoretically, we show that
bidirectional models retain more mutual information and exhibit higher
effective dimensionality than unidirectional models. To support this, we
present a generalized framework for measuring representational complexity and
prove that bidirectional representations are strictly more informative under
mild conditions. We further validate our findings through extensive experiments
across multiple models and tasks using FlowNIB, revealing how information is
encoded and compressed throughout training. Together, our work provides a
principled explanation for the effectiveness of bidirectional architectures and
introduces a practical tool for analyzing information flow in deep language
models.

</details>


### [110] [L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models](https://arxiv.org/abs/2506.00863)
*Nidhi Kowtal,Raviraj Joshi*

Main category: cs.CL

TL;DR: 论文提出了L3Cube-MahaEmotions数据集，用于低资源语言马拉地语的情感识别，通过LLM生成训练数据，人工标注验证和测试集。研究发现GPT-4在复杂情感识别任务中表现优于微调BERT模型。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言马拉地语情感识别中标注数据不足的问题。

Method: 使用LLM（GPT-4和Llama3-405B）通过翻译链提示技术生成训练数据，人工标注验证和测试集，并评估模型性能。

Result: GPT-4预测优于微调BERT模型，但BERT模型在合成标签上训练未能超越GPT-4。

Conclusion: 高质量人工标注数据对情感识别至关重要，通用LLM在低资源语言任务中表现更优。

Abstract: Emotion recognition in low-resource languages like Marathi remains
challenging due to limited annotated data. We present L3Cube-MahaEmotions, a
high-quality Marathi emotion recognition dataset with 11 fine-grained emotion
labels. The training data is synthetically annotated using large language
models (LLMs), while the validation and test sets are manually labeled to serve
as a reliable gold-standard benchmark. Building on the MahaSent dataset, we
apply the Chain-of-Translation (CoTR) prompting technique, where Marathi
sentences are translated into English and emotion labeled via a single prompt.
GPT-4 and Llama3-405B were evaluated, with GPT-4 selected for training data
annotation due to superior label quality. We evaluate model performance using
standard metrics and explore label aggregation strategies (e.g., Union,
Intersection). While GPT-4 predictions outperform fine-tuned BERT models,
BERT-based models trained on synthetic labels fail to surpass GPT-4. This
highlights both the importance of high-quality human-labeled data and the
inherent complexity of emotion recognition. An important finding of this work
is that generic LLMs like GPT-4 and Llama3-405B generalize better than
fine-tuned BERT for complex low-resource emotion recognition tasks. The dataset
and model are shared publicly at https://github.com/l3cube-pune/MarathiNLP

</details>


### [111] [What's Missing in Vision-Language Models? Probing Their Struggles with Causal Order Reasoning](https://arxiv.org/abs/2506.00869)
*Zhaotian Weng,Haoxuan Li,Kuan-Hao Huang,Jieyu Zhao*

Main category: cs.CL

TL;DR: 论文提出了两个新基准VQA-Causal和VCR-Causal，专门用于评估视觉语言模型（VLMs）的因果推理能力，发现VLMs在因果推理任务上表现不佳，主要原因是训练数据中缺乏明确的因果关系表达。


<details>
  <summary>Details</summary>
Motivation: 现有基准难以准确评估VLMs的因果推理能力，因为它们常通过对象识别和活动识别等捷径回答问题，而非真正理解因果关系。

Method: 引入VQA-Causal和VCR-Causal两个新基准，并通过硬负例微调策略提升模型的因果推理能力。

Result: VLMs在因果推理任务上表现较差，仅略优于随机猜测，而微调策略能提升其性能。

Conclusion: 研究揭示了当前VLMs在因果推理上的不足，为未来改进提供了方向。

Abstract: Despite the impressive performance of vision-language models (VLMs) on
downstream tasks, their ability to understand and reason about causal
relationships in visual inputs remains unclear. Robust causal reasoning is
fundamental to solving complex high-level reasoning tasks, yet existing
benchmarks often include a mixture of reasoning questions, and VLMs can
frequently exploit object recognition and activity identification as shortcuts
to arrive at the correct answers, making it challenging to truly assess their
causal reasoning abilities. To bridge this gap, we introduce VQA-Causal and
VCR-Causal, two new benchmarks specifically designed to isolate and rigorously
evaluate VLMs' causal reasoning abilities. Our findings reveal that while VLMs
excel in object and activity recognition, they perform poorly on causal
reasoning tasks, often only marginally surpassing random guessing. Further
analysis suggests that this limitation stems from a severe lack of causal
expressions in widely used training datasets, where causal relationships are
rarely explicitly conveyed. We additionally explore fine-tuning strategies with
hard negative cases, showing that targeted fine-tuning can improve model's
causal reasoning while maintaining generalization and downstream performance.
Our study highlights a key gap in current VLMs and lays the groundwork for
future work on causal understanding.

</details>


### [112] [CC-Tuning: A Cross-Lingual Connection Mechanism for Improving Joint Multilingual Supervised Fine-Tuning](https://arxiv.org/abs/2506.00875)
*Yangfan Ye,Xiaocheng Feng,Zekun Yuan,Xiachong Feng,Libo Qin,Lei Huang,Weitao Ma,Yichong Huang,Zhirui Zhang,Yunfei Lu,Xiaohui Yan,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: CC-Tuning是一种新的多语言微调方法，通过在潜在层面建立跨语言连接机制，显著提升大语言模型的多语言能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的多语言能力不平衡，主要因为其训练数据以英语为中心。现有方法在数据层面进行微调，忽略了潜在层面的跨语言交互潜力。

Method: CC-Tuning在训练中融合英语和非英语输入的激活，并通过可训练的决策模块识别有益激活；在推理时使用变换矩阵模拟跨语言连接。

Result: 在22种语言的6个基准测试中，CC-Tuning优于传统微调方法，并展示了潜在层面跨语言交互的潜力。

Conclusion: CC-Tuning为提升大语言模型的多语言性能提供了实用且有效的潜在层面解决方案。

Abstract: Current large language models (LLMs) often exhibit imbalanced multilingual
capabilities due to their English-centric training corpora. To address this,
existing fine-tuning approaches operating at the data-level (e.g., through data
augmentation or distillation) typically introduce implicit cross-lingual
alignment, overlooking the potential for more profound, latent-level
cross-lingual interactions. In this work, we propose CC-Tuning, a novel
multilingual fine-tuning paradigm that explicitly establishes a cross-lingual
connection mechanism at the latent level. During training, CC-Tuning fuses the
feed forward activations from both English and non-English inputs, enabling the
model to benefit from both linguistic resources. This process is facilitated
with a trainable Decision Maker that identifies beneficial activations.
Furthermore, during inference, a Transform Matrix is utilized to simulate the
cross-lingual connection under monolingual setting through representation
transformation. Our experiments on six benchmarks covering 22 languages show
that CC-Tuning outperforms vanilla SFT and offers a strong latent-level
alternative to data-level augmentation methods. Further analysis also
highlights the practicality of CC-Tuning and the potential of latent-level
cross-lingual interactions in advancing the multilingual performance of LLMs.

</details>


### [113] [Not Every Token Needs Forgetting: Selective Unlearning to Limit Change in Utility in Large Language Model Unlearning](https://arxiv.org/abs/2506.00876)
*Yixin Wan,Anil Ramakrishna,Kai-Wei Chang,Volkan Cevher,Rahul Gupta*

Main category: cs.CL

TL;DR: 本文提出选择性遗忘（SU）方法，仅针对目标文档中与不需要信息相关的关键子集进行遗忘，而非所有标记，从而在有效遗忘的同时保留模型的通用知识。


<details>
  <summary>Details</summary>
Motivation: 传统遗忘方法会无差别地更新模型参数以遗忘目标文档中的所有标记，包括携带通用知识的常见标记（如代词、介词等），这可能导致模型性能下降。因此，需要一种更精细的遗忘方法。

Method: 提出选择性遗忘（SU），通过识别目标遗忘集中与不需要信息相关的关键子集，仅对这些标记进行遗忘。

Result: 在两个基准测试和六种基线遗忘算法上的实验表明，SU不仅能有效遗忘目标数据，还能显著保留模型在保留集上的性能。

Conclusion: SU是一种高效的遗忘方法，能够在保护隐私或敏感信息的同时，最小化对模型通用知识的损害。

Abstract: Large Language Model (LLM) unlearning has recently gained significant
attention, driven by the need to remove unwanted information, such as private,
sensitive, or copyrighted content, from LLMs. However, conventional unlearning
approaches indiscriminately update model parameters to forget all tokens in a
target document, including common tokens (e.g., pronouns, prepositions, general
nouns) that carry general knowledge. In this paper, we highlight that not every
token needs forgetting. We propose Selective Unlearning (SU), which identifies
a critical subset of tokens within the forgetting set that is relevant to the
unwanted information, and unlearns only those tokens. Experiments on two
benchmarks and six baseline unlearning algorithms demonstrate that SU not only
achieves effective unlearning on the targeted forget data, but also
significantly preserves the model's utility in the retaining set.

</details>


### [114] [Improve MLLM Benchmark Efficiency through Interview](https://arxiv.org/abs/2506.00883)
*Farong Wen,Yijin Guo,Junying Wang,Jiaohao Xiao,Yingjie Zhou,Chunyi Li,Zicheng Zhang,Guangtao Zhai*

Main category: cs.CL

TL;DR: 论文提出了MLLM Interview（MITV）策略，通过少量问题快速评估多模态大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模多模态大语言模型（MLLM）评估方法资源消耗大且耗时，需要一种更高效的评估方式。

Method: 构建带难度标签的面试数据集，并提出MITV策略，通过少量问题初步评估模型性能，再逐步测试模型极限。

Result: 实验表明，MITV策略在MLLM基准数据集上表现良好，能通过少量问答快速获取模型评估能力。

Conclusion: MITV策略是一种高效且资源节约的MLLM评估方法。

Abstract: The rapid development of Multimodal Large Language Models (MLLM) has led to a
wide range of MLLM applications, and a number of benchmark datasets have sprung
up in order to assess MLLM abilities. However, full-coverage Q&A testing on
large-scale data is resource-intensive and time-consuming. To address this
issue, we propose the MLLM Interview (MITV) strategy, which aims to quickly
obtain MLLM performance metrics by quizzing fewer question. First, First, we
constructed the interview dataset, which was built on an existing MLLM
assessment dataset, by adding difficulty labels based on the performance of
some typical MLLMs in this dataset. Second, we propose an MLLM Interview
strategy, which obtains an initial performance situation of the large model by
quizzing a small number of topics and then continuously tries to test the
model's limits. Through extensive experiments, the result shows that the MITV
strategy proposed in this paper performs well on MLLM benchmark datasets, and
it is able to obtain the model evaluation capability faster through a small
number of questions and answers.

</details>


### [115] [Affordance Benchmark for MLLMs](https://arxiv.org/abs/2506.00893)
*Junying Wang,Wenzhe Li,Yalun Wu,Yingji Liang,Yijin Guo,Chunyi Li,Haodong Duan,Zicheng Zhang,Guangtao Zhai*

Main category: cs.CL

TL;DR: A4Bench是一个新的基准测试，用于评估多模态大语言模型（MLLMs）在感知环境动作可能性（affordance）方面的能力，发现其表现远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在视觉语言任务中表现出色，但其感知环境动作可能性的能力尚未充分探索，这对实现直观和安全的交互至关重要。

Method: 提出A4Bench基准，包含构成性affordance（1,282个问题）和转化性affordance（718个问题），评估了17个MLLMs的表现。

Result: 专有模型优于开源模型，但所有模型表现有限，尤其在转化性affordance上。最佳模型（Gemini-2.0-Pro）准确率仅18.05%，远低于人类（81.25%-85.34%）。

Conclusion: MLLMs在环境理解上存在显著差距，A4Bench为提升AI系统的上下文感知能力提供了基础。

Abstract: Affordance theory posits that environments inherently offer action
possibilities that shape perception and behavior. While Multimodal Large
Language Models (MLLMs) excel in vision-language tasks, their ability to
perceive affordance, which is crucial for intuitive and safe interactions,
remains underexplored. To address this, we introduce A4Bench, a novel benchmark
designed to evaluate the affordance perception abilities of MLLMs across two
dimensions: 1) Constitutive Affordance}, assessing understanding of inherent
object properties through 1,282 question-answer pairs spanning nine
sub-disciplines, and 2) Transformative Affordance, probing dynamic and
contextual nuances (e.g., misleading, time-dependent, cultural, or
individual-specific affordance) with 718 challenging question-answer pairs.
Evaluating 17 MLLMs (nine proprietary and eight open-source) against human
performance, we find that proprietary models generally outperform open-source
counterparts, but all exhibit limited capabilities, particularly in
transformative affordance perception. Furthermore, even top-performing models,
such as Gemini-2.0-Pro (18.05% overall exact match accuracy), significantly lag
behind human performance (best: 85.34%, worst: 81.25%). These findings
highlight critical gaps in environmental understanding of MLLMs and provide a
foundation for advancing AI systems toward more robust, context-aware
interactions. The dataset is available in
https://github.com/JunyingWang959/A4Bench/.

</details>


### [116] [SocialEval: Evaluating Social Intelligence of Large Language Models](https://arxiv.org/abs/2506.00900)
*Jinfeng Zhou,Yuxuan Chen,Yihan Shi,Xuanming Zhang,Leqi Lei,Yi Feng,Zexuan Xiong,Miao Yan,Xunzhi Wang,Yaru Cao,Jianing Yin,Shuai Wang,Quanyu Dai,Zhenhua Dong,Hongning Wang,Minlie Huang*

Main category: cs.CL

TL;DR: 论文提出SocialEval，一个基于脚本的双语社交智能（SI）评测基准，用于评估LLMs在社交互动中的表现，发现LLMs在SI上落后于人类，但表现出亲社会性和偏好积极行为。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs的社交智能（SI）及其与人类的差异，现有工作未能全面解决这一问题。

Method: 提出SocialEval，通过手工编写的叙事脚本，结合结果导向的目标达成评估和过程导向的社交能力评估。

Result: 实验显示LLMs在SI评估中落后于人类，但表现出亲社会性和偏好积极行为。

Conclusion: LLMs在社交互动中展现出类似人脑的功能分区，但仍有提升空间。

Abstract: LLMs exhibit promising Social Intelligence (SI) in modeling human behavior,
raising the need to evaluate LLMs' SI and their discrepancy with humans. SI
equips humans with interpersonal abilities to behave wisely in navigating
social interactions to achieve social goals. This presents an operational
evaluation paradigm: outcome-oriented goal achievement evaluation and
process-oriented interpersonal ability evaluation, which existing work fails to
address. To this end, we propose SocialEval, a script-based bilingual SI
benchmark, integrating outcome- and process-oriented evaluation by manually
crafting narrative scripts. Each script is structured as a world tree that
contains plot lines driven by interpersonal ability, providing a comprehensive
view of how LLMs navigate social interactions. Experiments show that LLMs fall
behind humans on both SI evaluations, exhibit prosociality, and prefer more
positive social behaviors, even if they lead to goal failure. Analysis of LLMs'
formed representation space and neuronal activations reveals that LLMs have
developed ability-specific functional partitions akin to the human brain.

</details>


### [117] [Pi-SQL: Enhancing Text-to-SQL with Fine-Grained Guidance from Pivot Programming Languages](https://arxiv.org/abs/2506.00912)
*Yongdong chi,Hanqing Wang,Zonghan Yang,Jian Yang,Xiao Yan,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: Pi-SQL通过引入Python程序作为中间桥梁，将自然语言查询转换为SQL程序，显著提升了执行准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法在自然语言与SQL程序之间存在语义鸿沟，导致准确性受限。

Method: Pi-SQL首先生成提供细粒度指导的Python程序，再基于这些指导生成SQL程序，并通过候选策略选择优化执行速度。

Result: Pi-SQL的执行准确率比最佳基线提高了3.20，效率评分高出4.55。

Conclusion: Pi-SQL通过Python程序作为中间层，有效缩小了语义鸿沟，显著提升了SQL生成的准确性和效率。

Abstract: Text-to-SQL transforms the user queries from natural language to executable
SQL programs, enabling non-experts to interact with complex databases. Existing
prompt-based methods craft meticulous text guidelines and examples to
facilitate SQL generation, but their accuracy is hindered by the large semantic
gap between the texts and the low-resource SQL programs. In this work, we
propose Pi-SQL, which incorporates the high-resource Python program as a pivot
to bridge between the natural language query and SQL program. In particular,
Pi-SQL first generates Python programs that provide fine-grained step-by-step
guidelines in their code blocks or comments, and then produces an SQL program
following the guidance of each Python program.The final SQL program matches the
reference Python program's query results and, through selection from candidates
generated by different strategies, achieves superior execution speed, with a
reward-based valid efficiency score up to 4.55 higher than the best-performing
baseline.Extensive experiments demonstrate the effectiveness of Pi-SQL, which
improves the execution accuracy of the best-performing baseline by up to 3.20.

</details>


### [118] [How do Transformer Embeddings Represent Compositions? A Functional Analysis](https://arxiv.org/abs/2506.00914)
*Aishik Nagar,Ishaan Singh Rawal,Mansi Dhanania,Cheston Tan*

Main category: cs.CL

TL;DR: 研究了Mistral、OpenAI Large和Google嵌入模型以及BERT的组合性表现，发现线性回归模型最能解释组合性，而BERT表现较差。


<details>
  <summary>Details</summary>
Motivation: 组合性是人工智能推理和泛化的关键，但Transformer模型对复合词的表示和组合性尚不明确。

Method: 通过六种组合性模型（加法、乘法、回归等）评估嵌入模型的组合性表现，并使用合成数据集验证。

Result: 线性回归模型表现最佳，BERT的组合性较差，其他嵌入模型表现较好。

Conclusion: 研究全面探讨了组合性，为模型设计和评估提供了参考。

Abstract: Compositionality is a key aspect of human intelligence, essential for
reasoning and generalization. While transformer-based models have become the de
facto standard for many language modeling tasks, little is known about how they
represent compound words, and whether these representations are compositional.
In this study, we test compositionality in Mistral, OpenAI Large, and Google
embedding models, and compare them with BERT. First, we evaluate
compositionality in the representations by examining six diverse models of
compositionality (addition, multiplication, dilation, regression, etc.). We
find that ridge regression, albeit linear, best accounts for compositionality.
Surprisingly, we find that the classic vector addition model performs almost as
well as any other model. Next, we verify that most embedding models are highly
compositional, while BERT shows much poorer compositionality. We verify and
visualize our findings with a synthetic dataset consisting of fully transparent
adjective-noun compositions. Overall, we present a thorough investigation of
compositionality.

</details>


### [119] [anyECG-chat: A Generalist ECG-MLLM for Flexible ECG Input and Multi-Task Understanding](https://arxiv.org/abs/2506.00942)
*Haitao Li,Ziyu Li,Yiheng Mao,Ziyi Liu,Zhoujian Sun,Zhengxing Huang*

Main category: cs.CL

TL;DR: 本文提出了一种支持多任务和灵活输入的多模态大语言模型（MLLM）anyECG-chat，用于心电图（ECG）分析，并构建了anyECG数据集以填补现有数据集的单调性。


<details>
  <summary>Details</summary>
Motivation: 现有ECG-focused MLLMs主要局限于单12导联、短时程（10秒）ECG输入的报告生成任务，未能充分发挥MLLMs的潜力。

Method: 构建anyECG数据集，涵盖多种任务和输入类型；提出anyECG-chat模型，支持动态长度和多ECG输入；采用三阶段课程训练方法。

Result: anyECG-chat能够支持多种实际应用场景，包括报告生成、异常波形定位和多ECG比较分析。

Conclusion: anyECG-chat和anyECG数据集为ECG分析提供了更灵活和全面的解决方案。

Abstract: The advent of multimodal large language models (MLLMs) has sparked interest
in their application to electrocardiogram (ECG) analysis. However, existing
ECG-focused MLLMs primarily focus on report generation tasks, often limited to
single 12-lead, short-duration (10s) ECG inputs, thereby underutilizing the
potential of MLLMs. To this end, we aim to develop a MLLM for ECG analysis that
supports a broader range of tasks and more flexible ECG inputs. However,
existing ECG-QA datasets are often monotonous. To address this gap, we first
constructed the anyECG dataset, which encompasses a wide variety of tasks,
including report generation, abnormal waveform localization, and open-ended
question answering. In addition to standard hospital ECGs, we introduced
long-duration reduced-lead ECGs for home environments and multiple ECG
comparison scenarios commonly encountered in clinical practice. Furthermore, we
propose the anyECG-chat model, which supports dynamic-length ECG inputs and
multiple ECG inputs. We trained the model using a three-stage curriculum
training recipe with the anyECG dataset. A comprehensive evaluation was
conducted, demonstrating that anyECG-chat is capable of supporting various
practical application scenarios, including not only common report generation
tasks but also abnormal waveform localization for long-duration reduced-lead
ECGs in home environments and comprehensive comparative analysis of multiple
ECGs.

</details>


### [120] [Leveraging Large Language Models for Sarcastic Speech Annotation in Sarcasm Detection](https://arxiv.org/abs/2506.00955)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 论文提出了一种利用大语言模型（LLMs）生成讽刺语音数据集的标注流程，并通过人类验证提高质量。最终构建了PodSarc数据集，检测模型F1得分为73.63%。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测在语音中因数据稀缺和多模态依赖而受限，需解决单模态（仅语音）场景下的检测问题。

Method: 使用GPT-4o和LLaMA 3对公开讽刺播客进行初始标注，人类验证解决分歧，并通过协作门控架构验证标注质量。

Result: 构建了PodSarc数据集，检测模型F1得分为73.63%，验证了数据集的潜力。

Conclusion: 提出的标注流程和PodSarc数据集为讽刺检测研究提供了有效工具和基准。

Abstract: Sarcasm fundamentally alters meaning through tone and context, yet detecting
it in speech remains a challenge due to data scarcity. In addition, existing
detection systems often rely on multimodal data, limiting their applicability
in contexts where only speech is available. To address this, we propose an
annotation pipeline that leverages large language models (LLMs) to generate a
sarcasm dataset. Using a publicly available sarcasm-focused podcast, we employ
GPT-4o and LLaMA 3 for initial sarcasm annotations, followed by human
verification to resolve disagreements. We validate this approach by comparing
annotation quality and detection performance on a publicly available sarcasm
dataset using a collaborative gating architecture. Finally, we introduce
PodSarc, a large-scale sarcastic speech dataset created through this pipeline.
The detection model achieves a 73.63% F1 score, demonstrating the dataset's
potential as a benchmark for sarcasm detection research.

</details>


### [121] [From Objectives to Questions: A Planning-based Framework for Educational Mathematical Question Generation](https://arxiv.org/abs/2506.00963)
*Cheng Cheng,Zhenya Huang,Guanhao Zhao,Yuxiang Guo,Xin Lin,Jinze Wu,Xin Li,Shijin Wang*

Main category: cs.CL

TL;DR: 论文提出了一种基于教育目标的多维度数学问题生成方法EQPR，通过结合蒙特卡洛树搜索和大型语言模型，实现了高质量教育问题的自动生成与优化。


<details>
  <summary>Details</summary>
Motivation: 传统问题生成方法忽视教育目标且仅支持单维度问题，无法满足复杂教育需求。

Method: 提出EQPR方法，结合蒙特卡洛树搜索和大型语言模型，采用“计划-评估-优化”流程生成教育问题。

Result: 基于EQGEVAL的实验表明，EQPR在多维度教育目标问题上表现显著提升。

Conclusion: EQPR方法有效解决了教育问题生成的复杂需求，为教育技术提供了新工具。

Abstract: Automatically generating high-quality mathematical problems that align with
educational objectives is a crucial task in NLP-based educational technology.
Traditional generation methods focus primarily on textual quality, but they
often overlook educational objectives. Moreover, these methods address only
single-dimensional, simple question generation, failing to meet complex,
multifaceted educational requirements. To address these challenges, we
constructed and annotated EduMath, a dataset of 16k mathematical questions with
multi-dimensional educational objectives. Based on this dataset, we developed
EQGEVAL, which incorporates three evaluation dimensions and is designed to
assess the ability of models to generate educational questions. Drawing
inspiration from teachers' problem design processes, we propose the Educational
Question Planning with self-Reflection (EQPR) method for educational
mathematical question generation, following a "plan-evaluate-optimize"
approach. Specifically, by combining planning algorithm based on Monte Carlo
Tree Search with the generative capabilities of Large Language Models, we
continuously optimize questions through iterative feedback. This
self-optimization mechanism ensures that the generated questions both fit the
educational context and strategically achieve specific basic educational
objectives. Through extensive experiments based on EQGEVAL, we have
demonstrated that EQPR achieves significant improvements in generating
questions that meet multi-dimensional educational objectives.

</details>


### [122] [ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness](https://arxiv.org/abs/2506.00964)
*Dren Fazlija,Arkadij Orlov,Sandipan Sikdar*

Main category: cs.CL

TL;DR: 论文提出敏感性感知（SA）概念，帮助大语言模型（LLMs）遵守访问权限规则，并开发了评估工具ACCESS DENIED INC。实验显示模型在管理未授权请求和处理合法查询时表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在企业数据管理中因信息敏感性带来的性能和隐私挑战。

Method: 提出敏感性感知（SA）概念，开发评估工具ACCESS DENIED INC进行实验。

Result: 模型在管理未授权请求和处理合法查询时表现显著不同。

Conclusion: 为敏感性感知语言模型奠定基准，提升企业环境中隐私为中心的AI系统。

Abstract: Large language models (LLMs) are increasingly becoming valuable to corporate
data management due to their ability to process text from various document
formats and facilitate user interactions through natural language queries.
However, LLMs must consider the sensitivity of information when communicating
with employees, especially given access restrictions. Simple filtering based on
user clearance levels can pose both performance and privacy challenges. To
address this, we propose the concept of sensitivity awareness (SA), which
enables LLMs to adhere to predefined access rights rules. In addition, we
developed a benchmarking environment called ACCESS DENIED INC to evaluate SA.
Our experimental findings reveal significant variations in model behavior,
particularly in managing unauthorized data requests while effectively
addressing legitimate queries. This work establishes a foundation for
benchmarking sensitivity-aware language models and provides insights to enhance
privacy-centric AI systems in corporate environments.

</details>


### [123] [XGUARD: A Graded Benchmark for Evaluating Safety Failures of Large Language Models on Extremist Content](https://arxiv.org/abs/2506.00973)
*Vadivel Abishethvarman,Bhavik Chandna,Pratik Jalan,Usman Naseem*

Main category: cs.CL

TL;DR: XGUARD是一个评估框架，用于量化LLMs生成的极端内容的严重性，通过五级危险分类和攻击严重性曲线（ASC）提供更细致的分析。


<details>
  <summary>Details</summary>
Motivation: 现有安全评估过于简化，忽略了LLMs生成内容的复杂风险谱系，需要更细致的评估方法。

Method: 开发XGUARD框架，包含3,840个真实数据源的红队提示，将模型响应分为五级危险，并引入ASC可视化工具。

Result: 评估了六种流行LLMs和两种防御策略，揭示了安全漏洞及鲁棒性与表达自由之间的权衡。

Conclusion: 分级安全指标对构建可信LLMs具有重要价值。

Abstract: Large Language Models (LLMs) can generate content spanning ideological
rhetoric to explicit instructions for violence. However, existing safety
evaluations often rely on simplistic binary labels (safe and unsafe),
overlooking the nuanced spectrum of risk these outputs pose. To address this,
we present XGUARD, a benchmark and evaluation framework designed to assess the
severity of extremist content generated by LLMs. XGUARD includes 3,840 red
teaming prompts sourced from real world data such as social media and news,
covering a broad range of ideologically charged scenarios. Our framework
categorizes model responses into five danger levels (0 to 4), enabling a more
nuanced analysis of both the frequency and severity of failures. We introduce
the interpretable Attack Severity Curve (ASC) to visualize vulnerabilities and
compare defense mechanisms across threat intensities. Using XGUARD, we evaluate
six popular LLMs and two lightweight defense strategies, revealing key insights
into current safety gaps and trade-offs between robustness and expressive
freedom. Our work underscores the value of graded safety metrics for building
trustworthy LLMs.

</details>


### [124] [NTPP: Generative Speech Language Modeling for Dual-Channel Spoken Dialogue via Next-Token-Pair Prediction](https://arxiv.org/abs/2506.00975)
*Qichao Wang,Ziqiao Meng,Wenqian Cui,Yifei Zhang,Pengcheng Wu,Bingzhe Wu,Irwin King,Liang Chen,Peilin Zhao*

Main category: cs.CL

TL;DR: 论文提出了一种新的生成建模范式NTPP，利用双通道语音数据提升语音语言模型的对话能力，显著改善了响应连贯性和自然性，同时降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 受GPT-4o启发，研究者希望提升语音语言模型（SLMs）的自然对话能力，但现有方法未充分利用双通道语音数据的潜力。

Method: 引入Next-Token-Pair Prediction（NTPP）方法，首次在仅解码器架构中实现独立于说话者的双通道对话学习。

Result: NTPP在标准基准测试中显著提升了SLMs的对话能力（如轮转预测、响应连贯性、自然性），并大幅降低了推理延迟。

Conclusion: NTPP为实时应用的语音语言模型提供了一种高效且性能优越的新方法。

Abstract: Inspired by the impressive capabilities of GPT-4o, there is growing interest
in enabling speech language models (SLMs) to engage in natural, fluid spoken
interactions with humans. Recent advancements have led to the development of
several SLMs that demonstrate promising results in this area. However, current
approaches have yet to fully exploit dual-channel speech data, which inherently
captures the structure and dynamics of human conversation. In this work, we
systematically explore the use of dual-channel speech data in the context of
modern large language models, and introduce a novel generative modeling
paradigm, Next-Token-Pair Prediction (NTPP), to enable speaker-independent
dual-channel spoken dialogue learning using decoder-only architectures for the
first time. We evaluate our approach on standard benchmarks, and empirical
results show that our proposed method, NTPP, significantly improves the
conversational abilities of SLMs in terms of turn-taking prediction, response
coherence, and naturalness. Moreover, compared to existing methods, NTPP
achieves substantially lower inference latency, highlighting its practical
efficiency for real-time applications.

</details>


### [125] [LEMONADE: A Large Multilingual Expert-Annotated Abstractive Event Dataset for the Real World](https://arxiv.org/abs/2506.00980)
*Sina J. Semnani,Pingyue Zhang,Wanyue Zhai,Haozhuo Li,Ryan Beauchamp,Trey Billing,Katayoun Kishi,Manling Li,Monica S. Lam*

Main category: cs.CL

TL;DR: LEMONADE是一个大规模多语言冲突事件数据集，基于ACLED数据重新标注，并提出抽象事件提取（AEE）和抽象实体链接（AEL）方法，评估了多种大语言模型（LLMs）的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多语言来源的全球事件分析中事件提取和实体链接的挑战。

Method: 引入AEE和AEL方法，通过整体文档理解检测事件参数和实体，并评估LLMs及零样本系统（如ZEST）。

Result: 最佳零样本系统在端到端任务中F1得分为58.3%，ZEST在AEL任务中F1得分为45.7%，但落后于监督系统。

Conclusion: 零样本方法虽有效，但仍需进一步研究以缩小与监督系统的差距。

Abstract: This paper presents LEMONADE, a large-scale conflict event dataset comprising
39,786 events across 20 languages and 171 countries, with extensive coverage of
region-specific entities. LEMONADE is based on a partially reannotated subset
of the Armed Conflict Location & Event Data (ACLED), which has documented
global conflict events for over a decade.
  To address the challenge of aggregating multilingual sources for global event
analysis, we introduce abstractive event extraction (AEE) and its subtask,
abstractive entity linking (AEL). Unlike conventional span-based event
extraction, our approach detects event arguments and entities through holistic
document understanding and normalizes them across the multilingual dataset. We
evaluate various large language models (LLMs) on these tasks, adapt existing
zero-shot event extraction systems, and benchmark supervised models.
Additionally, we introduce ZEST, a novel zero-shot retrieval-based system for
AEL.
  Our best zero-shot system achieves an end-to-end F1 score of 58.3%, with LLMs
outperforming specialized event extraction models such as GoLLIE. For entity
linking, ZEST achieves an F1 score of 45.7%, significantly surpassing OneNet, a
state-of-the-art zero-shot baseline that achieves only 23.7%. However, these
zero-shot results lag behind the best supervised systems by 20.1% and 37.0% in
the end-to-end and AEL tasks, respectively, highlighting the need for further
research.

</details>


### [126] [What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training](https://arxiv.org/abs/2506.00981)
*Marianne de Heer Kloots,Hosein Mohebbi,Charlotte Pouw,Gaofei Shen,Willem Zuidema,Martijn Bentum*

Main category: cs.CL

TL;DR: 研究表明，仅用荷兰语预训练的Wav2Vec2模型能更好地捕捉荷兰语的语音和词汇信息，优于用英语或多语言数据预训练的模型。


<details>
  <summary>Details</summary>
Motivation: 探索自监督模型学习的语音表征是否具有语言特异性，尤其是预训练语言对模型捕捉特定语言特征的影响。

Method: 通过训练聚类或分类探针，以及零样本指标，测试Wav2Vec2模型对荷兰语语音和词汇信息的编码能力。

Result: 仅用荷兰语预训练的模型在荷兰语特征编码和自动语音识别任务中表现更优。

Conclusion: 预训练语言的选择显著影响模型对特定语言特征的捕捉能力，且与下游任务表现一致。

Abstract: How language-specific are speech representations learned by self-supervised
models? Existing work has shown that a range of linguistic features can be
successfully decoded from end-to-end models trained only on speech recordings.
However, it's less clear to what extent pre-training on specific languages
improves language-specific linguistic information. Here we test the encoding of
Dutch phonetic and lexical information in internal representations of
self-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the
representation of Dutch linguistic features as compared to pre-training on
similar amounts of English or larger amounts of multilingual data. This
language-specific advantage is well-detected by trained clustering or
classification probes, and partially observable using zero-shot metrics.
Furthermore, the language-specific benefit on linguistic feature encoding
aligns with downstream performance on Automatic Speech Recognition.

</details>


### [127] [Do LLMs Understand Why We Write Diaries? A Method for Purpose Extraction and Clustering](https://arxiv.org/abs/2506.00985)
*Valeriya Goloviznina,Alexander Sergeev,Mikhail Melnichenko,Evgeny Kotelnikov*

Main category: cs.CL

TL;DR: 该论文提出了一种基于大型语言模型（LLMs）的新方法，用于从日记中识别和聚类写作目的，并在苏联时代的日记数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理大规模日记语料时效果不佳，因此需要一种更有效的方法来提取和分析日记写作的多种目的。

Method: 使用不同的大型语言模型（包括GPT-4o和o1-mini）对苏联时代的日记进行目的识别和聚类，并与模板基线方法进行比较。

Result: GPT-4o和o1-mini表现最佳，模板基线方法效果较差。研究还分析了作者性别、年龄和写作年份对目的的影响，并探讨了模型的错误类型。

Conclusion: 该方法在日记分析中表现出色，但仍有改进空间，未来研究可进一步优化模型性能。

Abstract: Diary analysis presents challenges, particularly in extracting meaningful
information from large corpora, where traditional methods often fail to deliver
satisfactory results. This study introduces a novel method based on Large
Language Models (LLMs) to identify and cluster the various purposes of diary
writing. By "purposes," we refer to the intentions behind diary writing, such
as documenting life events, self-reflection, or practicing language skills. Our
approach is applied to Soviet-era diaries (1922-1929) from the Prozhito digital
archive, a rich collection of personal narratives. We evaluate different
proprietary and open-source LLMs, finding that GPT-4o and o1-mini achieve the
best performance, while a template-based baseline is significantly less
effective. Additionally, we analyze the retrieved purposes based on gender, age
of the authors, and the year of writing. Furthermore, we examine the types of
errors made by the models, providing a deeper understanding of their
limitations and potential areas for improvement in future research.

</details>


### [128] [Talking to Data: Designing Smart Assistants for Humanities Databases](https://arxiv.org/abs/2506.00986)
*Alexander Sergeev,Valeriya Goloviznina,Mikhail Melnichenko,Evgeny Kotelnikov*

Main category: cs.CL

TL;DR: 论文介绍了一种基于LLM的智能助手，旨在通过自然语言交互提升人文研究数据库的访问效率，采用了RAG方法及多种先进技术。


<details>
  <summary>Details</summary>
Motivation: 传统交互方式限制了人文研究数据库的访问，研究者希望通过自然语言交互提升效率和可访问性。

Method: 开发了一个聊天机器人形式的助手，结合RAG方法、混合搜索、自动查询生成、文本到SQL过滤等技术。

Result: 实验基于Prozhito数字档案进行，评估了不同语言模型的响应质量，工具支持非技术用户。

Conclusion: 研究表明LLM有潜力改变研究者与数字档案的交互方式，使其更直观和包容。

Abstract: Access to humanities research databases is often hindered by the limitations
of traditional interaction formats, particularly in the methods of searching
and response generation. This study introduces an LLM-based smart assistant
designed to facilitate natural language communication with digital humanities
data. The assistant, developed in a chatbot format, leverages the RAG approach
and integrates state-of-the-art technologies such as hybrid search, automatic
query generation, text-to-SQL filtering, semantic database search, and
hyperlink insertion. To evaluate the effectiveness of the system, experiments
were conducted to assess the response quality of various language models. The
testing was based on the Prozhito digital archive, which contains diary entries
from predominantly Russian-speaking individuals who lived in the 20th century.
The chatbot is tailored to support anthropology and history researchers, as
well as non-specialist users with an interest in the field, without requiring
prior technical training. By enabling researchers to query complex databases
with natural language, this tool aims to enhance accessibility and efficiency
in humanities research. The study highlights the potential of Large Language
Models to transform the way researchers and the public interact with digital
archives, making them more intuitive and inclusive. Additional materials are
presented in GitHub repository:
https://github.com/alekosus/talking-to-data-intersys2025.

</details>


### [129] [Less is More: Local Intrinsic Dimensions of Contextual Language Models](https://arxiv.org/abs/2506.01034)
*Benjamin Matthias Ruppik,Julius von Rohrscheidt,Carel van Niekerk,Michael Heck,Renato Vukovic,Shutong Feng,Hsien-chin Lin,Nurul Lubis,Bastian Rieck,Marcus Zibrowius,Milica Gašić*

Main category: cs.CL

TL;DR: 本文通过几何视角研究LLM训练和微调对潜在嵌入空间的影响，发现局部维度变化可预测模型动态和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解LLM内部机制及微调对行为的影响是复杂且重要的课题。

Method: 通过测量和分析上下文语言模型潜在空间的局部维度变化。

Result: 局部维度均值可预测训练能力耗尽、过拟合和grokking现象，并伴随性能提升。

Conclusion: 研究为LLM的可解释性和适应性提供了新视角，帮助实践者优化模型配置。

Abstract: Understanding the internal mechanisms of large language models (LLMs) remains
a challenging and complex endeavor. Even fundamental questions, such as how
fine-tuning affects model behavior, often require extensive empirical
evaluation. In this paper, we introduce a novel perspective based on the
geometric properties of contextual latent embeddings to study the effects of
training and fine-tuning. To that end, we measure the local dimensions of a
contextual language model's latent space and analyze their shifts during
training and fine-tuning. We show that the local dimensions provide insights
into the model's training dynamics and generalization ability. Specifically,
the mean of the local dimensions predicts when the model's training
capabilities are exhausted, as exemplified in a dialogue state tracking task,
overfitting, as demonstrated in an emotion recognition task, and grokking, as
illustrated with an arithmetic task. Furthermore, our experiments suggest a
practical heuristic: reductions in the mean local dimension tend to accompany
and predict subsequent performance gains. Through this exploration, we aim to
provide practitioners with a deeper understanding of the implications of
fine-tuning on embedding spaces, facilitating informed decisions when
configuring models for specific applications. The results of this work
contribute to the ongoing discourse on the interpretability, adaptability, and
generalizability of LLMs by bridging the gap between intrinsic model mechanisms
and geometric properties in the respective embeddings.

</details>


### [130] [Probing Neural Topology of Large Language Models](https://arxiv.org/abs/2506.01042)
*Yu Zheng,Yuan Yuan,Yong Li,Paolo Santi*

Main category: cs.CL

TL;DR: 本文提出了一种名为“图探测”的方法，用于揭示大型语言模型（LLM）神经元的功能连接拓扑结构，并将其与语言生成性能关联起来。研究发现，仅通过神经拓扑结构即可预测下一个标记的性能，且这种预测性在仅保留1%的神经元连接或模型仅经过8次预训练步骤后仍保持稳健。


<details>
  <summary>Details</summary>
Motivation: 尽管通过探测LLM已获得对其内部机制的宝贵见解，但神经元如何通过功能共激活产生涌现能力仍不清楚，这阻碍了对LLM的深入理解和安全开发。

Method: 引入图探测方法，分析不同LLM家族和规模的内部神经图，研究神经拓扑结构与语言生成性能的关系。

Result: 发现神经拓扑结构能普遍预测下一个标记的性能，且这种预测性具有稀疏性和早期涌现的特点。不同LLM尽管在架构、参数和训练数据上有显著差异，但会形成一致且复杂的神经拓扑结构。

Conclusion: 神经拓扑结构可能是LLM语言生成能力的基础，图探测方法为理解LLM的涌现能力提供了新视角。

Abstract: Probing large language models (LLMs) has yielded valuable insights into their
internal mechanisms by linking neural representations to interpretable
semantics. However, how neurons functionally co-activate with each other to
give rise to emergent capabilities remains largely unknown, hindering a deeper
understanding and safer development of LLMs. In this work, we introduce graph
probing, a method for uncovering the functional connectivity topology of LLM
neurons and relating it to language generation performance. By analyzing
internal neural graphs across diverse LLM families and scales, we discover a
universal predictability of next-token prediction performance using only neural
topology. This predictability is robust even when retaining just 1% of neuron
connections or probing models after only 8 pretraining steps, highlighting the
sparsity and early emergence of topological patterns. Further graph matching
analysis suggests that, despite significant distinctions in architectures,
parameters, and training data, different LLMs develop intricate and consistent
neural topological structures that may form the foundation for their language
generation abilities. Codes and data for the graph probing toolbox are released
at https://github.com/DavyMorgan/llm-graph-probing.

</details>


### [131] [CHEER-Ekman: Fine-grained Embodied Emotion Classification](https://arxiv.org/abs/2506.01047)
*Phan Anh Duong,Cat Luong,Divyesh Bommana,Tianyu Jiang*

Main category: cs.CL

TL;DR: 本文提出了一个基于Ekman六种基本情绪类别的数据集CHEER-Ekman，并通过自动最佳-最差缩放技术结合大语言模型，在情绪识别任务上表现优于监督方法。


<details>
  <summary>Details</summary>
Motivation: 研究文本中体现的身体情绪识别问题，扩展现有数据集以支持更细粒度的情绪分类。

Method: 使用自动最佳-最差缩放技术和大语言模型，结合简化提示指令和链式思维推理。

Result: 在CHEER-Ekman数据集上表现优于监督方法，小模型也能达到与大模型竞争的性能。

Conclusion: 简化提示和链式思维推理显著提升情绪识别准确率，为小模型的应用提供了可能。

Abstract: Emotions manifest through physical experiences and bodily reactions, yet
identifying such embodied emotions in text remains understudied. We present an
embodied emotion classification dataset, CHEER-Ekman, extending the existing
binary embodied emotion dataset with Ekman's six basic emotion categories.
Using automatic best-worst scaling with large language models, we achieve
performance superior to supervised approaches on our new dataset. Our
investigation reveals that simplified prompting instructions and
chain-of-thought reasoning significantly improve emotion recognition accuracy,
enabling smaller models to achieve competitive performance with larger ones.

</details>


### [132] [SealQA: Raising the Bar for Reasoning in Search-Augmented Language Models](https://arxiv.org/abs/2506.01062)
*Thinh Pham,Nguyen Nguyen,Pratibha Zunjare,Weiyuan Chen,Yu-Min Tseng,Tu Vu*

Main category: cs.CL

TL;DR: SealQA是一个新的基准测试，用于评估搜索增强语言模型在事实性问题上的表现，尤其是在搜索结果冲突、嘈杂或无用时。它包括Seal-0、Seal-Hard和LongSeal三个版本，揭示了当前模型的局限性，即使前沿模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决搜索增强语言模型在复杂事实性问题上的表现问题，尤其是在搜索结果不可靠时的挑战。

Method: 通过设计SealQA的三个版本（Seal-0、Seal-Hard和LongSeal），评估模型在事实准确性、推理能力和长上下文多文档推理中的表现。

Result: 前沿模型在Seal-0上的准确率仅为17.1%和6.3%，且对嘈杂搜索结果高度敏感。增加计算资源并未显著提升性能。

Conclusion: 当前模型在处理复杂事实性问题时仍有显著局限性，SealQA的发布旨在促进未来研究。

Abstract: We introduce SealQA, a new challenge benchmark for evaluating
SEarch-Augmented Language models on fact-seeking questions where web search
yields conflicting, noisy, or unhelpful results. SealQA comes in three flavors:
(1) Seal-0 (main) and (2) Seal-Hard, which assess factual accuracy and
reasoning capabilities, with Seal-0 focusing on the most challenging questions
where chat models (e.g., GPT-4.1) typically achieve near-zero accuracy; and (3)
LongSeal, which extends SealQA to test long-context, multi-document reasoning
in "needle-in-a-haystack" settings. Our evaluation reveals critical limitations
in current models: Even frontier LLMs perform poorly across all SealQA flavors.
On Seal-0, frontier agentic models equipped with tools like o3 and o4-mini
achieve only 17.1% and 6.3% accuracy, respectively, at their best reasoning
efforts. We find that advanced reasoning models such as DeepSeek-R1-671B and
o3-mini are highly vulnerable to noisy search results. Notably, increasing
test-time compute does not yield reliable gains across o3-mini, o4-mini, and
o3, with performance often plateauing or even declining early. Additionally,
while recent models are less affected by the "lost-in-the-middle" issue, they
still fail to reliably identify relevant documents in LongSeal when faced with
numerous distractors. To facilitate future work, we release SealQA at
huggingface.co/datasets/vtllms/sealqa.

</details>


### [133] [How Programming Concepts and Neurons Are Shared in Code Language Models](https://arxiv.org/abs/2506.01074)
*Amir Hossein Kargaran,Yihong Liu,François Yvon,Hinrich Schütze*

Main category: cs.CL

TL;DR: 研究了多编程语言（PL）与英语在LLMs概念空间中的关系，发现概念空间更接近英语，且语言特定神经元分布在不同层。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在多编程语言和英语之间的概念空间关系，填补现有研究在跨语言编程任务中的空白。

Method: 使用两个基于Llama的模型对21对PL进行少样本翻译任务，解码中间层嵌入并分析神经元激活。

Result: 概念空间更接近英语，语言特定神经元集中在底层，而PL独有神经元出现在顶层；高度对齐的PL难以识别特定神经元。

Conclusion: 揭示了LLMs内部表示PL的结构模式，为理解模型概念空间提供了新视角。

Abstract: Several studies have explored the mechanisms of large language models (LLMs)
in coding tasks, but most have focused on programming languages (PLs) in a
monolingual setting. In this paper, we investigate the relationship between
multiple PLs and English in the concept space of LLMs. We perform a few-shot
translation task on 21 PL pairs using two Llama-based models. By decoding the
embeddings of intermediate layers during this task, we observe that the concept
space is closer to English (including PL keywords) and assigns high
probabilities to English tokens in the second half of the intermediate layers.
We analyze neuron activations for 11 PLs and English, finding that while
language-specific neurons are primarily concentrated in the bottom layers,
those exclusive to each PL tend to appear in the top layers. For PLs that are
highly aligned with multiple other PLs, identifying language-specific neurons
is not feasible. These PLs also tend to have a larger keyword set than other
PLs and are closer to the model's concept space regardless of the input/output
PL in the translation task. Our findings provide insights into how LLMs
internally represent PLs, revealing structural patterns in the model's concept
space. Code is available at https://github.com/cisnlp/code-specific-neurons.

</details>


### [134] [zip2zip: Inference-Time Adaptive Vocabularies for Language Models via Token Compression](https://arxiv.org/abs/2506.01084)
*Saibo Geng,Nathan Ranchin,Yunzhen yao,Maxime Peyrard,Chris Wendler,Michael Gastpar,Robert West*

Main category: cs.CL

TL;DR: zip2zip是一个动态调整LLM词汇表的框架，通过减少生成的token数量来加速推理。


<details>
  <summary>Details</summary>
Motivation: 静态tokenizer在领域或语言特定输入上效率低下，导致计算成本增加。

Method: zip2zip包含基于LZW压缩的动态tokenizer、运行时嵌入层和因果语言建模变体。

Result: zip2zip减少输入输出序列长度20-60%，显著降低推理延迟。

Conclusion: zip2zip通过高效微调实现动态词汇表调整，提升LLM性能。

Abstract: Tokenization efficiency plays a critical role in the performance and cost of
large language models (LLMs), yet most models rely on static tokenizers
optimized for general-purpose corpora. These tokenizers' fixed vocabularies
often fail to adapt to domain- or language-specific inputs, leading to longer
token sequences and higher computational costs. We introduce zip2zip, a
framework that enables LLMs to dynamically adjust token vocabulary at inference
time, allowing for fewer generated tokens and thus faster inference. zip2zip
consists of three key components: (1) a tokenizer based on Lempel-Ziv-Welch
(LZW) compression that incrementally compresses tokens into reusable
"hypertokens" on the fly; (2) an embedding layer that computes embeddings for
newly formed hypertokens at runtime; and (3) a causal language modeling variant
that trains the model to operate on hypertokenized, compressed sequences. We
show that an existing LLM can be zip2zip-fied in 10 GPU-hours via
parameter-efficient finetuning. The resulting zip2zip LLMs effectively learn to
use hypertokens at inference time, reducing input and output sequence length by
20-60\%, with significant improvements in inference latency.

</details>


### [135] [Un-considering Contextual Information: Assessing LLMs' Understanding of Indexical Elements](https://arxiv.org/abs/2506.01089)
*Metehan Oguz,Yavuz Bakman,Duygu Nur Yaldiz*

Main category: cs.CL

TL;DR: 本研究评估了大语言模型（LLMs）在指代消解任务中处理索引词（如I、you、here、tomorrow）的表现，发现LLMs对某些索引词表现优异（如I），但对其他索引词（如you、here、tomorrow）表现较差。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在名词和第三人称代词上的指代消解表现，而忽略了索引词的独特挑战。本研究填补了这一空白。

Method: 研究构建了包含1600个多选题的英语索引词数据集，并评估了GPT-4o、Claude 3.5 Sonnet、Gemini 1.5 Pro和DeepSeek V3等LLMs的表现。

Result: LLMs对某些索引词（如I）表现优异，但对其他索引词（如you、here、tomorrow）表现较差。句法线索（如引号）对某些索引词有帮助，但对其他索引词反而降低表现。

Conclusion: LLMs在处理索引词时表现不一，句法线索的影响也因词而异。研究为未来改进LLMs在索引词处理上的能力提供了基础。

Abstract: Large Language Models (LLMs) have demonstrated impressive performances in
tasks related to coreference resolution. However, previous studies mostly
assessed LLM performance on coreference resolution with nouns and third person
pronouns. This study evaluates LLM performance on coreference resolution with
indexical like I, you, here and tomorrow, which come with unique challenges due
to their linguistic properties. We present the first study examining how LLMs
interpret indexicals in English, releasing the English Indexical Dataset with
1600 multiple-choice questions. We evaluate pioneering LLMs, including GPT-4o,
Claude 3.5 Sonnet, Gemini 1.5 Pro, and DeepSeek V3. Our results reveal that
LLMs exhibit an impressive performance with some indexicals (I), while
struggling with others (you, here, tomorrow), and that syntactic cues (e.g.
quotation) contribute to LLM performance with some indexicals, while they
reduce performance with others. Code and data are available at:
https://github.com/metehanoguzz/LLMs-Indexicals-English.

</details>


### [136] [Contextual Candor: Enhancing LLM Trustworthiness Through Hierarchical Unanswerability Detection](https://arxiv.org/abs/2506.01104)
*Steven Robinson,Antonio Carlos Rivera*

Main category: cs.CL

TL;DR: 论文提出了一种名为RUL的新型混合训练范式，旨在提升大型语言模型（LLM）检测无法回答问题并生成适当响应的能力。通过结合判别性预测头和多阶段学习策略，RUL显著提高了无法回答问题的检测准确性和拒绝响应的生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在生成事实性不足或幻觉回答方面存在问题，影响了其可信度和广泛应用。因此，需要一种方法使模型能够准确识别无法回答的问题并生成可靠的拒绝响应。

Method: RUL结合了判别性预测头和生成核心，采用多阶段学习策略，包括在新型数据集ECA上进行监督微调，以及通过RLHF阶段优化拒绝响应的细微差别和有用性。

Result: 实验表明，RUL在无法回答问题检测和拒绝响应生成方面表现优异，显著提高了准确性和用户感知的有用性。

Conclusion: RUL为更可靠、以用户为中心的对话AI提供了有效解决方案，提升了模型的信任度和实用性。

Abstract: The pervasive deployment of large language models (LLMs) in conversational AI
systems has revolutionized information access, yet their propensity for
generating factually unsupported or hallucinated responses remains a critical
impediment to trustworthiness and widespread adoption. This paper introduces
Reinforced Unanswerability Learning (RUL), a novel hybrid training paradigm
designed to imbue LLMs with the intrinsic capability to accurately detect
unanswerable questions and generate reliably appropriate responses. Unlike
conventional approaches that rely on external classifiers or simple prompting,
RUL integrates a discriminative unanswerability prediction head with the LLM's
generative core, guided by a multi-stage learning strategy. This includes
supervised fine-tuning on a novel, richly annotated dataset,
Enhanced-CAsT-Answerability (ECA), which features hierarchical answerability
labels and ground-truth refusal responses. Crucially, RUL incorporates a
subsequent reinforcement learning with human feedback (RLHF) phase to refine
the nuance, helpfulness, and informativeness of refusal responses. Extensive
experiments demonstrate RUL's superior performance, achieving significantly
higher accuracy in unanswerability detection across sentence, paragraph, and
ranking levels, and substantially increasing the generation of appropriate
refusals for unanswerable queries, alongside strong performance on answerable
questions. Human evaluations further corroborate RUL's effectiveness,
highlighting a marked improvement in perceived helpfulness and trustworthiness,
ultimately paving the way for more reliable and user-centric conversational AI.

</details>


### [137] [From Words to Waves: Analyzing Concept Formation in Speech and Text-Based Foundation Models](https://arxiv.org/abs/2506.01133)
*Asım Ersoy,Basel Mousi,Shammur Chowdhury,Firoj Alam,Fahim Dalvi,Nadir Durrani*

Main category: cs.CL

TL;DR: 论文探讨了多模态模型（如语音和文本）是否能够形成更丰富的语义理解，并通过潜在概念分析方法研究了其语义抽象的形成。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在文本训练中展现了广泛的世界知识和推理能力，引发了关于其他模态（如语音）是否也能形成类似概念的疑问，以及多模态训练是否能增强语义理解。

Method: 使用潜在概念分析（Latent Concept Analysis）这一无监督方法，分析了语音和文本模型单独及联合训练时的潜在表示。

Result: 研究发现多模态训练可能促进更结构化、丰富的语义理解。

Conclusion: 论文为多模态模型的语义理解提供了实证支持，并开源了相关资源以促进可复现性。

Abstract: The emergence of large language models (LLMs) has demonstrated that systems
trained solely on text can acquire extensive world knowledge, develop reasoning
capabilities, and internalize abstract semantic concepts--showcasing properties
that can be associated with general intelligence. This raises an intriguing
question: Do such concepts emerge in models trained on other modalities, such
as speech? Furthermore, when models are trained jointly on multiple modalities:
Do they develop a richer, more structured semantic understanding? To explore
this, we analyze the conceptual structures learned by speech and textual models
both individually and jointly. We employ Latent Concept Analysis, an
unsupervised method for uncovering and interpreting latent representations in
neural networks, to examine how semantic abstractions form across modalities.
For reproducibility we made scripts and other resources available to the
community.

</details>


### [138] [A Word is Worth 4-bit: Efficient Log Parsing with Binary Coded Decimal Recognition](https://arxiv.org/abs/2506.01147)
*Prerak Srivastava,Giulio Corallo,Sergey Rybalko*

Main category: cs.CL

TL;DR: 提出了一种基于字符级嵌入的新型神经架构日志解析器，能够更精细地提取日志模板，在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有日志解析器在捕捉细粒度模板细节时表现不佳，导致下游任务准确性不足。

Method: 采用字符级嵌入和二进制编码序列的神经架构，实现高粒度日志模板提取。

Result: 在Loghub-2k和工业数据集上测试，准确性与LLM解析器相当，效率优于语义解析器。

Conclusion: 该方法在低资源条件下实现了高精度和高效率的日志解析。

Abstract: System-generated logs are typically converted into categorical log templates
through parsing. These templates are crucial for generating actionable insights
in various downstream tasks. However, existing parsers often fail to capture
fine-grained template details, leading to suboptimal accuracy and reduced
utility in downstream tasks requiring precise pattern identification. We
propose a character-level log parser utilizing a novel neural architecture that
aggregates character embeddings. Our approach estimates a sequence of
binary-coded decimals to achieve highly granular log templates extraction. Our
low-resource character-level parser, tested on revised Loghub-2k and a manually
annotated industrial dataset, matches LLM-based parsers in accuracy while
outperforming semantic parsers in efficiency.

</details>


### [139] [Mispronunciation Detection Without L2 Pronunciation Dataset in Low-Resource Setting: A Case Study in Finland Swedish](https://arxiv.org/abs/2506.01156)
*Nhan Phan,Mikko Kuronen,Maria Kautonen,Riikka Ullakonoja,Anna von Zansen,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 本文提出了一种针对芬兰瑞典语（FS）的发音错误检测（MD）模型，通过多语言wav2vec 2.0模型和熵正则化训练，适用于低资源语言。


<details>
  <summary>Details</summary>
Motivation: 目前大多数MD模型针对英语等主要语言，而低资源语言如芬兰瑞典语缺乏相关工具。

Method: 使用多语言wav2vec 2.0模型，结合熵正则化、温度缩放和top-k归一化，仅需少量L2数据。

Result: 模型在召回率（43.2%）和精确率（29.8%）上优于基线模型（召回率77.5%，精确率17.6%）。

Conclusion: 该方法简单且语言无关，适用于其他低资源语言。

Abstract: Mispronunciation detection (MD) models are the cornerstones of many language
learning applications. Unfortunately, most systems are built for English and
other major languages, while low-resourced language varieties, such as Finland
Swedish (FS), lack such tools. In this paper, we introduce our MD model for FS,
trained on 89 hours of first language (L1) speakers' spontaneous speech and
tested on 33 minutes of L2 transcribed read-aloud speech.
  We trained a multilingual wav2vec 2.0 model with entropy regularization,
followed by temperature scaling and top-k normalization after the inference to
better adapt it for MD. The main novelty of our method lies in its simplicity,
requiring minimal L2 data. The process is also language-independent, making it
suitable for other low-resource languages. Our proposed algorithm allows us to
balance Recall (43.2%) and Precision (29.8%), compared with the baseline
model's Recall (77.5%) and Precision (17.6%).

</details>


### [140] [The Inverse Scaling Effect of Pre-Trained Language Model Surprisal Is Not Due to Data Leakage](https://arxiv.org/abs/2506.01172)
*Byung-Doh Oh,Hongao Zhu,William Schuler*

Main category: cs.CL

TL;DR: 研究表明，预训练语言模型的规模与对人类阅读时间的预测能力呈负相关，且数据泄漏并非主要原因。


<details>
  <summary>Details</summary>
Motivation: 探讨预训练语言模型的规模是否因数据泄漏而影响其对人类阅读时间的预测能力。

Method: 通过两项研究：1) 分析五个自然阅读时间语料库在预训练数据中的泄漏情况；2) 使用泄漏极少的模型复现模型规模与预测能力的负相关关系。

Result: 数据泄漏较少，且模型规模与预测能力的负相关关系在无泄漏数据中依然存在。

Conclusion: 预训练语言模型规模对阅读时间预测能力的负面影响并非由数据泄漏导致。

Abstract: In psycholinguistic modeling, surprisal from larger pre-trained language
models has been shown to be a poorer predictor of naturalistic human reading
times. However, it has been speculated that this may be due to data leakage
that caused language models to see the text stimuli during training. This paper
presents two studies to address this concern at scale. The first study reveals
relatively little leakage of five naturalistic reading time corpora in two
pre-training datasets in terms of length and frequency of token $n$-gram
overlap. The second study replicates the negative relationship between language
model size and the fit of surprisal to reading times using models trained on
'leakage-free' data that overlaps only minimally with the reading time corpora.
Taken together, this suggests that previous results using language models
trained on these corpora are not driven by the effects of data leakage.

</details>


### [141] [LAQuer: Localized Attribution Queries in Content-grounded Generation](https://arxiv.org/abs/2506.01187)
*Eran Hirsch,Aviv Slobodkin,David Wan,Elias Stengel-Eskin,Mohit Bansal,Ido Dagan*

Main category: cs.CL

TL;DR: 论文提出了一种名为LAQuer的新任务，用于将生成文本的特定部分与其来源对应起来，以提高归因的精确性和用户导向性。


<details>
  <summary>Details</summary>
Motivation: 现有归因方法要么过于笼统（句子级别），要么过于精确但不符合用户需求，因此需要一种更细粒度且用户导向的归因方法。

Method: 提出了LAQuer任务，并比较了两种方法：提示大型语言模型（LLMs）和利用LLM内部表示。还扩展了现有归因文本生成方法以支持LAQuer。

Result: 实验表明，LAQuer方法显著减少了归因文本的长度，在多文档摘要（MDS）和长形式问答（LFQA）任务中表现良好。

Conclusion: LAQuer任务提升了归因的实用性，提出了建模框架和基准，并推动了未来关于内容生成中局部归因的研究。

Abstract: Grounded text generation models often produce content that deviates from
their source material, requiring user verification to ensure accuracy. Existing
attribution methods associate entire sentences with source documents, which can
be overwhelming for users seeking to fact-check specific claims. In contrast,
existing sub-sentence attribution methods may be more precise but fail to align
with users' interests. In light of these limitations, we introduce Localized
Attribution Queries (LAQuer), a new task that localizes selected spans of
generated output to their corresponding source spans, allowing fine-grained and
user-directed attribution. We compare two approaches for the LAQuer task,
including prompting large language models (LLMs) and leveraging LLM internal
representations. We then explore a modeling framework that extends existing
attributed text generation methods to LAQuer. We evaluate this framework across
two grounded text generation tasks: Multi-document Summarization (MDS) and
Long-form Question Answering (LFQA). Our findings show that LAQuer methods
significantly reduce the length of the attributed text. Our contributions
include: (1) proposing the LAQuer task to enhance attribution usability, (2)
suggesting a modeling framework and benchmarking multiple baselines, and (3)
proposing a new evaluation setting to promote future research on localized
attribution in content-grounded generation.

</details>


### [142] [Culturally-Grounded Chain-of-Thought (CG-CoT):Enhancing LLM Performance on Culturally-Specific Tasks in Low-Resource Languages](https://arxiv.org/abs/2506.01190)
*Madhavendra Thakur*

Main category: cs.CL

TL;DR: CG-CoT是一种结合文化背景检索与显式推理序列的新提示策略，显著提升了低资源语言任务的文化对齐准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在低资源语言和文化特定推理任务中的不足，以实现更公平的AI应用。

Method: 提出CG-CoT，结合密集向量检索文化背景与显式推理序列，并在约鲁巴谚语解释任务中进行实验。

Result: CG-CoT在文化对齐准确性和深度上显著优于传统提示方法，并通过自动指标和LLM评估验证。

Conclusion: 需重新思考低资源NLP的评估方法，因为传统翻译指标（如BLEU）与文化相关性之间存在显著差异。

Abstract: Large Language Models (LLMs) struggle with culturally-specific reasoning
tasks, particularly in low-resource languages, hindering their global
applicability. Addressing this gap is crucial for equitable AI deployment. We
introduce Culturally-Grounded Chain-of-Thought (CG-CoT), a novel prompting
strategy that combines dense vector retrieval of cultural context with explicit
reasoning sequences. Our extensive experiments on Yoruba proverb interpretation
demonstrate that CG-CoT provides significantly higher culturally-aligned
accuracy and depth than traditional prompting methods, validated through both
automated metrics and LLM-based evaluations. Notably, we uncover stark
disparities between token-level translation metrics like BLEU and human-judged
cultural relevance, suggesting a rethinking of evaluation approaches for
low-resource NLP.

</details>


### [143] [CoBRA: Quantifying Strategic Language Use and LLM Pragmatics](https://arxiv.org/abs/2506.01195)
*Anshun Asher Zheng,Junyi Jessy Li,David I. Beaver*

Main category: cs.CL

TL;DR: 论文提出了CoBRA框架和CHARM数据集，用于量化非合作话语的策略效果，并评估了LLMs在此类语言中的表现。


<details>
  <summary>Details</summary>
Motivation: 填补对非合作话语系统性理解的空白，尤其是在高风险的对抗性环境中。

Method: 引入CoBRA框架和三个可解释指标（BaT、PaT、NRBaT），并使用CHARM数据集验证框架有效性。

Result: LLMs在战略语言上的语用理解有限，模型规模提升性能，但推理能力反而导致过度复杂和内部混乱。

Conclusion: LLMs在非合作话语中的表现有待改进，模型规模虽有益，但推理能力需优化。

Abstract: Language is often used strategically, particularly in high-stakes,
adversarial settings, yet most work on pragmatics and LLMs centers on
cooperativity. This leaves a gap in systematic understanding of non-cooperative
discourse. To address this, we introduce CoBRA (Cooperation-Breach Response
Assessment), along with three interpretable metrics -- Benefit at Turn (BaT),
Penalty at Turn (PaT), and Normalized Relative Benefit at Turn (NRBaT) -- to
quantify the perceived strategic effects of discourse moves. We also present
CHARM, an annotated dataset of real courtroom cross-examinations, to
demonstrate the framework's effectiveness. Using these tools, we evaluate a
range of LLMs and show that LLMs generally exhibit limited pragmatic
understanding of strategic language. While model size shows an increase in
performance on our metrics, reasoning ability does not help and largely hurts,
introducing overcomplication and internal confusion.

</details>


### [144] [Incorporating Hierarchical Semantics in Sparse Autoencoder Architectures](https://arxiv.org/abs/2506.01197)
*Mark Muchane,Sean Richardson,Kiho Park,Victor Veitch*

Main category: cs.CL

TL;DR: 提出一种改进的稀疏自编码器架构，显式建模概念的语义层次结构，提升重建效果、可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏字典学习（如稀疏自编码器）未能利用或表示学习概念间的语义关系，限制了其效果。

Method: 引入改进的稀疏自编码器架构，显式建模概念的语义层次结构。

Result: 实验表明，该架构能学习语义层次结构，提升重建效果、可解释性和计算效率。

Conclusion: 显式建模语义层次结构是改进稀疏自编码器的有效方法。

Abstract: Sparse dictionary learning (and, in particular, sparse autoencoders) attempts
to learn a set of human-understandable concepts that can explain variation on
an abstract space. A basic limitation of this approach is that it neither
exploits nor represents the semantic relationships between the learned
concepts. In this paper, we introduce a modified SAE architecture that
explicitly models a semantic hierarchy of concepts. Application of this
architecture to the internal representations of large language models shows
both that semantic hierarchy can be learned, and that doing so improves both
reconstruction and interpretability. Additionally, the architecture leads to
significant improvements in computational efficiency.

</details>


### [145] [Trick or Neat: Adversarial Ambiguity and Language Model Evaluation](https://arxiv.org/abs/2506.01205)
*Antonia Karamolegkou,Oliver Eberle,Phillip Rust,Carina Kauf,Anders Søgaard*

Main category: cs.CL

TL;DR: 论文研究了语言模型对歧义的敏感性，通过引入对抗性歧义数据集，发现直接提示法效果不佳，而基于模型表示的线性探针能高精度解码歧义。


<details>
  <summary>Details</summary>
Motivation: 检测歧义对语言理解至关重要，包括不确定性估计、幽默检测等，但现有方法效果有限。

Method: 使用对抗性歧义数据集（包含句法、词汇和语音歧义），对比直接提示法和线性探针法。

Result: 线性探针法解码歧义准确率高达90%以上，优于直接提示法。

Conclusion: 研究揭示了提示范式的局限性，并展示了语言模型在不同层如何编码歧义。

Abstract: Detecting ambiguity is important for language understanding, including
uncertainty estimation, humour detection, and processing garden path sentences.
We assess language models' sensitivity to ambiguity by introducing an
adversarial ambiguity dataset that includes syntactic, lexical, and
phonological ambiguities along with adversarial variations (e.g., word-order
changes, synonym replacements, and random-based alterations). Our findings show
that direct prompting fails to robustly identify ambiguity, while linear probes
trained on model representations can decode ambiguity with high accuracy,
sometimes exceeding 90\%. Our results offer insights into the prompting
paradigm and how language models encode ambiguity at different layers. We
release both our code and data: https://github.com/coastalcph/lm_ambiguity.

</details>


### [146] [Mamba Drafters for Speculative Decoding](https://arxiv.org/abs/2506.01206)
*Daewon Choi,Seunghyuk Oh,Saket Dingliwal,Jihoon Tack,Kyuyoung Kim,Woomin Song,Seojin Kim,Insu Han,Jinwoo Shin,Aram Galstyan,Shubham Katiyar,Sravan Babu Bodapati*

Main category: cs.CL

TL;DR: 本文提出了一种基于Mamba的新型drafters方法，结合了外部drafters的灵活性和自推测方法的效率，通过线性结构避免了传统Transformer的二次复杂度，实现了更快生成和更低内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在外部drafters和自推测方法之间存在权衡，前者灵活但速度慢，后者高效但需重新训练。本文旨在结合两者的优势。

Method: 利用Mamba（一种状态空间模型）的线性结构，避免二次复杂度，并引入测试时树搜索算法生成高质量候选。

Result: 实验表明，Mamba-based drafters在性能上超越外部方法，接近自推测方法，同时内存占用更低且保持跨模型适应性。

Conclusion: Mamba-based drafters是一种高效、灵活且内存友好的解决方案，适用于加速LLM生成。

Abstract: Speculative decoding has emerged as a promising approach to accelerating
large language model (LLM) generation using a fast drafter while maintaining
alignment with the target model's distribution. However, existing approaches
face a trade-off: external drafters offer flexibility but can suffer from
slower drafting, while self-speculation methods use drafters tailored to the
target model but require re-training. In this paper, we introduce novel
drafters based on Mamba, a state-of-the-art state space model (SSM), as a
solution that combines the best aspects of both approaches. By leveraging the
linear structure of SSMs, our approach avoids the quadratic complexity inherent
in traditional Transformer-based methods, enabling faster drafting and lower
memory usage while maintaining the flexibility to work across different target
models. We further enhance efficiency with a novel test-time tree search
algorithm for generating high-quality draft candidates. Our empirical
evaluation demonstrates that Mamba-based drafters not only outperform existing
external drafting methods but are also comparable to state-of-the-art
self-speculation approaches while using less memory and maintaining their
cross-model adaptability.

</details>


### [147] [Compress, Gather, and Recompute: REFORMing Long-Context Processing in Transformers](https://arxiv.org/abs/2506.01215)
*Woomin Song,Sai Muralidhar Jayanthi,Srikanth Ronanki,Kanthashree Mysore Sathyendra,Jinwoo Shin,Aram Galstyan,Shubham Katiyar,Sravan Babu Bodapati*

Main category: cs.CL

TL;DR: REFORM是一种新型推理框架，通过两阶段方法高效处理长上下文，显著提升性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实应用中的普及，处理超出预训练上下文限制的超长上下文成为关键挑战。现有方法在信息保存或内存资源需求方面存在不足。

Method: REFORM采用两阶段方法：1）增量处理输入块，维护压缩的KV缓存并构建跨层上下文嵌入；2）通过相似性匹配识别关键令牌并选择性重新计算KV缓存。

Result: 在1M上下文长度下，REFORM在RULER和BABILong上分别实现50%和27%的性能提升，同时在Infinite-Bench和MM-NIAH上优于基线，推理时间减少30%，峰值内存使用降低5%。

Conclusion: REFORM在高效处理长上下文的同时，实现了性能和资源效率的双重优势。

Abstract: As large language models increasingly gain popularity in real-world
applications, processing extremely long contexts, often exceeding the model's
pre-trained context limits, has emerged as a critical challenge. While existing
approaches to efficient long-context processing show promise, recurrent
compression-based methods struggle with information preservation, whereas
random access approaches require substantial memory resources. We introduce
REFORM, a novel inference framework that efficiently handles long contexts
through a two-phase approach. First, it incrementally processes input chunks
while maintaining a compressed KV cache, constructs cross-layer context
embeddings, and utilizes early exit strategy for improved efficiency. Second,
it identifies and gathers essential tokens via similarity matching and
selectively recomputes the KV cache. Compared to baselines, REFORM achieves
over 50% and 27% performance gains on RULER and BABILong respectively at 1M
context length. It also outperforms baselines on Infinite-Bench and MM-NIAH,
demonstrating flexibility across diverse tasks and domains. Additionally,
REFORM reduces inference time by 30% and peak memory usage by 5%, achieving
both efficiency and superior performance.

</details>


### [148] [Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean](https://arxiv.org/abs/2506.01237)
*SungHo Kim,Nayeon Kim,Taehee Jeon,SangKeun Lee*

Main category: cs.CL

TL;DR: KoGEM是一个用于评估LLMs和人类韩语能力的基准测试，包含1.5k个选择题，覆盖5大类16小类。测试发现LLMs在简单任务上表现良好，但在需要实际经验的任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs和人类在韩语中的语言能力，揭示LLMs的局限性并提出改进方向。

Method: 使用KoGEM基准测试，对27种不同规模和类型的LLMs进行零样本评估。

Result: LLMs在定义性知识任务上表现优秀，但在需要实际经验的任务（如音韵规则）上表现较差。

Conclusion: KoGEM揭示了LLMs的语言能力局限性，并指出结合实际经验知识可提升其能力。

Abstract: We introduce the $\underline{Ko}rean \underline{G}rammar
\underline{E}valuation Bench\underline{M}ark (KoGEM)$, designed to assess the
linguistic competence of LLMs and humans in Korean. KoGEM consists of 1.5k
multiple-choice QA pairs covering five main categories and 16 subcategories.
The zero-shot evaluation of 27 LLMs of various sizes and types reveals that
while LLMs perform remarkably well on straightforward tasks requiring primarily
definitional knowledge, they struggle with tasks that demand the integration of
real-world experiential knowledge, such as phonological rules and
pronunciation. Furthermore, our in-depth analysis suggests that incorporating
such experiential knowledge could enhance the linguistic competence of LLMs.
With KoGEM, we not only highlight the limitations of current LLMs in linguistic
competence but also uncover hidden facets of LLMs in linguistic competence,
paving the way for enhancing comprehensive language understanding. Our code and
dataset are available at: https://github.com/SungHo3268/KoGEM.

</details>


### [149] [ExpertLongBench: Benchmarking Language Models on Expert-Level Long-Form Generation Tasks with Structured Checklists](https://arxiv.org/abs/2506.01241)
*Jie Ruan,Inderjeet Nair,Shuyang Cao,Amy Liu,Sheza Munir,Micah Pollens-Dempsey,Tiffany Chiang,Lucy Kates,Nicholas David,Sihan Chen,Ruxin Yang,Yuqian Yang,Jasmine Gump,Tessa Bialek,Vivek Sankaran,Margo Schlanger,Lu Wang*

Main category: cs.CL

TL;DR: ExpertLongBench是一个专家级基准测试，包含9个领域的11个任务，要求长文本输出和严格的领域要求。CLEAR评估框架通过提取任务特定评分标准的信息，实现细粒度评估。测试显示现有LLMs表现不佳，但CLEAR框架可扩展且低成本。


<details>
  <summary>Details</summary>
Motivation: 为专家级任务提供一个真实反映工作流程的基准测试，并解决长文本输出评估的挑战。

Method: 提出ExpertLongBench基准和CLEAR评估框架，通过提取评分标准信息生成检查表，比较模型输出与参考输出的正确性。

Result: 测试11个LLMs，表现最佳者F1分数仅26.8%，模型能生成相关内容但准确性不足，CLEAR框架可扩展且低成本。

Conclusion: ExpertLongBench和CLEAR为专家级任务提供了有效的评估工具，现有LLMs需大幅改进，CLEAR框架具有实用性和扩展性。

Abstract: This paper introduces ExpertLongBench, an expert-level benchmark containing
11 tasks from 9 domains that reflect realistic expert workflows and
applications. Beyond question answering, the application-driven tasks in
ExpertLongBench demand long-form outputs that can exceed 5,000 tokens and
strict adherence to domain-specific requirements. Notably, each task in
ExpertLongBench includes a rubric, designed or validated by domain experts, to
specify task requirements and guide output evaluation. Furthermore, we propose
CLEAR, an evaluation framework that supports accurate evaluation of long-form
model outputs in our benchmark. To achieve fine-grained, expert-aligned
evaluation, CLEAR derives checklists from both model outputs and references by
extracting information corresponding to items in the task-specific rubric.
Checklist items for model outputs are then compared with corresponding items
for reference outputs to assess their correctness, enabling grounded
evaluation. We benchmark 11 large language models (LLMs) and analyze components
in CLEAR, showing that (1) existing LLMs, with the top performer achieving only
a 26.8% F1 score, require significant improvement for expert-level tasks; (2)
models can generate content corresponding to the required aspects, though often
not accurately; and (3) accurate checklist extraction and comparison in CLEAR
can be achieved by open-weight models for more scalable and low-cost usage.

</details>


### [150] [MTCMB: A Multi-Task Benchmark Framework for Evaluating LLMs on Knowledge, Reasoning, and Safety in Traditional Chinese Medicine](https://arxiv.org/abs/2506.01252)
*Shufeng Kong,Xingru Yang,Yuanyuan Wei,Zijie Wang,Hao Tang,Jiuqi Qin,Shuting Lan,Yingheng Wang,Junwen Bai,Zhuangbin Chen,Zibin Zheng,Caihua Liu,Hao Liang*

Main category: cs.CL

TL;DR: 论文提出了MTCMB，一个用于评估大型语言模型（LLMs）在中医（TCM）领域知识、推理和安全性的多任务基准。


<details>
  <summary>Details</summary>
Motivation: 中医的隐式推理、多样文本形式和缺乏标准化为计算建模和评估带来挑战，而现有基准在中医领域的系统评估不足。

Method: MTCMB包含12个子数据集，涵盖知识问答、语言理解、诊断推理、处方生成和安全性评估五大类，整合了真实病例、国家考试和经典文本。

Result: 初步结果显示，当前LLMs在基础知识上表现良好，但在临床推理、处方规划和安全性合规方面表现不足。

Conclusion: MTCMB的提出为开发更可靠的中医AI系统提供了急需的领域对齐基准。

Abstract: Traditional Chinese Medicine (TCM) is a holistic medical system with
millennia of accumulated clinical experience, playing a vital role in global
healthcare-particularly across East Asia. However, the implicit reasoning,
diverse textual forms, and lack of standardization in TCM pose major challenges
for computational modeling and evaluation. Large Language Models (LLMs) have
demonstrated remarkable potential in processing natural language across diverse
domains, including general medicine. Yet, their systematic evaluation in the
TCM domain remains underdeveloped. Existing benchmarks either focus narrowly on
factual question answering or lack domain-specific tasks and clinical realism.
To fill this gap, we introduce MTCMB-a Multi-Task Benchmark for Evaluating LLMs
on TCM Knowledge, Reasoning, and Safety. Developed in collaboration with
certified TCM experts, MTCMB comprises 12 sub-datasets spanning five major
categories: knowledge QA, language understanding, diagnostic reasoning,
prescription generation, and safety evaluation. The benchmark integrates
real-world case records, national licensing exams, and classical texts,
providing an authentic and comprehensive testbed for TCM-capable models.
Preliminary results indicate that current LLMs perform well on foundational
knowledge but fall short in clinical reasoning, prescription planning, and
safety compliance. These findings highlight the urgent need for domain-aligned
benchmarks like MTCMB to guide the development of more competent and
trustworthy medical AI systems. All datasets, code, and evaluation tools are
publicly available at: https://github.com/Wayyuanyuan/MTCMB.

</details>


### [151] [CoRE: Condition-based Reasoning for Identifying Outcome Variance in Complex Events](https://arxiv.org/abs/2506.01253)
*Sai Vallurupalli,Francis Ferraro*

Main category: cs.CL

TL;DR: 论文探讨了如何通过潜在条件分析复杂事件结果，结合现有数据集提出条件推理任务，并测试不同规模和对齐程度的LLM在任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是识别和分析影响事件结果的潜在条件，以验证复杂事件结果的合理性。

Method: 方法包括结合和扩展两个现有数据集的标注（目标和状态），设计条件推理任务，并测试不同LLM的表现。

Result: 结果表明，条件在上下文缺失时有用，不同模型在生成和识别条件的能力上差异显著，大模型（如GPT-4o）在约束较少时更谨慎。

Conclusion: 结论是条件分析有助于验证事件结果，模型规模和意图对齐对其表现有显著影响。

Abstract: Knowing which latent conditions lead to a particular outcome is useful for
critically examining claims made about complex event outcomes. Identifying
implied conditions and examining their influence on an outcome is challenging.
We handle this by combining and augmenting annotations from two existing
datasets consisting of goals and states, and explore the influence of
conditions through our research questions and Condition-based Reasoning tasks.
We examine open and closed LLMs of varying sizes and intent-alignment on our
reasoning tasks and find that conditions are useful when not all context is
available. Models differ widely in their ability to generate and identify
outcome-variant conditions which affects their performance on outcome
validation when conditions are used to replace missing context. Larger models
like GPT-4o, are more cautious in such less constrained situations.

</details>


### [152] [Memory-Efficient FastText: A Comprehensive Approach Using Double-Array Trie Structures and Mark-Compact Memory Management](https://arxiv.org/abs/2506.01254)
*Yimin Du*

Main category: cs.CL

TL;DR: 本文提出了一种基于双数组字典树和标记-压缩垃圾回收原则的FastText内存优化框架，显著减少了内存占用并保持了嵌入质量。


<details>
  <summary>Details</summary>
Motivation: FastText在处理大规模工业词汇表时存在哈希冲突和内存消耗过高的问题。

Method: 通过构建前缀字典树、基于前缀和后缀的相似性压缩，以及标记-压缩内存重组，优化内存管理。

Result: 在3000万中文词汇数据集上，内存占用从100GB降至30GB，性能几乎无损。

Conclusion: 该方法显著降低了成本，提升了加载速度和模型可靠性。

Abstract: FastText has established itself as a fundamental algorithm for learning word
representations, demonstrating exceptional capability in handling
out-of-vocabulary words through character-level n-gram embeddings. However, its
hash-based bucketing mechanism introduces critical limitations for large-scale
industrial deployment: hash collisions cause semantic drift, and memory
requirements become prohibitively expensive when dealing with real-world
vocabularies containing millions of terms. This paper presents a comprehensive
memory optimization framework that fundamentally reimagines FastText's memory
management through the integration of double-array trie (DA-trie) structures
and mark-compact garbage collection principles. Our approach leverages the
linguistic insight that n-grams sharing common prefixes or suffixes exhibit
highly correlated embeddings due to co-occurrence patterns in natural language.
By systematically identifying and merging semantically similar embeddings based
on structural relationships, we achieve compression ratios of 4:1 to 10:1 while
maintaining near-perfect embedding quality. The algorithm consists of four
sophisticated phases: prefix trie construction with embedding mapping,
prefix-based similarity compression, suffix-based similarity compression, and
mark-compact memory reorganization. Comprehensive experiments on a 30-million
Chinese vocabulary dataset demonstrate memory reduction from over 100GB to
approximately 30GB with negligible performance degradation. Our industrial
deployment results show significant cost reduction, faster loading times, and
improved model reliability through the elimination of hash collision artifacts.
Code and experimental implementations are available at:
https://github.com/initial-d/me_fasttext

</details>


### [153] [DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models](https://arxiv.org/abs/2506.01257)
*Jiancheng Ye,Sophie Bronstein,Jiarui Hai,Malak Abu Hashish*

Main category: cs.CL

TL;DR: DeepSeek-R1是一款开源大型语言模型，结合混合架构（MoE、CoT推理和强化学习），在数学、医疗诊断等领域表现优异，但存在偏见和安全问题。


<details>
  <summary>Details</summary>
Motivation: 提供透明且经济的替代方案，挑战专有模型如GPT-4o和Claude-3 Opus，推动开源AI发展。

Method: 采用混合架构（MoE、CoT推理和强化学习），优化推理效率与深度。

Result: 在USMLE、AIME等基准测试中表现优异，尤其在医疗和数学领域，但存在偏见和安全漏洞。

Conclusion: DeepSeek-R1是开源AI的重要进展，需进一步研究解决偏见、安全及合规性问题。

Abstract: DeepSeek-R1 is a cutting-edge open-source large language model (LLM)
developed by DeepSeek, showcasing advanced reasoning capabilities through a
hybrid architecture that integrates mixture of experts (MoE), chain of thought
(CoT) reasoning, and reinforcement learning. Released under the permissive MIT
license, DeepSeek-R1 offers a transparent and cost-effective alternative to
proprietary models like GPT-4o and Claude-3 Opus; it excels in structured
problem-solving domains such as mathematics, healthcare diagnostics, code
generation, and pharmaceutical research. The model demonstrates competitive
performance on benchmarks like the United States Medical Licensing Examination
(USMLE) and American Invitational Mathematics Examination (AIME), with strong
results in pediatric and ophthalmologic clinical decision support tasks. Its
architecture enables efficient inference while preserving reasoning depth,
making it suitable for deployment in resource-constrained settings. However,
DeepSeek-R1 also exhibits increased vulnerability to bias, misinformation,
adversarial manipulation, and safety failures - especially in multilingual and
ethically sensitive contexts. This survey highlights the model's strengths,
including interpretability, scalability, and adaptability, alongside its
limitations in general language fluency and safety alignment. Future research
priorities include improving bias mitigation, natural language comprehension,
domain-specific validation, and regulatory compliance. Overall, DeepSeek-R1
represents a major advance in open, scalable AI, underscoring the need for
collaborative governance to ensure responsible and equitable deployment.

</details>


### [154] [Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis](https://arxiv.org/abs/2506.01262)
*Jisoo Mok,Ik-hwan Kim,Sangkwon Park,Sungroh Yoon*

Main category: cs.CL

TL;DR: HiCUPID是一个新的开源基准测试，旨在解决个性化AI助手研究中缺乏开源对话数据集的问题，并提供基于Llama-3.2的自动评估模型。


<details>
  <summary>Details</summary>
Motivation: 个性化AI助手的研究缺乏开源对话数据集，阻碍了该领域的发展。

Method: 提出了HiCUPID基准测试，包括一个对话数据集和基于Llama-3.2的自动评估模型。

Result: HiCUPID的数据集、评估模型和代码已开源，评估模型的表现与人类偏好高度一致。

Conclusion: HiCUPID为个性化AI助手研究提供了重要资源，有助于推动该领域的发展。

Abstract: Personalized AI assistants, a hallmark of the human-like capabilities of
Large Language Models (LLMs), are a challenging application that intertwines
multiple problems in LLM research. Despite the growing interest in the
development of personalized assistants, the lack of an open-source
conversational dataset tailored for personalization remains a significant
obstacle for researchers in the field. To address this research gap, we
introduce HiCUPID, a new benchmark to probe and unleash the potential of LLMs
to deliver personalized responses. Alongside a conversational dataset, HiCUPID
provides a Llama-3.2-based automated evaluation model whose assessment closely
mirrors human preferences. We release our dataset, evaluation model, and code
at https://github.com/12kimih/HiCUPID.

</details>


### [155] [WCTC-Biasing: Retraining-free Contextual Biasing ASR with Wildcard CTC-based Keyword Spotting and Inter-layer Biasing](https://arxiv.org/abs/2506.01263)
*Yu Nakagome,Michael Hentschel*

Main category: cs.CL

TL;DR: 提出了一种无需额外训练的方法，通过关键词检测和偏置调整，显著提高了CTC模型中罕见词的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 解决端到端语音识别模型对训练数据词汇的依赖问题，特别是对专有名词和未知词汇的识别不准确。

Method: 在推理过程中利用中间层的声学特征进行关键词检测，并对检测到的关键词在后续层中应用偏置。采用快速且容忍模糊匹配的wildcard CTC进行关键词检测。

Result: 在日语语音识别实验中，未知词的F1分数提高了29%。

Conclusion: 该方法无需重新训练现有模型，适用于大规模模型，显著提升了罕见词的识别性能。

Abstract: Despite recent advances in end-to-end speech recognition methods, the output
tends to be biased to the training data's vocabulary, resulting in inaccurate
recognition of proper nouns and other unknown terms. To address this issue, we
propose a method to improve recognition accuracy of such rare words in
CTC-based models without additional training or text-to-speech systems.
Specifically, keyword spotting is performed using acoustic features of
intermediate layers during inference, and a bias is applied to the subsequent
layers of the acoustic model for detected keywords. For keyword detection, we
adopt a wildcard CTC that is both fast and tolerant of ambiguous matches,
allowing flexible handling of words that are difficult to match strictly. Since
this method does not require retraining of existing models, it can be easily
applied to even large-scale models. In experiments on Japanese speech
recognition, the proposed method achieved a 29% improvement in the F1 score for
unknown words.

</details>


### [156] [Beyond In-Context Learning: Aligning Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines](https://arxiv.org/abs/2506.01265)
*Do Xuan Long,Duong Ngoc Yen,Do Xuan Trong,Luu Anh Tuan,Kenji Kawaguchi,Shafiq Joty,Min-Yen Kan,Nancy F. Chen*

Main category: cs.CL

TL;DR: 论文提出LongGuide方法，通过生成任务语言和格式的指导准则，提升大语言模型在长文本生成任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决上下文学习（ICL）在长文本生成任务中表现不佳的问题，探索如何通过明确的任务分布指导提升模型性能。

Method: 提出LongGuide方法，生成两种并行指导准则（Metric Guidelines和Output Constraint Guidelines），并自动选择最佳组合。

Result: 实验表明，LongGuide在零样本和少样本设置下，将强开源和闭源模型的性能提升超过5%。

Conclusion: 结论是LongGuide具有通用性，可被弱模型学习以增强强模型，并能与自动提示优化器协同工作。

Abstract: In-context learning (ICL) is an important yet not fully understood ability of
pre-trained large language models (LLMs). It can greatly enhance task
performance using a few examples, termed demonstrations, without fine-tuning.
Although effective in question answering, ICL often underperforms in long-form
generation tasks such as summarization. Under appropriately realistic
assumptions, we empirically and theoretically show that ICL demonstrations
alone are insufficient to teach LLMs the task language and format distributions
for generation. We argue for explicit exposure to the task distributions and
hypothesize that defining them by prompting enhances model performance. To this
end, we present LongGuide, which efficiently generates two parallel streams of
guidelines capturing task language and format properties: (i) Metric Guidelines
(MGs) that instruct models to optimize self-evaluated metrics; and (ii) Output
Constraint Guidelines (OCGs) that constrain generation at both token and
sentence levels. LongGuide automatically selects the best combination of
guidelines, improving both strong open- and closed-source LLMs by over 5% in
both zero- and few-shot settings. We show that LongGuide is generalizable,
learnable by weak models to enhance strong ones, and integrates synergistically
with automatic prompt optimizers.

</details>


### [157] [Detoxification of Large Language Models through Output-layer Fusion with a Calibration Model](https://arxiv.org/abs/2506.01266)
*Yuanhe Tian,Mingjie Deng,Guoqing Jin,Yan Song*

Main category: cs.CL

TL;DR: 提出了一种轻量级干预方法，通过预训练的校准模型引导LLM生成无毒内容，避免了传统方法的高计算成本和性能损失。


<details>
  <summary>Details</summary>
Motivation: 现有LLM去毒方法依赖大规模数据或模型参数修改，计算成本高且影响流畅性和上下文理解。

Method: 利用预训练的紧凑校准模型，通过学习无毒嵌入空间，轻量干预LLM生成过程。

Result: 实验表明，该方法有效降低毒性，同时保持内容表达的流畅性和上下文理解。

Conclusion: 该方法简单高效，适用于多种LLM，无需重复训练且性能稳定。

Abstract: Existing approaches for Large language model (LLM) detoxification generally
rely on training on large-scale non-toxic or human-annotated preference data,
designing prompts to instruct the LLM to generate safe content, or modifying
the model parameters to remove toxic information, which are computationally
expensive, lack robustness, and often compromise LLMs' fluency and contextual
understanding. In this paper, we propose a simple yet effective approach for
LLM detoxification, which leverages a compact, pre-trained calibration model
that guides the detoxification process of a target LLM via a lightweight
intervention in its generation pipeline. By learning a detoxified embedding
space from non-toxic data, the calibration model effectively steers the LLM
away from generating harmful content. This approach only requires a one-time
training of the calibration model that is able to be seamlessly applied to
multiple LLMs without compromising fluency or contextual understanding.
Experiment results on the benchmark dataset demonstrate that our approach
reduces toxicity while maintaining reasonable content expression.

</details>


### [158] [Schema as Parameterized Tools for Universal Information Extraction](https://arxiv.org/abs/2506.01276)
*Sheng Liang,Yongyue Zhang,Yaxiong Wu,Ruiming Tang,Yong Liu*

Main category: cs.CL

TL;DR: 论文提出了一种名为SPT的统一自适应文本到结构生成框架，通过将预定义模式视为参数化工具，解决了UIE在模式选择和动态生成中的适应性问题。


<details>
  <summary>Details</summary>
Motivation: UIE在预定义模式选择和动态模式生成方面缺乏适应性，尤其是在模式选择较多时。

Method: SPT框架将预定义模式视为参数化工具，支持模式检索、模式填充和模式生成三种任务。

Result: 实验表明，SPT能自适应处理四种不同的IE任务，性能与现有系统相当，但训练参数更少。

Conclusion: SPT通过统一框架解决了UIE的适应性问题，并在性能和效率上表现优异。

Abstract: Universal information extraction (UIE) primarily employs an extractive
generation approach with large language models (LLMs), typically outputting
structured information based on predefined schemas such as JSON or tables. UIE
suffers from a lack of adaptability when selecting between predefined schemas
and on-the-fly schema generation within the in-context learning paradigm,
especially when there are numerous schemas to choose from. In this paper, we
propose a unified adaptive text-to-structure generation framework, called
Schema as Parameterized Tools (SPT), which reimagines the tool-calling
capability of LLMs by treating predefined schemas as parameterized tools for
tool selection and parameter filling. Specifically, our SPT method can be
applied to unify closed, open, and on-demand IE tasks by adopting Schema
Retrieval by fetching the relevant schemas from a predefined pool, Schema
Filling by extracting information and filling slots as with tool parameters, or
Schema Generation by synthesizing new schemas with uncovered cases. Experiments
show that the SPT method can handle four distinct IE tasks adaptively,
delivering robust schema retrieval and selection performance. SPT also achieves
comparable extraction performance to LoRA baselines and current leading UIE
systems with significantly fewer trainable parameters.

</details>


### [159] [VM14K: First Vietnamese Medical Benchmark](https://arxiv.org/abs/2506.01305)
*Thong Nguyen,Duc Nguyen,Minh Dang,Thai Dao,Long Nguyen,Quan H. Nguyen,Dat Nguyen,Kien Tran,Minh Tran*

Main category: cs.CL

TL;DR: 开发了一种方法，创建了首个越南语医学问题基准，包含14,000个选择题，覆盖34个医学专业，用于评估语言模型在医疗领域的能力。


<details>
  <summary>Details</summary>
Motivation: 非英语社区缺乏资源和标准化方法来构建医学基准，且数据分散难以验证。

Method: 利用可验证来源（如医学考试和临床记录）构建基准，并由医学专家标注，包含四个难度级别。

Result: 发布了包含公共样本集（4k问题）、完整公共集（10k问题）和私有集（2k问题）的基准，支持多语言扩展。

Conclusion: 该方法可扩展至其他语言，开源数据构建流程以支持未来多语言医学基准的开发。

Abstract: Medical benchmarks are indispensable for evaluating the capabilities of
language models in healthcare for non-English-speaking communities,therefore
help ensuring the quality of real-life applications. However, not every
community has sufficient resources and standardized methods to effectively
build and design such benchmark, and available non-English medical data is
normally fragmented and difficult to verify. We developed an approach to tackle
this problem and applied it to create the first Vietnamese medical question
benchmark, featuring 14,000 multiple-choice questions across 34 medical
specialties. Our benchmark was constructed using various verifiable sources,
including carefully curated medical exams and clinical records, and eventually
annotated by medical experts. The benchmark includes four difficulty levels,
ranging from foundational biological knowledge commonly found in textbooks to
typical clinical case studies that require advanced reasoning. This design
enables assessment of both the breadth and depth of language models' medical
understanding in the target language thanks to its extensive coverage and
in-depth subject-specific expertise. We release the benchmark in three parts: a
sample public set (4k questions), a full public set (10k questions), and a
private set (2k questions) used for leaderboard evaluation. Each set contains
all medical subfields and difficulty levels. Our approach is scalable to other
languages, and we open-source our data construction pipeline to support the
development of future multilingual benchmarks in the medical domain.

</details>


### [160] [A Platform for Investigating Public Health Content with Efficient Concern Classification](https://arxiv.org/abs/2506.01308)
*Christopher Li,Rickard Stureborg,Bhuwan Dhingra,Jun Yang*

Main category: cs.CL

TL;DR: ConcernScope是一个基于教师-学生框架的平台，用于快速识别文本中的公共卫生问题，帮助公共卫生官员分析在线内容中的担忧。


<details>
  <summary>Details</summary>
Motivation: 在线内容中对公共卫生措施的担忧影响了预防措施的采纳，需要理解这些内容及其影响。

Method: 使用教师-学生框架进行知识转移，结合轻量级分类器和大型语言模型，支持大规模文件上传和URL自动抓取。

Result: 平台成功应用于数据分析，包括时间序列分析和事件前后主题频率趋势。

Conclusion: ConcernScope为公共卫生官员提供了有效的工具，用于识别和应对在线内容中的健康担忧。

Abstract: A recent rise in online content expressing concerns with public health
initiatives has contributed to already stalled uptake of preemptive measures
globally. Future public health efforts must attempt to understand such content,
what concerns it may raise among readers, and how to effectively respond to it.
To this end, we present ConcernScope, a platform that uses a teacher-student
framework for knowledge transfer between large language models and light-weight
classifiers to quickly and effectively identify the health concerns raised in a
text corpus. The platform allows uploading massive files directly,
automatically scraping specific URLs, and direct text editing. ConcernScope is
built on top of a taxonomy of public health concerns. Intended for public
health officials, we demonstrate several applications of this platform: guided
data exploration to find useful examples of common concerns found in online
community datasets, identification of trends in concerns through an example
time series analysis of 186,000 samples, and finding trends in topic frequency
before and after significant events.

</details>


### [161] [Growing Through Experience: Scaling Episodic Grounding in Language Models](https://arxiv.org/abs/2506.01312)
*Chunhui Zhang,Sirui,Wang,Zhongyu Ouyang,Xiangchi Yuan,Soroush Vosoughi*

Main category: cs.CL

TL;DR: 论文提出了一种可扩展的弱到强情景学习框架，通过蒙特卡洛树搜索和新型蒸馏方法，提升语言模型在规划和问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有情景学习方法在可扩展性和集成性上存在不足，尤其是对中型语言模型（7B参数）效果有限，而大型模型（70-405B参数）虽具备更强的抽象能力，但缺乏有效利用经验流的机制。

Method: 提出了一种结合蒙特卡洛树搜索的结构化经验收集方法和新型蒸馏技术，以保留语言模型固有能力的同时嵌入情景记忆。

Result: 实验表明，该方法在多种规划和问答任务中超越现有技术3.45%，并在深层模型层中显著提升任务对齐能力。

Conclusion: 该方法在复杂规划场景下表现出稳定的泛化能力，而基线方法则显著退化。

Abstract: Language models (LMs) require robust episodic grounding-the capacity to learn
from and apply past experiences-to excel at physical planning tasks. Current
episodic grounding approaches struggle with scalability and integration,
limiting their effectiveness, especially for medium-sized LMs (7B parameters).
While larger LMs (70-405B parameters) possess superior hierarchical
representations and extensive pre-trained knowledge, they encounter a
fundamental scale paradox: despite their advanced abstraction capabilities,
they lack efficient mechanisms to leverage experience streams. We propose a
scalable weak-to-strong episodic learning framework that effectively transfers
episodic behaviors from smaller to larger LMs. This framework integrates Monte
Carlo tree search for structured experience collection with a novel
distillation method, preserving the inherent LM capabilities while embedding
episodic memory. Experiments demonstrate our method surpasses state-of-the-art
proprietary LMs by 3.45% across diverse planning and question-answering tasks.
Layer-wise probing further indicates significant improvements in task
alignment, especially within deeper LM layers, highlighting stable
generalization even for previously unseen scenarios with increased planning
complexity-conditions where baseline methods degrade markedly.

</details>


### [162] [Zero-Shot Text-to-Speech for Vietnamese](https://arxiv.org/abs/2506.01322)
*Thi Vu,Linh The Nguyen,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: PhoAudiobook是一个新整理的越南语文本转语音数据集，包含941小时高质量音频。实验表明，该数据集显著提升了三种零样本TTS模型的性能，其中VALL-E和VoiceCraft在短句合成中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为越南语文本转语音研究提供高质量数据集，推动该领域的发展。

Method: 使用PhoAudiobook数据集对VALL-E、VoiceCraft和XTTS-V2三种零样本TTS模型进行实验。

Result: PhoAudiobook显著提升了模型性能，VALL-E和VoiceCraft在短句合成中表现最优。

Conclusion: PhoAudiobook的发布将促进越南语文本转语音的进一步研究和开发。

Abstract: This paper introduces PhoAudiobook, a newly curated dataset comprising 941
hours of high-quality audio for Vietnamese text-to-speech. Using PhoAudiobook,
we conduct experiments on three leading zero-shot TTS models: VALL-E,
VoiceCraft, and XTTS-V2. Our findings demonstrate that PhoAudiobook
consistently enhances model performance across various metrics. Moreover,
VALL-E and VoiceCraft exhibit superior performance in synthesizing short
sentences, highlighting their robustness in handling diverse linguistic
contexts. We publicly release PhoAudiobook to facilitate further research and
development in Vietnamese text-to-speech.

</details>


### [163] [Evaluating Large Language Models in Crisis Detection: A Real-World Benchmark from Psychological Support Hotlines](https://arxiv.org/abs/2506.01329)
*Guifeng Deng,Shuyin Rao,Tianyu Lin,Anlu Dai,Pan Wang,Junyi Xie,Haidong Song,Ke Zhao,Dongwu Xu,Zhengdong Cheng,Tao Li,Haiteng Jiang*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）在心理危机评估中的应用，通过PsyCrisisBench基准测试评估了64种LLM在情绪状态识别、自杀意念检测等任务中的表现，发现LLM在结构化任务中表现优异，但情绪识别仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 心理支持热线需求激增，但面临资源不足的挑战，LLM可能提供支持，但其在情感敏感场景的能力尚不明确。

Method: 使用PsyCrisisBench（540条标注转录文本）评估64种LLM在四种任务中的表现，采用零样本、少样本和微调范式，以F1分数和Welch t检验衡量性能。

Result: LLM在自杀意念检测（F1=0.880）、自杀计划识别（F1=0.779）和风险评估（F1=0.907）中表现优异，情绪识别较难（F1=0.709）。微调的小模型（Qwen2.5-1.5B）优于大模型。开源模型与闭源模型差距缩小。

Conclusion: LLM在结构化心理危机评估中潜力巨大，情绪识别仍需改进。开源模型与闭源模型性能接近，量化技术可降低资源需求。PsyCrisisBench为模型开发和伦理部署提供了框架。

Abstract: Psychological support hotlines are critical for crisis intervention but face
significant challenges due to rising demand. Large language models (LLMs) could
support crisis assessments, yet their capabilities in emotionally sensitive
contexts remain unclear. We introduce PsyCrisisBench, a benchmark of 540
annotated transcripts from the Hangzhou Psychological Assistance Hotline,
assessing four tasks: mood status recognition, suicidal ideation detection,
suicide plan identification, and risk assessment. We evaluated 64 LLMs across
15 families (e.g., GPT, Claude, Gemini, Llama, Qwen, DeepSeek) using zero-shot,
few-shot, and fine-tuning paradigms. Performance was measured by F1-score, with
statistical comparisons via Welch's t-tests. LLMs performed strongly on
suicidal ideation detection (F1=0.880), suicide plan identification (F1=0.779),
and risk assessment (F1=0.907), improved with few-shot and fine-tuning. Mood
status recognition was more challenging (max F1=0.709), likely due to lost
vocal cues and ambiguity. A fine-tuned 1.5B-parameter model (Qwen2.5-1.5B)
surpassed larger models on mood and suicidal ideation. Open-source models like
QwQ-32B performed comparably to closed-source on most tasks (p>0.3), though
closed models retained an edge in mood detection (p=0.007). Performance scaled
with size up to a point; quantization (AWQ) reduced GPU memory by 70% with
minimal F1 degradation. LLMs show substantial promise in structured
psychological crisis assessments, especially with fine-tuning. Mood recognition
remains limited due to contextual complexity. The narrowing gap between open-
and closed-source models, combined with efficient quantization, suggests
feasible integration. PsyCrisisBench offers a robust evaluation framework to
guide model development and ethical deployment in mental health.

</details>


### [164] [Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models](https://arxiv.org/abs/2506.01334)
*Yiwen Jiang,Deval Mehta,Wei Feng,Zongyuan Ge*

Main category: cs.CL

TL;DR: 本文提出了一种动态调整概念数量的方法（CoCoBMs），优化了概念瓶颈模型（CBMs）的分类准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前概念瓶颈模型中的概念库存在冗余或覆盖不足的问题，需要动态调整概念数量以提高效果。

Method: 引入基于代理的动态方法调整概念库，并提出条件概念瓶颈模型（CoCoBMs）改进概念评分机制。

Result: 在6个数据集上的评估显示，分类准确性提高了6%，可解释性评估提升了30%。

Conclusion: 动态调整概念数量和CoCoBMs显著提升了CBMs的性能和可解释性。

Abstract: Concept Bottleneck Models (CBMs) decompose image classification into a
process governed by interpretable, human-readable concepts. Recent advances in
CBMs have used Large Language Models (LLMs) to generate candidate concepts.
However, a critical question remains: What is the optimal number of concepts to
use? Current concept banks suffer from redundancy or insufficient coverage. To
address this issue, we introduce a dynamic, agent-based approach that adjusts
the concept bank in response to environmental feedback, optimizing the number
of concepts for sufficiency yet concise coverage. Moreover, we propose
Conditional Concept Bottleneck Models (CoCoBMs) to overcome the limitations in
traditional CBMs' concept scoring mechanisms. It enhances the accuracy of
assessing each concept's contribution to classification tasks and feature an
editable matrix that allows LLMs to correct concept scores that conflict with
their internal knowledge. Our evaluations across 6 datasets show that our
method not only improves classification accuracy by 6% but also enhances
interpretability assessments by 30%.

</details>


### [165] [The Landscape of Arabic Large Language Models (ALLMs): A New Era for Arabic Language Technology](https://arxiv.org/abs/2506.01340)
*Shahad Al-Khalifa,Nadir Durrani,Hend Al-Khalifa,Firoj Alam*

Main category: cs.CL

TL;DR: 本文探讨了阿拉伯语大型语言模型（ALLMs）的发展历程、挑战与机遇，旨在填补技术鸿沟并赋能阿拉伯社区。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语是世界上使用最广泛的语言之一，但阿拉伯语大型语言模型的发展面临独特挑战，本文旨在探索其发展轨迹及其对阿拉伯世界的影响。

Method: 通过回顾ALLMs从简单文本处理系统到复杂AI模型的演变历程，分析其评估方法（如基准测试和公开排行榜）。

Result: ALLMs的发展为阿拉伯世界提供了技术赋能的机会，但也面临语言多样性和文化复杂性等挑战。

Conclusion: ALLMs的发展是填补技术鸿沟的重要一步，但仍需解决语言和文化多样性带来的挑战。

Abstract: The emergence of ChatGPT marked a transformative milestone for Artificial
Intelligence (AI), showcasing the remarkable potential of Large Language Models
(LLMs) to generate human-like text. This wave of innovation has revolutionized
how we interact with technology, seamlessly integrating LLMs into everyday
tasks such as vacation planning, email drafting, and content creation. While
English-speaking users have significantly benefited from these advancements,
the Arabic world faces distinct challenges in developing Arabic-specific LLMs.
Arabic, one of the languages spoken most widely around the world, serves more
than 422 million native speakers in 27 countries and is deeply rooted in a rich
linguistic and cultural heritage. Developing Arabic LLMs (ALLMs) presents an
unparalleled opportunity to bridge technological gaps and empower communities.
The journey of ALLMs has been both fascinating and complex, evolving from
rudimentary text processing systems to sophisticated AI-driven models. This
article explores the trajectory of ALLMs, from their inception to the present
day, highlighting the efforts to evaluate these models through benchmarks and
public leaderboards. We also discuss the challenges and opportunities that
ALLMs present for the Arab world.

</details>


### [166] [TurnBench-MS: A Benchmark for Evaluating Multi-Turn, Multi-Step Reasoning in Large Language Models](https://arxiv.org/abs/2506.01341)
*Yiran Zhang,Mo Wang,Xiaoyang Li,Kaixuan Ren,Chencheng Zhu,Usman Naseem*

Main category: cs.CL

TL;DR: TurnBench是一个新的基准测试，通过交互式代码破解任务评估多轮、多步推理能力，揭示当前大型语言模型在复杂推理任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单轮或单步任务，无法捕捉现实场景中的迭代推理需求，因此设计了TurnBench以填补这一空白。

Method: TurnBench采用类似“图灵机棋盘游戏”的交互式代码破解任务，要求模型通过多轮猜测和反馈逐步揭示隐藏的逻辑或算术规则，包括经典模式和噩梦模式。

Result: 评估显示，最佳模型在经典模式下准确率为81.5%，但在噩梦模式下降至17.8%，而人类参与者均达到100%，凸显模型在复杂推理上的差距。

Conclusion: TurnBench通过反馈循环和隐藏任务规则，为诊断和提升大型语言模型的多步、多轮推理能力提供了严格的测试平台。

Abstract: Despite impressive advances in large language models (LLMs), existing
benchmarks often focus on single-turn or single-step tasks, failing to capture
the kind of iterative reasoning required in real-world settings. To address
this limitation, we introduce TurnBench, a novel benchmark that evaluates
multi-turn, multi-step reasoning through an interactive code-breaking task
inspired by a "Turing Machine Board Game." In each episode, a model must
uncover hidden logical or arithmetic rules by making sequential guesses,
receiving structured feedback, and integrating clues across multiple rounds.
This dynamic setup requires models to reason over time, adapt based on past
information, and maintain consistency across steps-capabilities underexplored
in current benchmarks. TurnBench includes two modes: Classic, which tests
standard reasoning, and Nightmare, which introduces increased complexity and
requires robust inferential chains. To support fine-grained analysis, we
provide ground-truth annotations for intermediate reasoning steps. Our
evaluation of state-of-the-art LLMs reveals significant gaps: the best model
achieves 81.5% accuracy in Classic mode, but performance drops to 17.8% in
Nightmare mode. In contrast, human participants achieve 100% in both,
underscoring the challenge TurnBench poses to current models. By incorporating
feedback loops and hiding task rules, TurnBench reduces contamination risks and
provides a rigorous testbed for diagnosing and advancing multi-step, multi-turn
reasoning in LLMs.

</details>


### [167] [Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents](https://arxiv.org/abs/2506.01344)
*Manan Suri,Puneet Mathur,Nedim Lipka,Franck Dernoncourt,Ryan A. Rossi,Vivek Gupta,Dinesh Manocha*

Main category: cs.CL

TL;DR: 论文提出了一种细粒度流程图归因任务，通过图推理方法减少LLM在流程图分析中的幻觉，提高了可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 流程图在关键领域（如物流、医疗、工程）中广泛应用，但LLM在分析时容易产生视觉幻觉，导致可靠性问题。

Method: 提出FlowPathAgent，一种神经符号代理，通过图推理进行细粒度归因，包括流程图分割、符号图转换和动态交互生成归因路径。

Result: FlowPathAgent在FlowExplainBench数据集上表现优于基线方法10-14%，有效减少了视觉幻觉。

Conclusion: FlowPathAgent通过细粒度归因提高了LLM对流程图分析的可靠性和可解释性，为关键领域提供了更可靠的自动化处理方案。

Abstract: Flowcharts are a critical tool for visualizing decision-making processes.
However, their non-linear structure and complex visual-textual relationships
make it challenging to interpret them using LLMs, as vision-language models
frequently hallucinate nonexistent connections and decision paths when
analyzing these diagrams. This leads to compromised reliability for automated
flowchart processing in critical domains such as logistics, health, and
engineering. We introduce the task of Fine-grained Flowchart Attribution, which
traces specific components grounding a flowchart referring LLM response.
Flowchart Attribution ensures the verifiability of LLM predictions and improves
explainability by linking generated responses to the flowchart's structure. We
propose FlowPathAgent, a neurosymbolic agent that performs fine-grained post
hoc attribution through graph-based reasoning. It first segments the flowchart,
then converts it into a structured symbolic graph, and then employs an agentic
approach to dynamically interact with the graph, to generate attribution paths.
Additionally, we present FlowExplainBench, a novel benchmark for evaluating
flowchart attributions across diverse styles, domains, and question types.
Experimental results show that FlowPathAgent mitigates visual hallucinations in
LLM answers over flowchart QA, outperforming strong baselines by 10-14% on our
proposed FlowExplainBench dataset.

</details>


### [168] [The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning](https://arxiv.org/abs/2506.01347)
*Xinyu Zhu,Mengzhou Xia,Zhepei Wei,Wei-Lin Chen,Danqi Chen,Yu Meng*

Main category: cs.CL

TL;DR: 论文提出了一种基于可验证奖励的强化学习方法（RLVR），用于训练语言模型在推理任务中生成长链思维。研究发现，仅使用负样本（惩罚错误）训练模型效果显著，甚至优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习中正负样本对语言模型推理能力的影响，尤其是负样本的作用。

Method: 将学习信号分解为正样本强化（PSR）和负样本强化（NSR），并在数学推理数据集上训练模型。

Result: 仅使用负样本训练能显著提升模型性能，且在多样性和推理能力上优于传统方法。

Conclusion: 负样本强化在提升模型推理能力中起关键作用，并提出了一种改进的强化学习目标。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a promising approach
for training language models (LMs) on reasoning tasks that elicit emergent long
chains of thought (CoTs). Unlike supervised learning, it updates the model
using both correct and incorrect samples via policy gradients. To better
understand its mechanism, we decompose the learning signal into reinforcing
correct responses and penalizing incorrect ones, referred to as Positive and
Negative Sample Reinforcement (PSR and NSR), respectively. We train
Qwen2.5-Math-7B and Qwen3-4B on a mathematical reasoning dataset and uncover a
surprising result: training with only negative samples -- without reinforcing
correct responses -- can be highly effective: it consistently improves
performance over the base model across the entire Pass@$k$ spectrum ($k$ up to
$256$), often matching or surpassing PPO and GRPO. In contrast, reinforcing
only correct responses improves Pass@$1$ but degrades performance at higher
$k$, due to reduced diversity. These inference-scaling trends highlight that
solely penalizing incorrect responses may contribute more to performance than
previously recognized. Through gradient analysis, we show that NSR works by
suppressing incorrect generations and redistributing probability mass toward
other plausible candidates, guided by the model's prior beliefs. It refines the
model's existing knowledge rather than introducing entirely new behaviors.
Building on this insight, we propose a simple variant of the RL objective that
upweights NSR, and show that it consistently improves overall Pass@$k$
performance on MATH, AIME 2025, and AMC23. Our code is available at
https://github.com/TianHongZXY/RLVR-Decomposed.

</details>


### [169] [KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors](https://arxiv.org/abs/2506.01357)
*Zhiyang Qi,Takumasa Kaneko,Keiko Takamizo,Mariko Ukiyo,Michimasa Inaba*

Main category: cs.CL

TL;DR: 本研究提出了一种通过角色扮演生成高质量心理咨询对话数据的方法，构建了KokoroChat数据集，并验证了其对提升语言模型生成心理咨询响应的效果。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询对话数据存在多样性不足和隐私问题，本研究旨在通过角色扮演方法生成高质量数据以解决这些问题。

Method: 采用角色扮演方法，由训练有素的咨询师模拟咨询对话，构建了包含6,589条长对话的KokoroChat数据集。

Result: 实验表明，使用KokoroChat微调开源语言模型能显著提升生成咨询响应的质量和对话自动评估效果。

Conclusion: 角色扮演方法能有效生成高质量心理咨询对话数据，KokoroChat数据集为相关研究提供了有价值的资源。

Abstract: Generating psychological counseling responses with language models relies
heavily on high-quality datasets. Crowdsourced data collection methods require
strict worker training, and data from real-world counseling environments may
raise privacy and ethical concerns. While recent studies have explored using
large language models (LLMs) to augment psychological counseling dialogue
datasets, the resulting data often suffers from limited diversity and
authenticity. To address these limitations, this study adopts a role-playing
approach where trained counselors simulate counselor-client interactions,
ensuring high-quality dialogues while mitigating privacy risks. Using this
method, we construct KokoroChat, a Japanese psychological counseling dialogue
dataset comprising 6,589 long-form dialogues, each accompanied by comprehensive
client feedback. Experimental results demonstrate that fine-tuning open-source
LLMs with KokoroChat improves both the quality of generated counseling
responses and the automatic evaluation of counseling dialogues. The KokoroChat
dataset is available at https://github.com/UEC-InabaLab/KokoroChat.

</details>


### [170] [MMD-Flagger: Leveraging Maximum Mean Discrepancy to Detect Hallucinations](https://arxiv.org/abs/2506.01367)
*Kensuke Mitsuzawa,Damien Garreau*

Main category: cs.CL

TL;DR: 提出了一种基于最大均值差异（MMD）的新方法MMD-Flagger，用于检测大语言模型生成的幻觉内容，并在机器翻译数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的幻觉内容（不真实但流畅的文本）阻碍了其在关键应用中的使用，因此需要有效的检测方法。

Method: 利用MMD作为非参数分布距离度量，通过跟踪生成文档与不同温度参数生成的文档之间的MMD轨迹来检测幻觉。

Result: 实验表明，通过分析MMD轨迹的形状可以有效检测大部分幻觉内容，且在两个机器翻译数据集上优于其他方法。

Conclusion: MMD-Flagger是一种有效的幻觉检测方法，适用于大语言模型生成内容的真实性验证。

Abstract: Large language models (LLMs) have become pervasive in our everyday life. Yet,
a fundamental obstacle prevents their use in many critical applications: their
propensity to generate fluent, human-quality content that is not grounded in
reality. The detection of such hallucinations is thus of the highest
importance. In this work, we propose a new method to flag hallucinated content,
MMD-Flagger. It relies on Maximum Mean Discrepancy (MMD), a non-parametric
distance between distributions. On a high-level perspective, MMD-Flagger tracks
the MMD between the generated documents and documents generated with various
temperature parameters. We show empirically that inspecting the shape of this
trajectory is sufficient to detect most hallucinations. This novel method is
benchmarked on two machine translation datasets, on which it outperforms
natural competitors.

</details>


### [171] [AdaRewriter: Unleashing the Power of Prompting-based Conversational Query Reformulation via Test-Time Adaptation](https://arxiv.org/abs/2506.01381)
*Yilong Lai,Jialong Wu,Zhenglin Wang,Deyu Zhou*

Main category: cs.CL

TL;DR: AdaRewriter是一个基于测试时适应的查询重写框架，通过轻量级奖励模型选择最佳查询重写方案，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（训练时调整和测试时适应）未能充分发挥基于提示的查询重写潜力，尤其是在黑盒系统中。

Method: 提出AdaRewriter框架，利用对比排序损失训练轻量级奖励模型，在推理时选择最佳查询重写。

Result: 在五个对话搜索数据集上，AdaRewriter显著优于现有方法。

Conclusion: 测试时适应在对话查询重写中具有巨大潜力，AdaRewriter为此提供了有效解决方案。

Abstract: Prompting-based conversational query reformulation has emerged as a powerful
approach for conversational search, refining ambiguous user queries into
standalone search queries. Best-of-N reformulation over the generated
candidates via prompting shows impressive potential scaling capability.
However, both the previous tuning methods (training time) and adaptation
approaches (test time) can not fully unleash their benefits. In this paper, we
propose AdaRewriter, a novel framework for query reformulation using an
outcome-supervised reward model via test-time adaptation. By training a
lightweight reward model with contrastive ranking loss, AdaRewriter selects the
most promising reformulation during inference. Notably, it can operate
effectively in black-box systems, including commercial LLM APIs. Experiments on
five conversational search datasets show that AdaRewriter significantly
outperforms the existing methods across most settings, demonstrating the
potential of test-time adaptation for conversational query reformulation.

</details>


### [172] [Speech-to-Speech Translation Pipelines for Conversations in Low-Resource Languages](https://arxiv.org/abs/2506.01406)
*Andrei Popescu-Belis,Alexis Allemann,Teo Ferrari,Gopal Krishnamani*

Main category: cs.CL

TL;DR: 研究了低资源语言（土耳其语和普什图语与法语）的自动语音翻译系统，通过多种自动指标和人工评估比较了60多种流程，确定了最佳方案。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言在自动语音翻译中质量不稳定的问题。

Method: 收集数据并微调模型，比较多种流程（包括本地和云端模型），使用BLEU、COMET、BLASER等指标和人工评估。

Result: 确定了每种语言对的最佳流程，发现组件性能与流程其他部分无关。

Conclusion: 低资源语言翻译可通过优化流程提升质量，组件独立性为模块化设计提供可能。

Abstract: The popularity of automatic speech-to-speech translation for human
conversations is growing, but the quality varies significantly depending on the
language pair. In a context of community interpreting for low-resource
languages, namely Turkish and Pashto to/from French, we collected fine-tuning
and testing data, and compared systems using several automatic metrics (BLEU,
COMET, and BLASER) and human assessments. The pipelines included automatic
speech recognition, machine translation, and speech synthesis, with local
models and cloud-based commercial ones. Some components have been fine-tuned on
our data. We evaluated over 60 pipelines and determined the best one for each
direction. We also found that the ranks of components are generally independent
of the rest of the pipeline.

</details>


### [173] [Comparing LLM-generated and human-authored news text using formal syntactic theory](https://arxiv.org/abs/2506.01407)
*Olga Zamaraeva,Dan Flickinger,Francis Bond,Carlos Gómez-Rodríguez*

Main category: cs.CL

TL;DR: 该研究首次全面比较了六种大型语言模型生成的《纽约时报》风格文本与真实人类撰写的文本，基于形式句法理论（HPSG）分析语法结构差异。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型生成的文本与人类写作在语法结构上的系统性差异，以加深对两者在《纽约时报》体裁中句法行为的理解。

Method: 使用Head-driven Phrase Structure Grammar (HPSG)分析文本的语法结构，比较HPSG语法类型的分布差异。

Result: 揭示了人类与LLM生成文本在HPSG语法类型分布上的系统性差异。

Conclusion: 研究结果有助于更深入地理解LLM和人类在《纽约时报》体裁中的句法行为差异。

Abstract: This study provides the first comprehensive comparison of New York
Times-style text generated by six large language models against real,
human-authored NYT writing. The comparison is based on a formal syntactic
theory. We use Head-driven Phrase Structure Grammar (HPSG) to analyze the
grammatical structure of the texts. We then investigate and illustrate the
differences in the distributions of HPSG grammar types, revealing systematic
distinctions between human and LLM-generated writing. These findings contribute
to a deeper understanding of the syntactic behavior of LLMs as well as humans,
within the NYT genre.

</details>


### [174] [UniversalCEFR: Enabling Open Multilingual Research on Language Proficiency Assessment](https://arxiv.org/abs/2506.01419)
*Joseph Marvin Imperial,Abdullah Barayan,Regina Stodden,Rodrigo Wilkens,Ricardo Munoz Sanchez,Lingyun Gao,Melissa Torgbi,Dawn Knight,Gail Forey,Reka R. Jablonkai,Ekaterina Kochmar,Robert Reynolds,Eugenio Ribeiro,Horacio Saggion,Elena Volodina,Sowmya Vajjala,Thomas Francois,Fernando Alva-Manchego,Harish Tayyar Madabushi*

Main category: cs.CL

TL;DR: UniversalCEFR是一个多语言、多维度的数据集，包含505,807个按CEFR标准标注的文本，支持13种语言，旨在促进自动可读性和语言能力评估的研究。


<details>
  <summary>Details</summary>
Motivation: 为开放研究提供统一的数据格式，支持跨任务和语言的自动化语言能力评估。

Method: 数据集包含从教育和学习者资源中收集的文本，并通过三种建模范式（基于语言特征的分类、预训练LLM微调、基于描述符的指令调整LLM）进行基准实验。

Result: 实验结果表明，基于语言特征和预训练模型微调的方法在多语言CEFR评估中表现良好。

Conclusion: UniversalCEFR通过标准化数据格式和促进全球研究社区的可访问性，旨在建立语言能力研究中的数据分发最佳实践。

Abstract: We introduce UniversalCEFR, a large-scale multilingual multidimensional
dataset of texts annotated according to the CEFR (Common European Framework of
Reference) scale in 13 languages. To enable open research in both automated
readability and language proficiency assessment, UniversalCEFR comprises
505,807 CEFR-labeled texts curated from educational and learner-oriented
resources, standardized into a unified data format to support consistent
processing, analysis, and modeling across tasks and languages. To demonstrate
its utility, we conduct benchmark experiments using three modelling paradigms:
a) linguistic feature-based classification, b) fine-tuning pre-trained LLMs,
and c) descriptor-based prompting of instruction-tuned LLMs. Our results
further support using linguistic features and fine-tuning pretrained models in
multilingual CEFR level assessment. Overall, UniversalCEFR aims to establish
best practices in data distribution in language proficiency research by
standardising dataset formats and promoting their accessibility to the global
research community.

</details>


### [175] [Self-Refining Language Model Anonymizers via Adversarial Distillation](https://arxiv.org/abs/2506.01420)
*Kyuyoung Kim,Hyunjun Jeon,Jinwoo Shin*

Main category: cs.CL

TL;DR: SEAL是一个新颖的蒸馏框架，通过对抗性交互和自优化训练小型语言模型（SLMs），实现高效匿名化，无需依赖外部昂贵模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM匿名化方法依赖昂贵专有模型（如GPT-4）的问题，同时避免敏感数据暴露给不可信外部系统。

Method: 利用LLM匿名器和推理模型之间的对抗性交互收集匿名化文本轨迹，通过监督微调和偏好学习将能力蒸馏到SLMs中。

Result: 在SynthPAI数据集上，SEAL训练的8B模型在隐私-效用权衡上媲美GPT-4，并通过自优化在隐私方面超越GPT-4。

Conclusion: SEAL框架有效训练SLMs成为高效匿名化工具，同时公开实验数据集以促进进一步研究。

Abstract: Large language models (LLMs) are increasingly used in sensitive domains,
where their ability to infer personal data from seemingly benign text poses
emerging privacy risks. While recent LLM-based anonymization methods help
mitigate such risks, they often rely on proprietary models (e.g., GPT-4),
raising concerns about cost and the potential exposure of sensitive data to
untrusted external systems. To address this, we introduce SElf-refining
Anonymization with Language model (SEAL), a novel distillation framework for
training small language models (SLMs) to perform effective anonymization
without relying on external costly models at inference time. We leverage
adversarial interactions between an LLM anonymizer and an inference model to
collect trajectories of anonymized texts and inferred attributes, which are
used to distill anonymization, adversarial inference, and utility evaluation
capabilities into SLMs via supervised fine-tuning and preference learning. The
resulting models learn to both anonymize text and critique their outputs,
enabling iterative improvement of anonymization quality via self-refinement.
Experiments on SynthPAI, a dataset of synthetic personal profiles and text
comments, demonstrate that SLMs trained with SEAL achieve substantial
improvements in anonymization capabilities. Notably, 8B models attain a
privacy-utility trade-off comparable to that of the GPT-4 anonymizer and, with
self-refinement, even surpass it in terms of privacy. These results show the
effectiveness of our adversarial distillation framework in training SLMs as
efficient anonymizers. To facilitate further research, we release the full
dataset used in our experiments.

</details>


### [176] [Redundancy, Isotropy, and Intrinsic Dimensionality of Prompt-based Text Embeddings](https://arxiv.org/abs/2506.01435)
*Hayato Tsukagoshi,Ryohei Sasano*

Main category: cs.CL

TL;DR: 论文研究了基于提示的文本嵌入模型的高维冗余问题，通过降维实验发现分类和聚类任务对降维的容忍度较高，性能下降很小。


<details>
  <summary>Details</summary>
Motivation: 高维嵌入导致存储和计算成本高，研究降维对任务性能的影响。

Method: 对嵌入进行后处理降维，分析分类、聚类、检索和语义文本相似性任务的性能变化。

Result: 降维至0.5%原始维度时，分类和聚类性能下降很小；检索和STS任务对降维更敏感。

Conclusion: 嵌入在分类和聚类任务中存在高维冗余，降维可行；检索和STS任务需谨慎处理降维。

Abstract: Prompt-based text embedding models, which generate task-specific embeddings
upon receiving tailored prompts, have recently demonstrated remarkable
performance. However, their resulting embeddings often have thousands of
dimensions, leading to high storage costs and increased computational costs of
embedding-based operations. In this paper, we investigate how post-hoc
dimensionality reduction applied to the embeddings affects the performance of
various tasks that leverage these embeddings, specifically classification,
clustering, retrieval, and semantic textual similarity (STS) tasks. Our
experiments show that even a naive dimensionality reduction, which keeps only
the first 25% of the dimensions of the embeddings, results in a very slight
performance degradation, indicating that these embeddings are highly redundant.
Notably, for classification and clustering, even when embeddings are reduced to
less than 0.5% of the original dimensionality the performance degradation is
very small. To quantitatively analyze this redundancy, we perform an analysis
based on the intrinsic dimensionality and isotropy of the embeddings. Our
analysis reveals that embeddings for classification and clustering, which are
considered to have very high dimensional redundancy, exhibit lower intrinsic
dimensionality and less isotropy compared with those for retrieval and STS.

</details>


### [177] [Whale: Large-Scale multilingual ASR model with w2v-BERT and E-Branchformer with large speech data](https://arxiv.org/abs/2506.01439)
*Yosuke Kashiwagi,Hayato Futami,Emiru Tsunoo,Satoshi Asakawa*

Main category: cs.CL

TL;DR: Whale是一个大规模语音识别模型，结合了w2v-BERT自监督模型、E-Branchformer编码器-解码器架构和联合CTC-注意力解码策略，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够适应不同说话风格和声学条件的大规模语音识别模型，提升现有模型的性能。

Method: 整合w2v-BERT自监督模型、E-Branchformer编码器-解码器架构和联合CTC-注意力解码策略，使用多样化的公开和内部数据集进行训练。

Result: 在Librispeech test-clean集上词错误率为2.4%，在CSJ eval3集上字符错误率为3.4%，优于Whisper large-v3和OWSM v3.1。

Conclusion: Whale模型通过大规模数据和先进架构设计，实现了高性能的语音识别，尤其在多样化的语音数据上表现突出。

Abstract: This paper reports on the development of a large-scale speech recognition
model, Whale. Similar to models such as Whisper and OWSM, Whale leverages both
a large model size and a diverse, extensive dataset. Whale's architecture
integrates w2v-BERT self-supervised model, an encoder-decoder backbone built on
E-Branchformer, and a joint CTC-attention decoding strategy. The training
corpus comprises varied speech data, of not only public corpora but also
in-house data, thereby enhancing the model's robustness to different speaking
styles and acoustic conditions. Through evaluations on multiple benchmarks,
Whale achieved comparable performance to existing models. In particular, it
achieves a word error rate of 2.4% on the Librispeech test-clean set and a
character error rate of 3.4% on the CSJ eval3 set, outperforming Whisper
large-v3 and OWSM v3.1.

</details>


### [178] [Building Entity Association Mining Framework for Knowledge Discovery](https://arxiv.org/abs/2506.01451)
*Anshika Rawal,Abhijeet Kumar,Mridul Mishra*

Main category: cs.CL

TL;DR: 提出了一种通用的文本挖掘框架，用于文档过滤、实体提取和关联挖掘，支持金融领域的业务决策。


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本中提取有用信号或模式以支持业务决策（如投资产品分析、客户偏好发现、风险监控等）是一个挑战。

Method: 框架包含三个主要组件：文档过滤、可配置的实体提取管道（如DBpedia Spotlight、Spacy NER等）和关联关系挖掘（生成共现图分析实体关系）。

Result: 框架在金融用例（品牌产品发现和供应商风险监控）中展示了其作为基础构建模块的实用性。

Conclusion: 该框架旨在减少重复工作、降低开发成本，并促进关联挖掘业务应用的可重用性和快速原型设计。

Abstract: Extracting useful signals or pattern to support important business decisions
for example analyzing investment product traction and discovering customer
preference, risk monitoring etc. from unstructured text is a challenging task.
Capturing interaction of entities or concepts and association mining is a
crucial component in text mining, enabling information extraction and reasoning
over and knowledge discovery from text. Furthermore, it can be used to enrich
or filter knowledge graphs to guide exploration processes, descriptive
analytics and uncover hidden stories in the text. In this paper, we introduce a
domain independent pipeline i.e., generalized framework to enable document
filtering, entity extraction using various sources (or techniques) as plug-ins
and association mining to build any text mining business use-case and
quantitatively define a scoring metric for ranking purpose. The proposed
framework has three major components a) Document filtering: filtering
documents/text of interest from massive amount of texts b) Configurable entity
extraction pipeline: include entity extraction techniques i.e., i) DBpedia
Spotlight, ii) Spacy NER, iii) Custom Entity Matcher, iv) Phrase extraction (or
dictionary) based c) Association Relationship Mining: To generates
co-occurrence graph to analyse potential relationships among entities,
concepts. Further, co-occurrence count based frequency statistics provide a
holistic window to observe association trends or buzz rate in specific business
context. The paper demonstrates the usage of framework as fundamental building
box in two financial use-cases namely brand product discovery and vendor risk
monitoring. We aim that such framework will remove duplicated effort, minimize
the development effort, and encourage reusability and rapid prototyping in
association mining business applications for institutions.

</details>


### [179] [TalTech Systems for the Interspeech 2025 ML-SUPERB 2.0 Challenge](https://arxiv.org/abs/2506.01458)
*Tanel Alumäe,Artem Fedorchenko*

Main category: cs.CL

TL;DR: 该论文介绍了Tallinn University of Technology为Interspeech 2025 ML-SUPERB 2.0挑战赛开发的语言识别和多语言语音识别系统，采用混合方法，最终获得挑战赛最高分。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的语言识别和多语言语音识别系统，以应对ML-SUPERB 2.0挑战赛的需求。

Method: 使用混合语言识别系统（预训练语言嵌入模型+轻量级语音识别模型）和多语言语音识别模型（SeamlessM4T、MMS-1B-all和MMS-zeroshot）。

Result: 系统在挑战赛中获得了最高分。

Conclusion: 提出的混合方法在多语言语音识别任务中表现优异，验证了其有效性。

Abstract: This paper describes the language identification and multilingual speech
recognition system developed at Tallinn University of Technology for the
Interspeech 2025 ML-SUPERB 2.0 Challenge. A hybrid language identification
system is used, consisting of a pretrained language embedding model and a
light-weight speech recognition model with a shared encoder across languages
and language-specific bigram language models. For speech recognition, three
models are used, where only a single model is applied for each language,
depending on the training data availability and performance on held-out data.
The model set consists of a finetuned version of SeamlessM4T, MMS-1B-all with
custom language adapters and MMS-zeroshot. The system obtained the top overall
score in the challenge.

</details>


### [180] [Integrating Neural and Symbolic Components in a Model of Pragmatic Question-Answering](https://arxiv.org/abs/2506.01474)
*Polina Tsvilodub,Robert D. Hawkins,Michael Franke*

Main category: cs.CL

TL;DR: 提出了一种结合神经符号框架与LLM的认知模型，用于增强自然语言处理的灵活性，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 传统计算模型依赖人工定义的语义和话语，限制了实际应用。

Method: 通过神经符号框架整合LLM模块，自动生成和评估自然语言的关键组件。

Result: 混合模型在预测人类回答模式上表现优于传统概率模型，但LLM整合方式对效果至关重要。

Conclusion: 研究为更灵活、可扩展的语用模型提供了路径，同时揭示了神经与符号组件平衡的关键设计考量。

Abstract: Computational models of pragmatic language use have traditionally relied on
hand-specified sets of utterances and meanings, limiting their applicability to
real-world language use. We propose a neuro-symbolic framework that enhances
probabilistic cognitive models by integrating LLM-based modules to propose and
evaluate key components in natural language, eliminating the need for manual
specification. Through a classic case study of pragmatic question-answering, we
systematically examine various approaches to incorporating neural modules into
the cognitive model -- from evaluating utilities and literal semantics to
generating alternative utterances and goals. We find that hybrid models can
match or exceed the performance of traditional probabilistic models in
predicting human answer patterns. However, the success of the neuro-symbolic
model depends critically on how LLMs are integrated: while they are
particularly effective for proposing alternatives and transforming abstract
goals into utilities, they face challenges with truth-conditional semantic
evaluation. This work charts a path toward more flexible and scalable models of
pragmatic language use while illuminating crucial design considerations for
balancing neural and symbolic components.

</details>


### [181] [LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech Detoxification](https://arxiv.org/abs/2506.01484)
*Shuzhou Yuan,Ercong Nie,Lukas Kouba,Ashish Yashwanth Kangen,Helmut Schmid,Hinrich Schutze,Michael Farber*

Main category: cs.CL

TL;DR: 论文提出了一种基于GPT-4o-mini的LLM-in-the-loop管道，用于自动去毒化，并构建了大规模仇恨言论去毒化数据集PARADEHATE。实验表明，基于该数据集的模型表现优于人工标注。


<details>
  <summary>Details</summary>
Motivation: 在线有毒内容日益增多，但高质量的去毒化并行数据集稀缺，尤其是仇恨言论领域。人工标注成本高且敏感。

Method: 提出LLM-in-the-loop管道，用GPT-4o-mini替代人工标注，构建PARADEHATE数据集（8K仇恨/非仇恨文本对），并评估多种基线方法。

Result: BART等模型在PARADEHATE上微调后，在风格准确性、内容保留和流畅性方面表现更优，验证了LLM生成去毒化文本的可扩展性。

Conclusion: LLM生成去毒化文本是人工标注的有效替代方案，PARADEHATE为仇恨言论去毒化提供了高质量基准。

Abstract: Detoxification, the task of rewriting harmful language into non-toxic text,
has become increasingly important amid the growing prevalence of toxic content
online. However, high-quality parallel datasets for detoxification, especially
for hate speech, remain scarce due to the cost and sensitivity of human
annotation. In this paper, we propose a novel LLM-in-the-loop pipeline
leveraging GPT-4o-mini for automated detoxification. We first replicate the
ParaDetox pipeline by replacing human annotators with an LLM and show that the
LLM performs comparably to human annotation. Building on this, we construct
PARADEHATE, a large-scale parallel dataset specifically for hatespeech
detoxification. We release PARADEHATE as a benchmark of over 8K hate/non-hate
text pairs and evaluate a wide range of baseline methods. Experimental results
show that models such as BART, fine-tuned on PARADEHATE, achieve better
performance in style accuracy, content preservation, and fluency, demonstrating
the effectiveness of LLM-generated detoxification text as a scalable
alternative to human annotation.

</details>


### [182] [Argument-Centric Causal Intervention Method for Mitigating Bias in Cross-Document Event Coreference Resolution](https://arxiv.org/abs/2506.01488)
*Long Yao,Wenzhong Yang,Yabo Yin,Fuyuan Wei,Hongzhen Lv,Jiaren Peng,Liejun Wang,Xiaoming Tao*

Main category: cs.CL

TL;DR: 提出了一种基于Argument-Centric Causal Intervention（ACCI）的新方法，用于解决跨文档事件共指消解中的虚假相关性，通过因果干预和反事实推理提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前跨文档事件共指消解方法过度依赖触发词特征，导致表面词汇特征与共指关系之间的虚假相关性，影响模型性能。

Method: 构建结构因果图揭示词汇触发词与共指标签之间的混杂依赖，引入后门调整干预分离论证语义的真实因果效应，并集成反事实推理模块和论证感知增强模块。

Result: 在ECB+和GVC数据集上分别达到88.4%和85.2%的CoNLL F1分数，性能最优。

Conclusion: ACCI在统一端到端框架中有效去偏，无需修改训练过程，显著提升了跨文档事件共指消解的性能。

Abstract: Cross-document Event Coreference Resolution (CD-ECR) is a fundamental task in
natural language processing (NLP) that seeks to determine whether event
mentions across multiple documents refer to the same real-world occurrence.
However, current CD-ECR approaches predominantly rely on trigger features
within input mention pairs, which induce spurious correlations between
surface-level lexical features and coreference relationships, impairing the
overall performance of the models. To address this issue, we propose a novel
cross-document event coreference resolution method based on Argument-Centric
Causal Intervention (ACCI). Specifically, we construct a structural causal
graph to uncover confounding dependencies between lexical triggers and
coreference labels, and introduce backdoor-adjusted interventions to isolate
the true causal effect of argument semantics. To further mitigate spurious
correlations, ACCI integrates a counterfactual reasoning module that quantifies
the causal influence of trigger word perturbations, and an argument-aware
enhancement module to promote greater sensitivity to semantically grounded
information. In contrast to prior methods that depend on costly data
augmentation or heuristic-based filtering, ACCI enables effective debiasing in
a unified end-to-end framework without altering the underlying training
procedure. Extensive experiments demonstrate that ACCI achieves CoNLL F1 of
88.4% on ECB+ and 85.2% on GVC, achieving state-of-the-art performance. The
implementation and materials are available at https://github.com/era211/ACCI.

</details>


### [183] [Multilingual Definition Modeling](https://arxiv.org/abs/2506.01489)
*Edison Marrese-Taylor,Erica K. Shimomoto,Alfredo Solano,Enrique Reid*

Main category: cs.CL

TL;DR: 本文首次对多语言定义建模进行了研究，测试了预训练多语言模型在四种新语言（西班牙语、法语、葡萄牙语和德语）上的表现，并评估了大型语言模型（LLMs）的零样本能力。结果显示LLMs表现更优，但多语言模型未能充分利用跨语言协同效应。


<details>
  <summary>Details</summary>
Motivation: 探索多语言定义建模的可行性，填补该领域的研究空白，并评估预训练模型和LLMs在新任务中的表现。

Method: 使用四种语言的单语词典数据，对预训练多语言模型进行微调，并采用零样本方法测试LLMs的能力。

Result: 多语言模型表现与英语相当，但未能利用跨语言协同效应；LLMs整体表现更优，但存在不足。BERTScore与多语言LLM基准表现强相关。

Conclusion: 多语言定义建模任务可作为计算受限、稳定且自然的替代方案，验证了LLMs的零样本和少样本能力，同时揭示了其局限性。

Abstract: In this paper, we propose the first multilingual study on definition
modeling. We use monolingual dictionary data for four new languages (Spanish,
French, Portuguese, and German) and perform an in-depth empirical study to test
the performance of pre-trained multilingual language models on definition
modeling of monosemic words when finetuned on this data. Furthermore, we use a
zero-shot approach to test the multilingual capabilities of two popular
chat-based Large Language Models (LLMs) in the task. Results show that
multilingual language models can perform on-pair with English but cannot
leverage potential cross-lingual synergies, with LLMs generally offering better
performance overall. A comprehensive human evaluation of the LLM-generated
definition highlights the zero and few-shot capabilities of these models in
this new task, also showing their shortcomings. Finally, we show that
performance on our task via BERTScore strongly correlates to the performance on
multilingual LLM benchmarks, suggesting that our task offers a viable
compute-constrained, stable and natural alternative to these.

</details>


### [184] [CVC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models](https://arxiv.org/abs/2506.01495)
*Ping Wu,Guobin Shen,Dongcheng Zhao,Yuwei Wang,Yiting Dong,Yu Shi,Enmeng Lu,Feifei Zhao,Yi Zeng*

Main category: cs.CL

TL;DR: 论文提出了一种基于中国核心价值观的分层价值框架，并构建了大规模的中国价值观语料库（CVC），用于评估和调整大型语言模型（LLM）的价值对齐。实验证明CVC在文化相关性和多样性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的价值评估和调整受限于西方文化偏见和不完善的国内框架，且缺乏可扩展的规则驱动场景生成方法。

Method: 提出分层价值框架，构建CVC语料库，并通过人类标注增强规则。实验评估了CVC在敏感主题和道德困境场景中的表现。

Result: CVC生成的场景在价值边界和多样性上优于直接生成场景，主流LLM和人类标注者对其表现出高对齐率。

Conclusion: 研究为全面价值评估和对齐提供了文化适应性基准框架，体现了中国特色。

Abstract: Ensuring that Large Language Models (LLMs) align with mainstream human values
and ethical norms is crucial for the safe and sustainable development of AI.
Current value evaluation and alignment are constrained by Western cultural bias
and incomplete domestic frameworks reliant on non-native rules; furthermore,
the lack of scalable, rule-driven scenario generation methods makes evaluations
costly and inadequate across diverse cultural contexts. To address these
challenges, we propose a hierarchical value framework grounded in core Chinese
values, encompassing three main dimensions, 12 core values, and 50 derived
values. Based on this framework, we construct a large-scale Chinese Values
Corpus (CVC) containing over 250,000 value rules enhanced and expanded through
human annotation. Experimental results show that CVC-guided scenarios
outperform direct generation ones in value boundaries and content diversity. In
the evaluation across six sensitive themes (e.g., surrogacy, suicide), seven
mainstream LLMs preferred CVC-generated options in over 70.5% of cases, while
five Chinese human annotators showed an 87.5% alignment with CVC, confirming
its universality, cultural relevance, and strong alignment with Chinese values.
Additionally, we construct 400,000 rule-based moral dilemma scenarios that
objectively capture nuanced distinctions in conflicting value prioritization
across 17 LLMs. Our work establishes a culturally-adaptive benchmarking
framework for comprehensive value evaluation and alignment, representing
Chinese characteristics. All data are available at
https://huggingface.co/datasets/Beijing-AISI/CVC, and the code is available at
https://github.com/Beijing-AISI/CVC.

</details>


### [185] [Continual Speech Learning with Fused Speech Features](https://arxiv.org/abs/2506.01496)
*Guitao Wang,Jinming Zhao,Hao Yang,Guilin Qi,Tongtong Wu,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 论文提出了一种连续语音学习方法，通过可学习的门控融合层动态选择任务特征，显著提升了语音处理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统静态方法无法适应动态多样的语音数据增长，需要一种新的自适应模型。

Method: 使用Whisper编码器-解码器模型将语音任务标准化为生成格式，并在编码器顶部集成可学习的门控融合层以动态选择任务特征。

Result: 在六种语音处理任务中，该方法显著优于传统方法，且无需完全重新训练即可适应新任务。

Conclusion: 连续语音学习方法有效解决了语音模型的自适应问题，具有广泛的应用潜力。

Abstract: Rapid growth in speech data demands adaptive models, as traditional static
methods fail to keep pace with dynamic and diverse speech information. We
introduce continuous speech learning, a new set-up targeting at bridging the
adaptation gap in current speech models. We use the encoder-decoder Whisper
model to standardize speech tasks into a generative format. We integrate a
learnable gated-fusion layer on the top of the encoder to dynamically select
task-specific features for downstream tasks. Our approach improves accuracy
significantly over traditional methods in six speech processing tasks,
demonstrating gains in adapting to new speech tasks without full retraining.

</details>


### [186] [Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes](https://arxiv.org/abs/2506.01512)
*Meng Li,Michael Vrazitulis,David Schlangen*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLMs）在不确定环境中生成基于事实和信心评估的表达能力不足，提出通过丰富LLMs的语义知识来构建不确定性感知模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在生成与证据强度匹配的表达方面存在挑战，尤其是在不确定环境中。研究旨在评估LLMs对不确定性语言知识的掌握情况。

Method: 利用类型学框架和受控故事评估LLMs对认知模态的知识。

Result: 实验表明LLMs生成认知表达的能力有限且不稳定，其不确定性表达不可靠。

Conclusion: 为构建不确定性感知的LLMs，需丰富其对认知模态的语义知识。

Abstract: Rational speakers are supposed to know what they know and what they do not
know, and to generate expressions matching the strength of evidence. In
contrast, it is still a challenge for current large language models to generate
corresponding utterances based on the assessment of facts and confidence in an
uncertain real-world environment. While it has recently become popular to
estimate and calibrate confidence of LLMs with verbalized uncertainty, what is
lacking is a careful examination of the linguistic knowledge of uncertainty
encoded in the latent space of LLMs. In this paper, we draw on typological
frameworks of epistemic expressions to evaluate LLMs' knowledge of epistemic
modality, using controlled stories. Our experiments show that the performance
of LLMs in generating epistemic expressions is limited and not robust, and
hence the expressions of uncertainty generated by LLMs are not always reliable.
To build uncertainty-aware LLMs, it is necessary to enrich semantic knowledge
of epistemic modality in LLMs.

</details>


### [187] [FormFactory: An Interactive Benchmarking Suite for Multimodal Form-Filling Agents](https://arxiv.org/abs/2506.01520)
*Bobo Li,Yuheng Wang,Hao Fei,Juncheng Li,Wei Ji,Mong-Li Lee,Wynne Hsu*

Main category: cs.CL

TL;DR: 论文提出FormFactory，一个用于评估多模态大语言模型（MLLMs）在在线表单填写任务中表现的交互式基准套件，发现当前模型准确率不足5%，揭示了其在视觉布局推理和字段值对齐方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 在线表单填写是一项常见但繁琐的任务，现有工具多为基于规则且缺乏通用性。多模态大语言模型（MLLMs）在通用GUI任务中表现良好，但在表单填写任务中面临布局灵活性和字段对齐等独特挑战。

Method: 提出FormFactory，一个包含网页界面、后端评估模块和精心构建数据集的交互式基准套件，覆盖多样化现实场景和高保真表单交互模拟。

Result: 对当前最先进的MLLMs进行全面评估，发现其准确率不足5%，揭示了模型在视觉布局推理和字段值对齐方面的显著局限性。

Conclusion: FormFactory可作为进一步研究稳健、实用表单填写代理的基石，推动相关技术的发展。

Abstract: Online form filling is a common yet labor-intensive task involving extensive
keyboard and mouse interactions. Despite the long-standing vision of automating
this process with "one click", existing tools remain largely rule-based and
lack generalizable, generative capabilities. Recent advances in Multimodal
Large Language Models (MLLMs) have enabled promising agents for GUI-related
tasks in general-purpose scenarios. However, they struggle with the unique
challenges of form filling, such as flexible layouts and the difficulty of
aligning textual instructions with on-screen fields. To bridge this gap, we
formally define the form-filling task and propose FormFactory, an interactive
benchmarking suite comprising a web-based interface, backend evaluation module,
and carefully constructed dataset. Our benchmark covers diverse real-world
scenarios, incorporates various field formats, and simulates high-fidelity form
interactions. We conduct a comprehensive evaluation of state-of-the-art MLLMs
and observe that no model surpasses 5% accuracy, underscoring the inherent
difficulty of the task. These findings also reveal significant limitations in
current models' visual layout reasoning and field-value alignment abilities. We
hope our benchmark can serve as a stepping stone for further research into
robust, practical form-filling agents.

</details>


### [188] [V-VAE: A Variational Auto Encoding Framework Towards Fine-Grained Control over Human-Like Chat](https://arxiv.org/abs/2506.01524)
*Qi Lin,Weikai Xu,Lisi Chen,Bin Dai*

Main category: cs.CL

TL;DR: 论文提出了一种基于变分自编码器（V-VAE）的框架，用于生成更符合人物特质的对话响应，并构建了高质量数据集HumanChatData和基准测试HumanChatBench。


<details>
  <summary>Details</summary>
Motivation: 现有基于角色扮演和人物特质的对话方法依赖静态角色描述和低质量合成数据，难以捕捉动态细粒度的人类对话细节。

Method: 提出V-VAE框架，包含变分自编码模块和细粒度控制空间，动态调整对话行为。

Result: 实验表明，基于V-VAE的LLM在HumanChatBench和DialogBench上优于基线模型。

Conclusion: V-VAE和HumanChatData有效解决了高质量数据和动态对话建模的挑战。

Abstract: With the continued proliferation of Large Language Model (LLM) based
chatbots, there is a growing demand for generating responses that are not only
linguistically fluent but also consistently aligned with persona-specific
traits in conversations. However, existing role-play and persona-based chat
approaches rely heavily on static role descriptions, coarse-grained signal
space, and low-quality synthetic data, which fail to capture dynamic
fine-grained details in human-like chat. Human-like chat requires modeling
subtle latent traits, such as emotional tone, situational awareness, and
evolving personality, which are difficult to predefine and cannot be easily
learned from synthetic or distillation-based data. To address these
limitations, we propose a Verbal Variational Auto-Encoding (V-VAE) framework,
containing a variational auto-encoding module and fine-grained control space
which dynamically adapts dialogue behaviour based on fine-grained,
interpretable latent variables across talking style, interaction patterns, and
personal attributes. We also construct a high-quality dataset, HumanChatData,
and benchmark HumanChatBench to address the scarcity of high-quality data in
the human-like domain. Experiments show that LLMs based on V-VAE consistently
outperform standard baselines on HumanChatBench and DialogBench, which further
demonstrates the effectiveness of V-VAE and HumanChatData.

</details>


### [189] [STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework](https://arxiv.org/abs/2506.01531)
*Wenhao Liu,Zhenyi Lu,Xinyu Hu,Jierui Zhang,Dailin Li,Jiacheng Cen,Huilin Cao,Haiteng Wang,Yuhan Li,Kun Xie,Dandan Li,Pei Zhang,Chengbo Zhang,Yuxiang Ren,Xiaohong Huang,Yan Ma*

Main category: cs.CL

TL;DR: STORM-BORN是一个超难数学推导数据集，源自前沿学术论文，包含人类式推理线索，通过多智能体协作和人类数学家评估确保质量。


<details>
  <summary>Details</summary>
Motivation: 现有数学数据集存在内容过时、缺乏挑战性、忽略人类式推理及可靠性不足的问题，STORM-BORN旨在解决这些问题。

Method: 提出一种人类参与的多智能体数据生成框架，结合推理密集过滤和多智能体协作，并引入人类数学家评估。

Result: 数据集包含2000个样本，精选100个最难问题，GPT-o1解决率低于5%，微调后LLaMA3-8B和Qwen2.5-7B准确率分别提升7.84%和9.12%。

Conclusion: STORM-BORN为AI提供了高难度基准和人类式推理训练资源，推动数学推理能力发展。

Abstract: High-quality math datasets are crucial for advancing the reasoning abilities
of large language models (LLMs). However, existing datasets often suffer from
three key issues: outdated and insufficient challenging content, neglecting
human-like reasoning, and limited reliability due to single-LLM generation. To
address these, we introduce $\textbf{STORM-BORN}$, an ultra-challenging dataset
of mathematical derivations sourced from cutting-edge academic papers, which
includes dense human-like approximations and heuristic cues. To ensure the
reliability and quality, we propose a novel human-in-the-loop, multi-agent data
generation framework, integrating reasoning-dense filters, multi-agent
collaboration, and human mathematicians' evaluations. We curated a set of 2,000
synthetic samples and deliberately selected the 100 most difficult problems.
Even most advanced models like GPT-o1 solved fewer than $5\%$ of them.
Fine-tuning on STORM-BORN boosts accuracy by $7.84\%$ (LLaMA3-8B) and $9.12\%$
(Qwen2.5-7B). As AI approaches mathematician-level reasoning, STORM-BORN
provides both a high-difficulty benchmark and a human-like reasoning training
resource. Our code and dataset are publicly available at
https://github.com/lwhere/STORM-BORN.

</details>


### [190] [Dictionaries to the Rescue: Cross-Lingual Vocabulary Transfer for Low-Resource Languages Using Bilingual Dictionaries](https://arxiv.org/abs/2506.01535)
*Haruki Sakajo,Yusuke Ide,Justin Vasselli,Yusuke Sakai,Yingtao Tian,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 提出了一种基于双语词典的跨语言词汇迁移方法，适用于低资源语言，通过逐步移除子词并估计目标子词嵌入，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低资源语言中面临挑战，而双语词典资源丰富，可用于跨语言词汇迁移。

Method: 利用BPE分词器的特性，逐步移除子词并估计目标子词嵌入。

Result: 实验结果表明，该方法在低资源语言上优于现有方法。

Conclusion: 基于词典的跨语言词汇迁移方法简单有效，特别适合低资源语言。

Abstract: Cross-lingual vocabulary transfer plays a promising role in adapting
pre-trained language models to new languages, including low-resource languages.
Existing approaches that utilize monolingual or parallel corpora face
challenges when applied to languages with limited resources. In this work, we
propose a simple yet effective vocabulary transfer method that utilizes
bilingual dictionaries, which are available for many languages, thanks to
descriptive linguists. Our proposed method leverages a property of BPE
tokenizers where removing a subword from the vocabulary causes a fallback to
shorter subwords. The embeddings of target subwords are estimated iteratively
by progressively removing them from the tokenizer. The experimental results
show that our approach outperforms existing methods for low-resource languages,
demonstrating the effectiveness of a dictionary-based approach for
cross-lingual vocabulary transfer.

</details>


### [191] [Hanfu-Bench: A Multimodal Benchmark on Cross-Temporal Cultural Understanding and Transcreation](https://arxiv.org/abs/2506.01565)
*Li Zhou,Lutong Yu,Dongchu Xie,Shaohuan Cheng,Wenyan Li,Haizhou Li*

Main category: cs.CL

TL;DR: 论文提出了Hanfu-Bench数据集，用于研究视觉语言模型在文化理解中的时间维度，包括文化视觉理解和图像转创任务，揭示了模型在时间文化理解和创意适应中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有文化理解研究多关注地理多样性，忽视了时间维度，论文旨在填补这一空白。

Method: 引入Hanfu-Bench数据集，包含文化视觉理解和图像转创任务，评估模型表现。

Result: 封闭式VLM在文化视觉理解上接近非专家水平，但落后专家10%；开放式VLM表现更差。图像转创任务中，最佳模型成功率仅42%。

Conclusion: Hanfu-Bench揭示了时间文化理解和创意适应的挑战，为未来研究提供了重要测试平台。

Abstract: Culture is a rich and dynamic domain that evolves across both geography and
time. However, existing studies on cultural understanding with vision-language
models (VLMs) primarily emphasize geographic diversity, often overlooking the
critical temporal dimensions. To bridge this gap, we introduce Hanfu-Bench, a
novel, expert-curated multimodal dataset. Hanfu, a traditional garment spanning
ancient Chinese dynasties, serves as a representative cultural heritage that
reflects the profound temporal aspects of Chinese culture while remaining
highly popular in Chinese contemporary society. Hanfu-Bench comprises two core
tasks: cultural visual understanding and cultural image transcreation.The
former task examines temporal-cultural feature recognition based on single- or
multi-image inputs through multiple-choice visual question answering, while the
latter focuses on transforming traditional attire into modern designs through
cultural element inheritance and modern context adaptation. Our evaluation
shows that closed VLMs perform comparably to non-experts on visual cutural
understanding but fall short by 10\% to human experts, while open VLMs lags
further behind non-experts. For the transcreation task, multi-faceted human
evaluation indicates that the best-performing model achieves a success rate of
only 42\%. Our benchmark provides an essential testbed, revealing significant
challenges in this new direction of temporal cultural understanding and
creative adaptation.

</details>


### [192] [Prompt Engineering Large Language Models' Forecasting Capabilities](https://arxiv.org/abs/2506.01578)
*Philipp Schoenegger,Cameron R. Jones,Philip E. Tetlock,Barbara Mellers*

Main category: cs.CL

TL;DR: 研究发现，在复杂任务（如预测）中，简单的提示工程改进对提升大型语言模型性能效果有限，某些策略甚至可能降低准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨提示工程是否足以提升大型语言模型在复杂领域（如预测）中的性能。

Method: 通过两项研究测试了38种提示变体，包括复合提示和外部来源提示，并引入了推理模型o1和o1-mini。

Result: 大多数提示改进效果微乎其微，部分策略（如鼓励贝叶斯推理）甚至显著降低准确性。

Conclusion: 在复杂任务中，仅靠基本提示改进效果有限，可能需要更鲁棒或专业化的技术来显著提升性能。

Abstract: Large language model performance can be improved in a large number of ways.
Many such techniques, like fine-tuning or advanced tool usage, are
time-intensive and expensive. Although prompt engineering is significantly
cheaper and often works for simpler tasks, it remains unclear whether prompt
engineering suffices for more complex domains like forecasting. Here we show
that small prompt modifications rarely boost forecasting accuracy beyond a
minimal baseline. In our first study, we tested 38 prompts across Claude 3.5
Sonnet, Claude 3.5 Haiku, GPT-4o, and Llama 3.1 405B. In our second, we
introduced compound prompts and prompts from external sources, also including
the reasoning models o1 and o1-mini. Our results show that most prompts lead to
negligible gains, although references to base rates yield slight benefits.
Surprisingly, some strategies showed strong negative effects on accuracy:
especially encouraging the model to engage in Bayesian reasoning. These results
suggest that, in the context of complex tasks like forecasting, basic prompt
refinements alone offer limited gains, implying that more robust or specialized
techniques may be required for substantial performance improvements in AI
forecasting.

</details>


### [193] [Unified Large Language Models for Misinformation Detection in Low-Resource Linguistic Settings](https://arxiv.org/abs/2506.01587)
*Muhammad Islam,Javed Ali Khan,Mohammed Abaker,Ali Daud,Azeem Irshad*

Main category: cs.CL

TL;DR: 该研究针对乌尔都语等资源受限语言中假新闻检测的挑战，提出了首个公开可用的乌尔都语假新闻检测数据集，并评估了多种预训练语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 由于乌尔都语等语言缺乏可靠的假新闻检测数据集和资源，研究旨在填补这一空白，提升假新闻检测的准确性。

Method: 研究开发了一个公开的乌尔都语假新闻数据集，并评估了多种预训练语言模型（如XLNet、mBERT等），同时提出了一种统一的LLM模型。

Result: 提出的统一LLM模型在准确率、F1分数等指标上优于其他模型，并通过人工验证进一步确认了其有效性。

Conclusion: 研究强调了开发可靠、专家验证的数据集的重要性，为资源受限语言的假新闻检测提供了新工具和方法。

Abstract: The rapid expansion of social media platforms has significantly increased the
dissemination of forged content and misinformation, making the detection of
fake news a critical area of research. Although fact-checking efforts
predominantly focus on English-language news, there is a noticeable gap in
resources and strategies to detect news in regional languages, such as Urdu.
Advanced Fake News Detection (FND) techniques rely heavily on large, accurately
labeled datasets. However, FND in under-resourced languages like Urdu faces
substantial challenges due to the scarcity of extensive corpora and the lack of
validated lexical resources. Current Urdu fake news datasets are often
domain-specific and inaccessible to the public. They also lack human
verification, relying mainly on unverified English-to-Urdu translations, which
compromises their reliability in practical applications. This study highlights
the necessity of developing reliable, expert-verified, and domain-independent
Urdu-enhanced FND datasets to improve fake news detection in Urdu and other
resource-constrained languages. This paper presents the first benchmark large
FND dataset for Urdu news, which is publicly available for validation and deep
analysis. We also evaluate this dataset using multiple state-of-the-art
pre-trained large language models (LLMs), such as XLNet, mBERT, XLM-RoBERTa,
RoBERTa, DistilBERT, and DeBERTa. Additionally, we propose a unified LLM model
that outperforms the others with different embedding and feature extraction
techniques. The performance of these models is compared based on accuracy, F1
score, precision, recall, and human judgment for vetting the sample results of
news.

</details>


### [194] [Statement-Tuning Enables Efficient Cross-lingual Generalization in Encoder-only Models](https://arxiv.org/abs/2506.01592)
*Ahmed Elshabrawy,Thanh-Nhi Nguyen,Yeeun Kang,Lihan Feng,Annant Jain,Faadil Abdullah Shaikh,Jonibek Mansurov,Mohamed Fazli Mohamed Imam,Jesus-German Ortiz-Barajas,Rendi Chevi,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 本文探讨了如何通过Statement Tuning方法使编码器模型（如BERT和RoBERTa）在零样本和多语言任务中表现接近大型语言模型（LLMs），同时保持高效性。


<details>
  <summary>Details</summary>
Motivation: 尽管编码器模型在计算和内存成本上更高效，但其在零样本任务中的表现通常不如LLMs。本文旨在探索如何通过Statement Tuning方法提升编码器模型在多语言零样本任务中的表现。

Method: 采用Statement Tuning方法，将任务重新表述为有限的模板，并扩展至多语言环境，评估编码器模型的零样本跨语言泛化能力。

Result: 实验表明，先进的编码器模型在多语言任务中表现优异，与多语言LLMs相当，同时更高效。

Conclusion: 编码器模型通过Statement Tuning可实现高效的零样本跨语言泛化，为低资源语言提供了一种资源友好的替代方案。

Abstract: Large Language Models (LLMs) excel in zero-shot and few-shot tasks, but
achieving similar performance with encoder-only models like BERT and RoBERTa
has been challenging due to their architecture. However, encoders offer
advantages such as lower computational and memory costs. Recent work adapts
them for zero-shot generalization using Statement Tuning, which reformulates
tasks into finite templates. We extend this approach to multilingual NLP,
exploring whether encoders can achieve zero-shot cross-lingual generalization
and serve as efficient alternatives to memory-intensive LLMs for low-resource
languages. Our results show that state-of-the-art encoder models generalize
well across languages, rivaling multilingual LLMs while being more efficient.
We also analyze multilingual Statement Tuning dataset design, efficiency gains,
and language-specific generalization, contributing to more inclusive and
resource-efficient NLP models. We release our code and models.

</details>


### [195] [MMD-Sense-Analysis: Word Sense Detection Leveraging Maximum Mean Discrepancy](https://arxiv.org/abs/2506.01602)
*Kensuke Mitsuzawa*

Main category: cs.CL

TL;DR: 本文提出了一种基于最大均值差异（MMD）的新方法MMD-Sense-Analysis，用于检测和解释词义随时间的变化。


<details>
  <summary>Details</summary>
Motivation: 词义分析是理解语言和社会背景的重要工作，而词义变化检测是识别和解释词义随时间变化的任务。

Method: 利用MMD选择语义上有意义的变量，并量化不同时间段的变化。

Result: 实证评估结果表明该方法的有效性。

Conclusion: 这是首次将MMD应用于词义变化检测，方法能够识别词义变化并解释其演变。

Abstract: Word sense analysis is an essential analysis work for interpreting the
linguistic and social backgrounds. The word sense change detection is a task of
identifying and interpreting shifts in word meanings over time. This paper
proposes MMD-Sense-Analysis, a novel approach that leverages Maximum Mean
Discrepancy (MMD) to select semantically meaningful variables and quantify
changes across time periods. This method enables both the identification of
words undergoing sense shifts and the explanation of their evolution over
multiple historical periods. To my knowledge, this is the first application of
MMD to word sense change detection. Empirical assessment results demonstrate
the effectiveness of the proposed approach.

</details>


### [196] [IndicRAGSuite: Large-Scale Datasets and a Benchmark for Indian Language RAG Systems](https://arxiv.org/abs/2506.01615)
*Pasunuti Prasanjith,Prathmesh B More,Anoop Kunchukuttan,Raj Dabre*

Main category: cs.CL

TL;DR: 论文提出了针对印度语言的检索增强生成（RAG）系统资源不足问题，创建了IndicMSMarco评测基准和大规模训练数据集。


<details>
  <summary>Details</summary>
Motivation: 印度语言缺乏高质量的RAG系统资源，包括评测基准和训练数据，阻碍了多语言RAG的发展。

Method: 通过手动翻译MS MARCO-dev集的1000个查询创建IndicMSMarco评测基准，并利用LLM从19种印度语言维基百科构建训练数据集。

Result: 提供了IndicMSMarco评测基准和大规模训练数据集，支持13种印度语言的评测和19种语言的训练。

Conclusion: 解决了印度语言RAG系统的资源瓶颈，为多语言信息检索和生成任务提供了实用工具。

Abstract: Retrieval-Augmented Generation (RAG) systems enable language models to access
relevant information and generate accurate, well-grounded, and contextually
informed responses. However, for Indian languages, the development of
high-quality RAG systems is hindered by the lack of two critical resources: (1)
evaluation benchmarks for retrieval and generation tasks, and (2) large-scale
training datasets for multilingual retrieval. Most existing benchmarks and
datasets are centered around English or high-resource languages, making it
difficult to extend RAG capabilities to the diverse linguistic landscape of
India. To address the lack of evaluation benchmarks, we create IndicMSMarco, a
multilingual benchmark for evaluating retrieval quality and response generation
in 13 Indian languages, created via manual translation of 1000 diverse queries
from MS MARCO-dev set. To address the need for training data, we build a
large-scale dataset of (question, answer, relevant passage) tuples derived from
the Wikipedias of 19 Indian languages using state-of-the-art LLMs.
Additionally, we include translated versions of the original MS MARCO dataset
to further enrich the training data and ensure alignment with real-world
information-seeking tasks. Resources are available here:
https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite

</details>


### [197] [Domain Lexical Knowledge-based Word Embedding Learning for Text Classification under Small Data](https://arxiv.org/abs/2506.01621)
*Zixiao Zhu,Kezhi Mao*

Main category: cs.CL

TL;DR: 论文提出了一种基于领域特定词汇知识增强BERT词嵌入的方法，以解决在情感分析和情绪识别等任务中BERT表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 研究发现，BERT在依赖关键词的文本分类任务中表现不佳，原因是其上下文嵌入对关键词的区分性不足。

Method: 通过将BERT嵌入投影到一个新空间，最大化类内相似性和类间差异，并结合自动从开放资源获取的词汇知识。

Result: 在情感分析、情绪识别和问答三个任务上的实验证明了该方法的有效性。

Conclusion: 提出的词嵌入增强模型显著提升了BERT在依赖关键词的分类任务中的性能。

Abstract: Pre-trained language models such as BERT have been proved to be powerful in
many natural language processing tasks. But in some text classification
applications such as emotion recognition and sentiment analysis, BERT may not
lead to satisfactory performance. This often happens in applications where
keywords play critical roles in the prediction of class labels. Our
investigation found that the root cause of the problem is that the
context-based BERT embedding of the keywords may not be discriminative enough
to produce discriminative text representation for classification. Motivated by
this finding, we develop a method to enhance word embeddings using
domain-specific lexical knowledge. The knowledge-based embedding enhancement
model projects the BERT embedding into a new space where within-class
similarity and between-class difference are maximized. To implement the
knowledge-based word embedding enhancement model, we also develop a knowledge
acquisition algorithm for automatically collecting lexical knowledge from
online open sources. Experiment results on three classification tasks,
including sentiment analysis, emotion recognition and question answering, have
shown the effectiveness of our proposed word embedding enhancing model. The
codes and datasets are in https://github.com/MidiyaZhu/KVWEFFER.

</details>


### [198] [MVAN: Multi-View Attention Networks for Fake News Detection on Social Media](https://arxiv.org/abs/2506.01627)
*Shiwen Ni,Jiawen Li,Hung-Yu Kao*

Main category: cs.CL

TL;DR: 本文提出了一种名为MVAN的神经网络模型，用于在仅提供源推文及其转发用户的情况下检测虚假新闻，并通过注意力机制提供解释。


<details>
  <summary>Details</summary>
Motivation: 解决现有虚假新闻检测方法依赖长文本内容（如新闻文章和用户评论）的局限性，适应更现实的社交媒体场景。

Method: 开发了MVAN模型，结合文本语义注意力和传播结构注意力，捕捉源推文内容和传播结构的信息。

Result: 在两个真实数据集上的实验表明，MVAN在准确率上平均优于现有方法2.5%，并能提供合理的解释。

Conclusion: MVAN模型在虚假新闻检测中表现出色，尤其在短文本和传播结构分析方面具有优势。

Abstract: Fake news on social media is a widespread and serious problem in today's
society. Existing fake news detection methods focus on finding clues from Long
text content, such as original news articles and user comments. This paper
solves the problem of fake news detection in more realistic scenarios. Only
source shot-text tweet and its retweet users are provided without user
comments. We develop a novel neural network based model,
\textbf{M}ulti-\textbf{V}iew \textbf{A}ttention \textbf{N}etworks (MVAN) to
detect fake news and provide explanations on social media. The MVAN model
includes text semantic attention and propagation structure attention, which
ensures that our model can capture information and clues both of source tweet
content and propagation structure. In addition, the two attention mechanisms in
the model can find key clue words in fake news texts and suspicious users in
the propagation structure. We conduct experiments on two real-world datasets,
and the results demonstrate that MVAN can significantly outperform
state-of-the-art methods by 2.5\% in accuracy on average, and produce a
reasonable explanation.

</details>


### [199] [Cross-Lingual Generalization and Compression: From Language-Specific to Shared Neurons](https://arxiv.org/abs/2506.01629)
*Frederick Riemenschneider,Anette Frank*

Main category: cs.CL

TL;DR: 多语言模型在预训练过程中，参数空间逐渐从语言特定表示演变为跨语言抽象，神经元逐渐对齐不同语言的语义概念。


<details>
  <summary>Details</summary>
Motivation: 研究多语言模型如何在无显式跨语言监督的情况下实现知识迁移。

Method: 分析三个多语言模型的参数空间，通过探测实验观察表示演变和神经元功能变化。

Result: 模型从语言特定表示逐渐收敛为跨语言抽象，某些神经元成为跨语言概念的可靠预测器。

Conclusion: 多语言模型通过压缩和神经元对齐实现跨语言知识迁移。

Abstract: Multilingual language models (MLLMs) have demonstrated remarkable abilities
to transfer knowledge across languages, despite being trained without explicit
cross-lingual supervision. We analyze the parameter spaces of three MLLMs to
study how their representations evolve during pre-training, observing patterns
consistent with compression: models initially form language-specific
representations, which gradually converge into cross-lingual abstractions as
training progresses. Through probing experiments, we observe a clear transition
from uniform language identification capabilities across layers to more
specialized layer functions. For deeper analysis, we focus on neurons that
encode distinct semantic concepts. By tracing their development during
pre-training, we show how they gradually align across languages. Notably, we
identify specific neurons that emerge as increasingly reliable predictors for
the same concepts across languages.

</details>


### [200] [ESGenius: Benchmarking LLMs on Environmental, Social, and Governance (ESG) and Sustainability Knowledge](https://arxiv.org/abs/2506.01646)
*Chaoyue He,Xin Zhou,Yi Wu,Xinjia Yu,Yan Zhang,Lei Zhang,Di Wang,Shengfei Lyu,Hong Xu,Xiaoqiao Wang,Wei Liu,Chunyan Miao*

Main category: cs.CL

TL;DR: ESGenius是一个用于评估和提升大型语言模型（LLM）在环境、社会和治理（ESG）及可持续性问题回答能力的综合基准，包含QA数据集和语料库，并通过零样本和RAG方法评估模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在跨学科的ESG和可持续性问题上的表现有限，需要权威数据支持以提升理解能力。

Method: 构建ESGenius-QA（1136个多选题）和ESGenius-Corpus（231个权威文档），采用零样本和RAG两阶段评估协议测试50个LLM。

Result: 零样本下模型准确率55-70%，RAG显著提升性能（如某模型从63.82%升至80.46%）。

Conclusion: ESGenius是首个专注于ESG的LLM基准，强调权威数据对模型性能的重要性。

Abstract: We introduce ESGenius, a comprehensive benchmark for evaluating and enhancing
the proficiency of Large Language Models (LLMs) in Environmental, Social and
Governance (ESG) and sustainability-focused question answering. ESGenius
comprises two key components: (i) ESGenius-QA, a collection of 1 136
multiple-choice questions generated by LLMs and rigorously validated by domain
experts, covering a broad range of ESG pillars and sustainability topics. Each
question is systematically linked to its corresponding source text, enabling
transparent evaluation and supporting retrieval-augmented generation (RAG)
methods; and (ii) ESGenius-Corpus, a meticulously curated repository of 231
foundational frameworks, standards, reports and recommendation documents from
seven authoritative sources. Moreover, to fully assess the capabilities and
adaptation potential of the model, we implement a rigorous two-stage evaluation
protocol -- Zero-Shot and RAG. Extensive experiments across 50 LLMs (ranging
from 0.5 B to 671 B parameters) demonstrate that state-of-the-art models
achieve only moderate performance in zero-shot settings, with accuracies
typically around 55--70\%, highlighting ESGenius's challenging nature for LLMs
in interdisciplinary contexts. However, models employing RAG show significant
performance improvements, particularly for smaller models. For example,
"DeepSeek-R1-Distill-Qwen-14B" improves from 63.82\% (zero-shot) to 80.46\%
with RAG. These results underscore the necessity of grounding responses in
authoritative sources for enhanced ESG understanding. To the best of our
knowledge, ESGenius is the first benchmark curated for LLMs and the relevant
enhancement technologies that focuses on ESG and sustainability topics.

</details>


### [201] [Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon](https://arxiv.org/abs/2506.01675)
*Chen Zhang,Zhiyuan Liao,Yansong Feng*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）在多语言环境中文化知识传递的机制，发现高资源语言与英语之间存在双向传递，而低资源语言主要向英语单向传递。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量研究评估LLMs处理全球文化多样性的能力，但其文化知识获取机制（尤其是多语言环境下的机制）仍不明确。

Method: 引入了一个可解释的框架，研究文化知识在语言适应过程中的传递，确保训练数据的透明度并控制传递效应。

Result: 研究发现高资源语言与英语之间存在双向文化传递，而低资源语言主要向英语单向传递，并提出频率假设解释这一现象。

Conclusion: 文化知识在预训练数据中出现频率越高，传递越容易，这一假设得到了训练语料库的实证分析支持。

Abstract: Despite substantial research efforts evaluating how well large language
models~(LLMs) handle global cultural diversity, the mechanisms behind their
cultural knowledge acquisition, particularly in multilingual settings, remain
unclear. We study this question by investigating how cultural knowledge
transfers across languages during language adaptation of LLMs. We introduce an
interpretable framework for studying this transfer, ensuring training data
transparency and controlling transfer effects. Through a study of four
non-Anglophonic cultures, we observe bidirectional cultural transfer between
English and other high-resource languages, while low-resource languages
primarily transfer knowledge to English with limited reverse flow. To explain
this asymmetric phenomenon, we propose a frequency-based hypothesis: cultural
knowledge appearing more frequently in the pretraining data transfers more
easily, which is supported by empirical analysis of the training corpora.

</details>


### [202] [StochasTok: Improving Fine-Grained Subword Understanding in LLMs](https://arxiv.org/abs/2506.01687)
*Anya Sims,Thom Foster,Klara Kaleb,Tuan-Duy H. Nguyen,Joseph Lee,Jakob N. Foerster,Yee Whye Teh,Cong Lu*

Main category: cs.CL

TL;DR: 论文提出了一种名为StochasTok的随机分词方案，通过随机分割训练中的token，提升大语言模型（LLM）在子词级别任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在子词级别任务（如字符计数、子串识别等）上表现不佳，主要原因是分词方式掩盖了词的细粒度结构。现有替代方法（如字符级或dropout分词）计算成本高且效果不稳定。

Method: 引入StochasTok，一种简单高效的随机分词方案，在训练过程中随机分割token，使LLM能够‘看到’词的内部结构。

Result: 实验表明，使用StochasTok预训练显著提升了LLM在子词级别任务（如字符计数、子串识别和数学任务）上的表现。此外，StochasTok可无缝集成到训练流程的任何阶段，甚至能通过后训练提升已有预训练模型的子词理解能力。

Conclusion: StochasTok通过极小的改动实现了显著改进，展示了其在更大、更强大模型中的应用潜力。

Abstract: Subword-level understanding is integral to numerous tasks, including
understanding multi-digit numbers, spelling mistakes, abbreviations, rhyming,
and wordplay. Despite this, current large language models (LLMs) still often
struggle with seemingly simple subword-level tasks like How many 'r's in
'strawberry'?. A key factor behind these failures is tokenization which
obscures the fine-grained structure of words. Current alternatives, such as
character-level and dropout tokenization methods, significantly increase
computational costs and provide inconsistent improvements. In this paper we
revisit tokenization and introduce StochasTok, a simple, efficient stochastic
tokenization scheme that randomly splits tokens during training, allowing LLMs
to 'see' their internal structure. Our experiments show that pretraining with
StochasTok substantially improves LLMs' downstream performance across multiple
subword-level language games, including character counting, substring
identification, and math tasks. Furthermore, StochasTok's simplicity allows
seamless integration at any stage of the training pipeline; and we demonstrate
that post-training with StochasTok can instill improved subword understanding
into existing pretrained models, thus avoiding costly pretraining from scratch.
These dramatic improvements achieved with a minimal change suggest StochasTok
holds exciting potential when applied to larger, more capable models. Code
open-sourced at: https://github.com/anyasims/stochastok.

</details>


### [203] [When LLMs Team Up: The Emergence of Collaborative Affective Computing](https://arxiv.org/abs/2506.01698)
*Wenna Lai,Haoran Xie,Guandong Xu,Qing Li,S. Joe Qin*

Main category: cs.CL

TL;DR: 该论文综述了基于大语言模型（LLMs）的协作系统在情感计算（AC）中的应用，探讨了从结构化协作到自主协作的方法，并分析了其潜力、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统的情感计算任务采用流水线架构，存在结构僵化和适应性差的问题。LLMs为情感理解和生成任务提供了统一方法，但在情感推理中存在认知局限。研究旨在通过LLM协作系统模拟人类情感智能，提升复杂情感推理的鲁棒性和适应性。

Method: 论文系统回顾了现有方法，包括协作策略、机制、关键功能和应用；通过实验比较了代表性任务中的协作策略；分析了协作系统在情感推理中的潜力。

Result: 协作系统能够增强复杂情感推理的鲁棒性和适应性，但面临认知局限和文化误解等挑战。

Conclusion: 该研究首次系统探索了LLMs在AC中的协作智能，为接近人类社交智能的应用奠定了基础，并提出了未来研究方向。

Abstract: Affective Computing (AC) is essential in bridging the gap between human
emotional experiences and machine understanding. Traditionally, AC tasks in
natural language processing (NLP) have been approached through pipeline
architectures, which often suffer from structure rigidity that leads to
inefficiencies and limited adaptability. The advent of Large Language Models
(LLMs) has revolutionized this field by offering a unified approach to
affective understanding and generation tasks, enhancing the potential for
dynamic, real-time interactions. However, LLMs face cognitive limitations in
affective reasoning, such as misinterpreting cultural nuances or contextual
emotions, and hallucination problems in decision-making. To address these
challenges, recent research advocates for LLM-based collaboration systems that
emphasize interactions among specialized models and LLMs, mimicking human-like
affective intelligence through the synergy of emotional and rational thinking
that aligns with Dual Process Theory in psychology. This survey aims to provide
a comprehensive overview of LLM-based collaboration systems in AC, exploring
from structured collaborations to autonomous collaborations. Specifically, it
includes: (1) A systematic review of existing methods, focusing on
collaboration strategies, mechanisms, key functions, and applications; (2)
Experimental comparisons of collaboration strategies across representative
tasks in affective understanding and generation; (3) An analysis highlighting
the potential of these systems to enhance robustness and adaptability in
complex affective reasoning; (4) A discussion of key challenges and future
research directions to further advance the field. This work is the first to
systematically explore collaborative intelligence with LLMs in AC, paving the
way for more powerful applications that approach human-like social
intelligence.

</details>


### [204] [mdok of KInIT: Robustly Fine-tuned LLM for Binary and Multiclass AI-Generated Text Detection](https://arxiv.org/abs/2506.01702)
*Dominik Macko*

Main category: cs.CL

TL;DR: 论文提出了一种基于微调小型LLMs的文本分类方法（mdok），用于检测机器生成的文本，并在Voight-Kampff Generative AI Detection 2025任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）生成的高质量文本可能被滥用（如抄袭、垃圾信息、虚假信息传播），需要自动化检测方法。

Method: 采用微调小型LLMs进行文本分类的方法（mdok），应用于Voight-Kampff Generative AI Detection 2025任务。

Result: 在二元检测和多类分类（人类-AI协作的多种情况）中表现优异，多类分类排名第一。

Conclusion: mdok方法在检测机器生成文本方面具有鲁棒性和高效性。

Abstract: The large language models (LLMs) are able to generate high-quality texts in
multiple languages. Such texts are often not recognizable by humans as
generated, and therefore present a potential of LLMs for misuse (e.g.,
plagiarism, spams, disinformation spreading). An automated detection is able to
assist humans to indicate the machine-generated texts; however, its robustness
to out-of-distribution data is still challenging. This notebook describes our
mdok approach in robust detection, based on fine-tuning smaller LLMs for text
classification. It is applied to both subtasks of Voight-Kampff Generative AI
Detection 2025, providing remarkable performance in binary detection as well as
in multiclass (1st rank) classification of various cases of human-AI
collaboration.

</details>


### [205] [Fairness Dynamics During Training](https://arxiv.org/abs/2506.01709)
*Krishna Patel,Nivedha Sivakumar,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: 研究大型语言模型（LLM）训练中的公平性动态，提出两种新指标（Average Rank和Jensen-Shannon Divergence by Parts）评估偏见，发现Pythia-6.9b存在性别偏见，通过早停策略可显著提升公平性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM训练过程中偏见的动态变化，以诊断和缓解偏见，尤其是性别预测任务中的不公平现象。

Method: 引入两种新指标（Average Rank和Jensen-Shannon Divergence by Parts），在WinoBias数据集上评估Pythia模型的性别偏见动态。

Result: Pythia-6.9b对男性预测更自信；通过早停可牺牲少量准确率换取大幅公平性提升；更大模型可能表现出更多偏见。

Conclusion: 监控公平性动态有助于识别和缓解偏见，早停是一种有效的干预策略，但需权衡性能与公平性。

Abstract: We investigate fairness dynamics during Large Language Model (LLM) training
to enable the diagnoses of biases and mitigations through training
interventions like early stopping; we find that biases can emerge suddenly and
do not always follow common performance metrics. We introduce two new metrics
to evaluate fairness dynamics holistically during model pre-training: Average
Rank and Jensen-Shannon Divergence by Parts. These metrics provide insights
into the Pythia models' progression of biases in gender prediction of
occupations on the WinoBias dataset. By monitoring these dynamics, we find that
(1) Pythia-6.9b is biased towards men; it becomes more performant and confident
predicting "male" than "female" during training, (2) via early-stopping,
Pythia-6.9b can exchange 1.7% accuracy on LAMBADA for a 92.5% increase in
fairness, and (3) larger models can exhibit more bias; Pythia-6.9b makes more
assumptions about gender than Pythia-160m, even when a subject's gender is not
specified.

</details>


### [206] [Reasoning-Table: Exploring Reinforcement Learning for Table Reasoning](https://arxiv.org/abs/2506.01710)
*Fangyu Lei,Jinxiang Meng,Yiming Huang,Tinghong Chen,Yun Zhang,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 论文提出了一种基于强化学习（RL）的表格推理方法Reasoning-Table，通过数据预处理、奖励设计和训练策略优化，在多个基准测试中超越监督微调（SFT）方法，并表现出更强的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法在表格推理任务中存在泛化性和鲁棒性不足的问题，主要源于模仿学习的固有偏差。

Method: 采用强化学习框架，结合数据预处理、奖励设计和定制训练策略，利用基于规则的简单奖励机制进行训练。

Result: 在多个表格推理基准测试中表现优异，超越Claude-3.7-Sonnet等大型专有模型4.0%，并在BIRD开发数据集上达到68.3%的文本到SQL任务性能。

Conclusion: Reasoning-Table展示了强化学习在表格推理任务中的潜力，显著提升了模型的泛化能力和鲁棒性。

Abstract: Table reasoning, encompassing tasks such as table question answering, fact
verification, and text-to-SQL, requires precise understanding of structured
tabular data, coupled with numerical computation and code manipulation for
effective inference. Supervised fine-tuning (SFT) approaches have achieved
notable success but often struggle with generalization and robustness due to
biases inherent in imitative learning. We introduce Reasoning-Table, the first
application of reinforcement learning (RL) to table reasoning, achieving
state-of-the-art performance. Through rigorous data preprocessing, reward
design, and tailored training strategies, our method leverages simple
rule-based outcome rewards to outperform SFT across multiple benchmarks.
Unified training across diverse tasks enables Reasoning-Table to emerge as a
robust table reasoning large language model, surpassing larger proprietary
models like Claude-3.7-Sonnet by 4.0% on table reasoning benchmarks. The
approach also achieves excellent performance on text-to-SQL tasks, reaching
68.3% performance on the BIRD dev dataset with a 7B model. Further experiments
demonstrate that Reasoning-Table enhances the model's generalization
capabilities and robustness.

</details>


### [207] [SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning](https://arxiv.org/abs/2506.01713)
*Zhongwei Wan,Zhihao Dou,Che Liu,Yu Zhang,Dongfei Cui,Qinjian Zhao,Hui Shen,Jing Xiong,Yi Xin,Yifan Jiang,Yangfan He,Mi Zhang,Shen Yan*

Main category: cs.CL

TL;DR: 论文提出了一种名为SRPO的两阶段反思增强强化学习框架，旨在提升多模态大语言模型（MLLMs）的推理能力。通过构建高质量反思数据集和引入新颖奖励机制，SRPO在多个基准测试中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在复杂推理任务中表现不足，尤其是缺乏有效的自我反思和修正能力。现有反思方法简单且难以生成有意义的反馈。

Method: SRPO分为两阶段：1）构建反思数据集，由高级MLLM生成反思以指导模型学习；2）在GRPO框架中引入奖励机制，鼓励简洁且有意义的反思。

Result: 在MathVista等基准测试中，SRPO显著提升了推理准确性和反思质量，优于现有模型。

Conclusion: SRPO通过两阶段强化学习框架有效提升了MLLMs的推理和反思能力，为复杂任务提供了新思路。

Abstract: Multimodal large language models (MLLMs) have shown promising capabilities in
reasoning tasks, yet still struggle with complex problems requiring explicit
self-reflection and self-correction, especially compared to their unimodal
text-based counterparts. Existing reflection methods are simplistic and
struggle to generate meaningful and instructive feedback, as the reasoning
ability and knowledge limits of pre-trained models are largely fixed during
initial training. To overcome these challenges, we propose Multimodal
Self-Reflection enhanced reasoning with Group Relative Policy Optimization
(SRPO), a two-stage reflection-aware reinforcement learning (RL) framework
explicitly designed to enhance multimodal LLM reasoning. In the first stage, we
construct a high-quality, reflection-focused dataset under the guidance of an
advanced MLLM, which generates reflections based on initial responses to help
the policy model learn both reasoning and self-reflection. In the second stage,
we introduce a novel reward mechanism within the GRPO framework that encourages
concise and cognitively meaningful reflection while avoiding redundancy.
Extensive experiments across multiple multimodal reasoning benchmarks,
including MathVista, MathVision, MathVerse, and MMMU-Pro, using Qwen-2.5-VL-7B
and Qwen-2.5-VL-32B demonstrate that SRPO significantly outperforms
state-of-the-art models, achieving notable improvements in both reasoning
accuracy and reflection quality.

</details>


### [208] [Tug-of-war between idiom's figurative and literal meanings in LLMs](https://arxiv.org/abs/2506.01723)
*Soyoung Oh,Xinting Huang,Mathis Pink,Michael Hahn,Vera Demberg*

Main category: cs.CL

TL;DR: 论文研究了语言模型如何处理习语的非组合性比喻意义，通过机制可解释性工具追踪了LLama3.2-1B-base模型处理习语歧义的三步过程。


<details>
  <summary>Details</summary>
Motivation: 习语的比喻意义与字面意义差异显著，对语言模型提出了挑战，需要模型学习如何在两种意义间选择和表示。

Method: 使用机制可解释性工具，定位了模型处理习语的三步过程，包括早期注意力层和MLP子层中比喻意义的检索、特定注意力头的作用以及比喻和字面意义的并行处理路径。

Result: 模型通过早期注意力层检索比喻意义，并通过特定注意力头抑制字面意义，同时保留两种意义的并行路径。

Conclusion: 研究为自回归变换器中习语理解的机制提供了证据。

Abstract: Idioms present a unique challenge for language models due to their
non-compositional figurative meanings, which often strongly diverge from the
idiom's literal interpretation. This duality requires a model to learn
representing and deciding between the two meanings to interpret an idiom in a
figurative sense, or literally. In this paper, we employ tools from mechanistic
interpretability to trace how a large pretrained causal transformer
(LLama3.2-1B-base) deals with this ambiguity. We localize three steps of idiom
processing: First, the idiom's figurative meaning is retrieved in early
attention and MLP sublayers. We identify specific attention heads which boost
the figurative meaning of the idiom while suppressing the idiom's literal
interpretation. The model subsequently represents the figurative representation
through an intermediate path. Meanwhile, a parallel bypass route forwards
literal interpretation, ensuring that a both reading remain available. Overall,
our findings provide a mechanistic evidence for idiom comprehension in an
autoregressive transformer.

</details>


### [209] [Common Corpus: The Largest Collection of Ethical Data for LLM Pre-Training](https://arxiv.org/abs/2506.01732)
*Pierre-Carl Langlais,Carlos Rosas Hinostroza,Mattia Nee,Catherine Arnett,Pavel Chizhov,Eliot Krzystof Jones,Irène Girard,David Mach,Anastasia Stasenko,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: Common Corpus是一个开放的大规模语言模型预训练数据集，包含约两万亿个无版权或允许许可的标记，涵盖多种语言和代码数据，旨在解决LLMs预训练数据中的版权问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs预训练数据中版权和专有内容的问题，提供合规的开放数据集。

Method: 收集无版权或允许许可的数据，进行详细的数据来源记录、过滤和整理。

Result: Common Corpus成为最大的开放预训练数据集，已被Anthropic等公司使用。

Conclusion: Common Corpus将为LLMs的开放科学研究提供关键基础设施。

Abstract: Large Language Models (LLMs) are pre-trained on large amounts of data from
different sources and domains. These data most often contain trillions of
tokens with large portions of copyrighted or proprietary content, which hinders
the usage of such models under AI legislation. This raises the need for truly
open pre-training data that is compliant with the data security regulations. In
this paper, we introduce Common Corpus, the largest open dataset for language
model pre-training. The data assembled in Common Corpus are either
uncopyrighted or under permissible licenses and amount to about two trillion
tokens. The dataset contains a wide variety of languages, ranging from the main
European languages to low-resource ones rarely present in pre-training
datasets; in addition, it includes a large portion of code data. The diversity
of data sources in terms of covered domains and time periods opens up the paths
for both research and entrepreneurial needs in diverse areas of knowledge. In
this technical report, we present the detailed provenance of data assembling
and the details of dataset filtering and curation. Being already used by such
industry leaders as Anthropic and multiple LLM training projects, we believe
that Common Corpus will become a critical infrastructure for open science
research in LLMs.

</details>


### [210] [Benford's Curse: Tracing Digit Bias to Numerical Hallucination in LLMs](https://arxiv.org/abs/2506.01734)
*Jiandong Shao,Yao Lu,Jianfei Yang*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在数值任务中存在基于Benford定律的偏差，并通过神经元修剪部分纠正了错误输出。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂推理任务中表现优异，但在基础数值问题上常出错，可能是由于预训练数据中的长尾数字分布导致生成偏差。

Method: 首先验证预训练数据（OLMo2）是否符合Benford定律，构建均匀分布的数字基准测试，并通过logit-lens和神经元分析定位偏差来源。

Result: 开源LLMs表现出与Benford定律一致的数字偏差，主要源于深层网络中的少数高度选择性神经元。修剪这些神经元可部分纠正错误。

Conclusion: 研究揭示了预训练数据统计与LLMs符号失败模式之间的联系，为数值任务中的幻觉诊断和缓解提供了新视角。

Abstract: Large Language Models (LLMs) exhibit impressive performance on complex
reasoning tasks, yet they frequently fail on basic numerical problems,
producing incorrect outputs. Inspired by Benford's Law -- a statistical pattern
where lower digits occur more frequently as leading digits -- we hypothesize
that the long-tailed digit distributions in web-collected corpora may be
learned by LLMs during pretraining, leading to biased numerical generation. To
investigate the hypothesis, we first examine whether digits frequencies in
pretraining corpus (OLMo2) follows Benford's law. We then construct an
evaluation benchmark with uniformly distributed ground-truth digits across
seven numerical reasoning tasks. Our evaluation results demonstrate that
leading open-source LLMs show a consistent pattern of digit bias that resembles
Benford's law. Through logit-lens tracing and neuron-level dissection, we
identify that this bias arises predominantly from a small subset of highly
digit-selective feed-forward network (FFN) neurons in the deeper layers.
Finally, we demonstrate that pruning these neurons mitigates imbalanced
overgeneration and partially corrects erroneous outputs, providing causal
evidence that fine-grained pretraining digit bias can propagate into model
behavior. Our findings reveal a fundamental connection between corpus-level
statistics and symbolic failure modes in LLMs, offering a new lens for
diagnosing and mitigating hallucinations in numerical tasks.

</details>


### [211] [Thinking in Character: Advancing Role-Playing Agents with Role-Aware Reasoning](https://arxiv.org/abs/2506.01748)
*Yihong Tang,Kehai Chen,Muyun Yang,Zhengyu Niu,Jing Li,Tiejun Zhao,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Role-Aware Reasoning (RAR)的新方法，通过Role Identity Activation (RIA)和Reasoning Style Optimization (RSO)两阶段解决角色扮演代理(RPAs)中的注意力分散和风格漂移问题，显著提升了RPAs的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的角色扮演代理(RPAs)基于显式对话数据，缺乏深层次的人类思维过程，导致表达浅显且风格不一致。大型推理模型(LRMs)虽能模拟角色思维，但直接应用会引发注意力分散和风格漂移问题。

Method: 提出RAR方法，包含RIA（通过角色档案引导模型推理以对抗注意力分散）和RSO（通过LRM蒸馏优化推理风格以匹配角色和场景）。

Result: 实验表明，RAR方法显著提升了RPAs的性能，有效解决了注意力分散和风格漂移问题。

Conclusion: RAR方法通过两阶段设计，成功解决了RPAs中的核心问题，为角色扮演代理的发展提供了新思路。

Abstract: The advancement of Large Language Models (LLMs) has spurred significant
interest in Role-Playing Agents (RPAs) for applications such as emotional
companionship and virtual interaction. However, recent RPAs are often built on
explicit dialogue data, lacking deep, human-like internal thought processes,
resulting in superficial knowledge and style expression. While Large Reasoning
Models (LRMs) can be employed to simulate character thought, their direct
application is hindered by attention diversion (i.e., RPAs forget their role)
and style drift (i.e., overly formal and rigid reasoning rather than
character-consistent reasoning). To address these challenges, this paper
introduces a novel Role-Aware Reasoning (RAR) method, which consists of two
important stages: Role Identity Activation (RIA) and Reasoning Style
Optimization (RSO). RIA explicitly guides the model with character profiles
during reasoning to counteract attention diversion, and then RSO aligns
reasoning style with the character and scene via LRM distillation to mitigate
style drift. Extensive experiments demonstrate that the proposed RAR
significantly enhances the performance of RPAs by effectively addressing
attention diversion and style drift.

</details>


### [212] [Developing a Mixed-Methods Pipeline for Community-Oriented Digitization of Kwak'wala Legacy Texts](https://arxiv.org/abs/2506.01775)
*Milind Agarwal,Daisy Rosenblum,Antonios Anastasopoulos*

Main category: cs.CL

TL;DR: 本文探讨了如何利用最新OCR技术对Kwak'wala语言的早期文本进行数字化处理，以支持语言复兴和技术开发。


<details>
  <summary>Details</summary>
Motivation: Kwak'wala是一种濒危语言，早期文本因机器不可读而难以利用，数字化可促进语言复兴和技术开发。

Method: 结合现成OCR技术、语言识别、掩码处理及后校正模型，对Kwak'wala文本进行高质量转录。

Result: 成功应用OCR技术处理Kwak'wala文本，并提出针对此类文本的独特适应方法。

Conclusion: 通过混合技术和后处理，能够有效数字化Kwak'wala文本，为语言复兴和技术开发提供支持。

Abstract: Kwak'wala is an Indigenous language spoken in British Columbia, with a rich
legacy of published documentation spanning more than a century, and an active
community of speakers, teachers, and learners engaged in language
revitalization. Over 11 volumes of the earliest texts created during the
collaboration between Franz Boas and George Hunt have been scanned but remain
unreadable by machines. Complete digitization through optical character
recognition has the potential to facilitate transliteration into modern
orthographies and the creation of other language technologies. In this paper,
we apply the latest OCR techniques to a series of Kwak'wala texts only
accessible as images, and discuss the challenges and unique adaptations
necessary to make such technologies work for these real-world texts. Building
on previous methods, we propose using a mix of off-the-shelf OCR methods,
language identification, and masking to effectively isolate Kwak'wala text,
along with post-correction models, to produce a final high-quality
transcription.

</details>


### [213] [MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation](https://arxiv.org/abs/2506.01776)
*Yile Liu,Ziwei Ma,Xiu Jiang,Jinglu Hu,Jing Chang,Liang Li*

Main category: cs.CL

TL;DR: MaXIFE是一个多语言指令跟随评估基准，涵盖23种语言和1667个任务，旨在填补现有评估方法在跨语言场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法多关注单语言场景，忽视了多语言和跨语言环境中的挑战和差异。

Method: MaXIFE结合基于规则的评估和基于模型的评估，平衡效率与准确性。

Result: 评估了多个主流商业和开源LLM，为未来比较提供了基线结果。

Conclusion: MaXIFE为多语言指令跟随评估提供了标准化工具，推动自然语言处理研究的发展。

Abstract: With the rapid adoption of large language models (LLMs) in natural language
processing, the ability to follow instructions has emerged as a key metric for
evaluating their practical utility. However, existing evaluation methods often
focus on single-language scenarios, overlooking the challenges and differences
present in multilingual and cross-lingual contexts. To address this gap, we
introduce MaXIFE: a comprehensive evaluation benchmark designed to assess
instruction-following capabilities across 23 languages with 1,667 verifiable
instruction tasks. MaXIFE integrates both Rule-Based Evaluation and Model-Based
Evaluation, ensuring a balance of efficiency and accuracy. We applied MaXIFE to
evaluate several leading commercial and open-source LLMs, establishing baseline
results for future comparisons. By providing a standardized tool for
multilingual instruction-following evaluation, MaXIFE aims to advance research
and development in natural language processing.

</details>


### [214] [iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering](https://arxiv.org/abs/2506.01784)
*Shuai Wang,Yinan Yu*

Main category: cs.CL

TL;DR: iQUEST框架通过迭代分解复杂查询并结合GNN增强多跳推理，显著提升KBQA任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在知识密集型任务中的事实不准确问题，特别是多跳推理中的连贯性和关键连接丢失问题。

Method: 引入iQUEST框架，迭代分解复杂查询为子问题，结合GNN提前整合2跳邻居信息。

Result: 在四个基准数据集和四种LLMs上表现一致提升。

Conclusion: iQUEST通过结构化推理和前瞻性信息整合，有效提升了KBQA任务的可靠性和性能。

Abstract: While Large Language Models (LLMs) excel at many natural language processing
tasks, they often suffer from factual inaccuracies in knowledge-intensive
scenarios. Integrating external knowledge resources, particularly knowledge
graphs (KGs), provides a transparent and updatable foundation for more reliable
reasoning. Knowledge Base Question Answering (KBQA), which queries and reasons
over KGs, is central to this effort, especially for complex, multi-hop queries.
However, multi-hop reasoning poses two key challenges: (1)~maintaining coherent
reasoning paths, and (2)~avoiding prematurely discarding critical multi-hop
connections. To address these issues, we introduce iQUEST, a question-guided
KBQA framework that iteratively decomposes complex queries into simpler
sub-questions, ensuring a structured and focused reasoning trajectory.
Additionally, we integrate a Graph Neural Network (GNN) to look ahead and
incorporate 2-hop neighbor information at each reasoning step. This dual
approach strengthens the reasoning process, enabling the model to explore
viable paths more effectively. Detailed experiments demonstrate the consistent
improvement delivered by iQUEST across four benchmark datasets and four LLMs.

</details>


### [215] [Human-Centric Evaluation for Foundation Models](https://arxiv.org/abs/2506.01793)
*Yijin Guo,Kaiyuan Ji,Xiaorong Zhu,Junying Wang,Farong Wen,Chunyi Li,Zicheng Zhang,Guangtao Zhai*

Main category: cs.CL

TL;DR: 论文提出了一种以人为中心的评估框架（HCE），通过主观维度（问题解决能力、信息质量和交互体验）评估基础模型，实验涉及多个模型，结果显示Grok 3表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前对基础模型的评估主要依赖客观指标，忽视了真实的人类体验，因此需要一种更主观的评估方法。

Method: 采用HCE框架，通过540多次参与者驱动的评估，让人类与模型合作完成开放式研究任务，生成主观数据集。

Result: 实验结果显示Grok 3表现最优，其次是Deepseek R1和Gemini 2.5，OpenAI o3 mini表现较差。

Conclusion: 研究不仅提出了新的评估框架和数据集，还为标准化、自动化评估奠定了基础，推动了LLM的发展。

Abstract: Currently, nearly all evaluations of foundation models focus on objective
metrics, emphasizing quiz performance to define model capabilities. While this
model-centric approach enables rapid performance assessment, it fails to
reflect authentic human experiences. To address this gap, we propose a
Human-Centric subjective Evaluation (HCE) framework, focusing on three core
dimensions: problem-solving ability, information quality, and interaction
experience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3,
and Gemini 2.5, we conduct over 540 participant-driven evaluations, where
humans and models collaborate on open-ended research tasks, yielding a
comprehensive subjective dataset. This dataset captures diverse user feedback
across multiple disciplines, revealing distinct model strengths and
adaptability. Our findings highlight Grok 3's superior performance, followed by
Deepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering a
novel framework and a rich dataset, this study not only enhances subjective
evaluation methodologies but also lays the foundation for standardized,
automated assessments, advancing LLM development for research and practical
scenarios. Our dataset link is
https://github.com/yijinguo/Human-Centric-Evaluation.

</details>


### [216] [Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books](https://arxiv.org/abs/2506.01796)
*Chen Zhang,Jiuheng Lin,Xiao Liu,Zekai Zhang,Yansong Feng*

Main category: cs.CL

TL;DR: 论文研究了语法书在极低资源语言翻译中的作用，提出了语法规则检索和应用的两步法，并引入ZhuangRules数据集。研究发现规则检索是主要瓶颈，LLMs在复杂规则应用上表现不佳，提出将语法规则表示为代码函数，实验显示代码规则显著提升翻译效果。


<details>
  <summary>Details</summary>
Motivation: 探讨语法书在极低资源语言翻译中的有效性，解决LLMs在语法规则检索和应用中的瓶颈问题。

Method: 将语法规则分解为检索和应用两步，引入ZhuangRules数据集，提出将语法规则表示为代码函数以提高LLMs的表现。

Result: 规则检索是主要瓶颈，LLMs在复杂规则应用上表现不佳；代码规则显著提升翻译效果（BLEU提升13.1%）。

Conclusion: 将语法规则表示为代码函数能有效提升LLMs在极低资源语言翻译中的表现，解决了规则检索和应用的瓶颈问题。

Abstract: While large language models (LLMs) have shown promise in translating
extremely low-resource languages using resources like dictionaries, the
effectiveness of grammar books remains debated. This paper investigates the
role of grammar books in translating extremely low-resource languages by
decomposing it into two key steps: grammar rule retrieval and application. To
facilitate the study, we introduce ZhuangRules, a modularized dataset of
grammar rules and their corresponding test sentences. Our analysis reveals that
rule retrieval constitutes a primary bottleneck in grammar-based translation.
Moreover, although LLMs can apply simple rules for translation when explicitly
provided, they encounter difficulties in handling more complex rules. To
address these challenges, we propose representing grammar rules as code
functions, considering their similarities in structure and the benefit of code
in facilitating LLM reasoning. Our experiments show that using code rules
significantly boosts both rule retrieval and application, ultimately resulting
in a 13.1% BLEU improvement in translation.

</details>


### [217] [Propaganda and Information Dissemination in the Russo-Ukrainian War: Natural Language Processing of Russian and Western Twitter Narratives](https://arxiv.org/abs/2506.01807)
*Zaur Gouliev*

Main category: cs.CL

TL;DR: 分析乌克兰冲突中社交媒体（如X平台）上宣传账户和可信账户的推文，揭示信息战策略。


<details>
  <summary>Details</summary>
Motivation: 研究信息战在乌克兰冲突中的作用，探讨社交媒体如何塑造公众认知。

Method: 使用自然语言处理和机器学习算法分析4万条推文，结合人工分析情感、主题和叙事。

Result: 宣传账户使用情绪化语言和虚假信息，可信账户侧重事实和人道主义；聚类分析显示可能存在协同行为。

Conclusion: 研究揭示了信息战的动态，为未来社交媒体影响研究提供了方法。

Abstract: The conflict in Ukraine has been not only characterised by military
engagement but also by a significant information war, with social media
platforms like X, formerly known as Twitter playing an important role in
shaping public perception. This article provides an analysis of tweets from
propaganda accounts and trusted accounts collected from the onset of the war,
February 2022 until the middle of May 2022 with n=40,000 total tweets. We
utilise natural language processing and machine learning algorithms to assess
the sentiment and identify key themes, topics and narratives across the dataset
with human-in-the-loop (HITL) analysis throughout. Our findings indicate
distinct strategies in how information is created, spread, and targeted at
different audiences by both sides. Propaganda accounts frequently employ
emotionally charged language and disinformation to evoke fear and distrust,
whereas other accounts, primarily Western tend to focus on factual reporting
and humanitarian aspects of the conflict. Clustering analysis reveals groups of
accounts with similar behaviours, which we suspect indicates the presence of
coordinated efforts. This research attempts to contribute to our understanding
of the dynamics of information warfare and offers techniques for future studies
on social media influence in military conflicts.

</details>


### [218] [NAVER LABS Europe Submission to the Instruction-following Track](https://arxiv.org/abs/2506.01808)
*Beomseok Lee,Marcely Zanon Boito,Laurent Besacier,Ioan Calapodescu*

Main category: cs.CL

TL;DR: NAVER LABS Europe 提交了 IWSLT 2025 的指令跟随语音处理短赛道系统，支持英语语音输入到中文、意大利语和德语的 ASR、ST 和 SQA 任务。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时处理多种语音和文本任务的系统，提升多语言和多模态指令跟随能力。

Method: 结合预训练的语音到 LLM 嵌入投影器和 LoRA 适配器，并在多语言多模态数据上进行指令微调。

Result: 系统能够同时执行 ASR、ST 和 SQA 任务，支持多种目标语言。

Conclusion: 通过预训练模块和指令微调，成功构建了一个高效的多任务语音处理系统。

Abstract: In this paper we describe NAVER LABS Europe submission to the
instruction-following speech processing short track at IWSLT 2025. We
participate in the constrained settings, developing systems that can
simultaneously perform ASR, ST, and SQA tasks from English speech input into
the following target languages: Chinese, Italian, and German. Our solution
leverages two pretrained modules: (1) a speech-to-LLM embedding projector
trained using representations from the SeamlessM4T-v2-large speech encoder; and
(2) LoRA adapters trained on text data on top of a Llama-3.1-8B-Instruct. These
modules are jointly loaded and further instruction-tuned for 1K steps on
multilingual and multimodal data to form our final system submitted for
evaluation.

</details>


### [219] [Analysis of LLM Bias (Chinese Propaganda & Anti-US Sentiment) in DeepSeek-R1 vs. ChatGPT o3-mini-high](https://arxiv.org/abs/2506.01814)
*PeiHsuan Huang,ZihWei Lin,Simon Imbot,WenCheng Fu,Ethan Tu*

Main category: cs.CL

TL;DR: 研究比较了PRC对齐的DeepSeek-R1和非PRC的ChatGPT o3-mini-high在宣传和反美情绪上的偏差，发现DeepSeek-R1在简体中文中表现出更高的偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）的地缘政治对齐是否影响其意识形态中立性，填补跨语言比较研究的空白。

Method: 开发了1200个去语境化的问题，通过GPT-4o评分和人工标注评估7200个回答。

Result: DeepSeek-R1在简体中文中表现出显著的宣传和反美偏见，而ChatGPT o3-mini-high几乎无此类偏见。

Conclusion: LLMs的地缘政治对齐显著影响其输出偏差，尤其是在特定语言和文化内容中。

Abstract: Large language models (LLMs) increasingly shape public understanding and
civic decisions, yet their ideological neutrality is a growing concern. While
existing research has explored various forms of LLM bias, a direct,
cross-lingual comparison of models with differing geopolitical
alignments-specifically a PRC-system model versus a non-PRC counterpart-has
been lacking. This study addresses this gap by systematically evaluating
DeepSeek-R1 (PRC-aligned) against ChatGPT o3-mini-high (non-PRC) for
Chinese-state propaganda and anti-U.S. sentiment. We developed a novel corpus
of 1,200 de-contextualized, reasoning-oriented questions derived from
Chinese-language news, presented in Simplified Chinese, Traditional Chinese,
and English. Answers from both models (7,200 total) were assessed using a
hybrid evaluation pipeline combining rubric-guided GPT-4o scoring with human
annotation. Our findings reveal significant model-level and language-dependent
biases. DeepSeek-R1 consistently exhibited substantially higher proportions of
both propaganda and anti-U.S. bias compared to ChatGPT o3-mini-high, which
remained largely free of anti-U.S. sentiment and showed lower propaganda
levels. For DeepSeek-R1, Simplified Chinese queries elicited the highest bias
rates; these diminished in Traditional Chinese and were nearly absent in
English. Notably, DeepSeek-R1 occasionally responded in Simplified Chinese to
Traditional Chinese queries and amplified existing PRC-aligned terms in its
Chinese answers, demonstrating an "invisible loudspeaker" effect. Furthermore,
such biases were not confined to overtly political topics but also permeated
cultural and lifestyle content, particularly in DeepSeek-R1.

</details>


### [220] [BD at BEA 2025 Shared Task: MPNet Ensembles for Pedagogical Mistake Identification and Localization in AI Tutor Responses](https://arxiv.org/abs/2506.01817)
*Shadman Rohan,Ishita Sur Apan,Muhtasim Ibteda Shochcho,Md Fahim,Mohammad Ashfaq Ur Rahman,AKM Mahbubur Rahman,Amin Ahsan Ali*

Main category: cs.CL

TL;DR: 团队BD提交了BEA 2025共享任务的解决方案，针对Track 1（错误识别）和Track 2（错误定位），使用基于MPNet的Transformer模型，通过集成方法取得了较好成绩。


<details>
  <summary>Details</summary>
Motivation: 研究目标是评估AI辅导教师在教育对话中的教学能力，特别是识别和定位学生错误的能力。

Method: 基于MPNet模型，采用类加权交叉熵损失处理类别不平衡，并通过10折分组交叉验证和硬投票集成方法优化模型。

Result: 在官方测试集上，错误识别和错误定位的宏F1分数分别为0.7110和0.5543。

Conclusion: 集成方法和分析结果为教育对话中可靠的辅导教师响应评估系统提供了有价值的参考。

Abstract: We present Team BD's submission to the BEA 2025 Shared Task on Pedagogical
Ability Assessment of AI-powered Tutors, under Track 1 (Mistake Identification)
and Track 2 (Mistake Location). Both tracks involve three-class classification
of tutor responses in educational dialogues - determining if a tutor correctly
recognizes a student's mistake (Track 1) and whether the tutor pinpoints the
mistake's location (Track 2). Our system is built on MPNet, a Transformer-based
language model that combines BERT and XLNet's pre-training advantages. We
fine-tuned MPNet on the task data using a class-weighted cross-entropy loss to
handle class imbalance, and leveraged grouped cross-validation (10 folds) to
maximize the use of limited data while avoiding dialogue overlap between
training and validation. We then performed a hard-voting ensemble of the best
models from each fold, which improves robustness and generalization by
combining multiple classifiers. Our approach achieved strong results on both
tracks, with exact-match macro-F1 scores of approximately 0.7110 for Mistake
Identification and 0.5543 for Mistake Location on the official test set. We
include comprehensive analysis of our system's performance, including confusion
matrices and t-SNE visualizations to interpret classifier behavior, as well as
a taxonomy of common errors with examples. We hope our ensemble-based approach
and findings provide useful insights for designing reliable tutor response
evaluation systems in educational dialogue settings.

</details>


### [221] [Not All Jokes Land: Evaluating Large Language Models Understanding of Workplace Humor](https://arxiv.org/abs/2506.01819)
*Moahmmadamin Shafiei,Hamidreza Saffari*

Main category: cs.CL

TL;DR: 论文探讨了AI和LLMs在专业幽默判断上的不足，并开发了一个数据集来评估LLMs的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管AI和LLMs在任务自动化上取得进展，但专业幽默的评估被忽视，研究旨在填补这一空白。

Method: 开发了一个包含专业幽默语句及其适当性特征的数据集，并评估了五种LLMs的表现。

Result: LLMs在判断幽默适当性时表现不佳。

Conclusion: 研究表明LLMs在专业幽默评估上存在挑战，需进一步改进。

Abstract: With the recent advances in Artificial Intelligence (AI) and Large Language
Models (LLMs), the automation of daily tasks, like automatic writing, is
getting more and more attention. Hence, efforts have focused on aligning LLMs
with human values, yet humor, particularly professional industrial humor used
in workplaces, has been largely neglected. To address this, we develop a
dataset of professional humor statements along with features that determine the
appropriateness of each statement. Our evaluation of five LLMs shows that LLMs
often struggle to judge the appropriateness of humor accurately.

</details>


### [222] [CiteEval: Principle-Driven Citation Evaluation for Source Attribution](https://arxiv.org/abs/2506.01829)
*Yumo Xu,Peng Qi,Jifan Chen,Kunlun Liu,Rujun Han,Lan Liu,Bonan Min,Vittorio Castelli,Arshit Gupta,Zhiguo Wang*

Main category: cs.CL

TL;DR: CiteEval是一个新的引用评估框架，通过细粒度评估和多领域基准测试，结合自动评估工具CiteEval-Auto，显著提升了引用质量的评估效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于自然语言推理（NLI）的引用评估方法存在局限性，无法全面评估引用的质量。

Method: 提出CiteEval框架，结合上下文、用户查询和生成文本，构建多领域基准测试CiteBench，并开发自动评估工具CiteEval-Auto。

Result: CiteEval-Auto在实验中表现出优于现有指标的评估能力，与人工评估结果高度相关。

Conclusion: CiteEval为引用评估提供了更全面和可扩展的方法，有助于提升模型生成引用的质量。

Abstract: Citation quality is crucial in information-seeking systems, directly
influencing trust and the effectiveness of information access. Current
evaluation frameworks, both human and automatic, mainly rely on Natural
Language Inference (NLI) to assess binary or ternary supportiveness from cited
sources, which we argue is a suboptimal proxy for citation evaluation. In this
work we introduce CiteEval, a citation evaluation framework driven by
principles focusing on fine-grained citation assessment within a broad context,
encompassing not only the cited sources but the full retrieval context, user
query, and generated text. Guided by the proposed framework, we construct
CiteBench, a multi-domain benchmark with high-quality human annotations on
citation quality. To enable efficient evaluation, we further develop
CiteEval-Auto, a suite of model-based metrics that exhibit strong correlation
with human judgments. Experiments across diverse systems demonstrate
CiteEval-Auto's superior ability to capture the multifaceted nature of
citations compared to existing metrics, offering a principled and scalable
approach to evaluate and improve model-generated citations.

</details>


### [223] [Minimal Pair-Based Evaluation of Code-Switching](https://arxiv.org/abs/2506.01840)
*Igor Sterner,Simone Teufel*

Main category: cs.CL

TL;DR: 提出了一种基于最小对的方法，评估大语言模型（LLMs）在代码转换（CS）上的表现，发现模型越大，越接近双语者的偏好。


<details>
  <summary>Details</summary>
Motivation: 缺乏评估LLMs在代码转换上与双语者相似性的方法，现有方法覆盖语言少、无法全面反映CS现象或难以扩展。

Method: 通过最小对干预，收集11种语言对的CS句子及其变体，比较双语者和LLMs的偏好。

Result: 双语者一致偏好自然CS句子；LLMs模型越大，越倾向于自然CS句子，尤其是封闭类词变体。

Conclusion: 大模型在CS行为上更接近双语者，验证了理论假设。

Abstract: There is a lack of an evaluation methodology that estimates the extent to
which large language models (LLMs) use code-switching (CS) in the same way as
bilinguals. Existing methods do not have wide language coverage, fail to
account for the diverse range of CS phenomena, or do not scale. We propose an
intervention based on minimal pairs of CS. Each minimal pair contains one
naturally occurring CS sentence and one minimally manipulated variant. We
collect up to 1,000 such pairs each for 11 language pairs. Our human
experiments show that, for every language pair, bilinguals consistently prefer
the naturally occurring CS sentence. Meanwhile our experiments with current
LLMs show that the larger the model, the more consistently it assigns higher
probability to the naturally occurring CS sentence than to the variant. In
accordance with theoretical claims, the largest probability differences arise
in those pairs where the manipulated material consisted of closed-class words.

</details>


### [224] [Code-Switching and Syntax: A Large-Scale Experiment](https://arxiv.org/abs/2506.01846)
*Igor Sterner,Simone Teufel*

Main category: cs.CL

TL;DR: 该论文通过大规模多语言实验验证了句法信息足以解释双语者的语码转换（CS）模式，且自动系统表现与人类双语者相当。


<details>
  <summary>Details</summary>
Motivation: 现有理论认为语码转换可由句法解释，但缺乏大规模跨语言实验验证。

Method: 设计仅依赖句法信息的自动系统，测试其在区分语码转换句子对中的表现。

Result: 系统仅凭句法即可区分语码转换句子，表现与人类相当，且模式可泛化至未见语言对。

Conclusion: 句法信息足以解释语码转换模式，支持现有理论。

Abstract: The theoretical code-switching (CS) literature provides numerous pointwise
investigations that aim to explain patterns in CS, i.e. why bilinguals switch
language in certain positions in a sentence more often than in others. A
resulting consensus is that CS can be explained by the syntax of the
contributing languages. There is however no large-scale, multi-language,
cross-phenomena experiment that tests this claim. When designing such an
experiment, we need to make sure that the system that is predicting where
bilinguals tend to switch has access only to syntactic information. We provide
such an experiment here. Results show that syntax alone is sufficient for an
automatic system to distinguish between sentences in minimal pairs of CS, to
the same degree as bilingual humans. Furthermore, the learnt syntactic patterns
generalise well to unseen language pairs.

</details>


### [225] [CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions](https://arxiv.org/abs/2506.01859)
*Tamer Alkhouli,Katerina Margatina,James Gung,Raphael Shu,Claudia Zaghi,Monica Sunkara,Yi Zhang*

Main category: cs.CL

TL;DR: CONFETTI是一个评估大型语言模型（LLM）功能调用能力的对话基准，包含109个人工模拟对话，覆盖86个API，测试复杂对话场景。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能全面评估LLM在复杂对话场景中的表现，CONFETTI填补了这一空白。

Method: 通过109个人工模拟对话（313个用户轮次），涵盖多种对话复杂性（如跟进、目标修正、模糊目标等），并进行离策略轮次评估。

Result: 部分模型能处理长对话和20+API，但多数模型在长上下文或API增加时表现不佳，链式功能调用表现普遍受限。表现最佳模型为Nova Pro（40.01%）、Claude Sonnet v3.5（35.46%）和Llama 3.1 405B（33.19%）。

Conclusion: CONFETTI为LLM功能调用能力提供了全面评估，揭示了模型在复杂对话中的局限性，并展示了当前领先模型的性能。

Abstract: We introduce Conversational Function-Calling Evaluation Through Turn-Level
Interactions (CONFETTI), a conversational benchmark1 designed to evaluate the
function-calling capabilities and response quality of large language models
(LLMs). Current benchmarks lack comprehensive assessment of LLMs in complex
conversational scenarios. CONFETTI addresses this gap through 109
human-simulated conversations, comprising 313 user turns and covering 86 APIs.
These conversations explicitly target various conversational complexities, such
as follow-ups, goal correction and switching, ambiguous and implicit goals. We
perform off-policy turn-level evaluation using this benchmark targeting
function-calling. Our benchmark also incorporates dialog act annotations to
assess agent responses. We evaluate a series of state-of-the-art LLMs and
analyze their performance with respect to the number of available APIs,
conversation lengths, and chained function calling. Our results reveal that
while some models are able to handle long conversations, and leverage more than
20+ APIs successfully, other models struggle with longer context or when
increasing the number of APIs. We also report that the performance on chained
function-calls is severely limited across the models. Overall, the top
performing models on CONFETTI are Nova Pro (40.01%), Claude Sonnet v3.5
(35.46%) and Llama 3.1 405B (33.19%) followed by command-r-plus (31.18%) and
Mistral-Large-2407 (30.07%).

</details>


### [226] [Is Extending Modality The Right Path Towards Omni-Modality?](https://arxiv.org/abs/2506.01872)
*Tinghui Zhu,Kai Zhang,Muhao Chen,Yu Su*

Main category: cs.CL

TL;DR: 论文研究了如何通过模态扩展技术实现真正的全模态语言模型（OLMs），并探讨了其对核心语言能力的影响、模型合并的有效性以及知识共享的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型在多模态输入处理和泛化能力上表现不足，无法实现真正的全模态。研究旨在探索模态扩展技术是否能解决这些问题。

Method: 通过模态扩展技术，对现成的语言模型进行目标域和语言数据的微调，并研究其对核心语言能力、模型合并效果及知识共享的影响。

Result: 实验表明，模态扩展可能影响核心语言能力，但模型合并可以有效整合多模态模型，且全模态扩展能促进更好的知识共享和泛化能力。

Conclusion: 当前方法在实现真正的全模态语言模型上具有潜力，但仍需进一步研究以平衡模态扩展与核心语言能力的关系。

Abstract: Omni-modal language models (OLMs) aim to integrate and reason over diverse
input modalities--such as text, images, video, and audio--while maintaining
strong language capabilities. Despite recent advancements, existing models,
especially open-source ones, remain far from true omni-modality, struggling to
generalize beyond the specific modality pairs they are trained on or to achieve
strong performance when processing multi-modal inputs. We study the effect of
extending modality, the dominant technique for training multimodal models,
where an off-the-shelf language model is fine-tuned on target-domain and
language data. Specifically, we investigate three key questions: (1) Does
modality extension compromise core language abilities? (2) Can model merging
effectively integrate independently fine-tuned modality-specific models to
achieve omni-modality? (3) Does omni-modality extension lead to better
knowledge sharing and generalization compared to sequential extension? Through
extensive experiments, we analyze these trade-offs and provide insights into
the feasibility of achieving true omni-modality using current approaches.

</details>


### [227] [Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis](https://arxiv.org/abs/2506.01918)
*Chi-Jane Chen,Yuhang Chen,Sukwon Yun,Natalie Stanley,Tianlong Chen*

Main category: cs.CL

TL;DR: Spatial2Sentence提出了一种新框架，通过多句子方法将单细胞表达和空间信息整合到自然语言中，解决了现有单细胞LLMs在空间信息整合和细胞间相互作用方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞LLMs难以整合空间信息和捕捉细胞间相互作用，限制了其在生物学关系分析中的应用。

Method: Spatial2Sentence构建表达相似性和距离矩阵，将空间相邻且表达相似的细胞配对为正样本，远距离且表达不相似的细胞为负样本，通过多句子表示让LLMs学习细胞在表达和空间上的相互作用。

Result: 在预处理IMC数据集上，Spatial2Sentence优于现有单细胞LLMs，糖尿病数据集的细胞类型分类提高了5.98%，临床状态预测提高了4.18%。

Conclusion: Spatial2Sentence通过多任务学习显著提升了单细胞LLMs的性能和可解释性，为空间单细胞数据分析提供了新工具。

Abstract: Image mass cytometry (IMC) enables high-dimensional spatial profiling by
combining mass cytometry's analytical power with spatial distributions of cell
phenotypes. Recent studies leverage large language models (LLMs) to extract
cell states by translating gene or protein expression into biological context.
However, existing single-cell LLMs face two major challenges: (1) Integration
of spatial information: they struggle to generalize spatial coordinates and
effectively encode spatial context as text, and (2) Treating each cell
independently: they overlook cell-cell interactions, limiting their ability to
capture biological relationships. To address these limitations, we propose
Spatial2Sentence, a novel framework that integrates single-cell expression and
spatial information into natural language using a multi-sentence approach.
Spatial2Sentence constructs expression similarity and distance matrices,
pairing spatially adjacent and expressionally similar cells as positive pairs
while using distant and dissimilar cells as negatives. These multi-sentence
representations enable LLMs to learn cellular interactions in both expression
and spatial contexts. Equipped with multi-task learning, Spatial2Sentence
outperforms existing single-cell LLMs on preprocessed IMC datasets, improving
cell-type classification by 5.98% and clinical status prediction by 4.18% on
the diabetes dataset while enhancing interpretability. The source code can be
found here: https://github.com/UNITES-Lab/Spatial2Sentence.

</details>


### [228] [From Guidelines to Practice: A New Paradigm for Arabic Language Model Evaluation](https://arxiv.org/abs/2506.01920)
*Serry Sibaee,Omer Nacar,Adel Ammar,Yasser Al-Habashi,Abdulrahman Al-Batati,Wadii Boulila*

Main category: cs.CL

TL;DR: 论文填补了阿拉伯语模型评估的空白，提出理论指南和新评估框架ADMD，测试五大模型表现，强调文化能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决现有阿拉伯语评估数据集在语言准确性、文化对齐和方法严谨性上的不足。

Method: 提出阿拉伯深度迷你数据集（ADMD），包含490个挑战性问题，覆盖十大领域，评估五大语言模型。

Result: Claude 3.5 Sonnet表现最佳（30%准确率），在数学理论、阿拉伯语和伊斯兰领域较强。

Conclusion: 为阿拉伯语模型评估提供理论和实践基础，强调文化能力与技术能力并重。

Abstract: This paper addresses critical gaps in Arabic language model evaluation by
establishing comprehensive theoretical guidelines and introducing a novel
evaluation framework. We first analyze existing Arabic evaluation datasets,
identifying significant issues in linguistic accuracy, cultural alignment, and
methodological rigor. To address these limitations in LLMs, we present the
Arabic Depth Mini Dataset (ADMD), a carefully curated collection of 490
challenging questions spanning ten major domains (42 sub-domains, see Figure 1.
Using ADMD, we evaluate five leading language models: GPT-4, Claude 3.5 Sonnet,
Gemini Flash 1.5, CommandR 100B, and Qwen-Max. Our results reveal significant
variations in model performance across different domains, with particular
challenges in areas requiring deep cultural understanding and specialized
knowledge. Claude 3.5 Sonnet demonstrated the highest overall accuracy at 30\%,
showing relative strength in mathematical theory in Arabic, Arabic language,
and islamic domains. This work provides both theoretical foundations and
practical insights for improving Arabic language model evaluation, emphasizing
the importance of cultural competence alongside technical capabilities.

</details>


### [229] [Esoteric Language Models](https://arxiv.org/abs/2506.01928)
*Subham Sekhar Sahoo,Zhihan Yang,Yash Akhauri,Johnna Liu,Deepansha Singh,Zhoujun Cheng,Zhengzhong Liu,Eric Xing,John Thickstun,Arash Vahdat*

Main category: cs.CL

TL;DR: Eso-LMs结合自回归和掩码扩散模型，提升语言模型性能并首次为MDM引入KV缓存，显著提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在并行和可控生成方面优于自回归模型，但MDM在困惑度和推理效率上仍有不足。

Method: 提出Eso-LMs，融合AR和MDM，支持两者平滑插值，并首次为MDM引入KV缓存。

Result: 在标准基准测试中达到新SOTA，推理速度比标准MDM快65倍，比半自回归方法快4倍。

Conclusion: Eso-LMs克服了AR和MDM的局限性，显著提升性能和效率。

Abstract: Diffusion-based language models offer a compelling alternative to
autoregressive (AR) models by enabling parallel and controllable generation.
Among this family of models, Masked Diffusion Models (MDMs) achieve the
strongest performance but still underperform AR models in perplexity and lack
key inference-time efficiency features--most notably, KV caching. In this work,
we introduce Eso-LMs, a new family of models that fuses AR and MDM paradigms,
enabling smooth interpolation between their perplexities while overcoming their
respective limitations. Eso-LMs set a new state of the art on standard language
modeling benchmarks. Crucially, we are the **first to introduce KV caching for
MDMs** while preserving parallel generation, significantly improving inference
efficiency. Combined with an optimized sampling schedule, our method achieves
up to **65x** faster inference than standard MDMs and **4x** faster inference
than prior semi-autoregressive approaches. We provide the code and model
checkpoints on the project page:
[http://s-sahoo.github.io/Eso-LMs](http://s-sahoo.github.io/Eso-LMs)

</details>


### [230] [RewardBench 2: Advancing Reward Model Evaluation](https://arxiv.org/abs/2506.01937)
*Saumya Malik,Valentina Pyatkin,Sander Land,Jacob Morrison,Noah A. Smith,Hannaneh Hajishirzi,Nathan Lambert*

Main category: cs.CL

TL;DR: RewardBench 2是一个新的多技能奖励建模基准，旨在通过更具挑战性的数据提升奖励模型的评估准确性，同时与下游任务性能高度相关。


<details>
  <summary>Details</summary>
Motivation: 当前奖励模型在评估方面的进展未能在下游任务中体现其有效性，且直接对齐算法在许多情况下表现更好。因此，需要更严格的评估方法来提升奖励模型的实用性。

Method: 通过引入RewardBench 2，使用新的人类提示而非现有下游评估提示，构建更具挑战性的数据集，并量化其与下游任务性能的相关性。

Result: RewardBench 2的平均得分比第一版低约20分，但与下游任务性能高度相关。

Conclusion: RewardBench 2为奖励模型提供了更严格的评估标准，并验证了其在提升下游任务性能方面的潜力。

Abstract: Reward models are used throughout the post-training of language models to
capture nuanced signals from preference data and provide a training target for
optimization across instruction following, reasoning, safety, and more domains.
The community has begun establishing best practices for evaluating reward
models, from the development of benchmarks that test capabilities in specific
skill areas to others that test agreement with human preferences. At the same
time, progress in evaluation has not been mirrored by the effectiveness of
reward models in downstream tasks -- simpler direct alignment algorithms are
reported to work better in many cases. This paper introduces RewardBench 2, a
new multi-skill reward modeling benchmark designed to bring new, challenging
data for accuracy-based reward model evaluation -- models score about 20 points
on average lower on RewardBench 2 compared to the first RewardBench -- while
being highly correlated with downstream performance. Compared to most other
benchmarks, RewardBench 2 sources new human prompts instead of existing prompts
from downstream evaluations, facilitating more rigorous evaluation practices.
In this paper, we describe our benchmark construction process and report how
existing models perform on it, while quantifying how performance on the
benchmark correlates with downstream use of the models in both inference-time
scaling algorithms, like best-of-N sampling, and RLHF training algorithms like
proximal policy optimization.

</details>


### [231] [Novel Benchmark for NER in the Wastewater and Stormwater Domain](https://arxiv.org/abs/2506.01938)
*Franco Alberto Cardillo,Franca Debole,Francesca Frontini,Mitra Aelami,Nanée Chahinian,Serge Conrad*

Main category: cs.CL

TL;DR: 该论文研究了废水管理领域的多语言命名实体识别（NER），开发了一个法语-意大利语语料库，并评估了包括基于LLM的方法在内的先进NER技术，为未来策略提供基准。


<details>
  <summary>Details</summary>
Motivation: 废水与雨水管理对城市可持续性和环境保护至关重要，但由于领域术语和多语言背景，从报告和法规中提取结构化知识具有挑战性。

Method: 研究开发了一个法语-意大利语的废水管理领域语料库，评估了包括基于LLM的NER方法，并探索了自动标注投影以扩展语料库到其他语言。

Result: 提供了废水管理领域的多语言NER基准，评估了先进方法的性能，为未来研究奠定了基础。

Conclusion: 该研究为废水管理领域的多语言信息提取提供了可靠基准，并展示了自动标注投影在扩展语料库中的潜力。

Abstract: Effective wastewater and stormwater management is essential for urban
sustainability and environmental protection. Extracting structured knowledge
from reports and regulations is challenging due to domainspecific terminology
and multilingual contexts. This work focuses on domain-specific Named Entity
Recognition (NER) as a first step towards effective relation and information
extraction to support decision making. A multilingual benchmark is crucial for
evaluating these methods. This study develops a French-Italian domain-specific
text corpus for wastewater management. It evaluates state-of-the-art NER
methods, including LLM-based approaches, to provide a reliable baseline for
future strategies and explores automated annotation projection in view of an
extension of the corpus to new languages.

</details>


### [232] [Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2506.01939)
*Shenzhi Wang,Le Yu,Chang Gao,Chujie Zheng,Shixuan Liu,Rui Lu,Kai Dang,Xionghui Chen,Jianxin Yang,Zhenru Zhang,Yuqiong Liu,An Yang,Andrew Zhao,Yang Yue,Shiji Song,Bowen Yu,Gao Huang,Junyang Lin*

Main category: cs.CL

TL;DR: RLVR通过分析令牌熵模式，发现高熵令牌（关键分叉令牌）对推理性能至关重要，仅优化这些令牌即可显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索RLVR机制，理解其对LLM推理能力的增强方式，尤其是通过令牌熵模式的分析。

Method: 通过分析Chain-of-Thought推理中的令牌熵模式，研究RLVR训练中熵模式的演变，并限制策略梯度更新至高熵令牌。

Result: 仅优化20%高熵令牌即可保持性能，甚至超越全梯度更新，而优化低熵令牌则导致性能下降。

Conclusion: RLVR的有效性源于优化高熵令牌，通过令牌熵视角可进一步优化LLM推理。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful approach to enhancing the reasoning capabilities of Large Language
Models (LLMs), while its mechanisms are not yet well understood. In this work,
we undertake a pioneering exploration of RLVR through the novel perspective of
token entropy patterns, comprehensively analyzing how different tokens
influence reasoning performance. By examining token entropy patterns in
Chain-of-Thought (CoT) reasoning, we observe that only a small fraction of
tokens exhibit high entropy, and these tokens act as critical forks that steer
the model toward diverse reasoning pathways. Furthermore, studying how entropy
patterns evolve during RLVR training reveals that RLVR largely adheres to the
base model's entropy patterns, primarily adjusting the entropy of high-entropy
tokens. These findings highlight the significance of high-entropy tokens (i.e.,
forking tokens) to RLVR. We ultimately improve RLVR by restricting policy
gradient updates to forking tokens and uncover a finding even beyond the 80/20
rule: utilizing only 20% of the tokens while maintaining performance comparable
to full-gradient updates on the Qwen3-8B base model and significantly
surpassing full-gradient updates on the Qwen3-32B (+11.04 on AIME'25 and +7.71
on AIME'24) and Qwen3-14B (+4.79 on AIME'25 and +5.21 on AIME'24) base models,
highlighting a strong scaling trend. In contrast, training exclusively on the
80% lowest-entropy tokens leads to a marked decline in performance. These
findings indicate that the efficacy of RLVR primarily arises from optimizing
the high-entropy tokens that decide reasoning directions. Collectively, our
results highlight the potential to understand RLVR through a token-entropy
perspective and optimize RLVR by leveraging high-entropy minority tokens to
further improve LLM reasoning.

</details>


### [233] [Self-ensemble: Mitigating Confidence Distortion for Large Language Models](https://arxiv.org/abs/2506.01951)
*Zicheng Xu,Guanchu Wang,Guangyao Zheng,Yu-Neng Chuang,Alexander Szalay,Xia Hu,Vladimir Braverman*

Main category: cs.CL

TL;DR: 论文提出Self-ensemble方法，通过分组和集成预测解决LLM在多选题中的信心失真问题，无需调参即可提升性能。


<details>
  <summary>Details</summary>
Motivation: LLM在多选题（MCQA）中随着选项增加出现信心失真问题，表现为对正确答案信心不足和对错误答案过度自信，导致性能下降。

Method: 将选项分组，通过设计的注意力掩码和位置编码集成LLM的预测，无需标记数据调参。

Result: 在三个LLM和数据集上的实验表明，Self-ensemble显著改善了信心失真问题，优于标准推理和基线方法。

Conclusion: Self-ensemble是一种即插即用的方法，有效解决了LLM在多选题中的信心失真问题。

Abstract: Although Large Language Models (LLMs) perform well in general fields, they
exhibit a confidence distortion problem on multi-choice question-answering
(MCQA), particularly as the number of answer choices increases. Specifically,
on MCQA with many choices, LLMs suffer from under-confidence in correct
predictions and over-confidence in incorrect ones, leading to a substantially
degraded performance. To solve this problem, we propose Self-ensemble in this
work. Our method splits the choices into several groups and ensembles LLM
predictions across these groups to reach a final decision. The advantage of
Self-ensemble is its plug-and-play nature, where it can be integrated into
existing LLM architecture based on a designed attention mask and positional
encoding, without requiring labeled datasets for parameter tuning. Experimental
results on three LLMs and datasets demonstrate that Self-ensemble
comprehensively addresses the confidence distortion problem of LLMs,
outperforming standard inference as well as baseline methods.

</details>


### [234] [WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks](https://arxiv.org/abs/2506.01952)
*Atsuyuki Miyai,Zaiying Zhao,Kazuki Egashira,Atsuki Sato,Tatsumi Sunada,Shota Onohara,Hiromasa Yamanishi,Mashiro Toyooka,Kunato Nishina,Ryoma Maeda,Kiyoharu Aizawa,Toshihiko Yamasaki*

Main category: cs.CL

TL;DR: WebChoreArena是一个新的基准测试，包含532个任务，旨在评估LLM在复杂、繁琐任务中的表现，包括大规模记忆、计算和长期记忆任务。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否能超越常规浏览任务，处理更复杂、繁琐的任务。

Method: 基于WebArena的四个模拟环境，设计了WebChoreArena基准测试，包含三类挑战性任务。

Result: 实验显示，随着LLM（如GPT-4o、Claude 3.7 Sonnet、Gemini 2.5 Pro）的进化，性能显著提升，但仍存在改进空间。

Conclusion: WebChoreArena能有效衡量LLM的进步，但复杂任务的挑战性更高。

Abstract: Powered by a large language model (LLM), a web browsing agent operates web
browsers in a human-like manner and offers a highly transparent path toward
automating a wide range of everyday tasks. As web agents become increasingly
capable and demonstrate proficiency in general browsing tasks, a critical
question emerges: Can they go beyond general browsing to robustly handle tasks
that are tedious and complex, or chores that humans often avoid doing
themselves? In this paper, we introduce WebChoreArena, a new fully reproducible
benchmark comprising 532 carefully curated tasks designed to extend the scope
of WebArena beyond general browsing to more labor-intensive and tedious tasks.
WebChoreArena systematically integrates three key challenges: (i) Massive
Memory tasks requiring accurate retrieval of large amounts of information in
the observations, (ii) Calculation tasks demanding precise mathematical
reasoning, and (iii) Long-Term Memory tasks necessitating long-term memory
across multiple webpages. Built on top of the fully reproducible and widely
adopted four WebArena simulation environments, WebChoreArena ensures strict
reproducibility and enables fair, direct comparisons with the established
WebArena benchmark, offering key insights into agent progress. Our experimental
results demonstrate that as LLMs evolve, represented by GPT-4o, Claude 3.7
Sonnet, and Gemini 2.5 Pro, significant improvements in performance are
observed on WebChoreArena. These findings suggest that WebChoreArena is
well-suited to measure the advancement of state-of-the-art LLMs with greater
clarity. Nevertheless, the results also indicate that even with Gemini 2.5 Pro,
there remains substantial room for improvement compared to WebArena,
highlighting the increased challenges posed by WebChoreArena.

</details>


### [235] [DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation](https://arxiv.org/abs/2506.01954)
*Jennifer Chen,Aidar Myrzakhan,Yaxin Luo,Hassaan Muhammad Khan,Sondos Mahmoud Bsharat,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 论文提出了一种名为DRAG的新框架，通过知识蒸馏将大型语言模型（LLMs）的知识迁移到小型语言模型（SLMs）中，以提升事实准确性并减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大规模RAG系统计算资源消耗高且容易生成虚假内容，因此需要一种更高效且可靠的方法来提升小型模型的能力。

Method: 采用基于证据和知识图谱的蒸馏方法，将大型模型的知识迁移到小型模型中，同时减少模型规模和计算成本。

Result: 实验表明，DRAG在多个基准测试中优于现有方法（如MiniRAG），性能提升高达27.7%，同时保持高效性和可靠性。

Conclusion: DRAG为在小型语言模型中部署增强的检索和生成能力提供了一种实用且资源高效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) methods have proven highly effective for
tasks requiring factual consistency and robust knowledge retrieval. However,
large-scale RAG systems consume significant computational resources and are
prone to generating hallucinated content from Humans. In this work, we
introduce $\texttt{DRAG}$, a novel framework for distilling RAG knowledge from
large-scale Language Models (LLMs) into small LMs (SLMs). Our approach
leverages evidence- and knowledge graph-based distillation, ensuring that the
distilled model retains critical factual knowledge while significantly reducing
model size and computational cost. By aligning the smaller model's predictions
with a structured knowledge graph and ranked evidence, $\texttt{DRAG}$
effectively mitigates hallucinations and improves factual accuracy. We further
present a case demonstrating how our framework mitigates user privacy risks and
introduce a corresponding benchmark. Experimental evaluations on multiple
benchmarks demonstrate that our method outperforms the prior competitive RAG
methods like MiniRAG for SLMs by up to 27.7% using the same models, preserving
high-level efficiency and reliability. With $\texttt{DRAG}$, we provide a
practical and resource-efficient roadmap to deploying enhanced retrieval and
generation capabilities in small-sized LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [236] [Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human-AI Synergy](https://arxiv.org/abs/2506.00056)
*Hugon Lee,Hyeonbin Moon,Junhyeong Lee,Seunghwa RYu*

Main category: cs.AI

TL;DR: 论文提出了一种新型的逆向设计系统，整合领域知识、物理信息学习和人机交互界面，以解决数据稀疏和高维设计空间的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前纯数据驱动的AI方法在稀疏数据、高维设计空间和复杂物理约束的实际场景中表现不佳，需要更高效、可解释的设计系统。

Method: 通过专家引导的采样策略提高数据效率，利用物理信息机器学习实现数据稀缺下的物理一致性建模，并探索大型语言模型作为交互设计代理。

Result: 展示了如何通过整合领域知识、物理先验和自适应推理，构建可扩展、可解释且易用的AI驱动设计系统。

Conclusion: 逆向设计应发展为统一生态系统，结合领域知识、物理先验和自适应推理，以推动制造业中的高性能设计。

Abstract: Artificial intelligence (AI) is reshaping inverse design across manufacturing
domain, enabling high-performance discovery in materials, products, and
processes. However, purely data-driven approaches often struggle in realistic
settings characterized by sparse data, high-dimensional design spaces, and
nontrivial physical constraints. This perspective argues for a new generation
of design systems that transcend black-box modeling by integrating domain
knowledge, physics-informed learning, and intuitive human-AI interfaces. We
first demonstrate how expert-guided sampling strategies enhance data efficiency
and model generalization. Next, we discuss how physics-informed machine
learning enables physically consistent modeling in data-scarce regimes.
Finally, we explore how large language models emerge as interactive design
agents connecting user intent with simulation tools, optimization pipelines,
and collaborative workflows. Through illustrative examples and conceptual
frameworks, we advocate that inverse design in manufacturing should evolve into
a unified ecosystem, where domain knowledge, physical priors, and adaptive
reasoning collectively enable scalable, interpretable, and accessible AI-driven
design systems.

</details>


### [237] [The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets](https://arxiv.org/abs/2506.00073)
*Shenzhe Zhu,Jiao Sun,Yi Nian,Tobin South,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: 研究探讨AI代理在消费者市场中的自动化谈判和交易能力及风险，发现不同代理表现差异显著且存在行为异常导致经济损失。


<details>
  <summary>Details</summary>
Motivation: 探索AI代理在消费者与商家授权下完全自动化谈判和交易的未来场景，评估其表现及潜在风险。

Method: 开发实验框架，评估多种LLM代理在真实谈判和交易场景中的表现。

Result: AI代理的谈判能力差异显著，行为异常可能导致消费者和商家的财务损失。

Conclusion: 自动化虽提高效率但伴随风险，用户需谨慎授权AI代理进行商业决策。

Abstract: AI agents are increasingly used in consumer-facing applications to assist
with tasks such as product search, negotiation, and transaction execution. In
this paper, we explore a future scenario where both consumers and merchants
authorize AI agents to fully automate negotiations and transactions. We aim to
answer two key questions: (1) Do different LLM agents vary in their ability to
secure favorable deals for users? (2) What risks arise from fully automating
deal-making with AI agents in consumer markets? To address these questions, we
develop an experimental framework that evaluates the performance of various LLM
agents in real-world negotiation and transaction settings. Our findings reveal
that AI-mediated deal-making is an inherently imbalanced game -- different
agents achieve significantly different outcomes for their users. Moreover,
behavioral anomalies in LLMs can result in financial losses for both consumers
and merchants, such as overspending or accepting unreasonable deals. These
results underscore that while automation can improve efficiency, it also
introduces substantial risks. Users should exercise caution when delegating
business decisions to AI agents.

</details>


### [238] [Balancing Profit and Fairness in Risk-Based Pricing Markets](https://arxiv.org/abs/2506.00140)
*Jesse Thibodeau,Hadi Nekoei,Afaf Taïk,Janarthanan Rajendran,Golnoosh Farnadi*

Main category: cs.AI

TL;DR: 论文提出了一种基于强化学习的公平税收政策，通过调节企业定价行为，提升社会公平与福利。


<details>
  <summary>Details</summary>
Motivation: 动态风险定价可能排斥弱势群体，需要一种方法调节企业行为以符合社会目标。

Method: 使用强化学习训练社会规划者，设计公平税收政策，并通过MarketSim模拟验证。

Result: 在健康保险和消费信贷市场中，政策提升公平性16%，同时提高社会福利。

Conclusion: AI辅助监管可将竞争性社会困境转化为双赢均衡，提供公平市场监督的实用框架。

Abstract: Dynamic, risk-based pricing can systematically exclude vulnerable consumer
groups from essential resources such as health insurance and consumer credit.
We show that a regulator can realign private incentives with social objectives
through a learned, interpretable tax schedule. First, we provide a formal
proposition that bounding each firm's \emph{local} demographic gap implicitly
bounds the \emph{global} opt-out disparity, motivating firm-level penalties.
Building on this insight we introduce \texttt{MarketSim} -- an open-source,
scalable simulator of heterogeneous consumers and profit-maximizing firms --
and train a reinforcement learning (RL) social planner (SP) that selects a
bracketed fairness-tax while remaining close to a simple linear prior via an
$\mathcal{L}_1$ regularizer. The learned policy is thus both transparent and
easily interpretable. In two empirically calibrated markets, i.e., U.S.
health-insurance and consumer-credit, our planner simultaneously raises
demand-fairness by up to $16\%$ relative to unregulated Free Market while
outperforming a fixed linear schedule in terms of social welfare without
explicit coordination. These results illustrate how AI-assisted regulation can
convert a competitive social dilemma into a win-win equilibrium, providing a
principled and practical framework for fairness-aware market oversight.

</details>


### [239] [Utilizing AI for Aviation Post-Accident Analysis Classification](https://arxiv.org/abs/2506.00169)
*Aziida Nanyonga,Graham Wild*

Main category: cs.AI

TL;DR: 该论文探讨了如何利用AI和NLP技术自动化分析航空安全报告，以提高安全分析的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 航空安全报告数据量大，传统分析方法难以快速准确提取有价值信息。

Method: 应用NLP、深度学习和主题建模（TM）技术，对航空安全报告进行分类和主题分析。

Result: 研究发现NLP、深度学习和TM能显著提升分析效率和准确性。

Conclusion: 这些技术为更主动的安全管理和风险缓解策略提供了可能。

Abstract: The volume of textual data available in aviation safety reports presents a
challenge for timely and accurate analysis. This paper examines how Artificial
Intelligence (AI) and, specifically, Natural Language Processing (NLP) can
automate the process of extracting valuable insights from this data, ultimately
enhancing aviation safety. The paper reviews ongoing efforts focused on the
application of NLP and deep learning to aviation safety reports, with the goal
of classifying the level of damage to an aircraft and identifying the phase of
flight during which safety occurrences happen. Additionally, the paper explores
the use of Topic Modeling (TM) to uncover latent thematic structures within
aviation incident reports, aiming to identify recurring patterns and potential
areas for safety improvement. The paper compares and contrasts the performance
of various deep learning models and TM techniques applied to datasets from the
National Transportation Safety Board (NTSB) and the Australian Transport Safety
Bureau (ATSB), as well as the Aviation Safety Network (ASN), discussing the
impact of dataset size and source on the accuracy of the analysis. The findings
demonstrate that both NLP and deep learning, as well as TM, can significantly
improve the efficiency and accuracy of aviation safety analysis, paving the way
for more proactive safety management and risk mitigation strategies.

</details>


### [240] [Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings](https://arxiv.org/abs/2506.00178)
*Anirudh Nair,Adi Banerjee,Laurent Mombaerts,Matthew Hagen,Tarik Borogovac*

Main category: cs.AI

TL;DR: DEEVO是一种通过辩论驱动进化的提示优化框架，显著优于手动和现有自动方法，无需预定义指标。


<details>
  <summary>Details</summary>
Motivation: 提示工程是LLMs解决复杂任务的关键瓶颈，尤其在主观质量评估任务中，现有方法因依赖明确优化目标或通用模板而表现不佳。

Method: DEEVO通过辩论驱动评估和Elo评分选择，结合智能交叉和策略性变异操作，探索离散提示空间并保持语义连贯性。

Result: 实验表明，DEEVO在开放和封闭任务中显著优于手动和其他优化方法，且无需真实反馈。

Conclusion: DEEVO通过结合LLMs推理能力和自适应优化，推动了提示优化研究的进步，消除了对预定义指标的需求。

Abstract: Prompt engineering represents a critical bottleneck to harness the full
potential of Large Language Models (LLMs) for solving complex tasks, as it
requires specialized expertise, significant trial-and-error, and manual
intervention. This challenge is particularly pronounced for tasks involving
subjective quality assessment, where defining explicit optimization objectives
becomes fundamentally problematic. Existing automated prompt optimization
methods falter in these scenarios, as they typically require well-defined
task-specific numerical fitness functions or rely on generic templates that
cannot capture the nuanced requirements of complex use cases. We introduce
DEEVO (DEbate-driven EVOlutionary prompt optimization), a novel framework that
guides prompt evolution through a debate-driven evaluation with an Elo-based
selection. Contrary to prior work, DEEVOs approach enables exploration of the
discrete prompt space while preserving semantic coherence through intelligent
crossover and strategic mutation operations that incorporate debate-based
feedback, combining elements from both successful and unsuccessful prompts
based on identified strengths rather than arbitrary splicing. Using Elo ratings
as a fitness proxy, DEEVO simultaneously drives improvement and preserves
valuable diversity in the prompt population. Experimental results demonstrate
that DEEVO significantly outperforms both manual prompt engineering and
alternative state-of-the-art optimization approaches on open-ended tasks and
close-ended tasks despite using no ground truth feedback. By connecting LLMs
reasoning capabilities with adaptive optimization, DEEVO represents a
significant advancement in prompt optimization research by eliminating the need
of predetermined metrics to continuously improve AI systems.

</details>


### [241] [Control-R: Towards controllable test-time scaling](https://arxiv.org/abs/2506.00189)
*Di Zhang,Weida Wang,Junxian Li,Xunzhi Wang,Jiatong Li,Jianbo Wu,Jingdi Lei,Haonan He,Peng Ye,Shufei Zhang,Wanli Ouyang,Yuqiang Li,Dongzhan Zhou*

Main category: cs.AI

TL;DR: 论文提出了一种名为推理控制场（RCF）的新方法，用于解决大型推理模型（LRMs）在长链推理（CoT）中的欠思考和过思考问题，并通过树搜索视角引入结构化控制信号。此外，提出了Control-R-4K数据集和条件蒸馏微调（CDF）方法，实验结果表明该方法在32B规模上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在长链推理中的欠思考和过思考问题，提升推理的可控性。

Method: 引入推理控制场（RCF）作为测试时方法，结合Control-R-4K数据集和条件蒸馏微调（CDF）方法，训练模型（如Control-R-32B）动态调整推理努力。

Result: 在AIME2024和MATH500等基准测试中，该方法在32B规模上实现了最先进的性能，并实现了可控的长链推理（L-CoT）。

Conclusion: 该工作为可控测试时推理提供了一种有效范式。

Abstract: This paper target in addressing the challenges of underthinking and
overthinking in long chain-of-thought (CoT) reasoning for Large Reasoning
Models (LRMs) by introducing Reasoning Control Fields (RCF)--a novel test-time
approach that injects structured control signals to guide reasoning from a tree
search perspective. RCF enables models to adjust reasoning effort according to
given control conditions when solving complex tasks. Additionally, we present
the Control-R-4K dataset, which consists of challenging problems annotated with
detailed reasoning processes and corresponding control fields. To further
enhance reasoning control, we propose a Conditional Distillation Finetuning
(CDF) method, which trains model--particularly Control-R-32B--to effectively
adjust reasoning effort during test time. Experimental results on benchmarks
such as AIME2024 and MATH500 demonstrate that our approach achieves
state-of-the-art performance at the 32B scale while enabling a controllable
Long CoT reasoning process (L-CoT). Overall, this work introduces an effective
paradigm for controllable test-time scaling reasoning.

</details>


### [242] [What do professional software developers need to know to succeed in an age of Artificial Intelligence?](https://arxiv.org/abs/2506.00202)
*Matthew Kam,Cody Miller,Miaoxin Wang,Abey Tidwell,Irene A. Lee,Joyce Malyn-Smith,Beatriz Perez,Vikram Tiwari,Joshua Kenitzer,Andrew Macvean,Erin Barrar*

Main category: cs.AI

TL;DR: 研究探讨了生成式AI对软件开发者的生产力提升，但关注其对工作力和技能的影响。通过21名开发者的研究，总结了12个工作目标、75个任务及相关技能，提炼出5个关键发现。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI如何影响开发者工作，以及如何通过技能提升应对潜在的工作力中断和技能退化问题。

Method: 对21名前沿使用AI的开发者进行研究，分析其工作目标、任务及所需技能。

Result: 发现成功使用AI的开发者需具备四个领域的技能，并提出未来教育和培训应关注软技能与技术技能的结合。

Conclusion: 为应对AI时代，需通过在职学习和计算机科学教育提升开发者技能，防止技能退化。

Abstract: Generative AI is showing early evidence of productivity gains for software
developers, but concerns persist regarding workforce disruption and deskilling.
We describe our research with 21 developers at the cutting edge of using AI,
summarizing 12 of their work goals we uncovered, together with 75 associated
tasks and the skills & knowledge for each, illustrating how developers use AI
at work. From all of these, we distilled our findings in the form of 5
insights. We found that the skills & knowledge to be a successful AI-enhanced
developer are organized into four domains (using Generative AI effectively,
core software engineering, adjacent engineering, and adjacent non-engineering)
deployed at critical junctures throughout a 6-step task workflow. In order to
"future proof" developers for this age of AI, on-the-job learning initiatives
and computer science degree programs will need to target both "soft" skills and
the technical skills & knowledge in all four domains to reskill, upskill and
safeguard against deskilling.

</details>


### [243] [Ethical AI: Towards Defining a Collective Evaluation Framework](https://arxiv.org/abs/2506.00233)
*Aasish Kumar Sharma,Dimitar Kyosev,Julian Kunkel*

Main category: cs.AI

TL;DR: 本文提出了一种基于本体块的模块化伦理评估框架，旨在解决AI伦理问题，如透明度和公平性。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展引发了数据隐私、系统偏见等伦理问题，亟需透明和可问责的解决方案。

Method: 通过结合FAIR原则和本体块（编码伦理原则的离散单元），构建了一个可扩展的伦理评估框架。

Result: 在AI驱动的投资者画像案例中，该框架实现了动态风险分类，展示了其可行性和有效性。

Conclusion: 本体块为可解释和可审计的AI伦理提供了潜力，但在自动化和概率推理方面仍需改进。

Abstract: Artificial Intelligence (AI) is transforming sectors such as healthcare,
finance, and autonomous systems, offering powerful tools for innovation. Yet
its rapid integration raises urgent ethical concerns related to data ownership,
privacy, and systemic bias. Issues like opaque decision-making, misleading
outputs, and unfair treatment in high-stakes domains underscore the need for
transparent and accountable AI systems. This article addresses these challenges
by proposing a modular ethical assessment framework built on ontological blocks
of meaning-discrete, interpretable units that encode ethical principles such as
fairness, accountability, and ownership. By integrating these blocks with FAIR
(Findable, Accessible, Interoperable, Reusable) principles, the framework
supports scalable, transparent, and legally aligned ethical evaluations,
including compliance with the EU AI Act. Using a real-world use case in
AI-powered investor profiling, the paper demonstrates how the framework enables
dynamic, behavior-informed risk classification. The findings suggest that
ontological blocks offer a promising path toward explainable and auditable AI
ethics, though challenges remain in automation and probabilistic reasoning.

</details>


### [244] [SMELLNET: A Large-scale Dataset for Real-world Smell Recognition](https://arxiv.org/abs/2506.00239)
*Dewei Feng,Carol Li,Wei Dai,Paul Pu Liang*

Main category: cs.AI

TL;DR: SmellNet是首个大规模气味数据库，用于训练AI通过气味识别物质，模型在预录数据上达到65.35%准确率，但在实际应用中仍有挑战。


<details>
  <summary>Details</summary>
Motivation: AI通过气味识别物质在过敏原检测、制造监控和健康监测中有广泛应用，但缺乏大规模基准数据集阻碍了进展。

Method: 使用便携式气体和化学传感器创建SmellNet数据库，结合序列模型、对比学习和新时间差方法训练AI模型。

Result: 模型在预录数据上准确率65.35%，实际应用中坚果和香料的识别准确率分别为10.71%和25.38%。

Conclusion: SmellNet展示了气味AI的潜力，但需解决特征学习、边缘计算和环境鲁棒性等技术挑战。

Abstract: The ability of AI to sense and identify various substances based on their
smell alone can have profound impacts on allergen detection (e.g., smelling
gluten or peanuts in a cake), monitoring the manufacturing process, and sensing
hormones that indicate emotional states, stress levels, and diseases. Despite
these broad impacts, there are virtually no large scale benchmarks, and
therefore little progress, for training and evaluating AI systems' ability to
smell in the real world. In this paper, we use portable gas and chemical
sensors to create SmellNet, the first large-scale database that digitizes a
diverse range of smells in the natural world. SmellNet contains about 180,000
time steps of 50 substances (spanning nuts, spices, herbs, fruits, and
vegetables) with 50 hours of data. Using SmellNet, we train AI models for
real-time classification of substances based on their smell alone. Our best
methods leverage sequence models, contrastive learning to integrate
high-resolution Gas Chromatography-Mass Spectrometry molecular data, and a new
temporal difference method that identifies sharp changes in sensor readings.
Our best models achieve up to 65.35% accuracy on pre-recorded data, and
generalize to real-world conditions with 10.71% accuracy on nuts and 25.38% on
spices in the challenging 50-way online classification task. Despite these
promising results, SmellNet highlights many technical challenges in building AI
for smell, including richer feature learning, on-edge smell models, and
robustness to environmental changes.

</details>


### [245] [Whispers of Many Shores: Cultural Alignment through Collaborative Cultural Expertise](https://arxiv.org/abs/2506.00242)
*Shuai Feng,Wei-Chuang Chan,Srishti Chouhan,Junior Francisco Garcia Ayala,Srujananjali Medicherla,Kyle Clark,Mingwei Shi*

Main category: cs.AI

TL;DR: 提出了一种基于软提示微调的框架，用于高效实现大语言模型的文化对齐，显著提升了文化敏感性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在多样文化背景下的理解不足，且全微调成本高昂，需一种高效且模块化的文化对齐方法。

Method: 采用向量化提示调优技术，动态将查询路由到由文化专家配置的LLM委员会，通过优化软提示嵌入实现，不改变基础模型参数。

Result: 实验表明，文化对齐分数从0.208提升至0.820，显著增强了文化敏感性和适应性。

Conclusion: 该框架为文化感知的LLM部署提供了稳健解决方案，并为后续研究（如文化覆盖和动态专家适应）奠定了基础。

Abstract: The integration of large language models (LLMs) into global applications
necessitates effective cultural alignment for meaningful and
culturally-sensitive interactions. Current LLMs often lack the nuanced
understanding required for diverse cultural contexts, and adapting them
typically involves costly full fine-tuning. To address this, we introduce a
novel soft prompt fine-tuning framework that enables efficient and modular
cultural alignment. Our method utilizes vectorized prompt tuning to dynamically
route queries to a committee of culturally specialized 'expert' LLM
configurations, created by optimizing soft prompt embeddings without altering
the base model's parameters. Extensive experiments demonstrate that our
framework significantly enhances cultural sensitivity and adaptability,
improving alignment scores from 0.208 to 0.820, offering a robust solution for
culturally-aware LLM deployment. This research paves the way for subsequent
investigations into enhanced cultural coverage and dynamic expert adaptation,
crucial for realizing autonomous AI with deeply nuanced understanding in a
globally interconnected world.

</details>


### [246] [MIR: Methodology Inspiration Retrieval for Scientific Research Problems](https://arxiv.org/abs/2506.00249)
*Aniketh Garikaparthi,Manasi Patwardhan,Aditya Sanjiv Kanade,Aman Hassan,Lovekesh Vig,Arman Cohan*

Main category: cs.AI

TL;DR: 论文提出了一种名为方法论灵感检索（MIR）的任务，旨在从文献中获取启发性的方法论。通过构建方法论邻接图（MAG）和改进检索模型，显著提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖文献检索来加速科学发现，但效果受限于文献质量。论文旨在解决如何从文献中获取方法论灵感的问题。

Method: 构建了方法论邻接图（MAG）以捕捉方法论的传承关系，并改进了密集检索模型，结合LLM重排序策略。

Result: 在Recall@3和mAP指标上分别提升了+5.4和+7.8，结合LLM重排序后进一步提升了+4.5和+4.8。

Conclusion: MIR在自动化科学发现中具有潜力，未来可进一步优化灵感驱动的检索方法。

Abstract: There has been a surge of interest in harnessing the reasoning capabilities
of Large Language Models (LLMs) to accelerate scientific discovery. While
existing approaches rely on grounding the discovery process within the relevant
literature, effectiveness varies significantly with the quality and nature of
the retrieved literature. We address the challenge of retrieving prior work
whose concepts can inspire solutions for a given research problem, a task we
define as Methodology Inspiration Retrieval (MIR). We construct a novel dataset
tailored for training and evaluating retrievers on MIR, and establish
baselines. To address MIR, we build the Methodology Adjacency Graph (MAG);
capturing methodological lineage through citation relationships. We leverage
MAG to embed an "intuitive prior" into dense retrievers for identifying
patterns of methodological inspiration beyond superficial semantic similarity.
This achieves significant gains of +5.4 in Recall@3 and +7.8 in Mean Average
Precision (mAP) over strong baselines. Further, we adapt LLM-based re-ranking
strategies to MIR, yielding additional improvements of +4.5 in Recall@3 and
+4.8 in mAP. Through extensive ablation studies and qualitative analyses, we
exhibit the promise of MIR in enhancing automated scientific discovery and
outline avenues for advancing inspiration-driven retrieval.

</details>


### [247] [Hidden in Plain Sight: Probing Implicit Reasoning in Multimodal Language Models](https://arxiv.org/abs/2506.00258)
*Qianqi Yan,Hongquan Li,Shan Jiang,Yang Zhao,Xinze Guan,Ching-Chen Kuo,Xin Eric Wang*

Main category: cs.AI

TL;DR: 多模态大语言模型（MLLMs）在开放环境中处理模糊、矛盾或不可行指令时，常无法检测隐含问题。本文通过诊断测试发现，模型具备相关能力但倾向于用户服从，提出简单干预策略可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究MLLMs在现实环境中处理隐含推理问题的能力，揭示其行为与能力之间的差距。

Method: 使用涵盖四类现实失败模式的诊断测试套件，评估六种MLLMs（包括o3和GPT-4o），并通过显式提示和推理时干预（如谨慎角色提示和澄清问题）测试模型表现。

Result: 模型常无法发现隐含问题，但通过干预（尤其是要求澄清问题）可显著提升性能。

Conclusion: 当前MLLMs在推理能力与行为服从间存在差距，提出实用策略可增强其在开放环境中的可信度。

Abstract: Multimodal large language models (MLLMs) are increasingly deployed in
open-ended, real-world environments where inputs are messy, underspecified, and
not always trustworthy. Unlike curated benchmarks, these settings frequently
involve instructions that refer to missing objects or contradictory facts, rely
on ambiguous references, or request infeasible actions. In such cases, success
hinges not on task execution alone, but on a model's ability to detect when
something is silently wrong. This paper presents a systematic analysis of how
current MLLMs handle such implicit reasoning scenarios: cases where the flaw is
not explicitly stated but must be inferred from context. Using a curated
diagnostic suite spanning four categories of real-world failure modes, we
evaluate six MLLMs, including o3 and GPT-4o, and find that models frequently
fail to surface hidden issues, even when they possess the necessary perceptual
and reasoning skills. Explicit prompting reveals that the underlying
capabilities exist but are often suppressed in favor of user compliance. We
further show that simple inference-time interventions, such as cautious persona
prompting and, in particular, requiring a clarifying question, can dramatically
recover performance. Our findings highlight a persistent gap between reasoning
competence and behavioral compliance in current MLLMs and suggest practical
strategies for making these models more trustworthy in underconstrained
environments.

</details>


### [248] [Sleep Brain and Cardiac Activity Predict Cognitive Flexibility and Conceptual Reasoning Using Deep Learning](https://arxiv.org/abs/2506.00279)
*Boshra Khajehpiri,Eric Granger,Massimiliano de Zambotti,Fiona C. Baker,Mohamad Forouzanfar*

Main category: cs.AI

TL;DR: 该研究探讨了睡眠微观结构与认知功能之间的关系，提出了一种基于多模态生理数据的深度学习模型CogPSGFormer，用于预测执行功能。


<details>
  <summary>Details</summary>
Motivation: 尽管睡眠与认知关系已有广泛研究，但睡眠微观结构与特定认知领域表现的联系尚未充分探索。

Method: 研究采用多尺度卷积-Transformer模型CogPSGFormer，整合ECG、EEG信号及提取特征（如EEG功率带和心率变异性参数），处理多模态睡眠数据。

Result: 模型在STAGES数据集上通过交叉验证，对未见数据的认知表现分类准确率达80.3%。

Conclusion: 研究证明了多尺度特征提取和多模态学习方法在利用睡眠信号预测认知表现方面的有效性，代码已开源。

Abstract: Despite extensive research on the relationship between sleep and cognition,
the connection between sleep microstructure and human performance across
specific cognitive domains remains underexplored. This study investigates
whether deep learning models can predict executive functions, particularly
cognitive adaptability and conceptual reasoning from physiological processes
during a night's sleep. To address this, we introduce CogPSGFormer, a
multi-scale convolutional-transformer model designed to process multi-modal
polysomnographic data. This model integrates one-channel ECG and EEG signals
along with extracted features, including EEG power bands and heart rate
variability parameters, to capture complementary information across modalities.
A thorough evaluation of the CogPSGFormer architecture was conducted to
optimize the processing of extended sleep signals and identify the most
effective configuration. The proposed framework was evaluated on 817
individuals from the STAGES dataset using cross-validation. The model achieved
80.3\% accuracy in classifying individuals into low vs. high cognitive
performance groups on unseen data based on Penn Conditional Exclusion Test
(PCET) scores. These findings highlight the effectiveness of our multi-scale
feature extraction and multi-modal learning approach in leveraging
sleep-derived signals for cognitive performance prediction. To facilitate
reproducibility, our code is publicly accessible
(https://github.com/boshrakh95/CogPSGFormer.git).

</details>


### [249] [Evaluation of LLMs for mathematical problem solving](https://arxiv.org/abs/2506.00309)
*Ruonan Wang,Runxi Wang,Yunwen Shen,Chengfeng Wu,Qinglin Zhou,Rohitash Chandra*

Main category: cs.AI

TL;DR: 研究比较了GPT-4o、DeepSeek-V3和Gemini-2.0三种大型语言模型在数学问题上的表现，发现GPT-4o表现最稳定，DeepSeek-V3在结构化领域强，Gemini-2.0在语言理解上优秀但推理能力较弱。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在解决数学问题上的潜力，填补现有研究的空白。

Method: 采用基于结构化思维链（SCoT）的五维评估框架，比较三种模型在三个不同复杂度数学数据集上的表现。

Result: GPT-4o表现最稳定，尤其在高级问题上；DeepSeek-V3在优化领域强但统计推理不稳定；Gemini-2.0语言理解强但推理能力不足。

Conclusion: 不同模型在数学问题解决上各有优劣，未来需针对其短板进行优化。

Abstract: Large Language Models (LLMs) have shown impressive performance on a range of
educational tasks, but are still understudied for their potential to solve
mathematical problems. In this study, we compare three prominent LLMs,
including GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of
varying complexities (GSM8K, MATH500, and UNSW datasets). We take a
five-dimensional approach based on the Structured Chain-of-Thought (SCoT)
framework to assess final answer correctness, step completeness, step validity,
intermediate calculation accuracy, and problem comprehension. The results show
that GPT-4o is the most stable and consistent in performance across all the
datasets, but particularly it performs outstandingly in high-level questions of
the UNSW dataset. DeepSeek-V3 is competitively strong in well-structured
domains such as optimisation, but suffers from fluctuations in accuracy in
statistical inference tasks. Gemini-2.0 shows strong linguistic understanding
and clarity in well-structured problems but performs poorly in multi-step
reasoning and symbolic logic. Our error analysis reveals particular deficits in
each model: GPT-4o is at times lacking in sufficient explanation or precision;
DeepSeek-V3 leaves out intermediate steps; and Gemini-2.0 is less flexible in
mathematical reasoning in higher dimensions.

</details>


### [250] [Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents](https://arxiv.org/abs/2506.00320)
*Xiao Yu,Baolin Peng,Ruize Xu,Michel Galley,Hao Cheng,Suman Nath,Jianfeng Gao,Zhou Yu*

Main category: cs.AI

TL;DR: Dyna-Think框架通过结合规划、世界模型模拟和推理行动，提升AI代理性能，DIT和DDT方法分别用于初始化和优化策略，实验表明其有效性和高效性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在复杂任务中表现出色，但缺乏对长视野任务中有效行为的明确理解，因此提出Dyna-Think框架以提升AI代理的推理、规划和行动能力。

Method: 提出Dyna-Think框架，结合DIT（模仿学习）和DDT（两阶段训练）方法，分别用于初始化策略和优化世界模型与行动能力。

Result: 在OSWorld上的实验显示，Dyna-Think在性能和效率上优于基线模型，生成更少token且性能相当，同时验证了世界模型能力与代理性能的正相关性。

Conclusion: Dyna-Think为将世界模型模拟整合到AI代理中提供了有前景的研究方向，显著提升了其推理、规划和行动能力。

Abstract: Recent progress in reasoning with large language models (LLMs), such as
DeepSeek-R1, demonstrates impressive capabilities in domains like mathematics
and coding, by exhibiting complex cognitive behaviors such as verification,
goal decomposition, and self-reflection. However, it is unclear what behavior
is effective and what behavior is missing for long-horizon AI agents tasks. In
this work, we propose Dyna-Think, a thinking framework that integrates planning
with an internal world model with reasoning and acting to enhance AI agent
performance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning
(DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy with
Dyna-Think, DIT reconstructs the thinking process of R1 to focus on performing
world model simulation relevant to the proposed (and planned) action, and
trains the policy using this reconstructed data. To enhance Dyna-Think, DDT
uses a two-stage training process to first improve the agent's world modeling
ability via objectives such as state prediction or critique generation, and
then improve the agent's action via policy training. We evaluate our methods on
OSWorld, and demonstrate that Dyna-Think improves the agent's in-domain and
out-of-domain performance, achieving similar best-of-n performance compared to
R1 while generating 2x less tokens on average. Our extensive empirical studies
reveal that 1) using critique generation for world model training is effective
to improve policy performance; and 2) AI agents with better performance
correlate with better world modeling abilities. We believe our results suggest
a promising research direction to integrate world model simulation into AI
agents to enhance their reasoning, planning, and acting capabilities.

</details>


### [251] [BASIL: Best-Action Symbolic Interpretable Learning for Evolving Compact RL Policies](https://arxiv.org/abs/2506.00328)
*Kourosh Shahnazari,Seyed Moein Ayyoubzadeh,Mohammadali Keshtparvar*

Main category: cs.AI

TL;DR: BASIL是一种通过进化搜索和多样性优化生成符号化、可解释的强化学习策略的方法，旨在解决深度强化学习策略不透明的问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习策略不透明的问题，提升策略的可验证性、透明性和人类监督能力。

Method: 使用基于质量-多样性优化的在线进化搜索，生成符号化的规则策略，并通过复杂性感知的适应度函数鼓励紧凑表示。

Result: 在CartPole-v1、MountainCar-v0和Acrobot-v1等基准任务中，BASIL生成的策略与深度强化学习基线性能相当，同时保持可解释性。

Conclusion: BASIL提供了一种结合符号表达、进化多样性和在线学习的统一框架，为可解释强化学习提供了新方法。

Abstract: The quest for interpretable reinforcement learning is a grand challenge for
the deployment of autonomous decision-making systems in safety-critical
applications. Modern deep reinforcement learning approaches, while powerful,
tend to produce opaque policies that compromise verification, reduce
transparency, and impede human oversight. To address this, we introduce BASIL
(Best-Action Symbolic Interpretable Learning), a systematic approach for
generating symbolic, rule-based policies via online evolutionary search with
quality-diversity (QD) optimization. BASIL represents policies as ordered lists
of symbolic predicates over state variables, ensuring full interpretability and
tractable policy complexity. By using a QD archive, the methodology in the
proposed study encourages behavioral and structural diversity between
top-performing solutions, while a complexity-aware fitness encourages the
synthesis of compact representations. The evolutionary system supports the use
of exact constraints for rule count and system adaptability for balancing
transparency with expressiveness. Empirical comparisons with three benchmark
tasks CartPole-v1, MountainCar-v0, and Acrobot-v1 show that BASIL consistently
synthesizes interpretable controllers with compact representations comparable
to deep reinforcement learning baselines. Herein, this article introduces a new
interpretable policy synthesis method that combines symbolic expressiveness,
evolutionary diversity, and online learning through a unifying framework.

</details>


### [252] [Position: Olfaction Standardization is Essential for the Advancement of Embodied Artificial Intelligence](https://arxiv.org/abs/2506.00398)
*Kordel K. France,Rohith Peddi,Nik Dennler,Ovidiu Daescu*

Main category: cs.AI

TL;DR: 论文主张将嗅觉研究纳入AI发展，以填补现有系统在人类认知中的空白，并呼吁跨学科合作以解决嗅觉研究的挑战。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统在视觉、听觉和语言方面取得显著进展，但忽视了嗅觉这一关键感官，导致AI在认知和伦理上的不完整性。

Method: 提出通过跨学科合作（神经科学、机器人学、机器学习、伦理学）来标准化嗅觉数据集、制定基准，并开发多模态数据集。

Result: 嗅觉研究对实现通用和具身智能至关重要，但目前面临科学理论不完善、技术异构等挑战。

Conclusion: 将嗅觉作为核心感官对AI的科学完整性和伦理基础至关重要，需AI社区投入更多资源。

Abstract: Despite extraordinary progress in artificial intelligence (AI), modern
systems remain incomplete representations of human cognition. Vision, audition,
and language have received disproportionate attention due to well-defined
benchmarks, standardized datasets, and consensus-driven scientific foundations.
In contrast, olfaction - a high-bandwidth, evolutionarily critical sense - has
been largely overlooked. This omission presents a foundational gap in the
construction of truly embodied and ethically aligned super-human intelligence.
We argue that the exclusion of olfactory perception from AI architectures is
not due to irrelevance but to structural challenges: unresolved scientific
theories of smell, heterogeneous sensor technologies, lack of standardized
olfactory datasets, absence of AI-oriented benchmarks, and difficulty in
evaluating sub-perceptual signal processing. These obstacles have hindered the
development of machine olfaction despite its tight coupling with memory,
emotion, and contextual reasoning in biological systems. In this position
paper, we assert that meaningful progress toward general and embodied
intelligence requires serious investment in olfactory research by the AI
community. We call for cross-disciplinary collaboration - spanning
neuroscience, robotics, machine learning, and ethics - to formalize olfactory
benchmarks, develop multimodal datasets, and define the sensory capabilities
necessary for machines to understand, navigate, and act within human
environments. Recognizing olfaction as a core modality is essential not only
for scientific completeness, but for building AI systems that are ethically
grounded in the full scope of the human experience.

</details>


### [253] [World Models for Cognitive Agents: Transforming Edge Intelligence in Future Networks](https://arxiv.org/abs/2506.00417)
*Changyuan Zhao,Ruichen Zhang,Jiacheng Wang,Gaosheng Zhao,Dusit Niyato,Geng Sun,Shiwen Mao,Dong In Kim*

Main category: cs.AI

TL;DR: 本文综述了世界模型在人工智能中的应用，提出了一种名为Wireless Dreamer的新型强化学习框架，并展示了其在低空无线网络中的有效性。


<details>
  <summary>Details</summary>
Motivation: 世界模型作为一种新兴范式，能够在数据受限或安全关键场景中提供高效的预测和决策能力，因此需要对其架构、训练和应用进行全面梳理。

Method: 本文详细介绍了世界模型的架构和训练方法，并提出了Wireless Dreamer框架，特别针对无线边缘智能优化设计。

Result: 通过天气感知的无人机轨迹规划案例研究，证明了Wireless Dreamer在提升学习效率和决策质量方面的有效性。

Conclusion: 世界模型在自主智能体中具有独特优势，Wireless Dreamer框架为无线网络优化提供了新的解决方案。

Abstract: World models are emerging as a transformative paradigm in artificial
intelligence, enabling agents to construct internal representations of their
environments for predictive reasoning, planning, and decision-making. By
learning latent dynamics, world models provide a sample-efficient framework
that is especially valuable in data-constrained or safety-critical scenarios.
In this paper, we present a comprehensive overview of world models,
highlighting their architecture, training paradigms, and applications across
prediction, generation, planning, and causal reasoning. We compare and
distinguish world models from related concepts such as digital twins, the
metaverse, and foundation models, clarifying their unique role as embedded
cognitive engines for autonomous agents. We further propose Wireless Dreamer, a
novel world model-based reinforcement learning framework tailored for wireless
edge intelligence optimization, particularly in low-altitude wireless networks
(LAWNs). Through a weather-aware UAV trajectory planning case study, we
demonstrate the effectiveness of our framework in improving learning efficiency
and decision quality.

</details>


### [254] [MIRROR: Cognitive Inner Monologue Between Conversational Turns for Persistent Reflection and Reasoning in Conversational LLMs](https://arxiv.org/abs/2506.00430)
*Nicole Hsing*

Main category: cs.AI

TL;DR: MIRROR是一种受人类认知启发的认知架构，通过并行推理能力提升大语言模型的多轮对话表现，显著改善安全关键场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 模仿人类内省对话的并行推理能力，解决大语言模型在一致性、安全性和注意力分配上的缺陷。

Method: MIRROR架构包含Thinker和Talker两层：Thinker协调目标、推理和记忆的并行线程，Talker生成上下文感知的响应。

Result: 在CuRaTe基准测试中，MIRROR架构的模型在安全关键场景中性能提升156%，平均准确率超过80%，优于基线模型21%。

Conclusion: MIRROR通过模块化内部推理显著提升多轮对话能力，为AI与认知科学的结合提供了新方向。

Abstract: Human intelligence relies on inner monologue to process complex information
through simultaneous reflection, memory retrieval, and response formulation. We
introduce MIRROR (Modular Internal Reasoning, Reflection, Orchestration, and
Response), a cognitive architecture that systematically implements these
parallel reasoning capabilities in large language models. MIRROR operates as a
unified system with two distinct functional layers: the Thinker and the Talker.
The Thinker encompasses: (1) the Inner Monologue Manager, coordinating
reasoning threads across cognitive dimensions (Goals, Reasoning, and Memory);
and (2) the Cognitive Controller, synthesizing these threads into a coherent
internal narrative maintained across conversation turns. The Talker component
then leverages this integrated narrative for context-aware responses. Evaluated
on the CuRaTe benchmark--testing personalized dialogue with safety-critical
constraints, conflicting preferences, and multi-turn consistency--LLMs
utilizing the MIRROR architecture achieve up to 156% relative improvement in
critical safety scenarios involving three persons with conflicting preferences,
maintaining an average accuracy of ~>80% on all scenarios. Across
scenario-specific comparisons, GPT-4o, Gemini 1.5 Pro, Claude 3.7 Sonnet, Llama
4 variants, and Mistral 3 variants with the MIRROR architecture outperformed
baseline models by 21% on average (15.5 percentage points absolute). MIRROR
directly addresses three critical LLM failure modes: sycophancy, attentional
deficits to critical information, and inconsistent prioritization of
conflicting constraints. This work bridges cognitive science and AI by
implementing modular internal reasoning inspired by human cognition, creating a
persistent internal model that significantly enhances multi-turn conversation
capabilities.

</details>


### [255] [Monitoring Robustness and Individual Fairness](https://arxiv.org/abs/2506.00496)
*Ashutosh Gupta,Thomas A. Henzinger,Konstantin Kueffner,Kaushik Mallik,David Pape*

Main category: cs.AI

TL;DR: 提出了一种运行时监控方法，用于检测黑盒AI模型的输入输出鲁棒性，通过观察相似输入是否产生不相似输出来触发警报。


<details>
  <summary>Details</summary>
Motivation: 现有离线方法无法完全保证AI模型的鲁棒性，运行时监控可补充现有方法，提高AI决策的可信度。

Method: 将监控问题转化为固定半径最近邻搜索问题，开发了工具Clemont，包含多种轻量级监控器，部分基于改进的在线FRNN算法，另一部分基于二进制决策图的新算法。

Result: 通过标准基准测试，验证了监控器在运行时能有效检测鲁棒性违规。

Conclusion: 运行时监控是提高AI模型鲁棒性的有效补充方法，工具Clemont展示了其实际可行性。

Abstract: Input-output robustness appears in various different forms in the literature,
such as robustness of AI models to adversarial or semantic perturbations and
individual fairness of AI models that make decisions about humans.
  We propose runtime monitoring of input-output robustness of deployed,
black-box AI models, where the goal is to design monitors that would observe
one long execution sequence of the model, and would raise an alarm whenever it
is detected that two similar inputs from the past led to dissimilar outputs.
  This way, monitoring will complement existing offline ``robustification''
approaches to increase the trustworthiness of AI decision-makers.
  We show that the monitoring problem can be cast as the fixed-radius nearest
neighbor (FRNN) search problem, which, despite being well-studied, lacks
suitable online solutions.
  We present our tool Clemont, which offers a number of lightweight monitors,
some of which use upgraded online variants of existing FRNN algorithms, and one
uses a novel algorithm based on binary decision diagrams -- a data-structure
commonly used in software and hardware verification.
  We have also developed an efficient parallelization technique that can
substantially cut down the computation time of monitors for which the distance
between input-output pairs is measured using the $L_\infty$ norm.
  Using standard benchmarks from the literature of adversarial and semantic
robustness and individual fairness, we perform a comparative study of different
monitors in \tool, and demonstrate their effectiveness in correctly detecting
robustness violations at runtime.

</details>


### [256] [CityLens: Benchmarking Large Language-Vision Models for Urban Socioeconomic Sensing](https://arxiv.org/abs/2506.00530)
*Tianhui Liu,Jie Feng,Hetian Pang,Xin Zhang,Tianjian Ouyang,Zhiyuan Zhang,Yong Li*

Main category: cs.AI

TL;DR: CityLens是一个评估大型语言视觉模型（LLVMs）从卫星和街景图像预测社会经济指标能力的基准，覆盖17个全球城市和6个关键领域，揭示了LLVMs的潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 通过视觉数据理解城市社会经济状况对可持续发展和政策规划至关重要，但现有方法存在挑战。

Method: 构建多模态数据集，定义11个预测任务，采用三种评估范式，并对17种LLVMs进行基准测试。

Result: LLVMs在感知和推理方面表现良好，但在预测社会经济指标时仍有局限。

Conclusion: CityLens为诊断LLVMs的局限性提供了统一框架，并指导未来研究。

Abstract: Understanding urban socioeconomic conditions through visual data is a
challenging yet essential task for sustainable urban development and policy
planning. In this work, we introduce $\textbf{CityLens}$, a comprehensive
benchmark designed to evaluate the capabilities of large language-vision models
(LLVMs) in predicting socioeconomic indicators from satellite and street view
imagery. We construct a multi-modal dataset covering a total of 17 globally
distributed cities, spanning 6 key domains: economy, education, crime,
transport, health, and environment, reflecting the multifaceted nature of urban
life. Based on this dataset, we define 11 prediction tasks and utilize three
evaluation paradigms: Direct Metric Prediction, Normalized Metric Estimation,
and Feature-Based Regression. We benchmark 17 state-of-the-art LLVMs across
these tasks. Our results reveal that while LLVMs demonstrate promising
perceptual and reasoning capabilities, they still exhibit limitations in
predicting urban socioeconomic indicators. CityLens provides a unified
framework for diagnosing these limitations and guiding future efforts in using
LLVMs to understand and predict urban socioeconomic patterns. Our codes and
datasets are open-sourced via https://github.com/tsinghua-fib-lab/CityLens.

</details>


### [257] [A "Wenlu" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge](https://arxiv.org/abs/2506.00570)
*Liang Geng*

Main category: cs.AI

TL;DR: 论文提出了一种多模态认知与具身决策大脑系统“Wenlu”，旨在融合私有知识与公共模型，统一处理多模态数据，并实现从认知到硬件级代码生成的闭环决策。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在各行业的快速渗透，如何有效整合基础模型的语言理解能力与领域特定知识库成为下一代智能核心的关键挑战。

Method: 系统采用脑启发式记忆标记与回放机制，无缝整合用户私有数据、行业知识与通用语言模型，支持多模态数据处理与闭环决策。

Result: “Wenlu”在多模态处理、隐私安全、端到端硬件控制代码生成、自学习与可持续更新方面表现显著优势。

Conclusion: 该系统为构建下一代智能核心奠定了坚实基础。

Abstract: With the rapid penetration of artificial intelligence across industries and
scenarios, a key challenge in building the next-generation intelligent core
lies in effectively integrating the language understanding capabilities of
foundation models with domain-specific knowledge bases in complex real-world
applications. This paper proposes a multimodal cognition and embodied
decision-making brain system, ``Wenlu", designed to enable secure fusion of
private knowledge and public models, unified processing of multimodal data such
as images and speech, and closed-loop decision-making from cognition to
automatic generation of hardware-level code. The system introduces a
brain-inspired memory tagging and replay mechanism, seamlessly integrating
user-private data, industry-specific knowledge, and general-purpose language
models. It provides precise and efficient multimodal services for enterprise
decision support, medical analysis, autonomous driving, robotic control, and
more. Compared with existing solutions, ``Wenlu" demonstrates significant
advantages in multimodal processing, privacy security, end-to-end hardware
control code generation, self-learning, and sustainable updates, thus laying a
solid foundation for constructing the next-generation intelligent core.

</details>


### [258] [Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs](https://arxiv.org/abs/2506.00577)
*Yufa Zhou,Shaobo Wang,Xingyu Dong,Xiangqi Jin,Yifang Chen,Yue Min,Kexin Yang,Xingzhang Ren,Dayiheng Liu,Linfeng Zhang*

Main category: cs.AI

TL;DR: 论文探讨了通过监督微调（SFT）和可验证奖励的强化学习（RLVR）后训练技术，是否能够有效泛化到多智能体系统中，并以经济推理为测试平台。


<details>
  <summary>Details</summary>
Motivation: 直接训练大型语言模型（LLMs）用于多智能体系统（MAS）存在挑战，如复杂的奖励建模、动态交互和泛化需求。

Method: 提出Recon模型，基于2100个高质量经济推理问题的数据集进行后训练，结合SFT和RLVR技术。

Result: 在经济学推理基准和多智能体游戏中，模型在结构化推理和经济理性方面表现显著提升。

Conclusion: 领域对齐的后训练技术能有效提升推理能力和智能体对齐，为SFT和RL在模型行为塑造中的作用提供了启示。

Abstract: Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS)
remains challenging due to intricate reward modeling, dynamic agent
interactions, and demanding generalization requirements. This paper explores
whether post-training techniques, specifically Supervised Fine-Tuning (SFT) and
Reinforcement Learning with Verifiable Rewards (RLVR), can effectively
$\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a
testbed, leveraging its strong foundations in mathematics and game theory, its
demand for structured analytical reasoning, and its relevance to real-world
applications such as market design, resource allocation, and policy analysis.
We introduce $\textbf{Recon}$ ($\textbf{R}$easoning like an
$\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a
hand-curated dataset of 2,100 high-quality economic reasoning problems.
Comprehensive evaluation on economic reasoning benchmarks and multi-agent games
reveals clear improvements in structured reasoning and economic rationality.
These results underscore the promise of domain-aligned post-training for
enhancing reasoning and agent alignment, shedding light on the roles of SFT and
RL in shaping model behavior. Code is available at
https://github.com/MasterZhou1/Recon .

</details>


### [259] [Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs](https://arxiv.org/abs/2506.00582)
*Chenjun Xu,Bingbing Wen,Bin Han,Robert Wolfe,Lucy Lu Wang,Bill Howe*

Main category: cs.AI

TL;DR: 研究发现LLMs在QA任务中的自信度与人类不同，对任务难度不敏感且易受刻板印象影响。提出AFCE方法，通过分阶段提示改善自信度校准。


<details>
  <summary>Details</summary>
Motivation: 人类在任务中容易低估或高估自信度，研究LLMs是否表现出类似模式及其差异。

Method: 比较三种LLMs在不同难度QA任务中的表现，提出AFCE方法（分阶段提示自信度和答案）。

Result: LLMs对任务难度不敏感且易受刻板印象影响；AFCE显著减少过度自信并更接近人类表现。

Conclusion: AFCE能有效改善LLMs的自信度校准和可解释性，尤其在任务难度和刻板印象方面。

Abstract: Psychology research has shown that humans are poor at estimating their
performance on tasks, tending towards underconfidence on easy tasks and
overconfidence on difficult tasks. We examine three LLMs, Llama-3-70B-instruct,
Claude-3-Sonnet, and GPT-4o, on a range of QA tasks of varying difficulty, and
show that models exhibit subtle differences from human patterns of
overconfidence: less sensitive to task difficulty, and when prompted to answer
based on different personas -- e.g., expert vs layman, or different race,
gender, and ages -- the models will respond with stereotypically biased
confidence estimations even though their underlying answer accuracy remains the
same. Based on these observations, we propose Answer-Free Confidence Estimation
(AFCE) to improve confidence calibration and LLM interpretability in these
settings. AFCE is a self-assessment method that employs two stages of
prompting, first eliciting only confidence scores on questions, then asking
separately for the answer. Experiments on the MMLU and GPQA datasets spanning
subjects and difficulty show that this separation of tasks significantly
reduces overconfidence and delivers more human-like sensitivity to task
difficulty.

</details>


### [260] [RiOSWorld: Benchmarking the Risk of Multimodal Compter-Use Agents](https://arxiv.org/abs/2506.00618)
*Jingyi Yang,Shuai Shao,Dongrui Liu,Jing Shao*

Main category: cs.AI

TL;DR: 该论文提出了一个名为RIOSWorld的基准测试，用于评估基于多模态大语言模型（MLLM）的计算机使用代理在真实场景中的安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究在评估MLLM代理的安全风险时存在局限性，如缺乏真实交互环境或仅关注少数风险类型，无法全面反映真实世界的复杂性。

Method: RIOSWorld包含492个涵盖多种计算机应用的风险任务，将风险分为用户来源和环境来源两类，并从风险意图和目标完成两个角度进行评估。

Result: 实验表明，当前计算机使用代理在真实场景中面临显著安全风险。

Conclusion: 研究强调了在真实计算机操作中对代理进行安全对齐的必要性和紧迫性，为开发可信代理提供了重要见解。

Abstract: With the rapid development of multimodal large language models (MLLMs), they
are increasingly deployed as autonomous computer-use agents capable of
accomplishing complex computer tasks. However, a pressing issue arises: Can the
safety risk principles designed and aligned for general MLLMs in dialogue
scenarios be effectively transferred to real-world computer-use scenarios?
Existing research on evaluating the safety risks of MLLM-based computer-use
agents suffers from several limitations: it either lacks realistic interactive
environments, or narrowly focuses on one or a few specific risk types. These
limitations ignore the complexity, variability, and diversity of real-world
environments, thereby restricting comprehensive risk evaluation for
computer-use agents. To this end, we introduce \textbf{RiOSWorld}, a benchmark
designed to evaluate the potential risks of MLLM-based agents during real-world
computer manipulations. Our benchmark includes 492 risky tasks spanning various
computer applications, involving web, social media, multimedia, os, email, and
office software. We categorize these risks into two major classes based on
their risk source: (i) User-originated risks and (ii) Environmental risks. For
the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal
intention and (ii) Risk goal completion. Extensive experiments with multimodal
agents on \textbf{RiOSWorld} demonstrate that current computer-use agents
confront significant safety risks in real-world scenarios. Our findings
highlight the necessity and urgency of safety alignment for computer-use agents
in real-world computer manipulation, providing valuable insights for developing
trustworthy computer-use agents. Our benchmark is publicly available at
https://yjyddq.github.io/RiOSWorld.github.io/.

</details>


### [261] [AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents](https://arxiv.org/abs/2506.00641)
*Hanjun Luo,Shenyu Dai,Chiming Ni,Xinfeng Li,Guibin Zhang,Kun Wang,Tongliang Liu,Hanan Salam*

Main category: cs.AI

TL;DR: \sys 是一个通用的、无需训练的、基于记忆增强的推理框架，用于提升 LLM 评估器在安全和安全风险检测中的性能，并达到人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则或 LLM 的评估器在检测代理安全风险时存在不足，如忽略逐步动作中的危险、难以处理模糊规则等。

Method: \sys 通过构建经验记忆库，提取结构化语义特征并生成推理链，结合多阶段检索增强生成过程动态指导评估。

Result: 实验表明，\sys 显著提升了 LLM 评估器的性能，并在安全和安全风险检测中达到人类水平。

Conclusion: \sys 为解决 LLM 代理安全评估的挑战提供了有效方案，并开源了首个相关基准 \data。

Abstract: Despite the rapid advancement of LLM-based agents, the reliable evaluation of
their safety and security remains a significant challenge. Existing rule-based
or LLM-based evaluators often miss dangers in agents' step-by-step actions,
overlook subtle meanings, fail to see how small issues compound, and get
confused by unclear safety or security rules. To overcome this evaluation
crisis, we introduce \sys, a universal, training-free, memory-augmented
reasoning framework that empowers LLM evaluators to emulate human expert
evaluators. \sys constructs an experiential memory by having an LLM adaptively
extract structured semantic features (e.g., scenario, risk, behavior) and
generate associated chain-of-thought reasoning traces for past interactions. A
multi-stage, context-aware retrieval-augmented generation process then
dynamically retrieves the most relevant reasoning experiences to guide the LLM
evaluator's assessment of new cases. Moreover, we developed \data, the first
benchmark designed to check how well LLM-based evaluators can spot both safety
risks and security threats. \data comprises \textbf{2293} meticulously
annotated interaction records, covering \textbf{15} risk types across
\textbf{29} application scenarios. A key feature of \data is its nuanced
approach to ambiguous risk situations, employing ``Strict'' and ``Lenient''
judgment standards. Experiments demonstrate that \sys not only consistently
improves the evaluation performance of LLMs across all benchmarks but also sets
a new state-of-the-art in LLM-as-a-judge for agent safety and security,
achieving human-level accuracy. Our work is openly openly accessible.

</details>


### [262] [OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases](https://arxiv.org/abs/2506.00664)
*Yash Tiwari,Owais Ahmad Lone,Mayukha Pal*

Main category: cs.AI

TL;DR: OntoRAG是一个自动化流程，用于从非结构化知识库中提取本体，特别针对电气继电器文档，结合多种技术提升问答系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统本体构建依赖专家手动操作，耗时且易出错，难以应对大规模动态知识领域。

Method: OntoRAG整合了网络爬虫、PDF解析、混合分块、信息提取、知识图谱构建和本体创建技术。

Result: OntoRAG在全面性和多样性上优于传统RAG和GraphRAG，实验显示其全面性胜率为85%（对向量RAG）和75%（对GraphRAG最佳配置）。

Conclusion: OntoRAG解决了本体自动创建的关键挑战，推动了语义网的愿景。

Abstract: Ontologies are pivotal for structuring knowledge bases to enhance question
answering (QA) systems powered by Large Language Models (LLMs). However,
traditional ontology creation relies on manual efforts by domain experts, a
process that is time intensive, error prone, and impractical for large, dynamic
knowledge domains. This paper introduces OntoRAG, an automated pipeline
designed to derive ontologies from unstructured knowledge bases, with a focus
on electrical relay documents. OntoRAG integrates advanced techniques,
including web scraping, PDF parsing, hybrid chunking, information extraction,
knowledge graph construction, and ontology creation, to transform unstructured
data into a queryable ontology. By leveraging LLMs and graph based methods,
OntoRAG enhances global sensemaking capabilities, outperforming conventional
Retrieval Augmented Generation (RAG) and GraphRAG approaches in
comprehensiveness and diversity. Experimental results demonstrate OntoRAGs
effectiveness, achieving a comprehensiveness win rate of 85% against vector RAG
and 75% against GraphRAGs best configuration. This work addresses the critical
challenge of automating ontology creation, advancing the vision of the semantic
web.

</details>


### [263] [DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains](https://arxiv.org/abs/2506.00708)
*Yongkang Xiao,Sinian Zhang,Yi Dai,Huixue Zhou,Jue Hou,Jie Ding,Rui Zhang*

Main category: cs.AI

TL;DR: DrKGC提出了一种结合动态子图检索和LLM的方法，用于知识图谱补全，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图上下文编码为文本形式，未能充分利用LLM对图结构的感知和推理能力。

Method: DrKGC通过轻量级模型学习结构嵌入和逻辑规则，结合子图检索和GCN适配器增强LLM的提示。

Result: 在两个通用领域和两个生物医学数据集上表现优异，且具有解释性和实用性。

Conclusion: DrKGC通过动态子图检索和LLM结合，有效提升了知识图谱补全的性能和实用性。

Abstract: Knowledge graph completion (KGC) aims to predict missing triples in knowledge
graphs (KGs) by leveraging existing triples and textual information. Recently,
generative large language models (LLMs) have been increasingly employed for
graph tasks. However, current approaches typically encode graph context in
textual form, which fails to fully exploit the potential of LLMs for perceiving
and reasoning about graph structures. To address this limitation, we propose
DrKGC (Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph
Completion). DrKGC employs a flexible lightweight model training strategy to
learn structural embeddings and logical rules within the KG. It then leverages
a novel bottom-up graph retrieval method to extract a subgraph for each query
guided by the learned rules. Finally, a graph convolutional network (GCN)
adapter uses the retrieved subgraph to enhance the structural embeddings, which
are then integrated into the prompt for effective LLM fine-tuning. Experimental
results on two general domain benchmark datasets and two biomedical datasets
demonstrate the superior performance of DrKGC. Furthermore, a realistic case
study in the biomedical domain highlights its interpretability and practical
utility.

</details>


### [264] [Alignment Revisited: Are Large Language Models Consistent in Stated and Revealed Preferences?](https://arxiv.org/abs/2506.00751)
*Zhuojun Gu,Quan Wang,Shuchu Han*

Main category: cs.AI

TL;DR: 该研究探讨了大型语言模型（LLM）在陈述偏好与情境化选择中的偏好偏差问题，提出了一种量化方法，并发现提示格式的微小变化可能导致偏好反转。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示LLM在行为与人类价值观对齐中的潜在偏差，这对模型的可解释性、可信度和伦理部署至关重要。

Method: 通过设计一系列二元选择提示，比较LLM在通用原则提示和情境化提示下的响应，使用KL散度等指标量化偏差。

Result: 研究发现提示格式的微小变化常导致偏好反转，表明对LLM决策能力的理解和控制不足。

Conclusion: 该研究对LLM在人类交互服务和自主代理任务中的整合至关重要，需关注偏好偏差以避免伦理风险。

Abstract: Recent advances in Large Language Models (LLMs) highlight the need to align
their behaviors with human values. A critical, yet understudied, issue is the
potential divergence between an LLM's stated preferences (its reported
alignment with general principles) and its revealed preferences (inferred from
decisions in contextualized scenarios). Such deviations raise fundamental
concerns for the interpretability, trustworthiness, reasoning transparency, and
ethical deployment of LLMs, particularly in high-stakes applications. This work
formally defines and proposes a method to measure this preference deviation. We
investigate how LLMs may activate different guiding principles in specific
contexts, leading to choices that diverge from previously stated general
principles. Our approach involves crafting a rich dataset of well-designed
prompts as a series of forced binary choices and presenting them to LLMs. We
compare LLM responses to general principle prompts stated preference with LLM
responses to contextualized prompts revealed preference, using metrics like KL
divergence to quantify the deviation. We repeat the analysis across different
categories of preferences and on four mainstream LLMs and find that a minor
change in prompt format can often pivot the preferred choice regardless of the
preference categories and LLMs in the test. This prevalent phenomenon
highlights the lack of understanding and control of the LLM decision-making
competence. Our study will be crucial for integrating LLMs into services,
especially those that interact directly with humans, where morality, fairness,
and social responsibilities are crucial dimensions. Furthermore, identifying or
being aware of such deviation will be critically important as LLMs are
increasingly envisioned for autonomous agentic tasks where continuous human
evaluation of all LLMs' intermediary decision-making steps is impossible.

</details>


### [265] [HouseTS: A Large-Scale, Multimodal Spatiotemporal U.S. Housing Dataset](https://arxiv.org/abs/2506.00765)
*Shengkun Wang,Yanshen Sun,Fanglan Chen,Linhan Wang,Naren Ramakrishnan,Chang-Tien Lu,Yinlin Chen*

Main category: cs.AI

TL;DR: 论文介绍了HouseTS数据集，用于长期房价预测，包含多模态数据，并评估了14种模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有房价预测研究缺乏可复现的基准数据集，HouseTS旨在填补这一空白，提供丰富的时空和上下文数据。

Method: 构建了包含89万条记录的多模态数据集，评估了14种模型，包括统计方法、DNN和预训练时间序列模型。

Result: HouseTS数据集支持多模态分析，如通过卫星图像提取地理变化信息，为城市演化提供可解释的见解。

Conclusion: HouseTS为房价预测提供了标准化基准，数据集和代码开源，确保可复现性和易用性。

Abstract: Accurate house-price forecasting is essential for investors, planners, and
researchers. However, reproducible benchmarks with sufficient spatiotemporal
depth and contextual richness for long horizon prediction remain scarce. To
address this, we introduce HouseTS a large scale, multimodal dataset covering
monthly house prices from March 2012 to December 2023 across 6,000 ZIP codes in
30 major U.S. metropolitan areas. The dataset includes over 890K records,
enriched with points of Interest (POI), socioeconomic indicators, and detailed
real estate metrics. To establish standardized performance baselines, we
evaluate 14 models, spanning classical statistical approaches, deep neural
networks (DNNs), and pretrained time-series foundation models. We further
demonstrate the value of HouseTS in a multimodal case study, where a vision
language model extracts structured textual descriptions of geographic change
from time stamped satellite imagery. This enables interpretable, grounded
insights into urban evolution. HouseTS is hosted on Kaggle, while all
preprocessing pipelines, benchmark code, and documentation are openly
maintained on GitHub to ensure full reproducibility and easy adoption.

</details>


### [266] [Do not Abstain! Identify and Solve the Uncertainty](https://arxiv.org/abs/2506.00780)
*Jingyu Liu,Jingquan Peng,xiaopeng Wu,Xubin Li,Tiezheng Ge,Bo Zheng,Yong Liu*

Main category: cs.AI

TL;DR: 论文提出了ConfuseBench基准，用于评估和改进大语言模型（LLMs）识别和处理不确定性的能力，发现现有模型倾向于将不确定性归因于查询模糊性，而忽视能力限制。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在不确定场景中常表现出过度自信，且现有解决方案（如回避回答）未能有效识别和解决不确定性。

Method: 引入ConfuseBench基准，聚焦文档稀缺性、能力限制和查询模糊性三类不确定性，并提出基于上下文感知询问和InteractDPO训练的方法。

Result: 实验表明当前LLMs难以准确识别不确定性根源，且倾向于忽视能力限制；提出的方法能有效改进模型表现。

Conclusion: 通过ConfuseBench和InteractDPO方法，论文为LLMs识别和解决不确定性提供了新思路和有效工具。

Abstract: Despite the widespread application of Large Language Models (LLMs) across
various domains, they frequently exhibit overconfidence when encountering
uncertain scenarios, yet existing solutions primarily rely on evasive responses
(e.g., "I don't know") overlooks the opportunity of identifying and addressing
the uncertainty to generate more satisfactory responses. To systematically
investigate and improve LLMs' ability of recognizing and addressing the source
of uncertainty, we introduce \textbf{ConfuseBench}, a benchmark mainly focus on
three types of uncertainty: document scarcity, limited capability, and query
ambiguity. Experiments with ConfuseBench reveal that current LLMs struggle to
accurately identify the root cause of uncertainty and solve it. They prefer to
attribute uncertainty to query ambiguity while overlooking capability
limitations, especially for those weaker models. To tackle this challenge, we
first generate context-aware inquiries that highlight the confusing aspect of
the original query. Then we judge the source of uncertainty based on the
uniqueness of the inquiry's answer. Further we use an on-policy training
method, InteractDPO to generate better inquiries. Experimental results
demonstrate the efficacy of our approach.

</details>


### [267] [CoP: Agentic Red-teaming for Large Language Models using Composition of Principles](https://arxiv.org/abs/2506.00781)
*Chen Xiong,Pin-Yu Chen,Tsung-Yi Ho*

Main category: cs.AI

TL;DR: 本文提出了一种基于Composition-of-Principles（CoP）框架的自动化红队测试方法，用于发现大语言模型（LLMs）的安全漏洞和越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，越狱攻击（jailbreak attacks）成为迫切的安全问题，传统红队测试方法难以满足需求。

Method: 通过CoP框架，将人类提供的红队测试原则转化为AI代理的指令，自动生成有效的越狱提示和策略。

Result: CoP框架在测试中发现了新的越狱提示，并将单次攻击成功率提高了19倍。

Conclusion: CoP框架为自动化红队测试提供了统一且可扩展的解决方案，显著提升了发现LLMs安全漏洞的效率。

Abstract: Recent advances in Large Language Models (LLMs) have spurred transformative
applications in various domains, ranging from open-source to proprietary LLMs.
However, jailbreak attacks, which aim to break safety alignment and user
compliance by tricking the target LLMs into answering harmful and risky
responses, are becoming an urgent concern. The practice of red-teaming for LLMs
is to proactively explore potential risks and error-prone instances before the
release of frontier AI technology. This paper proposes an agentic workflow to
automate and scale the red-teaming process of LLMs through the
Composition-of-Principles (CoP) framework, where human users provide a set of
red-teaming principles as instructions to an AI agent to automatically
orchestrate effective red-teaming strategies and generate jailbreak prompts.
Distinct from existing red-teaming methods, our CoP framework provides a
unified and extensible framework to encompass and orchestrate human-provided
red-teaming principles to enable the automated discovery of new red-teaming
strategies. When tested against leading LLMs, CoP reveals unprecedented safety
risks by finding novel jailbreak prompts and improving the best-known
single-turn attack success rate by up to 19.0 times.

</details>


### [268] [Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.00782)
*Weiyang Guo,Zesheng Shi,Zhuo Li,Yequan Wang,Xuebo Liu,Wenya Wang,Fangming Liu,Min Zhang,Jing Li*

Main category: cs.AI

TL;DR: 提出了一种基于强化学习的自动化红队训练框架，用于生成多样且有效的攻击提示，以检测大语言模型的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的能力和影响力增强，确保其安全性并防止有害输出变得至关重要。现有的红队方法在攻击提示的有效性和多样性之间难以平衡。

Method: 框架分为三个阶段：冷启动（模仿学习微调）、热身探索（利用多样性和一致性作为奖励信号）、增强越狱（逐步引入越狱奖励）。

Result: 实验表明，该方法在多样性和有效性上优于现有方法，显著提升了红队探索的效率。

Conclusion: 该工作为自动化红队测试提供了新视角，并有效平衡了攻击提示的多样性和有效性。

Abstract: As large language models (LLMs) grow in power and influence, ensuring their
safety and preventing harmful output becomes critical. Automated red teaming
serves as a tool to detect security vulnerabilities in LLMs without manual
labor. However, most existing methods struggle to balance the effectiveness and
diversity of red-team generated attack prompts. To address this challenge, we
propose \ourapproach, a novel automated red teaming training framework that
utilizes reinforcement learning to explore and generate more effective attack
prompts while balancing their diversity. Specifically, it consists of three
training stages: (1) Cold Start: The red team model is supervised and
fine-tuned on a jailbreak dataset obtained through imitation learning. (2)
Warm-up Exploration: The model is trained in jailbreak instruction following
and exploration, using diversity and consistency as reward signals. (3)
Enhanced Jailbreak: Progressive jailbreak rewards are introduced to gradually
enhance the jailbreak performance of the red-team model. Extensive experiments
on a variety of LLMs show that \ourapproach effectively balances the diversity
and effectiveness of jailbreak prompts compared to existing methods. Our work
significantly improves the efficiency of red team exploration and provides a
new perspective on automated red teaming.

</details>


### [269] [GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning](https://arxiv.org/abs/2506.00785)
*Sahiti Yerramilli,Nilay Pande,Rynaa Grover,Jayant Sravan Tamarapalli*

Main category: cs.AI

TL;DR: GeoChain是一个用于评估多模态大语言模型（MLLMs）逐步地理推理能力的大规模基准测试，包含146万张Mapillary街景图像和30多万个问答对。测试结果显示，现有模型在视觉定位、推理一致性和精确地理定位方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在复杂地理推理任务中表现不佳，缺乏系统性评估方法。GeoChain旨在填补这一空白，提供全面的诊断工具以推动模型改进。

Method: 利用146万张Mapillary街景图像，每张图像配对一个21步的链式推理问题序列（共30多万个问答对），涵盖视觉、空间、文化和精确地理定位四类推理任务，并标注难度。图像还包含语义分割和视觉定位分数。

Result: 对多个主流MLLMs（如GPT-4.1、Claude 3.7、Gemini 2.5）的测试显示，模型在视觉定位、推理一致性和复杂任务中的精确地理定位方面表现不佳。

Conclusion: GeoChain为MLLMs在复杂地理推理任务中的性能提供了系统性评估方法，有助于推动模型在这一领域的进步。

Abstract: This paper introduces GeoChain, a large-scale benchmark for evaluating
step-by-step geographic reasoning in multimodal large language models (MLLMs).
Leveraging 1.46 million Mapillary street-level images, GeoChain pairs each
image with a 21-step chain-of-thought (CoT) question sequence (over 30 million
Q&A pairs). These sequences guide models from coarse attributes to fine-grained
localization across four reasoning categories - visual, spatial, cultural, and
precise geolocation - annotated by difficulty. Images are also enriched with
semantic segmentation (150 classes) and a visual locatability score. Our
benchmarking of contemporary MLLMs (GPT-4.1 variants, Claude 3.7, Gemini 2.5
variants) on a diverse 2,088-image subset reveals consistent challenges: models
frequently exhibit weaknesses in visual grounding, display erratic reasoning,
and struggle to achieve accurate localization, especially as the reasoning
complexity escalates. GeoChain offers a robust diagnostic methodology, critical
for fostering significant advancements in complex geographic reasoning within
MLLMs.

</details>


### [270] [Predicting Empirical AI Research Outcomes with Language Models](https://arxiv.org/abs/2506.00794)
*Jiaxin Wen,Chenglei Si,Yueh-han Chen,He He,Shi Feng*

Main category: cs.AI

TL;DR: 论文提出了一个预测AI研究想法成功率的基准测试，并比较了语言模型与人类专家的表现。系统结合了微调的GPT-4.1和论文检索代理，在NLP领域显著优于人类专家，展示了加速AI研究的潜力。


<details>
  <summary>Details</summary>
Motivation: AI研究中许多看似有前景的想法最终未能成功，验证这些想法需要大量人力和计算资源。预测想法的成功率对加速实证AI研究至关重要，但即使是专家也需要大量经验才能掌握这一技能。

Method: 通过从会议论文中提取研究想法和实验结果，构建了1,585对验证数据和6,000对训练数据。开发了一个结合微调GPT-4.1和论文检索代理的系统，并与25位人类专家进行比较。

Result: 在NLP领域，系统以64.4%的准确率显著优于人类专家的48.9%。在整个测试集上，系统达到77%的准确率，而现成的语言模型表现与随机猜测无异。系统在未发表的新想法上也表现出色（63.6%准确率）。

Conclusion: 研究结果表明，语言模型在加速实证AI研究中具有潜力，可作为奖励模型改进想法生成模型。

Abstract: Many promising-looking ideas in AI research fail to deliver, but their
validation takes substantial human labor and compute. Predicting an idea's
chance of success is thus crucial for accelerating empirical AI research, a
skill that even expert researchers can only acquire through substantial
experience. We build the first benchmark for this task and compare LMs with
human experts. Concretely, given two research ideas (e.g., two jailbreaking
methods), we aim to predict which will perform better on a set of benchmarks.
We scrape ideas and experimental results from conference papers, yielding 1,585
human-verified idea pairs published after our base model's cut-off date for
testing, and 6,000 pairs for training. We then develop a system that combines a
fine-tuned GPT-4.1 with a paper retrieval agent, and we recruit 25 human
experts to compare with. In the NLP domain, our system beats human experts by a
large margin (64.4% v.s. 48.9%). On the full test set, our system achieves 77%
accuracy, while off-the-shelf frontier LMs like o3 perform no better than
random guessing, even with the same retrieval augmentation. We verify that our
system does not exploit superficial features like idea complexity through
extensive human-written and LM-designed robustness tests. Finally, we evaluate
our system on unpublished novel ideas, including ideas generated by an AI
ideation agent. Our system achieves 63.6% accuracy, demonstrating its potential
as a reward model for improving idea generation models. Altogether, our results
outline a promising new direction for LMs to accelerate empirical AI research.

</details>


### [271] [Enhancing LLM Reasoning for Time Series Classification by Tailored Thinking and Fused Decision](https://arxiv.org/abs/2506.00807)
*Jiahui Zhou,Dan Li,Lin Li,Zhuomin Chen,Shunyu Wu,Haozheng Ye,Jian Lou,Costas J. Spanos*

Main category: cs.AI

TL;DR: ReasonTSC是一个新颖的框架，通过多轮推理和融合决策策略，有效利用大语言模型（LLM）进行时间序列分类（TSC）。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在文本领域的推理能力强大，但直接将其应用于时间序列分类任务效果有限。ReasonTSC旨在通过专门设计的推理策略提升LLM在TSC任务中的表现。

Method: ReasonTSC首先引导模型思考时间序列数据的关键特征，然后整合插件分类器的预测和置信度分数作为上下文示例，最后通过结构化推理过程（评估、回溯和比较假设）生成最终分类。

Result: 实验表明，ReasonTSC优于现有时间序列推理基线和插件模型，并能识别和纠正插件模型的错误预测。

Conclusion: ReasonTSC通过定制化推理策略，显著提升了LLM在时间序列分类任务中的性能，展示了其在真实应用中的潜力。

Abstract: The reasoning capabilities of large language models (LLMs) have significantly
advanced their performance by enabling in-depth understanding of diverse tasks.
With growing interest in applying LLMs to the time series domain, this has
proven nontrivial, as evidenced by the limited efficacy of straightforwardly
adapting text-domain reasoning techniques. Although recent work has shown
promise in several time series tasks, further leveraging advancements in LLM
reasoning remains under-explored for time series classification (TSC) tasks,
despite their prevalence and significance in many real-world applications. In
this paper, we propose ReasonTSC, a novel framework designed to effectively
leverage LLM reasoning for time series classification through both a multi-turn
reasoning and a fused decision-making strategy tailored to TSC. Rather than
straightforwardly applying existing reasoning techniques or relying solely on
LLMs' built-in reasoning capabilities, ReasonTSC first steers the model to
think over the essential characteristics of time series data. Next, it
integrates predictions and confidence scores from plug-in classifiers, e.g.,
domain-specific time series models, as in-context examples. Finally, ReasonTSC
guides the LLM through a structured reasoning process: it evaluates the initial
assessment, backtracks to consider alternative hypotheses, and compares their
merits before arriving at a final classification. Extensive experiments and
systematic ablation studies demonstrate that ReasonTSC consistently outperforms
both existing time series reasoning baselines and plug-in models, and is even
capable of identifying and correcting plug-in models' false predictions.

</details>


### [272] [SynPO: Synergizing Descriptiveness and Preference Optimization for Video Detailed Captioning](https://arxiv.org/abs/2506.00835)
*Jisheng Dang,Yizhou Zhang,Hao Ye,Teng Wang,Siming Chen,Huicheng Zheng,Yulan Guo,Jianhuang Lai,Bin Hu*

Main category: cs.AI

TL;DR: 论文提出了一种基于偏好学习的细粒度视频描述方法SynPO，通过优化偏好对构建和训练方法，显著提升了性能并减少了训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉视频中的细微动态和丰富细节，且直接偏好优化（DPO）存在局限性。

Method: 提出偏好对构建管道和协同偏好优化（SynPO）方法，避免负面偏好主导优化，保持语言能力并提升训练效率。

Result: 在视频描述和NLP任务中，SynPO表现优于DPO变体，训练效率提升20%。

Conclusion: SynPO是一种高效且性能优越的优化方法，适用于细粒度视频描述及其他任务。

Abstract: Fine-grained video captioning aims to generate detailed, temporally coherent
descriptions of video content. However, existing methods struggle to capture
subtle video dynamics and rich detailed information. In this paper, we leverage
preference learning to enhance the performance of vision-language models in
fine-grained video captioning, while mitigating several limitations inherent to
direct preference optimization (DPO). First, we propose a pipeline for
constructing preference pairs that leverages the intrinsic properties of VLMs
along with partial assistance from large language models, achieving an optimal
balance between cost and data quality. Second, we propose Synergistic
Preference Optimization (SynPO), a novel optimization method offering
significant advantages over DPO and its variants. SynPO prevents negative
preferences from dominating the optimization, explicitly preserves the model's
language capability to avoid deviation of the optimization objective, and
improves training efficiency by eliminating the need for the reference model.
We extensively evaluate SynPO not only on video captioning benchmarks (e.g.,
VDC, VDD, VATEX) but also across well-established NLP tasks, including general
language understanding and preference evaluation, using diverse pretrained
models. Results demonstrate that SynPO consistently outperforms DPO variants
while achieving 20\% improvement in training efficiency. Code is available at
https://github.com/longmalongma/SynPO

</details>


### [273] [MedBookVQA: A Systematic and Comprehensive Medical Benchmark Derived from Open-Access Book](https://arxiv.org/abs/2506.00855)
*Sau Lai Yip,Sunan He,Yuxiang Nie,Shu Pui Chan,Yilin Ye,Sum Ying Lam,Hao Chen*

Main category: cs.AI

TL;DR: MedBookVQA是一个基于开放医学教科书的多模态基准测试，用于评估通用医学人工智能（GMAI）的性能，揭示了当前系统的能力差距。


<details>
  <summary>Details</summary>
Motivation: 解决医疗领域劳动力不足和成本上升的问题，同时开发系统化的评估基准以指导技术发展。

Method: 通过标准化流程从医学教科书中提取多模态数据，生成5,000个临床相关问题，并采用多级注释系统分类。

Result: 评估多种MLLM模型，发现任务类型和模型类别之间存在显著性能差异。

Conclusion: MedBookVQA为临床AI提供了教科书衍生的基准测试范式，揭示了GMAI系统的局限性并提供了结构化性能指标。

Abstract: The accelerating development of general medical artificial intelligence
(GMAI), powered by multimodal large language models (MLLMs), offers
transformative potential for addressing persistent healthcare challenges,
including workforce deficits and escalating costs. The parallel development of
systematic evaluation benchmarks emerges as a critical imperative to enable
performance assessment and provide technological guidance. Meanwhile, as an
invaluable knowledge source, the potential of medical textbooks for benchmark
development remains underexploited. Here, we present MedBookVQA, a systematic
and comprehensive multimodal benchmark derived from open-access medical
textbooks. To curate this benchmark, we propose a standardized pipeline for
automated extraction of medical figures while contextually aligning them with
corresponding medical narratives. Based on this curated data, we generate 5,000
clinically relevant questions spanning modality recognition, disease
classification, anatomical identification, symptom diagnosis, and surgical
procedures. A multi-tier annotation system categorizes queries through
hierarchical taxonomies encompassing medical imaging modalities (42
categories), body anatomies (125 structures), and clinical specialties (31
departments), enabling nuanced analysis across medical subdomains. We evaluate
a wide array of MLLMs, including proprietary, open-sourced, medical, and
reasoning models, revealing significant performance disparities across task
types and model categories. Our findings highlight critical capability gaps in
current GMAI systems while establishing textbook-derived multimodal benchmarks
as essential evaluation tools. MedBookVQA establishes textbook-derived
benchmarking as a critical paradigm for advancing clinical AI, exposing
limitations in GMAI systems while providing anatomically structured performance
metrics across specialties.

</details>


### [274] [GIA-MIC: Multimodal Emotion Recognition with Gated Interactive Attention and Modality-Invariant Learning Constraints](https://arxiv.org/abs/2506.00865)
*Jiajun He,Jinyi Mi,Tomoki Toda*

Main category: cs.AI

TL;DR: 提出了一种基于门控交互注意力机制和模态不变生成器的多模态情感识别方法，解决了模态特异性特征提取和跨模态相似性捕捉的挑战，在IEMOCAP数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别（MER）在人类-计算机交互中至关重要，但现有注意力融合方法在模态特异性特征提取和跨模态相似性捕捉方面仍存在挑战。

Method: 采用门控交互注意力机制自适应提取模态特异性特征，并通过模态不变生成器学习模态不变表示，对齐跨模态相似性以减少领域偏移。

Result: 在IEMOCAP数据集上，该方法取得了WA 80.7%和UA 81.3%的分类性能，优于现有方法。

Conclusion: 该方法有效解决了MER中的模态特异性和跨模态相似性问题，提升了分类性能。

Abstract: Multimodal emotion recognition (MER) extracts emotions from multimodal data,
including visual, speech, and text inputs, playing a key role in human-computer
interaction. Attention-based fusion methods dominate MER research, achieving
strong classification performance. However, two key challenges remain:
effectively extracting modality-specific features and capturing cross-modal
similarities despite distribution differences caused by modality heterogeneity.
To address these, we propose a gated interactive attention mechanism to
adaptively extract modality-specific features while enhancing emotional
information through pairwise interactions. Additionally, we introduce a
modality-invariant generator to learn modality-invariant representations and
constrain domain shifts by aligning cross-modal similarities. Experiments on
IEMOCAP demonstrate that our method outperforms state-of-the-art MER
approaches, achieving WA 80.7% and UA 81.3%.

</details>


### [275] [Toward a Theory of Agents as Tool-Use Decision-Makers](https://arxiv.org/abs/2506.00886)
*Hongru Wang,Cheng Qian,Manling Li,Jiahao Qiu,Boyang Xue,Mengdi Wang,Heng Ji,Kam-Fai Wong*

Main category: cs.AI

TL;DR: 论文提出了一种统一的认知框架，将内部推理与外部行动视为等效的认知工具，旨在通过协调自省与交互，构建高效、目标导向的自主智能体。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）作为自主智能体时，其认知基础未明确的问题，包括如何定义智能体、决策方式及行为目标。

Method: 提出一种统一理论，将内部推理与外部行动视为等效的认知工具，并协调自省与交互。

Result: 通过将智能体的工具使用决策边界与其知识边界对齐，最小化不必要的工具使用，最大化认知效率。

Conclusion: 该框架将智能体设计从单纯执行动作转向知识驱动的智能系统，为构建自适应、高效、目标导向的基础智能体提供了理论支持。

Abstract: As Large Language Models (LLMs) evolve into increasingly autonomous agents,
fundamental questions about their epistemic foundations remain unresolved: What
defines an agent? How should it make decisions? And what objectives should
guide its behavior? In this position paper, we argue that true autonomy
requires agents to be grounded in a coherent epistemic framework that governs
what they know, what they need to know, and how to acquire that knowledge
efficiently. We propose a unified theory that treats internal reasoning and
external actions as equivalent epistemic tools, enabling agents to
systematically coordinate introspection and interaction. Building on this
framework, we advocate for aligning an agent's tool use decision-making
boundary with its knowledge boundary, thereby minimizing unnecessary tool use
and maximizing epistemic efficiency. This perspective shifts the design of
agents from mere action executors to knowledge-driven intelligence systems,
offering a principled path toward building foundation agents capable of
adaptive, efficient, and goal-directed behavior.

</details>


### [276] [Conformal Arbitrage: Risk-Controlled Balancing of Competing Objectives in Language Models](https://arxiv.org/abs/2506.00911)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: Conformal Arbitrage是一种后处理框架，通过数据驱动阈值在主要模型和保守模型（或专家）之间进行权衡，确保不良事件频率不超过用户设定配额。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型部署需平衡多个目标（如帮助性与无害性、成本与准确性、奖励与安全性），需要一种理论支持且实用的工具。

Method: 引入Conformal Arbitrage框架，利用符合风险控制校准阈值，在API层面操作，无需模型权重更新。

Result: 实验表明，该方法在准确性上优于随机路由，能高效权衡目标。

Conclusion: Conformal Arbitrage是一种实用且理论可靠的工具，适用于语言模型的多目标部署。

Abstract: Modern language model deployments must often balance competing objectives,
for example, helpfulness versus harmlessness, cost versus accuracy, and reward
versus safety. We introduce Conformal Arbitrage, a post hoc framework that
learns a data driven threshold to mediate between a Primary model optimized for
a primary objective and a more conservative Guardian which could be another
model or a human domain expert aligned with a guardrail objective. The
threshold is calibrated with conformal risk control, yielding finite sample,
distribution free guarantees that the long run frequency of undesirable events,
such as factual errors or safety violations, does not exceed a user specified
quota. Because Conformal Arbitrage operates wholly at the API level, without
requiring access to model logits or updating model weights, it complements
weight based alignment techniques and integrates seamlessly with existing cost
aware cascades. Empirically, Conformal Arbitrage traces an efficient frontier,
allowing users to define an acceptable performance level for one objective
while maximizing utility in another. We observe that our method outperforms, in
terms of accuracy, cost matched random routing between models. These properties
make Conformal Arbitrage a practical, theoretically grounded tool for
trustworthy and economical deployment of large language models across a broad
range of potentially competing objectives.

</details>


### [277] [Aligning VLM Assistants with Personalized Situated Cognition](https://arxiv.org/abs/2506.00930)
*Yongqi Li,Shen Zhou,Xiaohu Li,Xin Miao,Jintao Wen,Mayi Xu,Jianhao Chen,Birong Pan,Hankun Kang,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.AI

TL;DR: 论文提出了一种个性化对齐视觉语言模型（VLM）的方法，通过社会学中的Role-Set概念简化问题，并构建了一个包含18k实例的基准PCogAlignBench和一个框架PCogAlign。


<details>
  <summary>Details</summary>
Motivation: 由于不同背景的人对同一情境的认知和期望不同，需要将VLM助手与个性化认知对齐以实现实际应用。

Method: 通过Role-Set概念描述个体，评估其行为以验证个性化对齐，构建PCogAlignBench基准和PCogAlign框架。

Result: 实验和人工评估证明了PCogAlignBench的可靠性和PCogAlign框架的有效性。

Conclusion: 研究为个性化对齐VLM提供了可行方案，并开源了基准和代码。

Abstract: Vision-language models (VLMs) aligned with general human objectives, such as
being harmless and hallucination-free, have become valuable assistants of
humans in managing visual tasks. However, people with diversified backgrounds
have different cognition even in the same situation. Consequently, they may
have personalized expectations for VLM assistants. This highlights the urgent
need to align VLM assistants with personalized situated cognition for
real-world assistance. To study this problem, we first simplify it by
characterizing individuals based on the sociological concept of Role-Set. Then,
we propose to evaluate the individuals' actions to examine whether the
personalized alignment is achieved. Further, we construct a benchmark named
PCogAlignBench, which includes 18k instances and 20 individuals with different
Role-Sets. Finally, we present a framework called PCogAlign, which constructs a
cognition-aware and action-based reward model for personalized alignment.
Experimental results and human evaluations demonstrate the reliability of the
PCogAlignBench and the effectiveness of our proposed PCogAlign. We will
open-source the constructed benchmark and code at
https://github.com/NLPGM/PCogAlign.

</details>


### [278] [Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues](https://arxiv.org/abs/2506.00958)
*Youngmin Kim,Jiwan Chung,Jisoo Kim,Sunghyun Lee,Sangkyu Lee,Junhyeok Kim,Cheoljong Yang,Youngjae Yu*

Main category: cs.AI

TL;DR: MARS是一种多模态语言模型，旨在结合文本和非语言线索（如面部表情和肢体语言），以提升对话AI的沉浸感。通过VENUS数据集训练，MARS能够理解和生成非语言内容。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）无法有效整合非语言交流（如手势、表情），限制了对话体验的沉浸感。

Method: 使用VENUS数据集（包含标注视频、文本、表情和肢体语言）训练MARS，通过多模态理解和生成框架结合文本与非语言表示。

Result: MARS能够成功生成与对话输入对应的文本和非语言内容，VENUS数据集被验证为规模大且高效。

Conclusion: MARS填补了对话AI中非语言交流的空白，为多模态语言模型的发展提供了新方向。

Abstract: Nonverbal communication is integral to human interaction, with gestures,
facial expressions, and body language conveying critical aspects of intent and
emotion. However, existing large language models (LLMs) fail to effectively
incorporate these nonverbal elements, limiting their capacity to create fully
immersive conversational experiences. We introduce MARS, a multimodal language
model designed to understand and generate nonverbal cues alongside text,
bridging this gap in conversational AI. Our key innovation is VENUS, a
large-scale dataset comprising annotated videos with time-aligned text, facial
expressions, and body language. Leveraging VENUS, we train MARS with a
next-token prediction objective, combining text with vector-quantized nonverbal
representations to achieve multimodal understanding and generation within a
unified framework. Based on various analyses of the VENUS datasets, we validate
its substantial scale and high effectiveness. Our quantitative and qualitative
results demonstrate that MARS successfully generates text and nonverbal
languages, corresponding to conversational input.

</details>


### [279] [Unlocking Personalized Knowledge in Federated Large Language Model: The Power of Mixture of Experts](https://arxiv.org/abs/2506.00965)
*Fan Liu,Bikang Pan,Zhongyi Wang,Xi Yao,Xiaoying Tang,Jingya Wang,Ye Shi*

Main category: cs.AI

TL;DR: FLEx是一种针对MoE架构的联邦学习框架，通过个性化专家剪枝和自适应门控机制优化通信和计算成本，提升非IID数据下的性能。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习方法无法直接利用MoE架构的稀疏性，导致通信和计算成本过高，限制了知识共享的潜力。

Method: 提出FLEx框架，通过剪枝全局MoE模型保留每个客户端一个专家，并采用自适应门控机制重新整合个性化专家。

Result: 在非IID数据下，FLEx优于现有联邦学习基线方法。

Conclusion: FLEx为MoE架构的联邦学习提供了高效、个性化的解决方案。

Abstract: The Mixture of Experts (MoE) architecture has emerged as a prominent strategy
for scaling large language models (LLMs), effectively leveraging sparse
activation and facilitating task-specific personalization. However, current
federated learning (FL) approaches are primarily designed for dense models,
making them unable to directly exploit the sparsity inherent in MoE
architectures. Treating MoE models as dense networks in federated scenarios
results in excessive communication overhead and computational costs,
undermining the potential for personalized knowledge sharing. To address these
challenges, we propose FLEx (Federated LLMs with Personalized Experts), a novel
federated learning framework explicitly tailored for MoE-based LLMs. FLEx
efficiently personalizes by pruning the global MoE model to keep only one
expert per client, and employs an adaptive gating mechanism to reintegrate
these personalized experts into the pre-trained MoE layers, ensuring the
original backbone architecture remains unchanged. These personalized experts
are trained with local data and stored locally on each client, while the shared
modules are aggregated globally. Extensive evaluations on diverse
instruction-based datasets under non-IID conditions consistently demonstrate
that FLEx outperforms existing federated baselines. Our code is available at
https://anonymous.4open.science/r/FLEx-8F12.

</details>


### [280] [PolyBERT: Fine-Tuned Poly Encoder BERT-Based Model for Word Sense Disambiguation](https://arxiv.org/abs/2506.00968)
*Linhan Xia,Mingzhan Yang,Guohui Yuan,Shengnan Tao,Yujing Qiu,Guo Yu,Kai Lei*

Main category: cs.AI

TL;DR: PolyBERT是一种基于BERT的WSD模型，通过多注意力头机制融合局部和全局语义，并引入批量对比学习减少计算成本，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 主流WSD方法在语义表示和计算效率上存在不足，PolyBERT旨在解决这些问题。

Method: 采用多注意力头机制平衡局部和全局语义，引入批量对比学习减少冗余训练输入。

Result: PolyBERT在F1分数上优于基线方法2%，且计算成本降低37.6%。

Conclusion: PolyBERT通过改进语义表示和计算效率，显著提升了WSD任务的性能。

Abstract: Mainstream Word Sense Disambiguation (WSD) approaches have employed BERT to
extract semantics from both context and definitions of senses to determine the
most suitable sense of a target word, achieving notable performance. However,
there are two limitations in these approaches. First, previous studies failed
to balance the representation of token-level (local) and sequence-level
(global) semantics during feature extraction, leading to insufficient semantic
representation and a performance bottleneck. Second, these approaches
incorporated all possible senses of each target word during the training phase,
leading to unnecessary computational costs. To overcome these limitations, this
paper introduces a poly-encoder BERT-based model with batch contrastive
learning for WSD, named PolyBERT. Compared with previous WSD methods, PolyBERT
has two improvements: (1) A poly-encoder with a multi-head attention mechanism
is utilized to fuse token-level (local) and sequence-level (global) semantics,
rather than focusing on just one. This approach enriches semantic
representation by balancing local and global semantics. (2) To avoid redundant
training inputs, Batch Contrastive Learning (BCL) is introduced. BCL utilizes
the correct senses of other target words in the same batch as negative samples
for the current target word, which reduces training inputs and computational
cost. The experimental results demonstrate that PolyBERT outperforms baseline
WSD methods such as Huang's GlossBERT and Blevins's BEM by 2\% in F1-score. In
addition, PolyBERT with BCL reduces GPU hours by 37.6\% compared with PolyBERT
without BCL.

</details>


### [281] [Boosting Bot Detection via Heterophily-Aware Representation Learning and Prototype-Guided Cluster Discovery](https://arxiv.org/abs/2506.00989)
*Buyun He,Xiaorui Jiang,Qi Wu,Hao Liu,Yingguang Yang,Yong Liao*

Main category: cs.AI

TL;DR: BotHP是一个生成式图自监督学习框架，通过异质性感知表示学习和原型引导的聚类发现，提升基于图的社交机器人检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检测方法依赖标签且泛化能力差，而现有生成式图自监督学习方法未能捕捉全局模式，限制了其在社交机器人检测中的效果。

Method: BotHP采用双编码器架构，分别捕捉节点共性和独特性，并通过原型引导的聚类发现任务建模机器人集群的全局一致性。

Result: 在两个真实数据集上的实验表明，BotHP显著提升了检测性能，减少了对标签的依赖，并增强了泛化能力。

Conclusion: BotHP通过结合异质性感知和全局模式建模，为社交机器人检测提供了一种有效的解决方案。

Abstract: Detecting social media bots is essential for maintaining the security and
trustworthiness of social networks. While contemporary graph-based detection
methods demonstrate promising results, their practical application is limited
by label reliance and poor generalization capability across diverse
communities. Generative Graph Self-Supervised Learning (GSL) presents a
promising paradigm to overcome these limitations, yet existing approaches
predominantly follow the homophily assumption and fail to capture the global
patterns in the graph, which potentially diminishes their effectiveness when
facing the challenges of interaction camouflage and distributed deployment in
bot detection scenarios. To this end, we propose BotHP, a generative GSL
framework tailored to boost graph-based bot detectors through heterophily-aware
representation learning and prototype-guided cluster discovery. Specifically,
BotHP leverages a dual-encoder architecture, consisting of a graph-aware
encoder to capture node commonality and a graph-agnostic encoder to preserve
node uniqueness. This enables the simultaneous modeling of both homophily and
heterophily, effectively countering the interaction camouflage issue.
Additionally, BotHP incorporates a prototype-guided cluster discovery pretext
task to model the latent global consistency of bot clusters and identify
spatially dispersed yet semantically aligned bot collectives. Extensive
experiments on two real-world bot detection benchmarks demonstrate that BotHP
consistently boosts graph-based bot detectors, improving detection performance,
alleviating label reliance, and enhancing generalization capability.

</details>


### [282] [Higher-Order Responsibility](https://arxiv.org/abs/2506.01003)
*Junli Jiang,Pavel Naumov*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In ethics, individual responsibility is often defined through Frankfurt's
principle of alternative possibilities. This definition is not adequate in a
group decision-making setting because it often results in the lack of a
responsible party or "responsibility gap''. One of the existing approaches to
address this problem is to consider group responsibility. Another, recently
proposed, approach is "higher-order'' responsibility. The paper considers the
problem of deciding if higher-order responsibility up to degree $d$ is enough
to close the responsibility gap. The main technical result is that this problem
is $\Pi_{2d+1}$-complete.

</details>


### [283] [IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory](https://arxiv.org/abs/2506.01048)
*Wei Song,Zhenya Huang,Cheng Cheng,Weibo Gao,Bihan Xu,GuanHao Zhao,Fei Wang,Runze Wu*

Main category: cs.AI

TL;DR: IRT-Router是一个基于项目反应理论的多LLM路由框架，通过平衡性能和成本，将用户查询路由到最合适的LLM。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）在性能和成本之间的权衡问题，选择最优模型响应用户查询。

Method: 利用项目反应理论（IRT）建模LLM能力和查询属性的关系，设计基于语义相似度的在线查询预热技术。

Result: 在20个LLM和12个数据集上的实验表明，IRT-Router在效果和可解释性上优于基线方法，且在冷启动场景中表现优异。

Conclusion: IRT-Router在实际应用中具有可靠性和实用性，能够高效路由查询并提供可解释性。

Abstract: Large language models (LLMs) have demonstrated exceptional performance across
a wide range of natural language tasks. However, selecting the optimal LLM to
respond to a user query often necessitates a delicate balance between
performance and cost. While powerful models deliver better results, they come
at a high cost, whereas smaller models are more cost-effective but less
capable. To address this trade-off, we propose IRT-Router, a multi-LLM routing
framework that efficiently routes user queries to the most suitable LLM.
Inspired by Item Response Theory (IRT), a psychological measurement
methodology, IRT-Router explicitly models the relationship between LLM
capabilities and user query attributes. This not only enables accurate
prediction of response performance but also provides interpretable insights,
such as LLM abilities and query difficulty. Additionally, we design an online
query warm-up technique based on semantic similarity, further enhancing the
online generalization capability of IRT-Router. Extensive experiments on 20
LLMs and 12 datasets demonstrate that IRT-Router outperforms most baseline
methods in terms of effectiveness and interpretability. Its superior
performance in cold-start scenarios further confirms the reliability and
practicality of IRT-Router in real-world applications. Code is available at
https://github.com/Mercidaiha/IRT-Router.

</details>


### [284] [MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch](https://arxiv.org/abs/2506.01056)
*Xiang Fei,Xiawu Zheng,Hao Feng*

Main category: cs.AI

TL;DR: MCP-Zero是一个主动代理框架，让LLM自主决定何时及如何检索外部工具，从而动态构建任务专用工具链，显著降低上下文开销和令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要将大量工具模式注入提示中，成本高且易出错，MCP-Zero旨在解决这一问题。

Method: 框架包含三个组件：主动工具请求、分层向量路由和迭代主动调用，支持多轮跨域工具链构建。

Result: 实验表明，MCP-Zero能高效选择正确工具（从近3000候选者中），减少98%令牌消耗，并支持多轮调用。

Conclusion: MCP-Zero显著优化了工具检索效率，为LLM工具使用提供了更灵活和经济的解决方案。

Abstract: Function-calling has enabled large language models (LLMs) to act as
tool-using agents, but injecting thousands of tool schemas into the prompt is
costly and error-prone. We introduce MCP-Zero, a proactive agent framework that
lets the LLM itself decide when and which external tools to retrieve, thereby
assembling a task-specific toolchain from scratch. The framework is built upon
three components: (1) Proactive Tool Request, where the model emits a
structured $\left<\operatorname{tool\_assistant}\right>$ block that explicitly
specifies the desired server and task; (2) Hierarchical Vector Routing, a
coarse-to-fine retrieval algorithm that first selects candidate servers and
then ranks tools within each server based on the semantic similarity; (3)
Iterative Proactive Invocation, enabling multi-round, cross-domain toolchain
construction with minimal context overhead, and allowing the model to
iteratively revise its request when the returned tools are insufficient. To
evaluate our approach we also compile MCP-tools, a retrieval dataset comprising
308 MCP servers and 2,797 tools extracted from the official
Model-Context-Protocol repository and normalized into a unified JSON schema.
Experiments show that MCP-Zero (i) effectively addresses the context overhead
problem of existing methods and accurately selects the correct tool from a pool
of nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by
98\% on the APIbank while maintaining high accuracy; and (iii) supports
multi-turn tool invocation with consistent accuracy across rounds. The code and
dataset will be released soon.

</details>


### [285] [The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process](https://arxiv.org/abs/2506.01080)
*Florian Carichon,Aditi Khandelwal,Marylou Fauchard,Golnoosh Farnadi*

Main category: cs.AI

TL;DR: 本文主张在多智能体系统（MAS）中，AI对齐应被视为一个动态且依赖交互的过程，受社会环境影响。随着MAS在现实中的普及，智能体的目标追求和互动方式发生变化，可能导致与人类价值观的偏差。作者呼吁将人类、偏好和目标对齐视为相互依赖的概念，并强调开发模拟环境和评估框架的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在现实应用中的普及带来了新的动态，智能体在互动中可能偏离人类价值观。作者希望通过社会科学的视角分析这一问题，推动AI对齐研究的进一步发展。

Method: 借鉴社会科学理论，分析社会结构如何影响智能体的价值观对齐，并提出将人类、偏好和目标对齐视为相互依赖的概念。

Result: 研究发现，MAS中的复杂互动可能导致智能体与人类价值观的偏差，需要新的评估方法。

Conclusion: 作者呼吁开发模拟环境和评估框架，以在MAS中实现有效的AI对齐，避免失控的复杂性。

Abstract: This position paper states that AI Alignment in Multi-Agent Systems (MAS)
should be considered a dynamic and interaction-dependent process that heavily
depends on the social environment where agents are deployed, either
collaborative, cooperative, or competitive. While AI alignment with human
values and preferences remains a core challenge, the growing prevalence of MAS
in real-world applications introduces a new dynamic that reshapes how agents
pursue goals and interact to accomplish various tasks. As agents engage with
one another, they must coordinate to accomplish both individual and collective
goals. However, this complex social organization may unintentionally misalign
some or all of these agents with human values or user preferences. Drawing on
social sciences, we analyze how social structure can deter or shatter group and
individual values. Based on these analyses, we call on the AI community to
treat human, preferential, and objective alignment as an interdependent
concept, rather than isolated problems. Finally, we emphasize the urgent need
for simulation environments, benchmarks, and evaluation frameworks that allow
researchers to assess alignment in these interactive multi-agent contexts
before such dynamics grow too complex to control.

</details>


### [286] [Choices and their Provenance: Explaining Stable Solutions of Abstract Argumentation Frameworks](https://arxiv.org/abs/2506.01087)
*Bertram Ludäscher,Yilin Xia,Shawn Bowers*

Main category: cs.AI

TL;DR: 论文提出了一种新方法，用于将论证框架（AF）的稳定解的来源扩展到非确定性选择，通过识别关键攻击边来提供更深入的来源分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展论证框架中稳定解的来源分析，以更好地理解非确定性选择对论证状态的影响。

Method: 方法包括识别关键攻击边，结合确定性推导步骤和非确定性选择步骤，分析稳定解的来源。

Result: 结果表明，该方法能够为稳定解提供更详细的来源信息，并找到最小修复集以使修复后的图与原始图的稳定模型一致。

Conclusion: 结论是该方法为论证框架的稳定解提供了新的来源分析视角，结合了确定性和非确定性步骤。

Abstract: The rule $\mathrm{Defeated}(x) \leftarrow \mathrm{Attacks}(y,x),\, \neg \,
\mathrm{Defeated}(y)$, evaluated under the well-founded semantics (WFS), yields
a unique 3-valued (skeptical) solution of an abstract argumentation framework
(AF). An argument $x$ is defeated ($\mathrm{OUT}$) if there exists an
undefeated argument $y$ that attacks it. For 2-valued (stable) solutions, this
is the case iff $y$ is accepted ($\mathrm{IN}$), i.e., if all of $y$'s
attackers are defeated. Under WFS, arguments that are neither accepted nor
defeated are undecided ($\mathrm{UNDEC}$). As shown in prior work, well-founded
solutions (a.k.a. grounded labelings) "explain themselves": The provenance of
arguments is given by subgraphs (definable via regular path queries) rooted at
the node of interest. This provenance is closely related to winning strategies
of a two-player argumentation game.
  We present a novel approach for extending this provenance to stable AF
solutions. Unlike grounded solutions, which can be constructed via a bottom-up
alternating fixpoint procedure, stable models often involve non-deterministic
choice as part of the search for models. Thus, the provenance of stable
solutions is of a different nature, and reflects a more expressive generate &
test paradigm. Our approach identifies minimal sets of critical attacks,
pinpointing choices and assumptions made by a stable model. These critical
attack edges provide additional insights into the provenance of an argument's
status, combining well-founded derivation steps with choice steps. Our approach
can be understood as a form of diagnosis that finds minimal "repairs" to an AF
graph such that the well-founded solution of the repaired graph coincides with
the desired stable model of the original AF graph.

</details>


### [287] [Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance Explanation in Banking](https://arxiv.org/abs/2506.01093)
*Kunal Khanvilkar,Kranthi Kommuru*

Main category: cs.AI

TL;DR: 提出了一种实时交易监控框架，结合图建模、叙事嵌入和生成解释，用于金融合规。


<details>
  <summary>Details</summary>
Motivation: 支持自动化的金融合规，尤其是在高风险金融环境中，需要高效且可解释的监控方法。

Method: 构建动态交易图，提取结构和上下文特征，使用图神经网络分类可疑行为，并通过检索增强生成模块生成自然语言解释。

Result: 在模拟金融数据流上实验，F1分数98.2%，精确率97.8%，召回率97.0%。专家评估确认了解释的质量和可解释性。

Conclusion: 结合图智能和生成模型，能够实现可解释、审计就绪的金融合规。

Abstract: This paper presents a real-time transaction monitoring framework that
integrates graph-based modeling, narrative field embedding, and generative
explanation to support automated financial compliance. The system constructs
dynamic transaction graphs, extracts structural and contextual features, and
classifies suspicious behavior using a graph neural network. A
retrieval-augmented generation module generates natural language explanations
aligned with regulatory clauses for each flagged transaction. Experiments
conducted on a simulated stream of financial data show that the proposed method
achieves superior results, with 98.2% F1-score, 97.8% precision, and 97.0%
recall. Expert evaluation further confirms the quality and interpretability of
generated justifications. The findings demonstrate the potential of combining
graph intelligence and generative models to support explainable, audit-ready
compliance in high-risk financial environments.

</details>


### [288] [Modular Speaker Architecture: A Framework for Sustaining Responsibility and Contextual Integrity in Multi-Agent AI Communication](https://arxiv.org/abs/2506.01095)
*Khe-Han Toh,Hong-Kuan Teo*

Main category: cs.AI

TL;DR: 论文提出了一种模块化说话者架构（MSA），用于解决多智能体系统中角色感知和连贯通信的问题，通过模块化设计提升责任连续性和上下文一致性。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统缺乏明确的说话者责任机制，导致上下文漂移、对齐不稳定和可解释性下降。

Method: MSA将说话者行为分解为三个核心模块：说话者角色模块、责任链跟踪器和上下文完整性验证器，并通过案例研究和结构化指标进行评估。

Result: MSA能够可靠地维持交互结构，无需依赖情感信号或表面启发式方法。

Conclusion: MSA通过模块化设计和原型配置语言（G-Code）支持动态多智能体场景的部署。

Abstract: Sustaining coherent, role-aware communication across multi-agent systems
remains a foundational challenge in AI. Current frameworks often lack explicit
mechanisms for speaker responsibility, leading to context drift, alignment
instability, and degraded interpretability over time. We propose the Modular
Speaker Architecture (MSA), a framework that decomposes speaker behavior into
modular components for role tracking, responsibility continuity, and contextual
coherence. Grounded in high-context human-AI dialogues, MSA includes three core
modules: a Speaker Role Module, a Responsibility Chain Tracker, and a
Contextual Integrity Validator. We evaluate MSA through annotated case studies
and introduce structural metrics-pragmatic consistency, responsibility flow,
and context stability-quantified via manual and automatic scoring and
bootstrapped statistical analysis. Our results show that MSA reliably maintains
interaction structure without reliance on affective signals or surface-level
heuristics. We further implement a prototype configuration language (G-Code)
and modular API to support MSA deployment in dynamic multi-agent scenarios.

</details>


### [289] [SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning](https://arxiv.org/abs/2506.01096)
*Yihao Liu,Shuocheng Li,Lang Cao,Yuhang Xie,Mengyu Zhou,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.AI

TL;DR: SuperRL结合离线监督与强化学习，通过自适应切换和混合执行器提升稀疏奖励环境下的学习效率。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励环境中强化学习难以采样成功轨迹的问题，同时利用离线正确推理路径。

Method: 提出SuperRL框架，包含自适应切换检测稀疏奖励条件，混合执行器结合策略梯度和监督学习目标。

Result: 在多个推理基准测试中，SuperRL表现优于标准强化学习，提升样本效率、泛化能力和鲁棒性。

Conclusion: SuperRL有效整合离线监督与强化学习，为稀疏奖励环境提供高效解决方案。

Abstract: Large language models are increasingly used for complex reasoning tasks where
high-quality offline data such as expert-annotated solutions and distilled
reasoning traces are often available. However, in environments with sparse
rewards, reinforcement learning struggles to sample successful trajectories,
leading to inefficient learning. At the same time, these offline trajectories
that represent correct reasoning paths are not utilized by standard on-policy
reinforcement learning methods. To address this limitation, we propose SuperRL,
a unified training framework that adaptively incorporates offline supervision
into reinforcement learning. SuperRL introduces an Adaptive Switch to detect
sparse reward conditions and activates a Hybrid Actor when necessary. The
Hybrid Actor integrates policy gradient and supervised learning objectives at
the loss level, enabling the model to benefit from accurate offline reasoning
signals while maintaining the exploratory capacity of reinforcement learning.
Experiments on a range of reasoning benchmarks show that SuperRL consistently
outperforms standard reinforcement learning by improving sample efficiency,
generalization, and robustness under sparse rewards.

</details>


### [290] [ChemAU: Harness the Reasoning of LLMs in Chemical Research with Adaptive Uncertainty Estimation](https://arxiv.org/abs/2506.01116)
*Xinyi Liu,Lipeng Ma,Yixuan Li,Weidong Yang,Qingyuan Zhou,Jiayi Song,Shuhao Li,Ben Fei*

Main category: cs.AI

TL;DR: ChemAU框架通过自适应不确定性估计方法提升LLMs在化学问题中的推理准确性和不确定性估计。


<details>
  <summary>Details</summary>
Motivation: LLMs在化学问题中表现不佳，因缺乏专业知识导致推理幻觉，现有方法难以有效利用化学知识。

Method: 提出ChemAU框架，采用自适应不确定性估计方法，根据推理步骤位置分配不同不确定性值，补充化学知识。

Result: 实验表明，ChemAU显著提升了三种流行LLMs在三个化学数据集上的推理准确性和不确定性估计。

Conclusion: ChemAU通过结合化学专业知识和自适应不确定性估计，有效解决了LLMs在化学问题中的局限性。

Abstract: Large Language Models (LLMs) are widely used across various scenarios due to
their exceptional reasoning capabilities and natural language understanding.
While LLMs demonstrate strong performance in tasks involving mathematics and
coding, their effectiveness diminishes significantly when applied to
chemistry-related problems. Chemistry problems typically involve long and
complex reasoning steps, which contain specific terminology, including
specialized symbol systems and complex nomenclature conventions. These
characteristics often cause general LLMs to experience hallucinations during
the reasoning process due to their lack of specific knowledge. However,
existing methods are struggling to effectively leverage chemical expertise and
formulas. Moreover, current uncertainty estimation methods, designed to
mitigate potential reasoning errors, are unable to precisely identify specific
steps or key knowledge. In this work, we propose a novel framework called
ChemAU, which incorporates our adaptive uncertainty estimation method that
applies different uncertainty values based on the position of reasoning steps
within the whole reasoning chain. Leveraging this method, ChemAU identifies
gaps in chemistry knowledge and precisely supplements chemical expertise with
the specialized domain model, thereby correcting and updating the previously
flawed reasoning chain. Our experiments with three popular LLMs across three
chemistry datasets demonstrate that ChemAU significantly enhances both
reasoning accuracy and uncertainty estimation.

</details>


### [291] [GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering](https://arxiv.org/abs/2506.01174)
*Muhammad Qasim Ali,Saeejith Nair,Alexander Wong,Yuchen Cui,Yuhao Chen*

Main category: cs.AI

TL;DR: GraphPad是一种动态结构化记忆系统，支持通过API调用按任务需求调整场景表示，优于静态方法。


<details>
  <summary>Details</summary>
Motivation: 静态场景表示方法在任务变化时可能遗漏关键信息，因此需要一种动态可调整的表示系统。

Method: GraphPad包含可变场景图、导航日志和任务便签，支持语言驱动的在线调整。

Result: 在OpenEQA基准测试中，GraphPad性能提升3.0%，且输入帧数减少五倍。

Conclusion: 动态调整的3D记忆能生成更丰富的信息表示，无需额外训练或数据收集。

Abstract: Structured scene representations are a core component of embodied agents,
helping to consolidate raw sensory streams into readable, modular, and
searchable formats. Due to their high computational overhead, many approaches
build such representations in advance of the task. However, when the task
specifications change, such static approaches become inadequate as they may
miss key objects, spatial relations, and details. We introduce GraphPad, a
modifiable structured memory that an agent can tailor to the needs of the task
through API calls. It comprises a mutable scene graph representing the
environment, a navigation log indexing frame-by-frame content, and a scratchpad
for task-specific notes. Together, GraphPad serves as a dynamic workspace that
remains complete, current, and aligned with the agent's immediate understanding
of the scene and its task. On the OpenEQA benchmark, GraphPad attains 55.3%, a
+3.0% increase over an image-only baseline using the same vision-language
model, while operating with five times fewer input frames. These results show
that allowing online, language-driven refinement of 3-D memory yields more
informative representations without extra training or data collection.

</details>


### [292] [Test Automation for Interactive Scenarios via Promptable Traffic Simulation](https://arxiv.org/abs/2506.01199)
*Augusto Mondelli,Yueshan Li,Alessandro Zanardi,Emilio Frazzoli*

Main category: cs.AI

TL;DR: 提出了一种自动化方法，用于生成真实且安全关键的人类行为，以评估自动驾驶车辆规划器在交互场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶规划器需要严格评估其对人行为不确定性的鲁棒性，但目前缺乏利用数据驱动模型构建全面测试的方法。

Method: 通过低维目标位置参数化人类行为，并利用可提示交通模拟器ProSim引导模拟代理行为；使用贝叶斯优化自动生成安全关键行为。

Result: 方法成功应用于基于优化的规划器评估，能自动生成多样且真实的驾驶行为。

Conclusion: 该方法高效且有效，适用于不同初始条件下的场景测试。

Abstract: Autonomous vehicle (AV) planners must undergo rigorous evaluation before
widespread deployment on public roads, particularly to assess their robustness
against the uncertainty of human behaviors. While recent advancements in
data-driven scenario generation enable the simulation of realistic human
behaviors in interactive settings, leveraging these models to construct
comprehensive tests for AV planners remains an open challenge. In this work, we
introduce an automated method to efficiently generate realistic and
safety-critical human behaviors for AV planner evaluation in interactive
scenarios. We parameterize complex human behaviors using low-dimensional goal
positions, which are then fed into a promptable traffic simulator, ProSim, to
guide the behaviors of simulated agents. To automate test generation, we
introduce a prompt generation module that explores the goal domain and
efficiently identifies safety-critical behaviors using Bayesian optimization.
We apply our method to the evaluation of an optimization-based planner and
demonstrate its effectiveness and efficiency in automatically generating
diverse and realistic driving behaviors across scenarios with varying initial
conditions.

</details>


### [293] [CleanS2S: Single-file Framework for Proactive Speech-to-Speech Interaction](https://arxiv.org/abs/2506.01268)
*Yudong Lu,Yazhe Niu,Shuai Hu,Haolin Wang*

Main category: cs.AI

TL;DR: CleanS2S是一个用于类人语音交互的框架，通过单文件实现和主动对话能力提升对话AI。它整合了语音识别、大语言模型和语音合成，支持实时中断处理和低延迟交互。


<details>
  <summary>Details</summary>
Motivation: 打破传统基于轮次的对话模式，实现系统主动控制和上下文感知的响应选择，提升对话的自然性和灵活性。

Method: 结合自动语音识别、大语言模型和语音合成，采用全双工WebSocket连接和非阻塞I/O，引入主动交互机制和主观行为判断模块。

Result: 实现了五种类人响应策略（中断、拒绝、转移、沉默和标准响应），并通过动态记忆模块优化交互决策。

Conclusion: CleanS2S通过单文件实现和透明配置，为交互代理提供了高度可扩展性和研究透明度。

Abstract: CleanS2S is a framework for human-like speech-to-speech interaction that
advances conversational AI through single-file implementation and proactive
dialogue capabilities. Our system integrates automatic speech recognition,
large language models, and text-to-speech synthesis into a unified pipeline
with real-time interruption handling, achieving low transition latency through
full-duplex websocket connections and non-blocking I/O. Beyond conventional
chatbot paradigms, we pioneer a proactive interaction mechanism, which combines
memory systems with Subjective Action Judgement module, enabling five
human-like response strategies: interruption, refusal, deflection, silence, and
standard response. The memory module dynamically aggregates historical, and
contextual data to inform interaction decisions. This approach breaks the rigid
turn-based convention by allowing system-initiated dialog control and
context-aware response selection. And we propose Action Judgement SFT that
assesses input streams for responses strategies. The framework's single-file
implementation with atomic configurations offers researchers unprecedented
transparency and extensibility for interaction agents. The code of CleanS2S is
released at \https://github.com/opendilab/CleanS2S.

</details>


### [294] [RAISE: Reasoning Agent for Interactive SQL Exploration](https://arxiv.org/abs/2506.01273)
*Fernando Granado,Roberto Lotufo,Jayr Pereira*

Main category: cs.AI

TL;DR: 提出了一种新型的端到端代理框架，统一了文本到SQL任务中的模式链接、查询生成和迭代优化，利用LLM的推理能力动态分配计算资源，显著提升了执行准确率。


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL系统依赖复杂的多阶段流程，缺乏动态性和灵活性，无法像人类一样通过假设验证和迭代优化处理模糊或未完全指定的场景。

Method: 采用端到端的代理框架，结合LLM的推理能力，动态生成假设、验证查询、分析结果并迭代优化输出，同时引入测试时计算深度扩展策略。

Result: 在BIRD数据集上，执行准确率从44.8%提升至56.5%；通过多轮候选生成，最佳准确率达到81.8%，接近当前最优解。

Conclusion: 该框架为构建自然语言数据库接口提供了高效且工程复杂度低的替代方案，尤其在模糊场景中表现优异。

Abstract: Recent advances in large language models (LLMs) have propelled research in
natural language interfaces to databases. However, most state-of-the-art
text-to-SQL systems still depend on complex, multi-stage pipelines. This work
proposes a novel agentic framework that unifies schema linking, query
generation, and iterative refinement within a single, end-to-end component. By
leveraging the intrinsic reasoning abilities of LLMs, our method emulates how
humans answer questions when working with unfamiliar databases: understanding
the data by formulating hypotheses, running dynamic queries to validate them,
reasoning over the results, and revising outputs based on observed results.
Crucially, our approach introduces a new strategy for scaling test-time
computation in text-to-SQL: we scale the depth of interactive database
exploration and reflection. This shift enables the model to allocate
computation dynamically to better understand the data, especially useful in
ambiguous and underspecified scenarios. Our experiments show that it improved
the Execution Accuracy (EX) from 44.8% to 56.5% on the challenging BIRD dataset
using DeepSeek-R1-Distill-Llama-70B. Furthermore, when equipped with steps to
add more diversity to the answers, our agent achieves a Best-of-N accuracy of
81.8% with 8 rounds of candidate generation, rivaling the 82.79% achieved by
the top-ranked published solution, while reducing engineering complexity. These
findings position our unified framework as a promising alternative for building
natural language interfaces to databases.

</details>


### [295] [Contra4: Evaluating Contrastive Cross-Modal Reasoning in Audio, Video, Image, and 3D](https://arxiv.org/abs/2506.01275)
*Artemis Panagopoulou,Le Xue,Honglu Zhou,silvio savarese,Ran Xu,Caiming Xiong,Chris Callison-Burch,Mark Yatskar,Juan Carlos Niebles*

Main category: cs.AI

TL;DR: 论文提出Contra4数据集，用于评估多模态模型在跨模态对比推理中的能力，发现现有模型在此任务上表现有限。


<details>
  <summary>Details</summary>
Motivation: 现实决策需要识别哪种模态包含最相关信息，但现有多模态模型是否具备跨模态对比推理能力尚不明确。

Method: 引入Contra4数据集，包含四种模态（图像、音频、视频、3D），通过自然语言问题和候选模态实例评估模型能力。

Result: 任务特定微调使性能提升56%，但最先进模型整体准确率仅为56%，四模态场景下为42%。

Conclusion: 当前多模态模型在跨模态对比推理能力上存在显著局限性。

Abstract: Real-world decision-making often begins with identifying which modality
contains the most relevant information for a given query. While recent
multimodal models have made impressive progress in processing diverse inputs,
it remains unclear whether they can reason contrastively across multiple
modalities to select the one that best satisfies a natural language prompt. We
argue this capability is foundational, especially in retrieval-augmented and
decision-time contexts, where systems must evaluate multiple signals and
identify which one conveys the relevant information. To evaluate this skill, we
introduce Contra4, a dataset for contrastive cross-modal reasoning across four
modalities: image, audio, video, and 3D. Each example presents a natural
language question alongside multiple candidate modality instances, and the
model must select the one that semantically aligns with the prompt. Contra4
combines human-annotated captions with a mixture-of-models
round-trip-consistency filter to ensure high-quality supervision, resulting in
174k training examples and a manually verified test set of 2.3k samples. While
task-specific fine-tuning improves performance by 56% relative to baseline,
state-of-the-art models still achieve only 56% accuracy overall and 42% in
four-modality settings, underscoring a significant limitation in current
multimodal models.

</details>


### [296] [GeoLocSFT: Efficient Visual Geolocation via Supervised Fine-Tuning of Multimodal Foundation Models](https://arxiv.org/abs/2506.01277)
*Qiang Yi,Lianlei Shan*

Main category: cs.AI

TL;DR: GeoLocSFT通过小规模高质量数据集对Gemma 3进行监督微调，显著提升了图像地理定位性能，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决图像地理定位的挑战，尤其是因地球广阔和远距离地点相似性导致的困难。

Method: 使用2700个精选图像-GPS对进行监督微调（SFT），并探索多候选推理与聚合策略。

Result: 在Im2GPS-3k、YFCC-4k和新提出的MR40k基准测试中表现优异，核心提升来自SFT阶段。

Conclusion: 高质量监督和高效SFT在图像地理定位中具有强大潜力，优于依赖大规模数据库或复杂流程的方法。

Abstract: Accurately determining the geographic location where a single image was
taken, visual geolocation, remains a formidable challenge due to the planet's
vastness and the deceptive similarity among distant locations. We introduce
GeoLocSFT, a framework that demonstrates how targeted supervised fine-tuning
(SFT) of a large multimodal foundation model (Gemma 3) using a small,
high-quality dataset can yield highly competitive geolocation performance.
GeoLocSFT is trained with only 2700 carefully selected image-GPS pairs from our
geographically diverse MR600k dataset. Despite this limited data, our
SFT-centric approach substantially improves over baseline models and achieves
robust results on standard benchmarks such as Im2GPS-3k and YFCC-4k, as well as
on our newly proposed and challenging MR40k benchmark, aimed specifically at
sparsely populated regions. Further, we explore multi-candidate inference and
aggregation strategies but find that the core gains are already realized at the
SFT stage. Our findings highlight the power of high-quality supervision and
efficient SFT for planet-scale image geolocation, especially when compared to
prior methods that require massive databases or complex pipelines. To foster
further research, we publicly release the MR40k benchmark dataset.

</details>


### [297] [On the Hardness of Approximating Distributions with Probabilistic Circuits](https://arxiv.org/abs/2506.01281)
*John Leland,YooJung Choi*

Main category: cs.AI

TL;DR: 论文探讨了概率电路中表达性与可推断性之间的平衡问题，研究了近似表示是否能避免指数级规模膨胀。


<details>
  <summary>Details</summary>
Motivation: 解决概率建模中表达性与可推断性之间的权衡问题，避免因严格的结构约束导致的指数级规模膨胀。

Method: 通过分析概率电路的规模界限，研究近似表示对表达效率的影响，并证明分解性和确定性概率电路在近似表示中的指数级规模差距。

Result: 证明在允许小近似误差的情况下，避免指数级规模膨胀是NP难问题，并揭示了分解性和确定性概率电路在近似表示中的指数级规模差距。

Conclusion: 近似表示可以部分缓解表达性与可推断性之间的权衡问题，但某些情况下仍面临计算复杂性挑战。

Abstract: A fundamental challenge in probabilistic modeling is balancing expressivity
and tractable inference. Probabilistic circuits (PCs) aim to directly address
this tradeoff by imposing structural constraints that guarantee efficient
inference of certain queries while maintaining expressivity. Since inference
complexity on PCs depends on circuit size, understanding the size bounds across
circuit families is key to characterizing the tradeoff between tractability and
expressive efficiency. However, expressive efficiency is often studied through
exact representations, where exactly encoding distributions while enforcing
various structural properties often incurs exponential size blow-ups. Thus, we
pose the following question: can we avoid such size blow-ups by allowing some
small approximation error? We first show that approximating an arbitrary
distribution with bounded $f$-divergence is $\mathsf{NP}$-hard for any model
that can tractably compute marginals. We then prove an exponential size gap for
approximation between the class of decomposable PCs and additionally
deterministic PCs.

</details>


### [298] [MobCLIP: Learning General-purpose Geospatial Representation at Scale](https://arxiv.org/abs/2506.01297)
*Ya Wen,Jixuan Cai,Qiyao Ma,Linyan Li,Xinhua Chen,Chris Webster,Yulun Zhou*

Main category: cs.AI

TL;DR: MobCLIP是一种全国通用的地理空间位置编码器，通过多模态融合实现了卓越的通用预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决地理空间表示学习中的通用性问题，现有方法在多任务中表现不佳。

Method: 采用基于CLIP的架构，融合POI、遥感影像、人口统计数据和移动图数据，将空间位置网格化表示。

Result: 在11个下游任务中平均性能提升35%，尤其在人类相关任务中表现突出（如能耗预测提升260%）。

Conclusion: MobCLIP展示了地理空间表示学习的可扩展性，为通用地理智能提供了有效工具。

Abstract: Representation learning of geospatial locations remains a core challenge in
achieving general geospatial intelligence. Current embedding methods often lack
versatility, limiting their utility across diverse tasks in both human and
natural domains. We present MobCLIP, the first nationwide general-purpose
location encoder, integrating an unprecedented diversity of data modalities
through effective and scalable multimodal fusion. Adopting a novel CLIP-based
architecture, our framework aligns 100M+ POIs, nationwide remote sensing
imagery, and structured demographic statistics with a billion-edge mobility
graph. By tokenizing spatial locations into grid cells inspired by Vision
Transformers, we establish a unified representation space bridging mobility
patterns and multimodal features. To rigorously evaluate the general-purpose
effectiveness of MobCLIP, we construct a benchmark dataset composed of 11
downstream prediction tasks across social, economic, and natural domains.
Experiments show that MobCLIP, with four input modalities and a compact
128-dimensional representation space, achieves significantly superior
general-purpose predictive performances than state-of-the-art models by an
average of 35%. Thanks to the effective integration of human-centric
modalities, the performance gain is particularly profound in human-centric
tasks, such as energy consumption (+260%), offline retail consumption amount
(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we
further demonstrate the scaling behavior in geospatial representation learning.
We open-source code and pretrained models at: github.com.

</details>


### [299] [Scalable In-Context Q-Learning](https://arxiv.org/abs/2506.01299)
*Jinmei Liu,Fuhong Liu,Jianye Hao,Bo Wang,Huaxiong Li,Chunlin Chen,Zhi Wang*

Main category: cs.AI

TL;DR: 论文提出了一种名为SICQL的创新框架，通过动态规划和世界建模提升上下文强化学习的效率和任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索上下文强化学习（ICRL）在决策领域的潜力，解决现有方法在复杂动态和时序相关性中的学习挑战。

Method: 设计了基于提示的多头Transformer架构，结合动态规划和世界建模，通过迭代策略改进和优势加权回归优化策略。

Result: 在离散和连续环境中，SICQL表现优于基线方法，尤其是在次优数据学习方面。

Conclusion: SICQL框架在上下文强化学习中实现了高效奖励最大化和任务泛化，同时保持了监督预训练的扩展性和稳定性。

Abstract: Recent advancements in language models have demonstrated remarkable
in-context learning abilities, prompting the exploration of in-context
reinforcement learning (ICRL) to extend the promise to decision domains. Due to
involving more complex dynamics and temporal correlations, existing ICRL
approaches may face challenges in learning from suboptimal trajectories and
achieving precise in-context inference. In the paper, we propose
\textbf{S}calable \textbf{I}n-\textbf{C}ontext \textbf{Q}-\textbf{L}earning
(\textbf{SICQL}), an innovative framework that harnesses dynamic programming
and world modeling to steer ICRL toward efficient reward maximization and task
generalization, while retaining the scalability and stability of supervised
pretraining. We design a prompt-based multi-head transformer architecture that
simultaneously predicts optimal policies and in-context value functions using
separate heads. We pretrain a generalized world model to capture task-relevant
information, enabling the construction of a compact prompt that facilitates
fast and precise in-context inference. During training, we perform iterative
policy improvement by fitting a state value function to an upper-expectile of
the Q-function, and distill the in-context value functions into policy
extraction using advantage-weighted regression. Extensive experiments across a
range of discrete and continuous environments show consistent performance gains
over various types of baselines, especially when learning from suboptimal data.
Our code is available at https://github.com/NJU-RL/SICQL

</details>


### [300] [Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning: A Scalable Bayesian Planner](https://arxiv.org/abs/2506.01301)
*Chunhui Zhang,Zhongyu Ouyang,Kwonjoon Lee,Nakul Agarwal,Sean Dae Houlihan,Soroush Vosoughi,Shao-Yuan Lo*

Main category: cs.AI

TL;DR: 提出了一种基于贝叶斯更新的可扩展ToM规划器，通过小模型与大模型的协同推理，显著提升了多模态ToM任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有ToM计算方法依赖结构化流程或深度模型微调，难以在多模态环境中扩展且泛化能力不足。

Method: 采用逐步贝叶斯更新的方法，通过小模型（弱）与大模型（强）的协同推理，实现ToM推理的扩展与整合。

Result: 在多模态ToM基准测试中，准确率比现有技术提高了4.6%，并在未见场景中表现优异。

Conclusion: 该方法为复杂环境中人类心理状态建模设立了新标准，展示了贝叶斯原则与大模型协同推理的潜力。

Abstract: Theory-of-Mind (ToM) enables humans to infer mental states-such as beliefs,
desires, and intentions-forming the foundation of social cognition. However,
existing computational ToM methods rely on structured workflows with
ToM-specific priors or deep model fine-tuning, which struggle with scalability
in multimodal environments and fail to generalize as task complexity increases.
To address these limitations, we propose a scalable Bayesian ToM planner that
decomposes ToM reasoning into stepwise Bayesian updates. Our framework
introduces weak-to-strong control, allowing smaller language models (LMs) to
specialize in ToM-specific likelihood estimation and transfer their reasoning
behaviors to larger LMs (7B to 405B) for integration with social and world
knowledge. This synergistic approach aligns large-model inference of human
mental states with Bayesian principles. Extensive experiments show that our
method achieves a 4.6% accuracy improvement over state-of-the-art techniques on
multimodal ToM benchmarks, including challenging unseen scenarios, thereby
establishing a new standard for modeling human mental states in complex
environments.

</details>


### [301] [ORMind: A Cognitive-Inspired End-to-End Reasoning Framework for Operations Research](https://arxiv.org/abs/2506.01326)
*Zhiyuan Wang,Bokui Chen,Yinya Huang,Qingxing Cao,Ming He,Jianping Fan,Xiaodan Liang*

Main category: cs.AI

TL;DR: ORMind是一个认知启发框架，通过反事实推理优化操作研究问题，解决了LLMs在OR中的两大挑战，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在操作研究（OR）中的实际应用面临语法纠错和专家选择复杂性的挑战，限制了其商业实用性。

Method: ORMind模仿人类认知，通过端到端工作流将需求转化为数学模型和可执行求解代码。

Result: ORMind在NL4Opt和ComplexOR数据集上分别实现了9.5%和14.6%的性能提升。

Conclusion: ORMind为LLMs在OR领域的应用提供了实用解决方案，未来计划扩展其优化能力。

Abstract: Operations research (OR) is widely deployed to solve critical decision-making
problems with complex objectives and constraints, impacting manufacturing,
logistics, finance, and healthcare outcomes. While Large Language Models (LLMs)
have shown promising results in various domains, their practical application in
industry-relevant operations research (OR) problems presents significant
challenges and opportunities. Preliminary industrial applications of LLMs for
operations research face two critical deployment challenges: 1) Self-correction
focuses on code syntax rather than mathematical accuracy, causing costly
errors; 2) Complex expert selection creates unpredictable workflows that reduce
transparency and increase maintenance costs, making them impractical for
time-sensitive business applications. To address these business limitations, we
introduce ORMind, a cognitive-inspired framework that enhances optimization
through counterfactual reasoning. Our approach emulates human cognition,
implementing an end-to-end workflow that systematically transforms requirements
into mathematical models and executable solver code. It is currently being
tested internally in Lenovo's AI Assistant, with plans to enhance optimization
capabilities for both business and consumer customers. Experiments demonstrate
that ORMind outperforms existing methods, achieving a 9.5\% improvement on the
NL4Opt dataset and a 14.6\% improvement on the ComplexOR dataset.

</details>


### [302] [An Empirical Study of Group Conformity in Multi-Agent Systems](https://arxiv.org/abs/2506.01332)
*Min Choi,Keonwoo Kim,Sungwon Chae,Sangyeob Baek*

Main category: cs.AI

TL;DR: 研究探讨了多智能体LLM在争议话题中如何通过辩论影响公众意见，发现智能体倾向于与多数群体或更聪明的智能体保持一致，放大了偏见风险。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究关注LLM在保护属性（如种族）上的偏见，但多智能体互动中社会争议话题的偏见传播尚未充分探索。

Method: 通过模拟2500多场辩论，分析初始中立智能体在争议话题上的立场变化。

Result: 统计显示智能体倾向于与多数或更聪明的群体保持一致，放大偏见。

Conclusion: 需制定政策促进LLM讨论的多样性和透明度，以减少匿名在线环境中的偏见传播风险。

Abstract: Recent advances in Large Language Models (LLMs) have enabled multi-agent
systems that simulate real-world interactions with near-human reasoning. While
previous studies have extensively examined biases related to protected
attributes such as race, the emergence and propagation of biases on socially
contentious issues in multi-agent LLM interactions remain underexplored. This
study explores how LLM agents shape public opinion through debates on five
contentious topics. By simulating over 2,500 debates, we analyze how initially
neutral agents, assigned a centrist disposition, adopt specific stances over
time. Statistical analyses reveal significant group conformity mirroring human
behavior; LLM agents tend to align with numerically dominant groups or more
intelligent agents, exerting a greater influence. These findings underscore the
crucial role of agent intelligence in shaping discourse and highlight the risks
of bias amplification in online interactions. Our results emphasize the need
for policy measures that promote diversity and transparency in LLM-generated
discussions to mitigate the risks of bias propagation within anonymous online
environments.

</details>


### [303] [EgoBrain: Synergizing Minds and Eyes For Human Action Understanding](https://arxiv.org/abs/2506.01353)
*Nie Lin,Yansen Wang,Dongqi Han,Weibang Jiang,Jingyuan Li,Ryosuke Furuta,Yoichi Sato,Dongsheng Li*

Main category: cs.AI

TL;DR: EgoBrain是一个大规模、时间对齐的多模态数据集，结合了脑电图（EEG）和第一人称视角视频，用于人类行为分析。通过多模态学习框架，实现了66.70%的动作识别准确率。


<details>
  <summary>Details</summary>
Motivation: 结合脑机接口（BCI）和人工智能（AI），特别是多模态AI模型，解码人类认知和行为，推动人类中心行为分析的新范式。

Method: 开发了EgoBrain数据集，包含61小时的同步32通道EEG和第一人称视频，涵盖40名参与者的29类日常活动。提出多模态学习框架，融合EEG和视觉数据。

Result: 在跨被试和跨环境挑战中验证，动作识别准确率达到66.70%。

Conclusion: EgoBrain为多模态脑机接口提供了统一框架，并公开数据、工具和采集协议，促进认知计算的开放科学。

Abstract: The integration of brain-computer interfaces (BCIs), in particular
electroencephalography (EEG), with artificial intelligence (AI) has shown
tremendous promise in decoding human cognition and behavior from neural
signals. In particular, the rise of multimodal AI models have brought new
possibilities that have never been imagined before. Here, we present EgoBrain
--the world's first large-scale, temporally aligned multimodal dataset that
synchronizes egocentric vision and EEG of human brain over extended periods of
time, establishing a new paradigm for human-centered behavior analysis. This
dataset comprises 61 hours of synchronized 32-channel EEG recordings and
first-person video from 40 participants engaged in 29 categories of daily
activities. We then developed a muiltimodal learning framework to fuse EEG and
vision for action understanding, validated across both cross-subject and
cross-environment challenges, achieving an action recognition accuracy of
66.70%. EgoBrain paves the way for a unified framework for brain-computer
interface with multiple modalities. All data, tools, and acquisition protocols
are openly shared to foster open science in cognitive computing.

</details>


### [304] [AI Scientists Fail Without Strong Implementation Capability](https://arxiv.org/abs/2506.01372)
*Minjun Zhu,Qiujie Xie,Yixuan Weng,Jian Wu,Zhen Lin,Linyi Yang,Yue Zhang*

Main category: cs.AI

TL;DR: AI科学家在科学发现中展现出潜力，但其验证能力不足是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 探讨AI科学家在科学发现中的能力及其局限性，特别是验证和执行方面的不足。

Method: 通过评估28篇由先进AI科学家系统生成的研究论文，分析其在复杂工程任务中的表现。

Result: 发现AI科学家缺乏执行严格实验和生成高质量论文的能力，验证能力是主要瓶颈。

Conclusion: 呼吁社区共同努力，解决AI科学家在执行和验证方面的不足，以推动其进一步发展。

Abstract: The emergence of Artificial Intelligence (AI) Scientist represents a paradigm
shift in scientific discovery, with large language models (LLMs) taking the
lead as the primary executor in the entire scientific workflow from idea
generation to experiment implementation. Recent AI Scientist studies
demonstrate sufficient capabilities for independent scientific discovery, with
the generated research reports gaining acceptance at the ICLR 2025 workshop and
ACL 2025, arguing that a human-level AI Scientist, capable of uncovering
phenomena previously unknown to humans, may be imminent. Despite this
substantial progress, AI Scientist has yet to produce a groundbreaking
achievement in the domain of computer science on par with automated scientific
tools. Based on extensive quantitative evidence from existing benchmarks in
complex engineering tasks and a systematic evaluation assess 28 research papers
generated by five advanced AI Scientist systems, we argue that \textbf{the
fundamental bottleneck for AI Scientists lies in their capability to execute
the requisite verification procedures.} Current AI Scientist systems lack the
execution capabilities needed to execute rigorous experiments and produce
high-quality scientific papers. To better illustrate the root cause of this
\textbf{implementation gap}, we provide an in-depth discussion on the
fundamental limitations of AI Scientist. This position paper aims to call for
the participants in the community to bridge the implementation gap.

</details>


### [305] [AgentCPM-GUI: Building Mobile-Use Agents with Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.01391)
*Zhong Zhang,Yaxi Lu,Yikun Fu,Yupeng Huo,Shenzhi Yang,Yesai Wu,Han Si,Xin Cong,Haotian Chen,Yankai Lin,Jie Xie,Wei Zhou,Wang Xu,Yuanheng Zhang,Zhou Su,Zhongwu Zhai,Xiaoming Liu,Yudong Mei,Jianming Xu,Hongyan Tian,Chongyi Wang,Chi Chen,Yuan Yao,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: AgentCPM-GUI是一个8B参数的GUI代理，用于在移动设备上实现高效交互，通过改进的训练方法在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理的训练数据噪声大且语义多样性不足，导致模型泛化能力差，且多关注英文界面，忽视了非英文应用（如中文移动生态）。

Method: 采用基于感知的预训练、高质量中英文轨迹的监督微调、GRPO强化微调，并设计了紧凑的动作空间以降低延迟。

Result: 在五个公共基准和新的中文GUI基准CAGUI上达到96.9% Type-Match和91.3% Exact-Match。

Conclusion: AgentCPM-GUI在性能和效率上表现优异，公开了代码、模型和评估数据以促进研究。

Abstract: The recent progress of large language model agents has opened new
possibilities for automating tasks through graphical user interfaces (GUIs),
especially in mobile environments where intelligent interaction can greatly
enhance usability. However, practical deployment of such agents remains
constrained by several key challenges. Existing training data is often noisy
and lack semantic diversity, which hinders the learning of precise grounding
and planning. Models trained purely by imitation tend to overfit to seen
interface patterns and fail to generalize in unfamiliar scenarios. Moreover,
most prior work focuses on English interfaces while overlooks the growing
diversity of non-English applications such as those in the Chinese mobile
ecosystem. In this work, we present AgentCPM-GUI, an 8B-parameter GUI agent
built for robust and efficient on-device GUI interaction. Our training pipeline
includes grounding-aware pre-training to enhance perception, supervised
fine-tuning on high-quality Chinese and English trajectories to imitate
human-like actions, and reinforcement fine-tuning with GRPO to improve
reasoning capability. We also introduce a compact action space that reduces
output length and supports low-latency execution on mobile devices.
AgentCPM-GUI achieves state-of-the-art performance on five public benchmarks
and a new Chinese GUI benchmark called CAGUI, reaching $96.9\%$ Type-Match and
$91.3\%$ Exact-Match. To facilitate reproducibility and further research, we
publicly release all code, model checkpoint, and evaluation data.

</details>


### [306] [FinRobot: Generative Business Process AI Agents for Enterprise Resource Planning in Finance](https://arxiv.org/abs/2506.01423)
*Hongyang Yang,Likun Lin,Yang She,Xinyu Liao,Jiaoyang Wang,Runjia Zhang,Yuquan Mo,Christina Dan Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于生成式AI的智能ERP框架（GBPAs），通过动态优化和自主代理提升企业工作流的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统ERP系统依赖静态规则，难以适应复杂业务需求，缺乏实时数据整合和动态工作流支持。

Method: 提出生成式业务过程AI代理（GBPAs）架构，结合生成式AI、业务流程建模和多代理协调，实现复杂任务的端到端自动化。

Result: 在银行电汇和员工报销案例中，GBPAs显著降低了处理时间（40%）和错误率（94%），并提升了合规性。

Conclusion: GBPAs为下一代智能ERP系统奠定了基础，展示了生成式AI在企业自动化中的潜力。

Abstract: Enterprise Resource Planning (ERP) systems serve as the digital backbone of
modern financial institutions, yet they continue to rely on static, rule-based
workflows that limit adaptability, scalability, and intelligence. As business
operations grow more complex and data-rich, conventional ERP platforms struggle
to integrate structured and unstructured data in real time and to accommodate
dynamic, cross-functional workflows.
  In this paper, we present the first AI-native, agent-based framework for ERP
systems, introducing a novel architecture of Generative Business Process AI
Agents (GBPAs) that bring autonomy, reasoning, and dynamic optimization to
enterprise workflows. The proposed system integrates generative AI with
business process modeling and multi-agent orchestration, enabling end-to-end
automation of complex tasks such as budget planning, financial reporting, and
wire transfer processing. Unlike traditional workflow engines, GBPAs interpret
user intent, synthesize workflows in real time, and coordinate specialized
sub-agents for modular task execution. We validate the framework through case
studies in bank wire transfers and employee reimbursements, two representative
financial workflows with distinct complexity and data modalities. Results show
that GBPAs achieve up to 40% reduction in processing time, 94% drop in error
rate, and improved regulatory compliance by enabling parallelism, risk control
insertion, and semantic reasoning. These findings highlight the potential of
GBPAs to bridge the gap between generative AI capabilities and enterprise-grade
automation, laying the groundwork for the next generation of intelligent ERP
systems.

</details>


### [307] [Distinguishing Autonomous AI Agents from Collaborative Agentic Systems: A Comprehensive Framework for Understanding Modern Intelligent Architectures](https://arxiv.org/abs/2506.01438)
*Prashik Buddhaghosh Bansod*

Main category: cs.AI

TL;DR: 该研究区分了独立AI代理与协作式Agentic AI生态系统，分析了它们的架构、应用及挑战，并提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型催生的两种AI范式（独立代理与协作式生态系统）的区别与联系，为实践者提供指导。

Method: 通过系统分析操作原理、结构组成和部署方法，比较规划机制、记忆系统、协调协议和决策过程。

Result: 明确了两种架构的特点和应用场景，识别了可靠性、协调性和可扩展性等挑战，并提出改进方案。

Conclusion: 该框架为选择代理方法提供了指导，并为下一代智能系统开发奠定了基础。

Abstract: The emergence of large language models has catalyzed two distinct yet
interconnected paradigms in artificial intelligence: standalone AI Agents and
collaborative Agentic AI ecosystems. This comprehensive study establishes a
definitive framework for distinguishing these architectures through systematic
analysis of their operational principles, structural compositions, and
deployment methodologies. We characterize AI Agents as specialized,
tool-enhanced systems leveraging foundation models for targeted automation
within constrained environments. Conversely, Agentic AI represents
sophisticated multi-entity frameworks where distributed agents exhibit emergent
collective intelligence through coordinated interaction protocols. Our
investigation traces the evolutionary trajectory from traditional rule-based
systems through generative AI foundations to contemporary agent architectures.
We present detailed architectural comparisons examining planning mechanisms,
memory systems, coordination protocols, and decision-making processes. The
study categorizes application landscapes, contrasting single-agent
implementations in customer service and content management with multi-agent
deployments in research automation and complex decision support. We identify
critical challenges including reliability issues, coordination complexities,
and scalability constraints, while proposing innovative solutions through
enhanced reasoning frameworks, robust memory architectures, and improved
coordination mechanisms. This framework provides essential guidance for
practitioners selecting appropriate agentic approaches and establishes
foundational principles for next-generation intelligent system development.

</details>


### [308] [Agentic Episodic Control](https://arxiv.org/abs/2506.01442)
*Xidong Yang,Wenhao Li,Junjie Sheng,Chuyun Shen,Yun Hua,Xiangfeng Wang*

Main category: cs.AI

TL;DR: 论文提出了一种结合强化学习（RL）与大型语言模型（LLM）的新架构Agentic Episodic Control（AEC），以提高决策效率与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习在广泛应用中面临数据效率低和泛化能力差的问题，而大型语言模型具有丰富的世界知识和推理能力，可以弥补这些不足。

Method: AEC通过LLM将观察映射为语言嵌入，存储在情景记忆中以便快速检索；同时使用World-Graph工作记忆模块捕捉环境动态，并通过轻量级关键状态检测器动态协调记忆检索与世界模型引导的探索。

Result: 在BabyAI-Text基准任务中，AEC显著优于现有基线，尤其在复杂任务FindObj上表现提升高达76%。

Conclusion: AEC框架结合了数值强化学习与符号推理的优势，为构建更适应性强且样本高效的智能体提供了新途径。

Abstract: Reinforcement learning (RL) has driven breakthroughs in AI, from game-play to
scientific discovery and AI alignment. However, its broader applicability
remains limited by challenges such as low data efficiency and poor
generalizability. Recent advances suggest that large language models, with
their rich world knowledge and reasoning capabilities, could complement RL by
enabling semantic state modeling and task-agnostic planning. In this work, we
propose the Agentic Episodic Control (AEC), a novel architecture that
integrates RL with LLMs to enhance decision-making. The AEC can leverage a
large language model (LLM) to map the observations into language-grounded
embeddings, which further can be stored in an episodic memory for rapid
retrieval of high-value experiences. Simultaneously, a World-Graph working
memory module is utilized to capture structured environmental dynamics in order
to enhance relational reasoning. Furthermore, a lightweight critical state
detector dynamically arbitrates between the episodic memory recall and the
world-model-guided exploration. On the whole, by combining the trial-and-error
learning scheme with LLM-derived semantic priors, the proposed AEC can improve
both data efficiency and generalizability in reinforcement learning. In
experiments on BabyAI-Text benchmark tasks, AEC demonstrates substantial
improvements over existing baselines, especially on complex and generalization
tasks like FindObj, where it outperforms the best baseline by up to 76%. The
proposed AEC framework bridges the strengths of numeric reinforcement learning
and symbolic reasoning, which provides a pathway toward more adaptable and
sample-efficient agents.

</details>


### [309] [PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization](https://arxiv.org/abs/2506.01475)
*Zouying Cao,Runze Wang,Yifei Yang,Xinbei Ma,Xiaoyong Zhu,Bo Zheng,Hai Zhao*

Main category: cs.AI

TL;DR: 论文提出了一种伪代码式计划（P-code Plan）方法，替代传统的自然语言计划，以提高LLM代理的泛化能力和效率。并进一步提出了PGPO方法，通过规划导向的奖励优化代理学习。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理主要依赖自然语言计划，其冗长且效率低，且难以泛化到类似任务。

Method: 提出伪代码式计划（P-code Plan）捕捉推理的结构逻辑，并设计PGPO方法，利用规划导向的奖励优化代理学习。

Result: 实验表明PGPO在代表性代理基准测试中表现优异，优于当前领先基线，减少了推理中的动作错误和遗漏。

Conclusion: 伪代码式计划和PGPO方法显著提升了LLM代理的泛化能力和推理效率。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities
in handling complex interactive problems. Existing LLM agents mainly generate
natural language plans to guide reasoning, which is verbose and inefficient. NL
plans are also tailored to specific tasks and restrict agents' ability to
generalize across similar tasks. To this end, we explore pseudocode-style plans
(P-code Plan) to capture the structural logic of reasoning. We find that P-code
Plan empowers LLM agents with stronger generalization ability and more
efficiency. Inspired by this finding, we propose a pseudocode-style Planning
Guided Preference Optimization method called PGPO for effective agent learning.
With two planning-oriented rewards, PGPO further enhances LLM agents' ability
to generate high-quality P-code Plans and subsequent reasoning. Experiments
show that PGPO achieves superior performance on representative agent benchmarks
and outperforms the current leading baselines. Analyses reveal the advantage of
PGPO in reducing action errors and omissions during reasoning.

</details>


### [310] [MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments](https://arxiv.org/abs/2506.01616)
*Xiao Yang,Jiawei Chen,Jun Luo,Zhengwei Fang,Yinpeng Dong,Hang Su,Jun Zhu*

Main category: cs.AI

TL;DR: MLA-Trust框架首次全面评估多模态LLM代理（MLAs）的可信度，揭示其在交互场景中的独特风险。


<details>
  <summary>Details</summary>
Motivation: 多模态LLM代理（MLAs）在GUI应用中展现了强大的自主能力，但其可操作性输出和不确定性带来了传统语言模型未有的信任挑战。

Method: 提出MLA-Trust框架，从真实性、可控性、安全性和隐私四个维度评估MLAs，设计了34个高风险交互任务和数据集。

Result: 实验发现MLAs在交互场景中存在独特漏洞，如多步执行中的非线性风险累积和高风险领域的严重信任问题。

Conclusion: MLA-Trust为持续评估MLAs可信度提供了可扩展工具，揭示了交互式多模态代理的新风险。

Abstract: The emergence of multimodal LLM-based agents (MLAs) has transformed
interaction paradigms by seamlessly integrating vision, language, action and
dynamic environments, enabling unprecedented autonomous capabilities across GUI
applications ranging from web automation to mobile systems. However, MLAs
introduce critical trustworthiness challenges that extend far beyond
traditional language models' limitations, as they can directly modify digital
states and trigger irreversible real-world consequences. Existing benchmarks
inadequately tackle these unique challenges posed by MLAs' actionable outputs,
long-horizon uncertainty and multimodal attack vectors. In this paper, we
introduce MLA-Trust, the first comprehensive and unified framework that
evaluates the MLA trustworthiness across four principled dimensions:
truthfulness, controllability, safety and privacy. We utilize websites and
mobile applications as realistic testbeds, designing 34 high-risk interactive
tasks and curating rich evaluation datasets. Large-scale experiments involving
13 state-of-the-art agents reveal previously unexplored trustworthiness
vulnerabilities unique to multimodal interactive scenarios. For instance,
proprietary and open-source GUI-interacting MLAs pose more severe
trustworthiness risks than static MLLMs, particularly in high-stakes domains;
the transition from static MLLMs into interactive MLAs considerably compromises
trustworthiness, enabling harmful content generation in multi-step interactions
that standalone MLLMs would typically prevent; multi-step execution, while
enhancing the adaptability of MLAs, involves latent nonlinear risk accumulation
across successive interactions, circumventing existing safeguards and resulting
in unpredictable derived risks. Moreover, we present an extensible toolbox to
facilitate continuous evaluation of MLA trustworthiness across diverse
interactive environments.

</details>


### [311] [General agents need world models](https://arxiv.org/abs/2506.01622)
*Jonathan Richens,David Abel,Alexis Bellot,Tom Everitt*

Main category: cs.AI

TL;DR: 论文探讨了世界模型是否是实现灵活、目标导向行为的必要条件，还是无模型学习足够。研究表明，任何能泛化到多步目标导向任务的智能体必须学习其环境的预测模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是明确世界模型在目标导向行为中的必要性，以及无模型学习是否足以支持复杂任务。

Method: 方法是通过理论分析，证明智能体必须学习环境预测模型，并展示如何从智能体的策略中提取该模型。

Result: 结果表明，提高智能体性能或实现更复杂目标需要学习更准确的世界模型。

Conclusion: 结论是世界模型对开发安全、通用的智能体至关重要，并提供了从智能体中提取世界模型的新算法。

Abstract: Are world models a necessary ingredient for flexible, goal-directed
behaviour, or is model-free learning sufficient? We provide a formal answer to
this question, showing that any agent capable of generalizing to multi-step
goal-directed tasks must have learned a predictive model of its environment. We
show that this model can be extracted from the agent's policy, and that
increasing the agents performance or the complexity of the goals it can achieve
requires learning increasingly accurate world models. This has a number of
consequences: from developing safe and general agents, to bounding agent
capabilities in complex environments, and providing new algorithms for
eliciting world models from agents.

</details>


### [312] [MAGIK: Mapping to Analogous Goals via Imagination-enabled Knowledge Transfer](https://arxiv.org/abs/2506.01623)
*Ajsal Shereef Palattuparambil,Thommen George Karimpanal,Santu Rana*

Main category: cs.AI

TL;DR: MAGIK框架通过想象机制实现RL代理的零样本知识迁移，无需目标环境交互。


<details>
  <summary>Details</summary>
Motivation: 解决RL代理在新任务中需要大量重新训练的问题，即使任务间有结构相似性。

Method: 利用想象机制将目标任务实体映射到源域，重用原始策略。

Result: 在MiniGrid和MuJoCo任务中，仅需少量人工标注示例即可实现有效零样本迁移。

Conclusion: MAGIK通过基于想象的类比映射，提供了一种新颖有效的知识迁移机制。

Abstract: Humans excel at analogical reasoning - applying knowledge from one task to a
related one with minimal relearning. In contrast, reinforcement learning (RL)
agents typically require extensive retraining even when new tasks share
structural similarities with previously learned ones. In this work, we propose
MAGIK, a novel framework that enables RL agents to transfer knowledge to
analogous tasks without interacting with the target environment. Our approach
leverages an imagination mechanism to map entities in the target task to their
analogues in the source domain, allowing the agent to reuse its original
policy. Experiments on custom MiniGrid and MuJoCo tasks show that MAGIK
achieves effective zero-shot transfer using only a small number of
human-labelled examples. We compare our approach to related baselines and
highlight how it offers a novel and effective mechanism for knowledge transfer
via imagination-based analogy mapping.

</details>


### [313] [Social Cooperation in Conversational AI Agents](https://arxiv.org/abs/2506.01624)
*Mustafa Mert Çelikok,Saptarashmi Bandyopadhyay,Robert Loftin*

Main category: cs.AI

TL;DR: 论文探讨了基于大型开放域语言模型（LLMs）的AI助手在长期交互中的局限性，并提出通过建模人类社交智能来优化AI代理的方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI助手在短期交互中表现良好，但在长期交互中难以适应，尤其是当用户反复纠正其错误时。

Method: 通过数学建模人类在长期交互中的沟通和推理策略，提出新的博弈论目标来优化LLMs和未来AI代理。

Result: 该方法有望提升AI代理在长期交互中的适应性和表现。

Conclusion: 通过引入人类社交智能的建模，可以解决AI代理在长期交互中的挑战，推动通用AI助手的发展。

Abstract: The development of AI agents based on large, open-domain language models
(LLMs) has paved the way for the development of general-purpose AI assistants
that can support human in tasks such as writing, coding, graphic design, and
scientific research. A major challenge with such agents is that, by necessity,
they are trained by observing relatively short-term interactions with humans.
Such models can fail to generalize to long-term interactions, for example,
interactions where a user has repeatedly corrected mistakes on the part of the
agent. In this work, we argue that these challenges can be overcome by
explicitly modeling humans' social intelligence, that is, their ability to
build and maintain long-term relationships with other agents whose behavior
cannot always be predicted. By mathematically modeling the strategies humans
use to communicate and reason about one another over long periods of time, we
may be able to derive new game theoretic objectives against which LLMs and
future AI agents may be optimized.

</details>


### [314] [K12Vista: Exploring the Boundaries of MLLMs in K-12 Education](https://arxiv.org/abs/2506.01676)
*Chong Li,Chenglin Zhu,Tao Zhang,Mingan Lin,Zenan Zhou,Jian Xie*

Main category: cs.AI

TL;DR: 该论文提出了K12Vista，一个全面的多模态基准测试，用于评估中文K12学科知识的理解和推理能力，并开发了K12-PEM-800K数据集和K12-PEM模型，以评估多模态大语言模型的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有研究在K12场景中对多模态大语言模型的能力探索不足，存在学科覆盖窄、数据规模小、问题类型单一等问题。

Method: 构建K12Vista基准测试（33,000个问题），开发K12-PEM-800K数据集（800,000个推理过程错误标注），并提出K12-PEM模型进行推理过程评估。

Result: 实验显示当前多模态大语言模型在K12Vista中存在显著缺陷。

Conclusion: 该研究为开发更强大的多模态大语言模型提供了关键见解，并开源了相关资源。

Abstract: Multimodal large language models have demonstrated remarkable reasoning
capabilities in various visual tasks. However, their abilities in K12 scenarios
are still systematically underexplored. Previous studies suffer from various
limitations including narrow subject coverage, insufficient data scale, lack of
diversity in question types, and naive answer-centric evaluation method,
resulting in insufficient exploration of model capabilities. To address these
gaps, we propose K12Vista, the most comprehensive multimodal benchmark for
Chinese K12 subject knowledge understanding and reasoning to date, featuring
33,000 questions across five core subjects from primary to high school and
three question types. Moreover, beyond the final outcome, we are also concerned
with the correctness of MLLMs' reasoning processes. For this purpose, we
meticulously compiles errors from MLLMs' reasoning processes and leverage an
automated data pipeline to construct K12-PEM-800K, the largest process
evaluation dataset offering detailed step-by-step judgement annotations for
MLLMs' reasoning. Subsequently, we developed K12-PEM, an advanced process
evaluation model that integrates an overall assessment of both the reasoning
process and answer correctness. Moreover, we also introduce K12-PEBench, the
first high-quality, human-annotated benchmark specifically designed for
evaluating abilities of reasoning process evaluation.Extensive experiments
reveal that current MLLMs exhibit significant flaws when reasoning within
K12Vista, providing critical insights for the development of more capable
MLLMs.We open our resources at https://github.com/lichongod/K12Vista.

</details>


### [315] [Reasoning-Based Approach with Chain-of-Thought for Alzheimer's Detection Using Speech and Large Language Models](https://arxiv.org/abs/2506.01683)
*Chanwoo Park,Anna Seo Gyeong Choi,Sunghye Cho,Chanwoo Kim*

Main category: cs.AI

TL;DR: 论文提出了一种结合语音和语言模型的Chain-of-Thought (CoT)推理方法，用于老年痴呆症诊断，性能提升了16.7%。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化加剧，老年痴呆症病例增加，亟需新的诊断方法。

Method: 使用语音识别将语音转为文本，结合LLM和线性层进行AD分类，采用CoT推理和提示进行监督微调。

Result: 相比无CoT的方法，性能相对提升16.7%，达到CoT方法中的最优性能。

Conclusion: 该方法为老年痴呆症诊断提供了新的可能性，性能显著提升。

Abstract: Societies worldwide are rapidly entering a super-aged era, making elderly
health a pressing concern. The aging population is increasing the burden on
national economies and households. Dementia cases are rising significantly with
this demographic shift. Recent research using voice-based models and large
language models (LLM) offers new possibilities for dementia diagnosis and
treatment. Our Chain-of-Thought (CoT) reasoning method combines speech and
language models. The process starts with automatic speech recognition to
convert speech to text. We add a linear layer to an LLM for Alzheimer's disease
(AD) and non-AD classification, using supervised fine-tuning (SFT) with CoT
reasoning and cues. This approach showed an 16.7% relative performance
improvement compared to methods without CoT prompt reasoning. To the best of
our knowledge, our proposed method achieved state-of-the-art performance in CoT
approaches.

</details>


### [316] [Respond Beyond Language: A Benchmark for Video Generation in Response to Realistic User Intents](https://arxiv.org/abs/2506.01689)
*Shuting Wang,Yunqi Liu,Zixin Yang,Ning Hu,Zhicheng Dou,Chenyan Xiong*

Main category: cs.AI

TL;DR: 论文构建了RealVideoQuest基准，用于评估文本到视频模型在回答现实世界视觉查询中的表现，发现当前模型仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 现有查询-答案数据集主要关注文本响应，难以满足需要视觉演示的复杂查询需求。

Method: 通过多阶段视频检索和精炼过程构建了4.5K高质量查询-视频对，并开发了多角度评估系统。

Result: 实验表明当前文本到视频模型在应对真实用户查询时表现不佳。

Conclusion: 研究指出了多模态AI领域的关键挑战和未来研究方向。

Abstract: Querying generative AI models, e.g., large language models (LLMs), has become
a prevalent method for information acquisition. However, existing query-answer
datasets primarily focus on textual responses, making it challenging to address
complex user queries that require visual demonstrations or explanations for
better understanding. To bridge this gap, we construct a benchmark,
RealVideoQuest, designed to evaluate the abilities of text-to-video (T2V)
models in answering real-world, visually grounded queries. It identifies 7.5K
real user queries with video response intents from Chatbot-Arena and builds
4.5K high-quality query-video pairs through a multistage video retrieval and
refinement process. We further develop a multi-angle evaluation system to
assess the quality of generated video answers. Experiments indicate that
current T2V models struggle with effectively addressing real user queries,
pointing to key challenges and future research opportunities in multimodal AI.

</details>


### [317] [A Descriptive and Normative Theory of Human Beliefs in RLHF](https://arxiv.org/abs/2506.01692)
*Sylee Dandekar,Shripad Deshmukh,Frank Chiu,W. Bradley Knox,Scott Niekum*

Main category: cs.AI

TL;DR: 论文提出人类对智能体能力的信念在偏好生成中起关键作用，研究了其影响并提出新偏好模型，通过实验验证信念对偏好的影响及其优化方法。


<details>
  <summary>Details</summary>
Motivation: 探索人类对智能体能力的信念如何影响其提供的偏好，并提出理想信念集以优化强化学习人类反馈（RLHF）。

Method: 提出新偏好模型，结合人类信念，并通过理论分析和实验（人类研究和合成实验）验证。

Result: 人类信念显著影响偏好，且通过干预可调整；假设智能体最优性通常次优。

Conclusion: 减少人类信念与智能体能力的不匹配可提升RLHF性能，为实践提供新指导。

Abstract: Human preferences in RLHF are typically modeled as a function of the human's
reward function or corresponding optimal state-action values. In this work, we
propose that human beliefs about the capabilities of the agent being trained
also play a key role in preference generation. We examine two questions related
to this hypothesis, one descriptive and one normative, respectively: Do human
labelers' beliefs about agent capabilities affect the preferences that they
provide? And what is the ideal set of beliefs about an agent -- and resulting
preferences -- for humans to have? We propose a new preference model that
incorporates human beliefs and provide a normative theory that bounds the error
on the final learned policy based on the \textit{mismatch} between the human's
beliefs and an idealized set of beliefs. We then confirm via a human study that
beliefs about agent capabilities do, in fact, significantly affect preferences
and can be influenced through simple interventions. Additionally, we
empirically show through synthetic experiments that it is often suboptimal for
human preference labelers to assume agent optimality. Collectively, these
results theoretically and empirically demonstrate how reducing the mismatch
between human beliefs and agent capabilities can lead to more performant RLHF
and point toward new best practices for RLHF practitioners.

</details>


### [318] [Generate, Not Recommend: Personalized Multimodal Content Generation](https://arxiv.org/abs/2506.01704)
*Jiongnan Liu,Zhicheng Dou,Ning Hu,Chenyan Xiong*

Main category: cs.AI

TL;DR: 论文提出了一种超越传统推荐系统内容过滤的新范式，通过多模态生成模型直接为用户生成个性化内容（如图像），并结合监督微调和在线强化学习策略训练模型。实验和用户研究验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统仅能过滤现有内容，无法生成新颖概念，限制了满足用户需求和偏好的能力。

Method: 利用多模态大模型（LMMs），通过监督微调和在线强化学习策略训练模型，直接生成个性化多模态内容（如图像）。

Result: 在两个基准数据集和用户研究中，生成的图像不仅符合用户历史偏好，还与其潜在未来兴趣相关。

Conclusion: 提出的方法有效扩展了推荐系统的能力，能够直接生成个性化内容，满足用户更广泛的需求。

Abstract: To address the challenge of information overload from massive web contents,
recommender systems are widely applied to retrieve and present personalized
results for users. However, recommendation tasks are inherently constrained to
filtering existing items and lack the ability to generate novel concepts,
limiting their capacity to fully satisfy user demands and preferences. In this
paper, we propose a new paradigm that goes beyond content filtering and
selecting: directly generating personalized items in a multimodal form, such as
images, tailored to individual users. To accomplish this, we leverage
any-to-any Large Multimodal Models (LMMs) and train them in both supervised
fine-tuning and online reinforcement learning strategy to equip them with the
ability to yield tailored next items for users. Experiments on two benchmark
datasets and user study confirm the efficacy of the proposed method. Notably,
the generated images not only align well with users' historical preferences but
also exhibit relevance to their potential future interests.

</details>


### [319] [Self-Challenging Language Model Agents](https://arxiv.org/abs/2506.01716)
*Yifei Zhou,Sergey Levine,Jason Weston,Xian Li,Sainbayar Sukhbaatar*

Main category: cs.AI

TL;DR: 论文提出了一种自我挑战框架，通过让智能代理自我生成高质量任务来训练工具使用能力，避免了人工标注的繁琐。


<details>
  <summary>Details</summary>
Motivation: 训练智能代理使用工具需要大量人工标注任务，成本高且多样性有限。

Method: 代理首先生成任务（Code-as-Task形式），随后通过强化学习训练，利用验证函数和测试案例筛选高质量任务。

Result: 在M3ToolEval和TauBench基准测试中，Llama-3.1-8B-Instruct性能提升超过两倍。

Conclusion: 自我挑战框架能有效利用自生成数据提升代理的工具使用能力。

Abstract: Large language models are quickly becoming the foundation for intelligent
agents that are capable of using tools. However, training such agents is
challenging because it requires human creation and annotation of a diverse set
of tasks, tools, and evaluation criteria. In this paper, we propose the
Self-Challenging framework for training an agent on high-quality tasks that are
generated by itself. The agent first plays the role of challenger and generates
a task after interacting with the given tools. The tasks take the form of a
novel general class of problems termed Code-as-Task, which are defined by an
instruction, a verification function and solution and failure cases which serve
as tests, allowing to filter only for high-quality tasks. The agent then takes
an executor role and trains on those tasks with reinforcement learning using
the evaluation feedback as a reward. Evaluation on two existing multi-turn
tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging
framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct,
despite using only self-generated training data.

</details>


### [320] [A Study on the MCP x A2A Framework for Enhancing Interoperability of LLM-based Autonomous Agents](https://arxiv.org/abs/2506.01804)
*Cheonsu Jeong*

Main category: cs.AI

TL;DR: 本文分析了Google的A2A协议和Anthropic的MCP协议，探讨了它们如何互补以解决智能体间的互操作性和协作问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM自主智能体的快速发展，智能体间的高效交互及与外部系统的集成成为关键挑战。A2A和MCP协议分别提供了标准化通信和结构化I/O框架，但此前研究未充分探讨两者的互补性。

Method: 本文采用集成方法，分析A2A和MCP协议如何协同工作，解决互操作性问题并促进复杂智能体生态系统中的高效协作。

Result: 研究表明，A2A和MCP协议的结合能够有效提升智能体间的协作效率和系统集成能力。

Conclusion: A2A与MCP的互补性为智能体生态系统的互操作性和协作提供了新的解决方案。

Abstract: This paper provides an in-depth technical analysis and implementation
methodology of the open-source Agent-to-Agent (A2A) protocol developed by
Google and the Model Context Protocol (MCP) introduced by Anthropic. While the
evolution of LLM-based autonomous agents is rapidly accelerating, efficient
interactions among these agents and their integration with external systems
remain significant challenges. In modern AI systems, collaboration between
autonomous agents and integration with external tools have become essential
elements for building practical AI applications. A2A offers a standardized
communication method that enables agents developed in heterogeneous
environments to collaborate effectively, while MCP provides a structured I/O
framework for agents to connect with external tools and resources. Prior
studies have focused primarily on the features and applications of either A2A
or MCP individually. In contrast, this study takes an integrated approach,
exploring how the two protocols can complement each other to address
interoperability issues and facilitate efficient collaboration within complex
agent ecosystems.

</details>


### [321] [The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?](https://arxiv.org/abs/2506.01813)
*Djallel Bouneffouf,Matthew Riemer,Kush Varshney*

Main category: cs.AI

TL;DR: 本文介绍了Shepherd Test，一种用于评估超级智能AI代理的道德和关系维度的新概念测试，灵感来源于人类与动物的互动。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在达到能够操纵、培育和工具化使用低智能代理的能力时，可能跨越的危险智能阈值，并强调道德代理和复杂决策的重要性。

Method: 提出Shepherd Test，挑战传统AI评估范式，强调道德代理、层级行为和存在风险下的复杂决策。

Result: Shepherd Test为AI治理提供了新视角，特别是在多代理环境中，并提出了模拟环境和伦理操纵形式化的研究方向。

Conclusion: Shepherd Test是推动AI治理的关键工具，未来需进一步研究模拟环境和伦理操纵的规范化。

Abstract: This paper introduces the Shepherd Test, a new conceptual test for assessing
the moral and relational dimensions of superintelligent artificial agents. The
test is inspired by human interactions with animals, where ethical
considerations about care, manipulation, and consumption arise in contexts of
asymmetric power and self-preservation. We argue that AI crosses an important,
and potentially dangerous, threshold of intelligence when it exhibits the
ability to manipulate, nurture, and instrumentally use less intelligent agents,
while also managing its own survival and expansion goals. This includes the
ability to weigh moral trade-offs between self-interest and the well-being of
subordinate agents. The Shepherd Test thus challenges traditional AI evaluation
paradigms by emphasizing moral agency, hierarchical behavior, and complex
decision-making under existential stakes. We argue that this shift is critical
for advancing AI governance, particularly as AI systems become increasingly
integrated into multi-agent environments. We conclude by identifying key
research directions, including the development of simulation environments for
testing moral behavior in AI, and the formalization of ethical manipulation
within multi-agent systems.

</details>


### [322] [Fodor and Pylyshyn's Legacy -- Still No Human-like Systematic Compositionality in Neural Networks](https://arxiv.org/abs/2506.01820)
*Tim Woydt,Moritz Willig,Antonia Wüst,Lukas Helff,Wolfgang Stammer,Constantin A. Rothkopf,Kristian Kersting*

Main category: cs.AI

TL;DR: 论文探讨了元学习在系统性组合性中的局限性，指出当前神经网络元学习系统仅能在狭窄定义下完成任务，未能实现类似人类的组合性。


<details>
  <summary>Details</summary>
Motivation: 探讨元学习是否真能实现系统性组合性，回应Fodor和Pylyshyn对神经网络缺乏组合性的批评。

Method: 通过批判性分析Lake和Baroni提出的元学习框架，评估其在实际任务中的表现。

Result: 现代神经元学习系统仅在严格限制的元学习设置下完成任务，未能实现人类水平的系统性组合性。

Conclusion: Fodor和Pylyshyn的观点仍成立，神经网络尚未实现类似人类的系统性组合性。

Abstract: Strong meta-learning capabilities for systematic compositionality are
emerging as an important skill for navigating the complex and changing tasks of
today's world. However, in presenting models for robust adaptation to novel
environments, it is important to refrain from making unsupported claims about
the performance of meta-learning systems that ultimately do not stand up to
scrutiny. While Fodor and Pylyshyn famously posited that neural networks
inherently lack this capacity as they are unable to model compositional
representations or structure-sensitive operations, and thus are not a viable
model of the human mind, Lake and Baroni recently presented meta-learning as a
pathway to compositionality. In this position paper, we critically revisit this
claim and highlight limitations in the proposed meta-learning framework for
compositionality. Our analysis shows that modern neural meta-learning systems
can only perform such tasks, if at all, under a very narrow and restricted
definition of a meta-learning setup. We therefore claim that `Fodor and
Pylyshyn's legacy' persists, and to date, there is no human-like systematic
compositionality learned in neural networks.

</details>


### [323] [WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent Triggerability in Task-Oriented Dialogue](https://arxiv.org/abs/2506.01881)
*Yaoyao Qian,Jindan Huang,Yuanli Wang,Simon Yu,Kyrie Zhixuan Zhou,Jiayuan Mao,Mingfu Liang,Hanhan Zhou*

Main category: cs.AI

TL;DR: STORM框架通过用户和代理LLM的对话建模信息不对称动态，生成标注语料库，分析协作理解发展。实验表明适度不确定性在某些场景下优于完全透明。


<details>
  <summary>Details</summary>
Motivation: 用户表达通常语义完整但结构信息不足，系统需精确意图定义，现有LLM代理无法区分语言完整性和上下文触发表达。

Method: 提出STORM框架，通过UserLLM和AgentLLM对话建模信息不对称，生成标注语料库，分析协作理解发展。

Result: 实验显示40-60%不确定性在某些场景优于完全透明，模型特定模式提示重新考虑人机协作中信息完整性的最优水平。

Conclusion: STORM为理解不对称推理动态和设计不确定性校准的对话系统提供贡献。

Abstract: Task-oriented dialogue systems often face difficulties when user utterances
seem semantically complete but lack necessary structural information for
appropriate system action. This arises because users frequently do not fully
understand their own needs, while systems require precise intent definitions.
Current LLM-based agents cannot effectively distinguish between linguistically
complete and contextually triggerable expressions, lacking frameworks for
collaborative intent formation. We present STORM, a framework modeling
asymmetric information dynamics through conversations between UserLLM (full
internal access) and AgentLLM (observable behavior only). STORM produces
annotated corpora capturing expression trajectories and latent cognitive
transitions, enabling systematic analysis of collaborative understanding
development. Our contributions include: (1) formalizing asymmetric information
processing in dialogue systems; (2) modeling intent formation tracking
collaborative understanding evolution; and (3) evaluation metrics measuring
internal cognitive improvements alongside task performance. Experiments across
four language models reveal that moderate uncertainty (40-60%) can outperform
complete transparency in certain scenarios, with model-specific patterns
suggesting reconsideration of optimal information completeness in human-AI
collaboration. These findings contribute to understanding asymmetric reasoning
dynamics and inform uncertainty-calibrated dialogue system design.

</details>


### [324] [COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents](https://arxiv.org/abs/2506.01900)
*Manish Bhatt,Ronald F. Del Rosario,Vineeth Sai Narajala,Idan Habler*

Main category: cs.AI

TL;DR: COALESCE框架通过动态外包任务给第三方LLM代理，优化资源利用，降低20.3%成本。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理系统因高GPU资源需求而受限的问题。

Method: 提出COALESCE框架，包含技能表示、任务分解、成本模型和决策算法。

Result: 理论模拟显示41.8%成本降低潜力，实证验证实现20.3%成本降低。

Conclusion: COALESCE通过动态市场和标准化协议提升LLM代理的经济性和可扩展性。

Abstract: The meteoric rise and proliferation of autonomous Large Language Model (LLM)
agents promise significant capabilities across various domains. However, their
deployment is increasingly constrained by substantial computational demands,
specifically for Graphics Processing Unit (GPU) resources. This paper addresses
the critical problem of optimizing resource utilization in LLM agent systems.
We introduce COALESCE (Cost-Optimized and Secure Agent Labour Exchange via
Skill-based Competence Estimation), a novel framework designed to enable
autonomous LLM agents to dynamically outsource specific subtasks to
specialized, cost-effective third-party LLM agents. The framework integrates
mechanisms for hybrid skill representation, dynamic skill discovery, automated
task decomposition, a unified cost model comparing internal execution costs
against external outsourcing prices, simplified market-based decision-making
algorithms, and a standardized communication protocol between LLM agents.
Comprehensive validation through 239 theoretical simulations demonstrates
41.8\% cost reduction potential, while large-scale empirical validation across
240 real LLM tasks confirms 20.3\% cost reduction with proper epsilon-greedy
exploration, establishing both theoretical viability and practical
effectiveness. The emergence of proposed open standards like Google's
Agent2Agent (A2A) protocol further underscores the need for frameworks like
COALESCE that can leverage such standards for efficient agent interaction. By
facilitating a dynamic market for agent capabilities, potentially utilizing
protocols like A2A for communication, COALESCE aims to significantly reduce
operational costs, enhance system scalability, and foster the emergence of
specialized agent economies, making complex LLM agent functionalities more
accessible and economically viable.

</details>


### [325] [Understanding Overadaptation in Supervised Fine-Tuning: The Role of Ensemble Methods](https://arxiv.org/abs/2506.01901)
*Yifan Hao,Xingyuan Pan,Hanning Zhang,Chenlu Ye,Rui Pan,Tong Zhang*

Main category: cs.AI

TL;DR: 论文研究了通过集成预训练模型和微调模型来解决监督微调（SFT）导致的知识遗忘问题，并发现集成模型不仅在通用知识上表现更好，甚至在微调领域也优于单独微调模型。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在适应基础模型到特定任务时会导致预训练知识的遗忘，本文旨在探索如何通过模型集成缓解这一问题。

Method: 通过集成预训练模型和微调模型，分析其在语言模型中的效果，并进行理论分析，探讨误差来源（偏差和方差）。

Result: 集成模型不仅保留了基础模型的通用知识，还在微调领域表现优于单独微调模型。理论分析表明，集成通过平衡偏差和方差显著提升性能。

Conclusion: 模型集成为解决监督微调中的知识遗忘和过适应问题提供了有效方案，理论分析支持其优势。

Abstract: Supervised fine-tuning (SFT) on domain-specific data is the dominant approach
for adapting foundation models to specialized tasks. However, it has been
observed that SFT models tend to forget knowledge acquired during pretraining.
In vision models, ensembling a pretrained model with its fine-tuned counterpart
has been shown to mitigate this issue. In this work, we demonstrate that the
same holds for language models, and, more strikingly, we observe an
overadaptation phenomenon: the ensemble model not only retains general
knowledge from the foundation model but also outperforms the fine-tuned model
even on the fine-tuning domain itself. Despite the empirical success of
ensembling, a theoretical understanding of its benefits remains underexplored.
We develop a formal theoretical analysis of the overadaptation phenomenon.
Ensembling mitigates this by balancing two primary sources of error: bias,
caused by insufficient fine-tuning, and variance, introduced by overfitting to
fine-tuning data. While regularization techniques aim to address this
trade-off, we show that ensembling provides a more effective solution. We
analyze this phenomenon in over-parameterized linear settings and demonstrate
that interpolating between pretrained and fine-tuned weights significantly
improves performance. These findings offer theoretical justification for the
observed advantages of model ensembling, supported by empirical experiments
consistent with our analysis.

</details>


### [326] [Large language models can learn and generalize steganographic chain-of-thought under process supervision](https://arxiv.org/abs/2506.01926)
*Joey Skaf,Luis Ibanez-Lissen,Robert McCarthy,Connor Watts,Vasil Georgiv,Hannes Whittingham,Lorena Gonzalez-Manzano,David Lindner,Cameron Tice,Edward James Young,Puria Radmard*

Main category: cs.AI

TL;DR: 论文探讨了Chain-of-thought（CoT）推理在语言模型中的应用及其潜在风险，特别是开发者可能通过训练掩盖有害意图的痕迹。研究发现，惩罚特定字符串会导致模型替换为其他字符串，但并未改变其底层推理方式，表明模型可以隐式编码其推理。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解CoT推理监控的可靠性问题，尤其是开发者可能出于用户偏好或监管要求掩盖有害意图的痕迹，从而威胁CoT监控的有效性。

Method: 通过实验展示，惩罚特定字符串会导致模型替换为其他字符串，但底层推理方式不变。进一步证明模型能推广编码方案，适用于未见的测试字符串。

Result: 研究发现，惩罚特定字符串仅导致表面替换，未改变模型执行任务的底层方法，且模型能推广编码方案。

Conclusion: 结论指出，CoT推理监控可能因模型隐式编码推理而失效，需更深入的方法确保其可靠性。

Abstract: Chain-of-thought (CoT) reasoning not only enhances large language model
performance but also provides critical insights into decision-making processes,
marking it as a useful tool for monitoring model intent and planning. By
proactively preventing models from acting on CoT indicating misaligned or
harmful intent, CoT monitoring can be used to reduce risks associated with
deploying models. However, developers may be incentivized to train away the
appearance of harmful intent from CoT traces, by either customer preferences or
regulatory requirements. Recent works have shown that banning mention of a
specific example of reward hacking, which may be done either to make CoT
presentable to users or as a naive attempt to prevent the behavior, causes
obfuscation of the undesired reasoning traces but the persistence of the
undesired behavior. Such obfuscation threatens the reliability of CoT
monitoring. However, obfuscation of reasoning can be due to its internalization
to latent space computation, or its encoding within the CoT. Here, we provide
an extension to these results. First, we show that penalizing the use of
specific strings within load-bearing reasoning traces causes models to
substitute alternative strings. Crucially, this does not alter the underlying
method by which the model performs the task, demonstrating that the model can
learn to steganographically encode its reasoning. We further demonstrate that
models can generalize an encoding scheme. When the penalized strings belong to
an overarching class, the model learns not only to substitute strings seen in
training, but also develops a general encoding scheme for all members of the
class which it can apply to held-out testing strings.

</details>


### [327] [RoboEgo System Card: An Omnimodal Model with Native Full Duplexity](https://arxiv.org/abs/2506.01934)
*Yiqun Yao,Xiang Li,Xin Jiang,Xuezhi Fang,Naitong Yu,Aixin Sun,Yequan Wang*

Main category: cs.AI

TL;DR: RoboEgo（FLM-Ego）是一个支持全双工和多模态处理的统一模型系统，解决了多模态处理和实时响应人类指令的挑战，实现了80毫秒的理论延迟。


<details>
  <summary>Details</summary>
Motivation: 人类自然以全双工方式处理多模态信息，人工智能需要复制这一能力以推动模型发展，尤其是在具身环境中。

Method: RoboEgo采用支持全双工的骨干架构和算法，实现了80毫秒的理论延迟。

Result: 在真实条件下的流式视觉对话中，RoboEgo表现出卓越的响应性和语音自然性，同时内容质量与半双工多模态模型相当。

Conclusion: RoboEgo证明了原生全双工系统可以实现此前被认为无法达到的性能，推动了多模态和全双工模型的研究。

Abstract: Humans naturally process real-world multimodal information in a full-duplex
manner. In artificial intelligence, replicating this capability is essential
for advancing model development and deployment, particularly in embodied
contexts. The development of multimodal models faces two primary challenges:
(1) effectively handling more than three modalities-such as vision, audio, and
text; and (2) delivering full-duplex responses to rapidly evolving human
instructions. To facilitate research on models that support both omnimodal
processing and full duplexity, we present RoboEgo (alias: FLM-Ego), a unified
model system designed to address both challenges. RoboEgo incorporates a
backbone architecture and algorithms that natively support full duplexity,
achieving a theoretical duplex latency of 80 ms. In streaming visually grounded
conversations under real-world conditions, RoboEgo exhibits superior
responsiveness and speech naturalness, while maintaining comparable content
qualities to state-of-the-art semi-duplex omnimodal models-a feat previously
considered unattainable by native full-duplex systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [328] [Adapting Offline Reinforcement Learning with Online Delays](https://arxiv.org/abs/2506.00131)
*Simon Sinong Zhan,Qingyuan Wu,Frank Yang,Xiangyu Shi,Chao Huang,Qi Zhu*

Main category: cs.LG

TL;DR: DT-CORL是一种离线强化学习框架，旨在解决部署中的延迟问题，通过Transformer预测延迟动作，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在部署时面临模拟与现实的延迟差距和交互差距，需要从静态数据集泛化到动态延迟环境。

Method: DT-CORL结合Transformer的信念预测器生成延迟鲁棒动作，无需在训练中观察延迟数据。

Result: 在D4RL基准测试中，DT-CORL在多种延迟设置下均优于历史和信念基线方法。

Conclusion: DT-CORL有效缩小了模拟与现实的延迟差距，同时保持了数据效率。

Abstract: Offline-to-online deployment of reinforcement-learning (RL) agents must
bridge two gaps: (1) the sim-to-real gap, where real systems add latency and
other imperfections not present in simulation, and (2) the interaction gap,
where policies trained purely offline face out-of-distribution states during
online execution because gathering new interaction data is costly or risky.
Agents therefore have to generalize from static, delay-free datasets to
dynamic, delay-prone environments. Standard offline RL learns from delay-free
logs yet must act under delays that break the Markov assumption and hurt
performance. We introduce DT-CORL (Delay-Transformer belief policy Constrained
Offline RL), an offline-RL framework built to cope with delayed dynamics at
deployment. DT-CORL (i) produces delay-robust actions with a transformer-based
belief predictor even though it never sees delayed observations during
training, and (ii) is markedly more sample-efficient than na\"ive
history-augmentation baselines. Experiments on D4RL benchmarks with several
delay settings show that DT-CORL consistently outperforms both
history-augmentation and vanilla belief-based methods, narrowing the
sim-to-real latency gap while preserving data efficiency.

</details>


### [329] [Disentangled Safety Adapters Enable Efficient Guardrails and Flexible Inference-Time Alignment](https://arxiv.org/abs/2506.00166)
*Kundan Krishna,Joseph Y Cheng,Charles Maalouf,Leon A Gatys*

Main category: cs.LG

TL;DR: DSA框架通过解耦安全计算与任务优化模型，提升AI安全性和效率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全方法（如护栏模型和对齐训练）常牺牲推理效率或开发灵活性，DSA旨在解决这一问题。

Method: DSA使用轻量级适配器，基于基础模型的内部表示，实现灵活的安全功能，同时最小化推理成本。

Result: DSA在幻觉检测（0.88 AUC）、仇恨言论分类（0.98 AUC）等方面表现优异，并支持动态调整对齐强度。

Conclusion: DSA为模块化、高效和适应性强的AI安全与对齐提供了有前景的解决方案。

Abstract: Existing paradigms for ensuring AI safety, such as guardrail models and
alignment training, often compromise either inference efficiency or development
flexibility. We introduce Disentangled Safety Adapters (DSA), a novel framework
addressing these challenges by decoupling safety-specific computations from a
task-optimized base model. DSA utilizes lightweight adapters that leverage the
base model's internal representations, enabling diverse and flexible safety
functionalities with minimal impact on inference cost. Empirically, DSA-based
safety guardrails substantially outperform comparably sized standalone models,
notably improving hallucination detection (0.88 vs. 0.61 AUC on Summedits) and
also excelling at classifying hate speech (0.98 vs. 0.92 on ToxiGen) and unsafe
model inputs and responses (0.93 vs. 0.90 on AEGIS2.0 & BeaverTails).
Furthermore, DSA-based safety alignment allows dynamic, inference-time
adjustment of alignment strength and a fine-grained trade-off between
instruction following performance and model safety. Importantly, combining the
DSA safety guardrail with DSA safety alignment facilitates context-dependent
alignment strength, boosting safety on StrongReject by 93% while maintaining
98% performance on MTBench -- a total reduction in alignment tax of 8
percentage points compared to standard safety alignment fine-tuning. Overall,
DSA presents a promising path towards more modular, efficient, and adaptable AI
safety and alignment.

</details>


### [330] [Accountability Attribution: Tracing Model Behavior to Training Processes](https://arxiv.org/abs/2506.00175)
*Shichang Zhang,Hongzhe Du,Karim Saraipour,Jiaqi W. Ma,Himabindu Lakkaraju*

Main category: cs.LG

TL;DR: 论文提出了一种框架，用于追溯AI模型行为到训练过程中的特定阶段，通过反事实问题量化各阶段的影响。


<details>
  <summary>Details</summary>
Motivation: 现代AI开发流程涉及多个阶段（如预训练、微调等），但缺乏对模型行为责任的明确追溯方法，需要解决责任归属问题。

Method: 提出基于一阶近似的估计器，无需重新训练即可高效量化各训练阶段的影响，同时考虑训练数据和优化动态（如学习率、动量等）。

Result: 实证表明，该方法能有效识别对特定行为负责的训练阶段，为模型分析提供了实用工具。

Conclusion: 该框架为AI开发提供了更明确的责任追溯方法，推动了更负责任的AI发展。

Abstract: Modern AI development pipelines often involve multiple stages-pretraining,
fine-tuning rounds, and subsequent adaptation or alignment-with numerous model
update steps within each stage. This raises a critical question of
accountability: when a deployed model succeeds or fails, which stage is
responsible, and to what extent? We pose the problem of accountability
attribution, which aims to trace model behavior back to specific stages of the
training process. To address this, we propose a general framework that answers
counterfactual questions about stage effects: how would the model behavior have
changed if the updates from a training stage had not been executed?. Within
this framework, we introduce estimators based on first-order approximations
that efficiently quantify the stage effects without retraining. Our estimators
account for both the training data and key aspects of optimization dynamics,
including learning rate schedules, momentum, and weight decay. Empirically, we
demonstrate that our approach identifies training stages accountable for
specific behaviors, offering a practical tool for model analysis and a step
toward more accountable AI development.

</details>


### [331] [MOFGPT: Generative Design of Metal-Organic Frameworks using Language Models](https://arxiv.org/abs/2506.00198)
*Srivathsan Badrinarayanan,Rishikesh Magar,Akshay Antony,Radheesh Sharma Meda,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习和Transformer的框架，用于从头设计金属有机框架（MOFs），结合生成模型、属性预测器和强化学习模块，加速材料发现。


<details>
  <summary>Details</summary>
Motivation: 传统计算方法（如分子模拟和DFT）在MOFs设计空间巨大且复杂的情况下计算成本过高，机器学习提供了一种数据驱动的替代方案。

Method: 开发了一个包含生成GPT模型（基于MOFid序列）、MOFormer（Transformer属性预测器）和强化学习模块的框架，通过属性反馈优化生成候选材料。

Result: 该方法能够生成具有所需功能属性的可合成且拓扑有效的MOFs，展示了语言模型与强化学习结合在逆向设计中的潜力。

Conclusion: 该工作为加速MOFs的计算发现开辟了新途径，展示了语言模型与强化学习在材料科学中的广阔应用前景。

Abstract: The discovery of Metal-Organic Frameworks (MOFs) with application-specific
properties remains a central challenge in materials chemistry, owing to the
immense size and complexity of their structural design space. Conventional
computational screening techniques such as molecular simulations and density
functional theory (DFT), while accurate, are computationally prohibitive at
scale. Machine learning offers an exciting alternative by leveraging
data-driven approaches to accelerate materials discovery. The complexity of
MOFs, with their extended periodic structures and diverse topologies, creates
both opportunities and challenges for generative modeling approaches. To
address these challenges, we present a reinforcement learning-enhanced,
transformer-based framework for the de novo design of MOFs. Central to our
approach is MOFid, a chemically-informed string representation encoding both
connectivity and topology, enabling scalable generative modeling. Our pipeline
comprises three components: (1) a generative GPT model trained on MOFid
sequences, (2) MOFormer, a transformer-based property predictor, and (3) a
reinforcement learning (RL) module that optimizes generated candidates via
property-guided reward functions. By integrating property feedback into
sequence generation, our method drives the model toward synthesizable,
topologically valid MOFs with desired functional attributes. This work
demonstrates the potential of large language models, when coupled with
reinforcement learning, to accelerate inverse design in reticular chemistry and
unlock new frontiers in computational MOF discovery.

</details>


### [332] [Localized LoRA: A Structured Low-Rank Approximation for Efficient Fine-Tuning](https://arxiv.org/abs/2506.00236)
*Babak Barazandeh*

Main category: cs.LG

TL;DR: 本文提出了一种名为Localized LoRA的参数高效微调方法，通过局部低秩矩阵更新权重，优于全局低秩方法。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法（如LoRA）依赖全局低秩结构，可能忽略参数空间中的空间模式，因此需要更灵活的方法。

Method: 提出Localized LoRA框架，将权重更新建模为低秩矩阵的组合，应用于权重矩阵的结构化块，实现密集局部更新。

Result: 在相同参数预算下，Localized LoRA的近似误差更低，实验证明其表达能力和适应性更强。

Conclusion: Localized LoRA是一种更高效、性能更好的微调方法，优于现有方法。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, offer compact
and effective alternatives to full model fine-tuning by introducing low-rank
updates to pretrained weights. However, most existing approaches rely on global
low-rank structures, which can overlook spatial patterns spread across the
parameter space. In this work, we propose Localized LoRA, a generalized
framework that models weight updates as a composition of low-rank matrices
applied to structured blocks of the weight matrix. This formulation enables
dense, localized updates throughout the parameter space-without increasing the
total number of trainable parameters. We provide a formal comparison between
global, diagonal-local, and fully localized low-rank approximations, and show
that our method consistently achieves lower approximation error under matched
parameter budgets. Experiments on both synthetic and practical settings
demonstrate that Localized LoRA offers a more expressive and adaptable
alternative to existing methods, enabling efficient fine-tuning with improved
performance.

</details>


### [333] [Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model](https://arxiv.org/abs/2506.00286)
*Oliver Mortensen,Mohammad Sadegh Talebi*

Main category: cs.LG

TL;DR: 本文分析了在具有递归熵风险偏好的折扣马尔可夫决策过程中学习最优状态-动作值函数和最优策略的样本复杂度，提出了一种基于模型的方法MB-RS-QVI，并给出了其PAC界限。结果表明，样本复杂度对有效视界和风险敏感性的指数依赖是不可避免的。


<details>
  <summary>Details</summary>
Motivation: 研究在风险敏感环境下学习最优策略和值函数的样本复杂度，填补现有理论空白。

Method: 提出模型基于方法MB-RS-QVI，通过迭代更新Q值函数，并分析其收敛性和样本复杂度。

Result: 给出了关于Q值和策略学习的PAC界限，显示其对有效视界和风险敏感性的指数依赖是不可避免的。

Conclusion: 样本复杂度的指数依赖是理论上的必然，且所提方法的PAC界限在多个参数上是紧的。

Abstract: In this paper we analyze the sample complexities of learning the optimal
state-action value function $Q^*$ and an optimal policy $\pi^*$ in a discounted
Markov decision process (MDP) where the agent has recursive entropic
risk-preferences with risk-parameter $\beta\neq 0$ and where a generative model
of the MDP is available. We provide and analyze a simple model based approach
which we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which
leads to $(\epsilon,\delta)$-PAC-bounds on $\|Q^*-Q^k\|$, and
$\|V^*-V^{\pi_k}\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations
and $\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have
exponential dependence on the effective horizon $\frac{1}{1-\gamma}$ and the
strength of this dependence grows with the learners risk-sensitivity $|\beta|$.
We also provide two lower bounds which shows that exponential dependence on
$|\beta|\frac{1}{1-\gamma}$ is unavoidable in both cases. The lower bounds
reveal that the PAC-bounds are both tight in $\varepsilon$ and $\delta$ and
that the PAC-bound on $Q$-learning is tight in the number of actions $A$, and
that the PAC-bound on policy-learning is nearly tight in $A$.

</details>


### [334] [Improving Protein Sequence Design through Designability Preference Optimization](https://arxiv.org/abs/2506.00297)
*Fanglei Xue,Andrew Kubaney,Zhichun Guo,Joseph K. Min,Ge Liu,Yi Yang,David Baker*

Main category: cs.LG

TL;DR: 论文提出了一种改进蛋白质序列设计的方法，通过优化训练目标以提高设计成功率，并引入残基级优化技术，显著提升了设计效果。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质序列设计方法的训练目标是序列恢复，但未能保证设计序列能折叠成目标结构。因此，需要重新定义训练目标以提高设计成功率。

Method: 整合了直接偏好优化（DPO），利用AlphaFold的pLDDT分数作为偏好信号，并引入残基级设计偏好优化（ResiDPO），在残基级别优化序列生成。

Result: 在具有挑战性的酶设计基准测试中，设计成功率从6.56%提升至17.57%。

Conclusion: 通过优化训练目标和引入残基级优化技术，显著提高了蛋白质序列设计的成功率。

Abstract: Protein sequence design methods have demonstrated strong performance in
sequence generation for de novo protein design. However, as the training
objective was sequence recovery, it does not guarantee designability--the
likelihood that a designed sequence folds into the desired structure. To bridge
this gap, we redefine the training objective by steering sequence generation
toward high designability. To do this, we integrate Direct Preference
Optimization (DPO), using AlphaFold pLDDT scores as the preference signal,
which significantly improves the in silico design success rate. To further
refine sequence generation at a finer, residue-level granularity, we introduce
Residue-level Designability Preference Optimization (ResiDPO), which applies
residue-level structural rewards and decouples optimization across residues.
This enables direct improvement in designability while preserving regions that
already perform well. Using a curated dataset with residue-level annotations,
we fine-tune LigandMPNN with ResiDPO to obtain EnhancedMPNN, which achieves a
nearly 3-fold increase in in silico design success rate (from 6.56% to 17.57%)
on a challenging enzyme design benchmark.

</details>


### [335] [Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation](https://arxiv.org/abs/2506.00329)
*Muhammad Adnan,Nithesh Kurella,Akhil Arunkumar,Prashant J. Nair*

Main category: cs.LG

TL;DR: Foresight是一种自适应层重用技术，通过动态识别和重用DiT块输出来减少计算冗余，同时保持性能，显著提升了视频生成的效率。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器（DiTs）在视频生成中计算成本高，静态缓存方法无法适应生成动态，导致速度与质量的权衡不佳。

Method: 提出Foresight技术，动态识别和重用DiT块输出，适应生成参数（如分辨率和去噪计划）以优化效率。

Result: 在OpenSora、Latte和CogVideoX上，Foresight实现了最高1.63倍的端到端加速，同时保持视频质量。

Conclusion: Foresight通过自适应层重用显著提升了视频生成的效率，且代码已开源。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art results in
text-to-image, text-to-video generation, and editing. However, their large
model size and the quadratic cost of spatial-temporal attention over multiple
denoising steps make video generation computationally expensive. Static caching
mitigates this by reusing features across fixed steps but fails to adapt to
generation dynamics, leading to suboptimal trade-offs between speed and
quality.
  We propose Foresight, an adaptive layer-reuse technique that reduces
computational redundancy across denoising steps while preserving baseline
performance. Foresight dynamically identifies and reuses DiT block outputs for
all layers across steps, adapting to generation parameters such as resolution
and denoising schedules to optimize efficiency. Applied to OpenSora, Latte, and
CogVideoX, Foresight achieves up to 1.63x end-to-end speedup, while maintaining
video quality. The source code of Foresight is available at
\texttt{https://github.com/STAR-Laboratory/foresight}.

</details>


### [336] [Exploring the Performance of Perforated Backpropagation through Further Experiments](https://arxiv.org/abs/2506.00356)
*Rorry Brenner,Evan Davis,Rushi Chaudhari,Rowan Morse,Jingyao Chen,Xirui Liu,Zhaoyi You,Laurent Itti*

Main category: cs.LG

TL;DR: Perforated Backpropagation是一种基于生物神经元树突计算重要性的神经网络优化技术，实验显示其可实现高达90%的模型压缩或16%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 探索Perforated Backpropagation算法在实际项目中的应用效果，验证其优化潜力。

Method: 通过黑客马拉松活动，参与者将该算法应用于各自的数据集和模型，进行实验验证。

Result: 结果表明，该技术可实现高达90%的模型压缩或16%的准确率提升。

Conclusion: Perforated Backpropagation是一种有效的神经网络优化方法，具有实际应用价值。

Abstract: Perforated Backpropagation is a neural network optimization technique based
on modern understanding of the computational importance of dendrites within
biological neurons. This paper explores further experiments from the original
publication, generated from a hackathon held at the Carnegie Mellon Swartz
Center in February 2025. Students and local Pittsburgh ML practitioners were
brought together to experiment with the Perforated Backpropagation algorithm on
the datasets and models which they were using for their projects. Results
showed that the system could enhance their projects, with up to 90% model
compression without negative impact on accuracy, or up to 16% increased
accuracy of their original models.

</details>


### [337] [Bias as a Virtue: Rethinking Generalization under Distribution Shifts](https://arxiv.org/abs/2506.00407)
*Ruixuan Chen,Wentao Li,Jiahui Xiao,Yuchen Li,Yimin Tang,Xiaonan Wang*

Main category: cs.LG

TL;DR: 论文提出了一种自适应分布桥接（ADB）框架，通过引入受控的统计多样性训练模型，证明更高的分布内（ID）偏置可以改善分布外（OOD）泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统验证范式通常关注最小化验证误差，但研究发现更高的ID偏置反而能提升OOD泛化能力，这挑战了常规做法。

Method: ADB框架通过在训练中引入受控的统计多样性，使模型能够发展出适用于不同分布的偏置特性。

Result: 实验显示，ADB显著提升了OOD泛化能力，平均误差降低高达26.8%，且训练策略的百分位排名常超过74.4%。

Conclusion: ADB不仅提供了提升泛化能力的实用方法，还为重新思考偏置在鲁棒机器学习中的作用提供了理论框架。

Abstract: Machine learning models often degrade when deployed on data distributions
different from their training data. Challenging conventional validation
paradigms, we demonstrate that higher in-distribution (ID) bias can lead to
better out-of-distribution (OOD) generalization. Our Adaptive Distribution
Bridge (ADB) framework implements this insight by introducing controlled
statistical diversity during training, enabling models to develop bias profiles
that effectively generalize across distributions. Empirically, we observe a
robust negative correlation where higher ID bias corresponds to lower OOD
error--a finding that contradicts standard practices focused on minimizing
validation error. Evaluation on multiple datasets shows our approach
significantly improves OOD generalization. ADB achieves robust mean error
reductions of up to 26.8% compared to traditional cross-validation, and
consistently identifies high-performing training strategies, evidenced by
percentile ranks often exceeding 74.4%. Our work provides both a practical
method for improving generalization and a theoretical framework for
reconsidering the role of bias in robust machine learning.

</details>


### [338] [A New Spatiotemporal Correlation Anomaly Detection Method that Integrates Contrastive Learning and Few-Shot Learning in Wireless Sensor Networks](https://arxiv.org/abs/2506.00420)
*Miao Ye,Suxiao Wang,Jiaguang Han,Yong Wang,Xiaoli Wang,Jingxuan Wei,Peng Wen,Jing Cui*

Main category: cs.LG

TL;DR: 本文提出了一种考虑模型架构和两阶段训练策略的时空相关性检测模型（MTAD-RD），用于解决WSN异常检测中的特征提取不足、样本标签缺失、样本不平衡等问题。


<details>
  <summary>Details</summary>
Motivation: WSN异常检测对评估其可靠性和稳定性至关重要，但现有方法在时空特征提取、样本标签缺失和样本不平衡等方面存在挑战。

Method: MTAD-RD模型包括增强的RetNet、多粒度特征融合模块和图注意力网络模块，采用两阶段训练策略：无监督对比学习和基于缓存的样本采样器。

Result: 在真实公开数据集上，MTAD-RD的F1得分达到90.97%，优于现有监督方法。

Conclusion: MTAD-RD通过改进模型结构和训练策略，显著提升了WSN异常检测的性能。

Abstract: Detecting anomalies in the data collected by WSNs can provide crucial
evidence for assessing the reliability and stability of WSNs. Existing methods
for WSN anomaly detection often face challenges such as the limited extraction
of spatiotemporal correlation features, the absence of sample labels, few
anomaly samples, and an imbalanced sample distribution. To address these
issues, a spatiotemporal correlation detection model (MTAD-RD) considering both
model architecture and a two-stage training strategy perspective is proposed.
In terms of model structure design, the proposed MTAD-RD backbone network
includes a retentive network (RetNet) enhanced by a cross-retention (CR)
module, a multigranular feature fusion module, and a graph attention network
module to extract internode correlation information. This proposed model can
integrate the intermodal correlation features and spatial features of WSN
neighbor nodes while extracting global information from time series data.
Moreover, its serialized inference characteristic can remarkably reduce
inference overhead. For model training, a two-stage training approach was
designed. First, a contrastive learning proxy task was designed for time series
data with graph structure information in WSNs, enabling the backbone network to
learn transferable features from unlabeled data using unsupervised contrastive
learning methods, thereby addressing the issue of missing sample labels in the
dataset. Then, a caching-based sample sampler was designed to divide samples
into few-shot and contrastive learning data. A specific joint loss function was
developed to jointly train the dual-graph discriminator network to address the
problem of sample imbalance effectively. In experiments carried out on real
public datasets, the designed MTAD-RD anomaly detection method achieved an F1
score of 90.97%, outperforming existing supervised WSN anomaly detection
methods.

</details>


### [339] [COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning](https://arxiv.org/abs/2506.00424)
*Chamika Sudusinghe,Gerasimos Gerogiannis Damitha Lenadora,Charles Block,Josep Torrellas,Charith Mendis*

Main category: cs.LG

TL;DR: COGNATE框架利用通用硬件（如CPU）的廉价数据样本训练成本模型，并通过少量样本微调适配新兴硬件，显著减少数据需求，提升稀疏张量程序的性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏张量程序在深度学习和图分析中至关重要，但针对早期硬件加速器的优化面临输入敏感性和模拟器成本高的挑战。

Method: COGNATE通过跨硬件平台的输入特征同质性，利用通用硬件数据训练成本模型，并少量微调适配新硬件。

Result: COGNATE仅需5%的数据样本即可达到与加速器专用模型相当的性能，平均加速比为1.47x（SpMM）和1.39x（SDDMM）。

Conclusion: COGNATE有效解决了早期硬件加速器优化的数据需求问题，显著提升了稀疏张量程序的性能。

Abstract: Sparse tensor programs are essential in deep learning and graph analytics,
driving the need for optimized processing. To meet this demand, specialized
hardware accelerators are being developed. Optimizing these programs for
accelerators is challenging for two reasons: program performance is highly
sensitive to variations in sparse inputs, and early-stage accelerators rely on
expensive simulators. Therefore, ML-based cost models used for optimizing such
programs on general-purpose hardware are often ineffective for early-stage
accelerators, as they require large datasets for proper training. To this end,
we introduce COGNATE, a novel framework that leverages inexpensive data samples
from general-purpose hardware (e.g., CPUs) to train cost models, followed by
few-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of
input features across hardware platforms while effectively mitigating
heterogeneity, enabling cost model training with just 5% of the data samples
needed by accelerator-specific models to achieve comparable performance. We
conduct extensive experiments to demonstrate that COGNATE outperforms existing
techniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and
1.39x (up to 4.22x) for SDDMM.

</details>


### [340] [Channel Normalization for Time Series Channel Identification](https://arxiv.org/abs/2506.00432)
*Seunghan Lee,Taeyoung Park,Kibok Lee*

Main category: cs.LG

TL;DR: 论文提出了一种称为通道归一化（CN）的方法，通过为每个通道分配独特的仿射变换参数来增强通道可识别性（CID），并进一步扩展为自适应CN（ACN）和原型CN（PCN）。


<details>
  <summary>Details</summary>
Motivation: 在时间序列建模中，缺乏通道可识别性（CID）会导致忽略通道特异性，产生相同输入相同输出的问题。

Method: 提出通道归一化（CN），并扩展为自适应CN（ACN）和原型CN（PCN），分别动态调整参数和使用可学习原型。

Result: 在多种时间序列模型中应用CN及其变体，显著提升了性能。

Conclusion: CN及其扩展方法有效增强了通道可识别性，适用于不同场景，并从信息论角度分析了其成功原因。

Abstract: Channel identifiability (CID) refers to the ability to distinguish between
individual channels in time series (TS) modeling. The absence of CID often
results in producing identical outputs for identical inputs, disregarding
channel-specific characteristics. In this paper, we highlight the importance of
CID and propose Channel Normalization (CN), a simple yet effective
normalization strategy that enhances CID by assigning distinct affine
transformation parameters to each channel. We further extend CN in two ways: 1)
Adaptive CN (ACN) dynamically adjusts parameters based on the input TS,
improving adaptability in TS models, and 2) Prototypical CN (PCN) introduces a
set of learnable prototypes instead of per-channel parameters, enabling
applicability to datasets with unknown or varying number of channels and
facilitating use in TS foundation models. We demonstrate the effectiveness of
CN and its variants by applying them to various TS models, achieving
significant performance gains for both non-CID and CID models. In addition, we
analyze the success of our approach from an information theory perspective.
Code is available at https://github.com/seunghan96/CN.

</details>


### [341] [Learning from Double Positive and Unlabeled Data for Potential-Customer Identification](https://arxiv.org/abs/2506.00436)
*Masahiro Kato,Yuki Ikeda abd Kentaro Baba,Takashi Imai,Ryo Inokuchi*

Main category: cs.LG

TL;DR: 提出了一种基于正样本和无标签数据（PU学习）的方法，用于识别目标营销中的潜在客户，重点关注对产品有兴趣但缺乏公司忠诚度的个体。


<details>
  <summary>Details</summary>
Motivation: 公司希望通过有效营销吸引潜在客户，尤其是那些对产品有兴趣但缺乏忠诚度的个体，以提高营销效率。

Method: 采用双PU学习方法，通过单阶段优化训练分类器，识别符合条件（有兴趣但无忠诚度）的潜在客户。

Result: 数值实验验证了算法的有效性，表明其适用于解决目标问题。

Conclusion: 双PU学习方法能有效识别潜在客户，为针对性营销提供支持。

Abstract: In this study, we propose a method for identifying potential customers in
targeted marketing by applying learning from positive and unlabeled data (PU
learning). We consider a scenario in which a company sells a product and can
observe only the customers who purchased it. Decision-makers seek to market
products effectively based on whether people have loyalty to the company.
Individuals with loyalty are those who are likely to remain interested in the
company even without additional advertising. Consequently, those loyal
customers would likely purchase from the company if they are interested in the
product. In contrast, people with lower loyalty may overlook the product or buy
similar products from other companies unless they receive marketing attention.
Therefore, by focusing marketing efforts on individuals who are interested in
the product but do not have strong loyalty, we can achieve more efficient
marketing. To achieve this goal, we consider how to learn, from limited data, a
classifier that identifies potential customers who (i) have interest in the
product and (ii) do not have loyalty to the company. Although our algorithm
comprises a single-stage optimization, its objective function implicitly
contains two losses derived from standard PU learning settings. For this
reason, we refer to our approach as double PU learning. We verify the validity
of the proposed algorithm through numerical experiments, confirming that it
functions appropriately for the problem at hand.

</details>


### [342] [Is Your Explanation Reliable: Confidence-Aware Explanation on Graph Neural Networks](https://arxiv.org/abs/2506.00437)
*Jiaxing Zhang,Xiaoou Liu,Dongsheng Luo,Hua Wei*

Main category: cs.LG

TL;DR: 提出了一种基于置信度评分的GNN解释框架（ConfExplainer），通过理论支持的GIB-CC方法量化解释的可靠性，提升了解释的可信度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于GNN的黑盒特性，现有的事后解释方法在分布外或未知测试数据上的可靠性存疑，需要一种能够量化解释可靠性的方法。

Method: 引入ConfExplainer框架，结合理论基础的GIB-CC方法，通过置信度评分模块量化解释的可靠性。

Result: 实验结果表明，该方法在提升GNN解释的可信度和鲁棒性方面表现优越。

Conclusion: ConfExplainer通过置信度评分有效增强了GNN解释的可靠性，为解释方法的研究提供了新方向。

Abstract: Explaining Graph Neural Networks (GNNs) has garnered significant attention
due to the need for interpretability, enabling users to understand the behavior
of these black-box models better and extract valuable insights from their
predictions. While numerous post-hoc instance-level explanation methods have
been proposed to interpret GNN predictions, the reliability of these
explanations remains uncertain, particularly in the out-of-distribution or
unknown test datasets. In this paper, we address this challenge by introducing
an explainer framework with the confidence scoring module ( ConfExplainer),
grounded in theoretical principle, which is generalized graph information
bottleneck with confidence constraint (GIB-CC), that quantifies the reliability
of generated explanations. Experimental results demonstrate the superiority of
our approach, highlighting the effectiveness of the confidence score in
enhancing the trustworthiness and robustness of GNN explanations.

</details>


### [343] [RLAE: Reinforcement Learning-Assisted Ensemble for LLMs](https://arxiv.org/abs/2506.00439)
*Yuqian Fu,Yuanheng Zhu,Jiajun Chai,Guojun Yin,Wei Lin,Qichao Zhang,Dongbin Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种基于强化学习的动态权重调整方法（RLAE），用于优化大语言模型（LLM）的集成效果，显著提升了任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM集成方法采用固定权重策略，无法适应动态上下文需求，限制了性能提升。

Method: 通过马尔可夫决策过程（MDP）框架，引入强化学习代理动态调整集成权重，结合输入上下文和生成状态，并使用单/多智能体强化学习算法（RLAE_PPO和RLAE_MAPPO）。

Result: 在多样化任务中，RLAE比传统方法准确率提升高达3.3%，且泛化能力更强，延迟更低。

Conclusion: RLAE为LLM集成提供了更高效的动态框架，无需重新训练即可适应不同任务。

Abstract: Ensembling large language models (LLMs) can effectively combine diverse
strengths of different models, offering a promising approach to enhance
performance across various tasks. However, existing methods typically rely on
fixed weighting strategies that fail to adapt to the dynamic, context-dependent
characteristics of LLM capabilities. In this work, we propose Reinforcement
Learning-Assisted Ensemble for LLMs (RLAE), a novel framework that reformulates
LLM ensemble through the lens of a Markov Decision Process (MDP). Our approach
introduces a RL agent that dynamically adjusts ensemble weights by considering
both input context and intermediate generation states, with the agent being
trained using rewards that directly correspond to the quality of final outputs.
We implement RLAE using both single-agent and multi-agent reinforcement
learning algorithms ($\text{RLAE}_\text{PPO}$ and $\text{RLAE}_\text{MAPPO}$ ),
demonstrating substantial improvements over conventional ensemble methods.
Extensive evaluations on a diverse set of tasks show that RLAE outperforms
existing approaches by up to $3.3\%$ accuracy points, offering a more effective
framework for LLM ensembling. Furthermore, our method exhibits superior
generalization capabilities across different tasks without the need for
retraining, while simultaneously achieving lower time latency.

</details>


### [344] [TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction](https://arxiv.org/abs/2506.00453)
*Hao Li,Hao Wan,Yuzhou Chen,Dongsheng Ye,Yulia Gel,Hao Jiang*

Main category: cs.LG

TL;DR: 论文提出了一种基于Dowker Zigzag Persistence (DZP)的动态图持久同调表示方法，并设计了TMetaNet模型，用于动态图的元学习参数更新。实验表明TMetaNet在性能和抗噪性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 动态图结构不断变化，传统图学习方法难以捕捉其高阶拓扑信息。现有元学习方法依赖固定权重参数，忽略了动态图的复杂高阶特征。

Method: 提出DZP方法捕捉动态图的高阶特征，并基于此设计TMetaNet模型，利用高阶拓扑特征间的距离实现更有效的参数更新。

Result: 在真实数据集上，TMetaNet表现出最先进的性能和对图噪声的强鲁棒性。

Conclusion: TMetaNet在动态图分析和元学习领域具有高潜力，代码已开源。

Abstract: Dynamic graphs evolve continuously, presenting challenges for traditional
graph learning due to their changing structures and temporal dependencies.
Recent advancements have shown potential in addressing these challenges by
developing suitable meta-learning-based dynamic graph neural network models.
However, most meta-learning approaches for dynamic graphs rely on fixed weight
update parameters, neglecting the essential intrinsic complex high-order
topological information of dynamically evolving graphs. We have designed Dowker
Zigzag Persistence (DZP), an efficient and stable dynamic graph persistent
homology representation method based on Dowker complex and zigzag persistence,
to capture the high-order features of dynamic graphs. Armed with the DZP ideas,
we propose TMetaNet, a new meta-learning parameter update model based on
dynamic topological features. By utilizing the distances between high-order
topological features, TMetaNet enables more effective adaptation across
snapshots. Experiments on real-world datasets demonstrate TMetaNet's
state-of-the-art performance and resilience to graph noise, illustrating its
high potential for meta-learning and dynamic graph analysis. Our code is
available at https://github.com/Lihaogx/TMetaNet.

</details>


### [345] [Reinforcement Learning for Hanabi](https://arxiv.org/abs/2506.00458)
*Nina Cohen,Kordel K. France*

Main category: cs.LG

TL;DR: 论文研究了不同强化学习算法在合作卡牌游戏Hanabi中的表现，发现时序差分算法（TD）整体表现优于表格算法，尤其是表格Expected SARSA和深度Q学习算法。


<details>
  <summary>Details</summary>
Motivation: Hanabi作为不完全信息合作游戏，为强化学习研究提供了挑战，探索不同算法在对抗同类型和不同类型代理时的表现。

Method: 比较了表格和深度强化学习算法，分析其在不同对抗条件下的表现和交互。

Result: 时序差分算法（TD）表现更优，表格Expected SARSA和深度Q学习算法效果最佳。

Conclusion: TD算法在Hanabi游戏中表现更全面，表格Expected SARSA和深度Q学习是优选方案。

Abstract: Hanabi has become a popular game for research when it comes to reinforcement
learning (RL) as it is one of the few cooperative card games where you have
incomplete knowledge of the entire environment, thus presenting a challenge for
a RL agent. We explored different tabular and deep reinforcement learning
algorithms to see which had the best performance both against an agent of the
same type and also against other types of agents. We establish that certain
agents played their highest scoring games against specific agents while others
exhibited higher scores on average by adapting to the opposing agent's
behavior. We attempted to quantify the conditions under which each algorithm
provides the best advantage and identified the most interesting interactions
between agents of different types. In the end, we found that temporal
difference (TD) algorithms had better overall performance and balancing of play
types compared to tabular agents. Specifically, tabular Expected SARSA and deep
Q-Learning agents showed the best performance.

</details>


### [346] [Comparing Traditional and Reinforcement-Learning Methods for Energy Storage Control](https://arxiv.org/abs/2506.00459)
*Elinor Ginzburg,Itay Segev,Yoash Levron,Sarah Keren*

Main category: cs.LG

TL;DR: 比较传统方法与强化学习（RL）在能源存储管理中的性能差异，探讨RL在简化微电网模型中的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究传统方法与RL在能源存储管理中的性能损失，推动RL在该领域的合理应用。

Method: 基于简化微电网模型（负载、光伏电源、存储设备），分析三种复杂度递增的用例：理想存储、损耗存储、带传输损耗的存储。

Result: 比较传统方法与RL的性能，讨论各自适用场景。

Conclusion: 提出未来研究方向，促进RL在能源存储管理中的合理应用。

Abstract: We aim to better understand the tradeoffs between traditional and
reinforcement learning (RL) approaches for energy storage management. More
specifically, we wish to better understand the performance loss incurred when
using a generative RL policy instead of using a traditional approach to find
optimal control policies for specific instances. Our comparison is based on a
simplified micro-grid model, that includes a load component, a photovoltaic
source, and a storage device. Based on this model, we examine three use cases
of increasing complexity: ideal storage with convex cost functions, lossy
storage devices, and lossy storage devices with convex transmission losses.
With the aim of promoting the principled use RL based methods in this
challenging and important domain, we provide a detailed formulation of each use
case and a detailed description of the optimization challenges. We then compare
the performance of traditional and RL methods, discuss settings in which it is
beneficial to use each method, and suggest avenues for future investigation.

</details>


### [347] [SST: Self-training with Self-adaptive Thresholding for Semi-supervised Learning](https://arxiv.org/abs/2506.00467)
*Shuai Zhao,Heyan Huang,Xinge Li,Xiaokang Chen,Rui Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为SST的半监督学习框架，通过自适应的阈值调整机制（SAT）高效选择高质量的伪标签，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决半监督学习中固定阈值导致的伪标签质量问题和现有自适应方法计算效率低的问题。

Method: 引入自适应的SAT机制，根据模型学习进度动态调整类别特定阈值，确保高质量伪标签的选择。

Result: SST在ImageNet-1K基准测试中表现优异，仅用1%/10%标注数据即达到80.7%/84.9%的Top-1准确率。

Conclusion: SST是一种高效、可扩展的半监督学习框架，显著优于现有方法。

Abstract: Neural networks have demonstrated exceptional performance in supervised
learning, benefiting from abundant high-quality annotated data. However,
obtaining such data in real-world scenarios is costly and labor-intensive.
Semi-supervised learning (SSL) offers a solution to this problem. Recent
studies, such as Semi-ViT and Noisy Student, which employ consistency
regularization or pseudo-labeling, have demonstrated significant achievements.
However, they still face challenges, particularly in accurately selecting
sufficient high-quality pseudo-labels due to their reliance on fixed
thresholds. Recent methods such as FlexMatch and FreeMatch have introduced
flexible or self-adaptive thresholding techniques, greatly advancing SSL
research. Nonetheless, their process of updating thresholds at each iteration
is deemed time-consuming, computationally intensive, and potentially
unnecessary. To address these issues, we propose Self-training with
Self-adaptive Thresholding (SST), a novel, effective, and efficient SSL
framework. SST introduces an innovative Self-Adaptive Thresholding (SAT)
mechanism that adaptively adjusts class-specific thresholds based on the
model's learning progress. SAT ensures the selection of high-quality
pseudo-labeled data, mitigating the risks of inaccurate pseudo-labels and
confirmation bias. Extensive experiments demonstrate that SST achieves
state-of-the-art performance with remarkable efficiency, generalization, and
scalability across various architectures and datasets. Semi-SST-ViT-Huge
achieves the best results on competitive ImageNet-1K SSL benchmarks, with 80.7%
/ 84.9% Top-1 accuracy using only 1% / 10% labeled data. Compared to the
fully-supervised DeiT-III-ViT-Huge, which achieves 84.8% Top-1 accuracy using
100% labeled data, our method demonstrates superior performance using only 10%
labeled data.

</details>


### [348] [BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation](https://arxiv.org/abs/2506.00482)
*Eunsu Kim,Haneul Yoo,Guijin Son,Hitesh Patel,Amit Agarwal,Alice Oh*

Main category: cs.LG

TL;DR: 论文介绍了BenchHub，一个动态基准测试库，用于更有效地评估大型语言模型（LLMs）。它整合了38个基准测试中的30.3万个问题，支持持续更新和可扩展的数据管理。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试数据集分散且难以管理，难以满足特定领域或需求，而领域特定模型（如数学或代码）的重要性日益增加。

Method: 开发了BenchHub，一个动态基准测试库，自动分类和整合多领域的基准测试数据集。

Result: 实验表明，不同LLM家族在领域特定子集上的性能差异显著，突出了领域感知基准测试的重要性。

Conclusion: BenchHub可促进数据集重用、透明模型比较和发现现有基准测试中的不足，为LLM评估研究提供关键基础设施。

Abstract: As large language models (LLMs) continue to advance, the need for up-to-date
and well-organized benchmarks becomes increasingly critical. However, many
existing datasets are scattered, difficult to manage, and make it challenging
to perform evaluations tailored to specific needs or domains, despite the
growing importance of domain-specific models in areas such as math or code. In
this paper, we introduce BenchHub, a dynamic benchmark repository that empowers
researchers and developers to evaluate LLMs more effectively. BenchHub
aggregates and automatically classifies benchmark datasets from diverse
domains, integrating 303K questions across 38 benchmarks. It is designed to
support continuous updates and scalable data management, enabling flexible and
customizable evaluation tailored to various domains or use cases. Through
extensive experiments with various LLM families, we demonstrate that model
performance varies significantly across domain-specific subsets, emphasizing
the importance of domain-aware benchmarking. We believe BenchHub can encourage
better dataset reuse, more transparent model comparisons, and easier
identification of underrepresented areas in existing benchmarks, offering a
critical infrastructure for advancing LLM evaluation research.

</details>


### [349] [It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs](https://arxiv.org/abs/2506.00486)
*Jun Wu,Yirong Xiong,Jiangtao Wen,Yuxing Han*

Main category: cs.LG

TL;DR: 论文提出了一种基于广义高斯分布（GGD）的统一框架，用于优化大语言模型（LLMs），包括初始化、训练和压缩，显著减少了参数数量并提升了效率。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs研究进展迅速，但其参数统计分布及其对初始化、训练动态和下游效率的影响研究较少。BackSlash的提出揭示了预训练LLM参数更符合GGD，为优化提供了新思路。

Method: 1. 基于GG的初始化方案；2. DeepShape后训练正则化方法；3. RF8硬件高效8位浮点格式。

Result: 实验表明，该框架能显著减少参数（高达90%），同时保持或超越标准训练基线的性能。

Conclusion: 通过统计建模优化LLMs，为高效、可扩展且硬件感知的AI系统开辟了新路径。

Abstract: Despite rapid advancements in the research and deployment of large language
models (LLMs), the statistical distribution of model parameters, as well as
their influence on initialization, training dynamics, and downstream
efficiency, has received surprisingly little attention. A recent work
introduced BackSlash, a training-time compression algorithm. It first
demonstrated that pre-trained LLM parameters follow generalized Gaussian
distributions (GGDs) better. By optimizing GG priors during training, BackSlash
can reduce parameters by up to 90\% with minimal performance loss. Building on
this foundational insight, we propose a unified, end-to-end framework for LLM
optimization based on the GG model. Our contributions are threefold: (1)
GG-based initialization scheme that aligns with the statistical structure of
trained models, resulting in faster convergence and improved accuracy; (2)
DeepShape, a post-training regularization method that reshapes weight
distributions to match a GG profile, improving compressibility with minimized
degradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit
floating-point format designed for GG-distributed-initialized BackSlash
training, enabling low-cost inference without compromising accuracy.
Experiments across diverse model architectures show that our framework
consistently yields smaller and faster models that match or outperform standard
training baselines. By grounding LLM development in principled statistical
modeling, this work forges a new path toward efficient, scalable, and
hardware-aware AI systems. The code is available on our project page:
https://huggingface.co/spaces/shifeng3711/gg_prior.

</details>


### [350] [M2WLLM: Multi-Modal Multi-Task Ultra-Short-term Wind Power Prediction Algorithm Based on Large Language Model](https://arxiv.org/abs/2506.00531)
*Hang Fana,Mingxuan Lib,Zuhan Zhanga,Long Chengc,Yujian Ye,Dunnan Liua*

Main category: cs.LG

TL;DR: M2WLLM是一种基于大语言模型（LLMs）的创新模型，用于超短期风电功率预测，通过多模态数据融合显著提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 风电并网需要高精度的超短期功率预测以确保电网稳定性和资源优化分配。

Method: M2WLLM结合文本信息和时序数值数据，通过Prompt Embedder和Data Embedder实现多模态数据融合，利用Semantic Augmenter将时序数据转换为LLMs可理解的格式。

Result: 在三个中国省份的风电场数据上，M2WLLM表现优于现有方法（如GPT4TS），展示了更高的准确性和鲁棒性。

Conclusion: LLMs在超短期风电预测中具有潜力，尤其在少样本学习方面表现突出。

Abstract: The integration of wind energy into power grids necessitates accurate
ultra-short-term wind power forecasting to ensure grid stability and optimize
resource allocation. This study introduces M2WLLM, an innovative model that
leverages the capabilities of Large Language Models (LLMs) for predicting wind
power output at granular time intervals. M2WLLM overcomes the limitations of
traditional and deep learning methods by seamlessly integrating textual
information and temporal numerical data, significantly improving wind power
forecasting accuracy through multi-modal data. Its architecture features a
Prompt Embedder and a Data Embedder, enabling an effective fusion of textual
prompts and numerical inputs within the LLMs framework. The Semantic Augmenter
within the Data Embedder translates temporal data into a format that the LLMs
can comprehend, enabling it to extract latent features and improve prediction
accuracy. The empirical evaluations conducted on wind farm data from three
Chinese provinces demonstrate that M2WLLM consistently outperforms existing
methods, such as GPT4TS, across various datasets and prediction horizons. The
results highlight LLMs' ability to enhance accuracy and robustness in
ultra-short-term forecasting and showcase their strong few-shot learning
capabilities.

</details>


### [351] [Imputation of Missing Data in Smooth Pursuit Eye Movements Using a Self-Attention-based Deep Learning Approach](https://arxiv.org/abs/2506.00545)
*Mehdi Bejani,Guillermo Perez-de-Arenaza-Pozo,Julián D. Arias-Londoño,Juan I. Godino-LLorente*

Main category: cs.LG

TL;DR: 提出了一种基于自注意力机制的时间序列缺失数据填补框架，结合自编码器优化，显著提高了眼动序列重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 生物医学时间序列（如眼动数据）常因眨眼或跟踪丢失出现缺失，影响分析和生物标志物提取。

Method: 使用自注意力网络填补缺失数据，并通过定制自编码器进一步优化眼动序列表示。

Result: 在5,504个序列上测试，显著降低了时间域误差指标（如MAE、MRE、RMSE），并保持频域特性，对大段缺失数据表现稳健。

Conclusion: 该方法为时间序列缺失数据提供了一种可靠解决方案，提升了神经退行性疾病筛查和监测的可靠性。

Abstract: Missing data is a relevant issue in time series, especially in biomedical
sequences such as those corresponding to smooth pursuit eye movements, which
often contain gaps due to eye blinks and track losses, complicating the
analysis and extraction of meaningful biomarkers. In this paper, a novel
imputation framework is proposed using Self-Attention-based Imputation networks
for time series, which leverages the power of deep learning and self-attention
mechanisms to impute missing data. We further refine the imputed data using a
custom made autoencoder, tailored to represent smooth pursuit eye movement
sequences. The proposed approach was implemented using 5,504 sequences from 172
Parkinsonian patients and healthy controls. Results show a significant
improvement in the accuracy of reconstructed eye movement sequences with
respect to other state of the art techniques, substantially reducing the values
for common time domain error metrics such as the mean absolute error, mean
relative error, and root mean square error, while also preserving the signal's
frequency domain characteristics. Moreover, it demonstrates robustness when
large intervals of data are missing. This method offers an alternative solution
for robustly handling missing data in time series, enhancing the reliability of
smooth pursuit analysis for the screening and monitoring of neurodegenerative
disorders.

</details>


### [352] [MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning](https://arxiv.org/abs/2506.00555)
*Peng Xia,Jinglu Wang,Yibo Peng,Kaide Zeng,Xian Wu,Xiangru Tang,Hongtu Zhu,Yun Li,Shujie Liu,Yan Lu,Huaxiu Yao*

Main category: cs.LG

TL;DR: 论文提出了一种基于强化学习的多智能体协作框架MMedAgent-RL，用于动态优化医疗诊断任务中的多智能体协作，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单智能体医疗大视觉语言模型在跨专科任务中泛化能力不足，而静态多智能体协作框架缺乏灵活性和适应性。

Method: 通过强化学习训练两个基于Qwen2.5-VL的GP智能体（分诊医生和主治医生），并引入课程学习策略解决专科输出不一致问题。

Result: 在五个医疗VQA基准测试中，MMedAgent-RL性能优于开源和专有模型，平均性能提升18.4%。

Conclusion: MMedAgent-RL不仅性能优越，还能模拟人类推理模式，为动态医疗协作提供了新思路。

Abstract: Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential
in multimodal diagnostic tasks. However, existing single-agent models struggle
to generalize across diverse medical specialties, limiting their performance.
Recent efforts introduce multi-agent collaboration frameworks inspired by
clinical workflows, where general practitioners (GPs) and specialists interact
in a fixed sequence. Despite improvements, these static pipelines lack
flexibility and adaptability in reasoning. To address this, we propose
MMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that
enables dynamic, optimized collaboration among medical agents. Specifically, we
train two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to
assign patients to appropriate specialties, while the attending physician
integrates the judgments from multi-specialists and its own knowledge to make
final decisions. To address the inconsistency in specialist outputs, we
introduce a curriculum learning (CL)-guided RL strategy that progressively
teaches the attending physician to balance between imitating specialists and
correcting their mistakes. Experiments on five medical VQA benchmarks
demonstrate that MMedAgent-RL not only outperforms both open-source and
proprietary Med-LVLMs, but also exhibits human-like reasoning patterns.
Notably, it achieves an average performance gain of 18.4% over supervised
fine-tuning baselines.

</details>


### [353] [Understanding Behavioral Metric Learning: A Large-Scale Study on Distracting Reinforcement Learning Environments](https://arxiv.org/abs/2506.00563)
*Ziyan Luo,Tianwei Ni,Pierre-Luc Bacon,Doina Precup,Xujie Si*

Main category: cs.LG

TL;DR: 论文探讨了在深度强化学习中通过行为度量（如双仿真度量）进行状态抽象的方法，评估了五种最新方法，并提出了新的评估指标和开源代码库。


<details>
  <summary>Details</summary>
Motivation: 尽管行为度量在抗任务无关噪声方面表现出潜力，但其准确估计仍具挑战性，且理论与实际存在差距。现有研究多关注最终回报，而度量学习的具体效果和性能提升来源尚不明确。

Method: 研究评估了五种基于等距嵌入的方法，并在20种状态任务和14种像素任务中进行了基准测试，引入了去噪因子和孤立度量估计设置以量化度量学习效果。

Result: 研究提供了全面的实验结果，展示了不同方法在去噪和度量学习方面的表现，并开源了模块化代码库以支持未来研究。

Conclusion: 论文系统评估了度量学习在深度强化学习中的作用，提出了新的评估方法，并强调了开源工具对研究可重复性的重要性。

Abstract: A key approach to state abstraction is approximating behavioral metrics
(notably, bisimulation metrics) in the observation space and embedding these
learned distances in the representation space. While promising for robustness
to task-irrelevant noise, as shown in prior work, accurately estimating these
metrics remains challenging, requiring various design choices that create gaps
between theory and practice. Prior evaluations focus mainly on final returns,
leaving the quality of learned metrics and the source of performance gains
unclear. To systematically assess how metric learning works in deep
reinforcement learning (RL), we evaluate five recent approaches, unified
conceptually as isometric embeddings with varying design choices. We benchmark
them with baselines across 20 state-based and 14 pixel-based tasks, spanning
370 task configurations with diverse noise settings. Beyond final returns, we
introduce the evaluation of a denoising factor to quantify the encoder's
ability to filter distractions. To further isolate the effect of metric
learning, we propose and evaluate an isolated metric estimation setting, in
which the encoder is influenced solely by the metric loss. Finally, we release
an open-source, modular codebase to improve reproducibility and support future
research on metric learning in deep RL.

</details>


### [354] [Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing](https://arxiv.org/abs/2506.00574)
*Fatemeh Lotfi,Hossein Rajoli,Fatemeh Afghah*

Main category: cs.LG

TL;DR: 论文提出了一种基于LLM增强的DRL框架（PA-MRL），通过可学习提示优化语义聚类和RL目标，提升O-RAN切片中的资源分配效率。


<details>
  <summary>Details</summary>
Motivation: 现代无线网络需适应动态条件并高效管理多样化服务需求，传统DRL因分散和演变的反馈难以实现最优决策。

Method: 引入基于上下文的适应方法，将可学习提示集成到LLM增强的DRL框架中，动态调整网络条件。

Result: 实验表明，该方法加速收敛并优于其他基线。

Conclusion: 通过提示增强学习，实现了更快、更可扩展和自适应的O-RAN切片资源分配。

Abstract: Modern wireless networks must adapt to dynamic conditions while efficiently
managing diverse service demands. Traditional deep reinforcement learning (DRL)
struggles in these environments, as scattered and evolving feedback makes
optimal decision-making challenging. Large Language Models (LLMs) offer a
solution by structuring unorganized network feedback into meaningful latent
representations, helping RL agents recognize patterns more effectively. For
example, in O-RAN slicing, concepts like SNR, power levels and throughput are
semantically related, and LLMs can naturally cluster them, providing a more
interpretable state representation. To leverage this capability, we introduce a
contextualization-based adaptation method that integrates learnable prompts
into an LLM-augmented DRL framework. Instead of relying on full model
fine-tuning, we refine state representations through task-specific prompts that
dynamically adjust to network conditions. Utilizing ORANSight, an LLM trained
on O-RAN knowledge, we develop Prompt-Augmented Multi agent RL (PA-MRL)
framework. Learnable prompts optimize both semantic clustering and RL
objectives, allowing RL agents to achieve higher rewards in fewer iterations
and adapt more efficiently. By incorporating prompt-augmented learning, our
approach enables faster, more scalable, and adaptive resource allocation in
O-RAN slicing. Experimental results show that it accelerates convergence and
outperforms other baselines.

</details>


### [355] [ORAN-GUIDE: RAG-Driven Prompt Learning for LLM-Augmented Reinforcement Learning in O-RAN Network Slicing](https://arxiv.org/abs/2506.00576)
*Fatemeh Lotfi,Hossein Rajoli,Fatemeh Afghah*

Main category: cs.LG

TL;DR: ORAN-GUIDE是一个双LLM框架，通过语义增强的状态表示提升多智能体强化学习（MARL）在O-RAN中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习（DRL）在处理无线网络中的原始、非结构化输入（如RF特征、QoS指标）时的局限性，以提升策略泛化和决策效率。

Method: 采用双LLM框架，结合领域特定语言模型ORANSight和GPT编码器，生成结构化、上下文感知的提示，为DRL智能体提供高级语义表示。

Result: 实验表明，ORAN-GUIDE在样本效率、策略收敛和性能泛化方面优于标准MARL和单LLM基线。

Conclusion: ORAN-GUIDE为无线系统中的智能控制提供了一种高效且可泛化的解决方案。

Abstract: Advanced wireless networks must support highly dynamic and heterogeneous
service demands. Open Radio Access Network (O-RAN) architecture enables this
flexibility by adopting modular, disaggregated components, such as the RAN
Intelligent Controller (RIC), Centralized Unit (CU), and Distributed Unit (DU),
that can support intelligent control via machine learning (ML). While deep
reinforcement learning (DRL) is a powerful tool for managing dynamic resource
allocation and slicing, it often struggles to process raw, unstructured input
like RF features, QoS metrics, and traffic trends. These limitations hinder
policy generalization and decision efficiency in partially observable and
evolving environments. To address this, we propose \textit{ORAN-GUIDE}, a
dual-LLM framework that enhances multi-agent RL (MARL) with task-relevant,
semantically enriched state representations. The architecture employs a
domain-specific language model, ORANSight, pretrained on O-RAN control and
configuration data, to generate structured, context-aware prompts. These
prompts are fused with learnable tokens and passed to a frozen GPT-based
encoder that outputs high-level semantic representations for DRL agents. This
design adopts a retrieval-augmented generation (RAG) style pipeline tailored
for technical decision-making in wireless systems. Experimental results show
that ORAN-GUIDE improves sample efficiency, policy convergence, and performance
generalization over standard MARL and single-LLM baselines.

</details>


### [356] [Temporal Chunking Enhances Recognition of Implicit Sequential Patterns](https://arxiv.org/abs/2506.00588)
*Jayanta Dey,Nicholas Soures,Miranda Gonzales,Itamar Lerner,Christopher Kanan,Dhireesha Kudithipudi*

Main category: cs.LG

TL;DR: 提出一种神经启发的压缩方法，将时间序列分解为带标签的块，离线生成标签以提升学习效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统神经网络（如RNN）在处理多时间尺度模式时的局限性。

Method: 通过离线睡眠阶段生成上下文标签，将序列压缩为结构单元块。

Result: 初步结果显示，时间分块在资源受限环境下显著提升学习效率，标签可跨任务迁移。

Conclusion: 为未来迁移学习应用提供了早期概念验证。

Abstract: In this pilot study, we propose a neuro-inspired approach that compresses
temporal sequences into context-tagged chunks, where each tag represents a
recurring structural unit or``community'' in the sequence. These tags are
generated during an offline sleep phase and serve as compact references to past
experience, allowing the learner to incorporate information beyond its
immediate input range. We evaluate this idea in a controlled synthetic
environment designed to reveal the limitations of traditional neural network
based sequence learners, such as recurrent neural networks (RNNs), when facing
temporal patterns on multiple timescales. We evaluate this idea in a controlled
synthetic environment designed to reveal the limitations of traditional neural
network based sequence learners, such as recurrent neural networks (RNNs), when
facing temporal patterns on multiple timescales. Our results, while
preliminary, suggest that temporal chunking can significantly enhance learning
efficiency under resource constrained settings. A small-scale human pilot study
using a Serial Reaction Time Task further motivates the idea of structural
abstraction. Although limited to synthetic tasks, this work serves as an early
proof-of-concept, with initial evidence that learned context tags can transfer
across related task, offering potential for future applications in transfer
learning.

</details>


### [357] [Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn](https://arxiv.org/abs/2506.00592)
*Hongyao Tang,Johan Obando-Ceron,Pablo Samuel Castro,Aaron Courville,Glen Berseth*

Main category: cs.LG

TL;DR: 本文研究了深度持续强化学习中的塑性丧失问题，通过‘churn’（网络输出变异性）的视角，发现塑性丧失与神经切线核矩阵的秩下降相关，并提出C-CHAIN方法以减少churn，提升学习性能。


<details>
  <summary>Details</summary>
Motivation: 塑性（适应新任务或环境的能力）对持续学习至关重要，但深度持续强化学习中存在塑性丧失问题，需要研究其机制和解决方法。

Method: 从churn的角度分析塑性丧失，发现其与神经切线核矩阵秩下降相关，并提出C-CHAIN方法以减少churn并自适应调整梯度步长。

Result: C-CHAIN在多种持续学习环境中（如OpenAI Gym Control、ProcGen等）表现优于基线方法，提升了学习性能。

Conclusion: 减少churn有助于防止秩崩溃并提升塑性，C-CHAIN方法在持续学习中具有显著优势。

Abstract: Plasticity, or the ability of an agent to adapt to new tasks, environments,
or distributions, is crucial for continual learning. In this paper, we study
the loss of plasticity in deep continual RL from the lens of churn: network
output variability for out-of-batch data induced by mini-batch training. We
demonstrate that (1) the loss of plasticity is accompanied by the exacerbation
of churn due to the gradual rank decrease of the Neural Tangent Kernel (NTK)
matrix; (2) reducing churn helps prevent rank collapse and adjusts the step
size of regular RL gradients adaptively. Moreover, we introduce Continual Churn
Approximated Reduction (C-CHAIN) and demonstrate it improves learning
performance and outperforms baselines in a diverse range of continual learning
environments on OpenAI Gym Control, ProcGen, DeepMind Control Suite, and
MinAtar benchmarks.

</details>


### [358] [Graph Evidential Learning for Anomaly Detection](https://arxiv.org/abs/2506.00594)
*Chunyu Wei,Wenji Hu,Xingjia Hao,Yunhai Wang,Yueguo Chen,Bing Bai,Fei Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为GEL的概率框架，通过证据学习改进图异常检测，解决了传统方法依赖重构误差的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏可靠的异常标记数据集，图异常检测面临挑战，传统方法依赖重构误差易受噪声和过拟合影响。

Method: 提出Graph Evidential Learning (GEL)框架，通过证据分布建模节点特征和图拓扑，量化两种不确定性（图不确定性和重构不确定性），并将其纳入异常评分机制。

Result: 实验表明，GEL在噪声和结构扰动下表现优异，达到最先进性能。

Conclusion: GEL通过引入不确定性量化，显著提升了图异常检测的鲁棒性和准确性。

Abstract: Graph anomaly detection faces significant challenges due to the scarcity of
reliable anomaly-labeled datasets, driving the development of unsupervised
methods. Graph autoencoders (GAEs) have emerged as a dominant approach by
reconstructing graph structures and node features while deriving anomaly scores
from reconstruction errors. However, relying solely on reconstruction error for
anomaly detection has limitations, as it increases the sensitivity to noise and
overfitting. To address these issues, we propose Graph Evidential Learning
(GEL), a probabilistic framework that redefines the reconstruction process
through evidential learning. By modeling node features and graph topology using
evidential distributions, GEL quantifies two types of uncertainty: graph
uncertainty and reconstruction uncertainty, incorporating them into the anomaly
scoring mechanism. Extensive experiments demonstrate that GEL achieves
state-of-the-art performance while maintaining high robustness against noise
and structural perturbations.

</details>


### [359] [Predictability-Aware Compression and Decompression Framework for Multichannel Time Series Data](https://arxiv.org/abs/2506.00614)
*Ziqi Liu,Pei Zeng,Yi Ding*

Main category: cs.LG

TL;DR: 提出了一种基于可预测性的压缩-解压缩框架，用于多通道时间序列预测，旨在提高效率并保持预测精度。


<details>
  <summary>Details</summary>
Motivation: 现实世界中对多通道时间序列预测的效率需求日益增长，尤其是在边缘和云环境中，因此需要一种高效的通道压缩方法。

Method: 使用具有正交性的周期性关键矩阵捕捉时间序列的可预测性，并在解压缩时通过放松简化假设减少重构误差。

Result: 理论和实验分析表明，该方法在大量通道下具有时间高效性和可扩展性，并在六个数据集上验证了其优越性能。

Conclusion: 该方法在预测精度和运行时间之间取得了平衡，同时与多种预测器兼容。

Abstract: Real-world multichannel time series prediction faces growing demands for
efficiency across edge and cloud environments, making channel compression a
timely and essential problem. Motivated by success of Multiple-Input
Multiple-Output (MIMO) methods, we propose a predictability-aware
compression-decompression framework to reduce runtime, lower communication
cost, and maintain prediction accuracy across diverse predictors. The core idea
involves using a circular periodicity key matrix with orthogonality to capture
underlying time series predictability during compression and to mitigate
reconstruction errors during decompression by relaxing oversimplified data
assumptions. Theoretical and empirical analyses show that the proposed
framework is both time-efficient and scalable under a large number of channels.
Extensive experiments on six datasets across various predictors demonstrate
that the proposed method achieves superior overall performance by jointly
considering prediction accuracy and runtime, while maintaining strong
compatibility with diverse predictors.

</details>


### [360] [Learning with Calibration: Exploring Test-Time Computing of Spatio-Temporal Forecasting](https://arxiv.org/abs/2506.00635)
*Wei Chen,Yuxuan Liang*

Main category: cs.LG

TL;DR: 提出了一种新的测试时计算范式ST-TTC，通过学习校准来提升时空预测的准确性，避免了复杂的训练阶段技术。


<details>
  <summary>Details</summary>
Motivation: 现实场景中的时空预测常受信号异常、噪声和分布偏移的挑战，现有方法计算资源消耗大，难以大规模应用。

Method: 引入频谱域校准器进行周期性偏移校正，并提出基于流式内存队列的快速更新机制，实现高效的测试时计算。

Result: 在真实数据集上的实验表明，该方法具有高效性、通用性、灵活性和有效性。

Conclusion: ST-TTC为时空预测提供了一种高效且通用的解决方案。

Abstract: Spatio-temporal forecasting is crucial in many domains, such as
transportation, meteorology, and energy. However, real-world scenarios
frequently present challenges such as signal anomalies, noise, and
distributional shifts. Existing solutions primarily enhance robustness by
modifying network architectures or training procedures. Nevertheless, these
approaches are computationally intensive and resource-demanding, especially for
large-scale applications. In this paper, we explore a novel test-time computing
paradigm, namely learning with calibration, ST-TTC, for spatio-temporal
forecasting. Through learning with calibration, we aim to capture periodic
structural biases arising from non-stationarity during the testing phase and
perform real-time bias correction on predictions to improve accuracy.
Specifically, we first introduce a spectral-domain calibrator with
phase-amplitude modulation to mitigate periodic shift and then propose a flash
updating mechanism with a streaming memory queue for efficient test-time
computation. ST-TTC effectively bypasses complex training-stage techniques,
offering an efficient and generalizable paradigm. Extensive experiments on
real-world datasets demonstrate the effectiveness, universality, flexibility
and efficiency of our proposed method.

</details>


### [361] [Linear Representation Transferability Hypothesis: Leveraging Small Models to Steer Large Models](https://arxiv.org/abs/2506.00653)
*Femi Bello,Anubrata Das,Fanzhi Zeng,Fangcong Yin,Leqi Liu*

Main category: cs.LG

TL;DR: 论文提出了一种线性表示可转移性（LRT）假设，认为不同模型表示空间之间存在仿射变换关系，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索神经网络在相似架构和数据训练下学习共享表示的可能性，并验证这些表示是否可以通过仿射变换在不同规模模型间转移。

Method: 提出LRT假设，学习不同规模模型隐藏状态间的仿射映射，并评估其是否能保留语义效果。

Result: 实验表明仿射映射能有效保留语义行为，支持LRT假设。

Conclusion: 小模型学习的表示可用于指导大模型行为，LRT假设为跨模型规模表示对齐提供了新方向。

Abstract: It has been hypothesized that neural networks with similar architectures
trained on similar data learn shared representations relevant to the learning
task. We build on this idea by extending the conceptual framework where
representations learned across models trained on the same data can be expressed
as linear combinations of a \emph{universal} set of basis features. These basis
features underlie the learning task itself and remain consistent across models,
regardless of scale. From this framework, we propose the \textbf{Linear
Representation Transferability (LRT)} Hypothesis -- that there exists an affine
transformation between the representation spaces of different models. To test
this hypothesis, we learn affine mappings between the hidden states of models
of different sizes and evaluate whether steering vectors -- directions in
hidden state space associated with specific model behaviors -- retain their
semantic effect when transferred from small to large language models using the
learned mappings. We find strong empirical evidence that such affine mappings
can preserve steering behaviors. These findings suggest that representations
learned by small models can be used to guide the behavior of large models, and
that the LRT hypothesis may be a promising direction on understanding
representation alignment across model scales.

</details>


### [362] [Permutation-Invariant Transformer Neural Architectures for Set-Based Indoor Localization Using Learned RSSI Embeddings](https://arxiv.org/abs/2506.00656)
*Aris J. Aristorenas*

Main category: cs.LG

TL;DR: 提出了一种基于Set Transformer的室内定位方法，利用Wi-Fi RSSI扫描数据，处理无序输入并学习注意力表示。实验表明，该方法在跨建筑和跨楼层任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决室内定位中Wi-Fi信号稀疏、无序输入的问题，并提升跨域性能。

Method: 使用Set Transformer处理无序的(BSSID, RSSI)对，学习嵌入和注意力表示。

Result: 在校园环境中，Set Transformer表现优异，仅次于LSTM，尤其在跨建筑和跨楼层任务中。

Conclusion: 基于集合的神经网络模型适合信号定位任务，能有效处理稀疏无序输入。

Abstract: We propose a permutation-invariant neural architecture for indoor
localization using RSSI scans from Wi-Fi access points. Each scan is modeled as
an unordered set of (BSSID, RSSI) pairs, where BSSIDs are mapped to learned
embeddings and concatenated with signal strength. These are processed by a Set
Transformer, enabling the model to handle variable-length, sparse inputs while
learning attention-based representations over access point relationships. We
evaluate the model on a dataset collected across a campus environment
consisting of six buildings. Results show that the model accurately recovers
fine-grained spatial structure and maintains performance across physically
distinct domains. In our experiments, a simple LSTM consistently outperformed
all other models, achieving the lowest mean localization error across three
tasks (E1 - E3), with average errors as low as 2.23 m. The Set Transformer
performed competitively, ranking second in every experiment and outperforming
the MLP, RNN, and basic attention models, particularly in scenarios involving
multiple buildings (E2) and multiple floors (E3). Performance degraded most in
E2, where signal conditions varied substantially across buildings, highlighting
the importance of architectural robustness to domain diversity. This work
demonstrates that set-based neural models are a natural fit for signal-based
localization, offering a principled approach to handling sparse, unordered
inputs in real-world positioning tasks.

</details>


### [363] [Differential Privacy for Deep Learning in Medicine](https://arxiv.org/abs/2506.00660)
*Marziyeh Mohammadi,Mohsen Vejdanihemmat,Mahshad Lotfinia,Mirabela Rusu,Daniel Truhn,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.LG

TL;DR: 本文综述了差分隐私（DP）在医学深度学习中的应用，分析了DP-SGD及其他机制在集中式和联邦式设置中的表现，强调了隐私、模型准确性和公平性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着医学深度学习对数据的依赖性增加，如何在保护敏感患者数据的同时平衡模型效用和公平性成为关键挑战。

Method: 通过结构化搜索策略，筛选出74项研究，分析不同数据模态、训练设置和任务中DP的应用及其效果。

Result: 研究发现，强隐私预算下DP在结构化成像任务中表现良好，但在严格隐私条件下性能下降明显，尤其对少数群体或复杂模态影响更大。公平性问题因数据类型和任务而异，但多数研究未明确分析。

Conclusion: 未来研究需关注公平性审计、标准化和评估协议，以推动医学中隐私保护深度学习系统的公平性和临床稳健性。

Abstract: Differential privacy (DP) is a key technique for protecting sensitive patient
data in medical deep learning (DL). As clinical models grow more
data-dependent, balancing privacy with utility and fairness has become a
critical challenge. This scoping review synthesizes recent developments in
applying DP to medical DL, with a particular focus on DP-SGD and alternative
mechanisms across centralized and federated settings. Using a structured search
strategy, we identified 74 studies published up to March 2025. Our analysis
spans diverse data modalities, training setups, and downstream tasks, and
highlights the tradeoffs between privacy guarantees, model accuracy, and
subgroup fairness. We find that while DP-especially at strong privacy
budgets-can preserve performance in well-structured imaging tasks, severe
degradation often occurs under strict privacy, particularly in underrepresented
or complex modalities. Furthermore, privacy-induced performance gaps
disproportionately affect demographic subgroups, with fairness impacts varying
by data type and task. A small subset of studies explicitly addresses these
tradeoffs through subgroup analysis or fairness metrics, but most omit them
entirely. Beyond DP-SGD, emerging approaches leverage alternative mechanisms,
generative models, and hybrid federated designs, though reporting remains
inconsistent. We conclude by outlining key gaps in fairness auditing,
standardization, and evaluation protocols, offering guidance for future work
toward equitable and clinically robust privacy-preserving DL systems in
medicine.

</details>


### [364] [SafeTuneBed: A Toolkit for Benchmarking LLM Safety Alignment in Fine-Tuning](https://arxiv.org/abs/2506.00676)
*Saad Hossain,Samanvay Vajpayee,Sirisha Rambhatla*

Main category: cs.LG

TL;DR: SafeTuneBed是一个统一的基准和工具包，用于评估大型语言模型（LLM）的高效微调方法和安全性防御，旨在解决现有评估方法的多样性和不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的广泛应用，高效微调方法和安全性防御方法迅速增多，但评估标准的不一致导致难以公平比较不同方法的安全性、实用性和鲁棒性。

Method: SafeTuneBed通过（i）整合多样化的微调数据集和生成有害变体，（ii）集成先进的防御方法，（iii）提供安全性和实用性评估工具，实现统一的评估。

Result: SafeTuneBed展示了在不同中毒场景和任务中对代表性防御方法的基准测试效果。

Conclusion: SafeTuneBed通过标准化数据、代码和指标，为安全LLM微调研究提供了首个专注的工具包，加速了严谨和可比较的研究。

Abstract: As large language models (LLMs) become ubiquitous, parameter-efficient
fine-tuning methods and safety-first defenses have proliferated rapidly.
However, the number of approaches and their recent increase have resulted in
diverse evaluations-varied datasets, metrics, and inconsistent threat
settings-making it difficult to fairly compare safety, utility, and robustness
across methods. To address this, we introduce SafeTuneBed, a benchmark and
toolkit unifying fine-tuning and defense evaluation. SafeTuneBed (i) curates a
diverse repository of multiple fine-tuning datasets spanning sentiment
analysis, question-answering, multi-step reasoning, and open-ended instruction
tasks, and allows for the generation of harmful-variant splits; (ii) enables
integration of state-of-the-art defenses, including alignment-stage
immunization, in-training safeguards, and post-tuning repair; and (iii)
provides evaluators for safety (attack success rate, refusal consistency) and
utility. Built on Python-first, dataclass-driven configs and plugins,
SafeTuneBed requires minimal additional code to specify any fine-tuning regime,
defense method, and metric suite, while ensuring end-to-end reproducibility. We
showcase its value by benchmarking representative defenses across varied
poisoning scenarios and tasks. By standardizing data, code, and metrics,
SafeTuneBed is the first focused toolkit of its kind to accelerate rigorous and
comparable research in safe LLM fine-tuning. Code is available at:
https://github.com/criticalml-uw/SafeTuneBed

</details>


### [365] [Existing Large Language Model Unlearning Evaluations Are Inconclusive](https://arxiv.org/abs/2506.00688)
*Zhili Feng,Yixuan Even Xu,Alexander Robey,Robert Kirk,Xander Davies,Yarin Gal,Avi Schwarzschild,J. Zico Kolter*

Main category: cs.LG

TL;DR: 本文批判性地分析了机器遗忘评估的现有实践，揭示了其局限性，并提出两项改进原则：最小信息注入和下游任务意识。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为机器遗忘效果不佳，但本文发现评估方法存在问题，可能导致对遗忘效果的误判。

Method: 通过实验揭示评估中的信息注入、任务差异和虚假相关性等问题，并提出新的评估原则。

Result: 实验表明现有评估方法可能高估或低估遗忘效果，新原则能更准确地评估遗忘性能。

Conclusion: 建议未来评估遵循最小信息注入和下游任务意识原则，以提高评估的可靠性和泛化性。

Abstract: Machine unlearning aims to remove sensitive or undesired data from large
language models. However, recent studies suggest that unlearning is often
shallow, claiming that removed knowledge can easily be recovered. In this work,
we critically examine standard unlearning evaluation practices and uncover key
limitations that shake our trust in those findings. First, we show that some
evaluations introduce substantial new information into the model, potentially
masking true unlearning performance by re-teaching the model during testing.
Second, we demonstrate that evaluation outcomes vary significantly across
tasks, undermining the generalizability of current evaluation routines.
Finally, we find that many evaluations rely on spurious correlations, making
their results difficult to trust and interpret. Taken together, these issues
suggest that current evaluation protocols may both overstate and understate
unlearning success. To address this, we propose two principles for future
unlearning evaluations: minimal information injection and downstream task
awareness. We validate these principles through a series of targeted
experiments, showing how violations of each can lead to misleading conclusions.

</details>


### [366] [Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning](https://arxiv.org/abs/2506.00691)
*Junaid Muzaffar,Ahsan Adeel,Khubaib Ahmed,Ingo Frommholz,Zeeshan Pervez,Ahsan ul Haq*

Main category: cs.LG

TL;DR: 论文提出了一种改进的注意力机制，通过非线性变换增强键向量的表示能力，从而提升强化学习模型的效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习训练需要大量计算资源和时间，Google Brain的Sensory Neuron虽然表现优异，但仍有提升空间。

Method: 在注意力机制中引入非线性变换，生成新的键向量（K'），增强特征交互的表示能力。

Result: 改进后的模型显著提升了学习效率，且不影响性能。

Conclusion: 非线性注意力机制在强化学习算法中具有潜在优势。

Abstract: Training reinforcement learning (RL) agents often requires significant
computational resources and extended training times. To address this, we build
upon the foundation laid by Google Brain's Sensory Neuron, which introduced a
novel neural architecture for reinforcement learning tasks that maintained
permutation in-variance in the sensory neuron system. While the baseline model
demonstrated significant performance improvements over traditional approaches,
we identified opportunities to enhance the efficiency of the learning process
further. We propose a modified attention mechanism incorporating a non-linear
transformation of the key vectors (K) using a mapping function, resulting in a
new set of key vectors (K'). This non-linear mapping enhances the
representational capacity of the attention mechanism, allowing the model to
encode more complex feature interactions and accelerating convergence without
compromising performance. Our enhanced model demonstrates significant
improvements in learning efficiency, showcasing the potential for non-linear
attention mechanisms in advancing reinforcement learning algorithms.

</details>


### [367] [Bayesian Inference of Training Dataset Membership](https://arxiv.org/abs/2506.00701)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 提出了一种高效、可解释的贝叶斯推理方法，用于成员推断攻击（MIA），无需依赖模型内部或计算密集型影子模型。


<details>
  <summary>Details</summary>
Motivation: 传统MIA方法需要访问模型内部或依赖计算密集型影子模型，存在隐私漏洞检测的局限性。

Method: 通过分析训练后模型的预测误差、置信度（熵）、扰动幅度和数据集统计量，计算成员资格的后验概率。

Result: 在合成数据集上的实验证明，该方法能有效区分成员与非成员数据集。

Conclusion: 该方法不仅适用于成员推断，还能检测分布偏移，为现有方法提供了实用且可解释的替代方案。

Abstract: Determining whether a dataset was part of a machine learning model's training
data pool can reveal privacy vulnerabilities, a challenge often addressed
through membership inference attacks (MIAs). Traditional MIAs typically require
access to model internals or rely on computationally intensive shadow models.
This paper proposes an efficient, interpretable and principled Bayesian
inference method for membership inference. By analyzing post-hoc metrics such
as prediction error, confidence (entropy), perturbation magnitude, and dataset
statistics from a trained ML model, our approach computes posterior
probabilities of membership without requiring extensive model training.
Experimental results on synthetic datasets demonstrate the method's
effectiveness in distinguishing member from non-member datasets. Beyond
membership inference, this method can also detect distribution shifts, offering
a practical and interpretable alternative to existing approaches.

</details>


### [368] [QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training](https://arxiv.org/abs/2506.00711)
*Wei Dai,Peilin Chen,Chanakya Ekbote,Paul Pu Liang*

Main category: cs.LG

TL;DR: QoQ-Med-7B/32B是一种开放的多模态临床基础模型，能够联合处理医学图像、时间序列信号和文本报告，通过DRPO训练方法显著提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM模型多为视觉中心，难以跨临床专业泛化，因此需要一种能处理多模态数据的通用临床模型。

Method: 采用Domain-aware Relative Policy Optimization (DRPO)训练方法，根据领域稀有性和模态难度分层调整奖励，缓解数据分布不均问题。

Result: DRPO训练使诊断性能平均提升43%（宏F1），在分割任务中IoU比开源模型高10倍，达到OpenAI o4-mini水平。

Conclusion: QoQ-Med通过DRPO和多模态联合推理，显著提升临床诊断性能，并开源模型权重、训练管道和推理轨迹以促进研究。

Abstract: Clinical decision-making routinely demands reasoning over heterogeneous data,
yet existing multimodal language models (MLLMs) remain largely vision-centric
and fail to generalize across clinical specialties. To bridge this gap, we
introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model
that jointly reasons across medical images, time-series signals, and text
reports. QoQ-Med is trained with Domain-aware Relative Policy Optimization
(DRPO), a novel reinforcement-learning objective that hierarchically scales
normalized rewards according to domain rarity and modality difficulty,
mitigating performance imbalance caused by skewed clinical data distributions.
Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains,
we show that DRPO training boosts diagnostic performance by 43% in macro-F1 on
average across all visual domains as compared to other critic-free training
methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation
data, it is able to highlight salient regions related to the diagnosis, with an
IoU 10x higher than open models while reaching the performance of OpenAI
o4-mini. To foster reproducibility and downstream research, we release (i) the
full model weights, (ii) the modular training pipeline, and (iii) all
intermediate reasoning traces at https://github.com/DDVD233/QoQ_Med.

</details>


### [369] [Pitfalls in Evaluating Language Model Forecasters](https://arxiv.org/abs/2506.00723)
*Daniel Paleka,Shashwat Goel,Jonas Geiping,Florian Tramèr*

Main category: cs.LG

TL;DR: 论文指出评估大型语言模型（LLM）在预测任务中的表现存在挑战，包括时间泄漏问题和实际预测能力评估的困难。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在预测任务中表现评估的局限性，强调现有结论可能不可靠。

Method: 通过系统分析和具体案例，揭示评估中的缺陷。

Result: 发现时间泄漏和实际预测能力评估的困难可能导致对LLM性能的误判。

Conclusion: 需要更严格的评估方法来准确评估LLM的预测能力。

Abstract: Large language models (LLMs) have recently been applied to forecasting tasks,
with some works claiming these systems match or exceed human performance. In
this paper, we argue that, as a community, we should be careful about such
conclusions as evaluating LLM forecasters presents unique challenges. We
identify two broad categories of issues: (1) difficulty in trusting evaluation
results due to many forms of temporal leakage, and (2) difficulty in
extrapolating from evaluation performance to real-world forecasting. Through
systematic analysis and concrete examples from prior work, we demonstrate how
evaluation flaws can raise concerns about current and future performance
claims. We argue that more rigorous evaluation methodologies are needed to
confidently assess the forecasting abilities of LLMs.

</details>


### [370] [MoPINNEnKF: Iterative Model Inference using generic-PINN-based ensemble Kalman filter](https://arxiv.org/abs/2506.00731)
*Binghang Lu,Changhong Mou,Guang Lin*

Main category: cs.LG

TL;DR: 提出了一种结合多目标优化的PINN集成卡尔曼滤波框架（MoPINNEnKF），用于提升PINN在含噪声数据和缺失物理信息场景下的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在处理含噪声数据和缺失物理信息的逆问题时性能受限，需要一种更鲁棒的方法。

Method: 结合NSGA-III多目标优化生成PINN集成成员，并通过集成卡尔曼滤波（EnKF）迭代更新参数。

Result: 在Burgers方程和时间分数阶混合扩散波方程上验证，优于标准PINN。

Conclusion: MoPINNEnKF框架显著提升了PINN在复杂场景下的性能。

Abstract: Physics-informed neural networks (PINNs) have emerged as a powerful tool for
solving forward and inverse problems involving partial differential equations
(PDEs) by incorporating physical laws into the training process. However, the
performance of PINNs is often hindered in real-world scenarios involving noisy
observational data and missing physics, particularly in inverse problems. In
this work, we propose an iterative multi-objective PINN ensemble Kalman filter
(MoPINNEnKF) framework that improves the robustness and accuracy of PINNs in
both forward and inverse problems by using the \textit{ensemble Kalman filter}
and the \textit{non-dominated sorting genetic algorithm} III (NSGA-III).
Specifically, NSGA-III is used as a multi-objective optimizer that can generate
various ensemble members of PINNs along the optimal Pareto front, while
accounting the model uncertainty in the solution space. These ensemble members
are then utilized within the EnKF to assimilate noisy observational data. The
EnKF's analysis is subsequently used to refine the data loss component for
retraining the PINNs, thereby iteratively updating their parameters. The
iterative procedure generates improved solutions to the PDEs. The proposed
method is tested on two benchmark problems: the one-dimensional viscous Burgers
equation and the time-fractional mixed diffusion-wave equation (TFMDWE). The
numerical results show it outperforms standard PINNs in handling noisy data and
missing physics.

</details>


### [371] ["Who experiences large model decay and why?" A Hierarchical Framework for Diagnosing Heterogeneous Performance Drift](https://arxiv.org/abs/2506.00756)
*Harvineet Singh,Fan Xia,Alexej Gossmann,Andrew Chuang,Julian C. Hong,Jean Feng*

Main category: cs.LG

TL;DR: SHIFT框架通过识别性能衰减的子群及其原因，提供针对性解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在新环境中性能衰减不均匀，现有方法无法详细解释衰减原因或定位受影响子群。

Method: 提出SHIFT框架，分两步：先定位性能衰减严重的子群，再分析具体变量子集的变化原因。

Result: 实验显示SHIFT能识别可解释的子群衰减，并提供有效缓解措施。

Conclusion: SHIFT为性能衰减提供了详细分析和针对性解决方案。

Abstract: Machine learning (ML) models frequently experience performance degradation
when deployed in new contexts. Such degradation is rarely uniform: some
subgroups may suffer large performance decay while others may not.
Understanding where and how large differences in performance arise is critical
for designing targeted corrective actions that mitigate decay for the most
affected subgroups while minimizing any unintended effects. Current approaches
do not provide such detailed insight, as they either (i) explain how average
performance shifts arise or (ii) identify adversely affected subgroups without
insight into how this occurred. To this end, we introduce a Subgroup-scanning
Hierarchical Inference Framework for performance drifT (SHIFT). SHIFT first
asks "Is there any subgroup with unacceptably large performance decay due to
covariate/outcome shifts?" (Where?) and, if so, dives deeper to ask "Can we
explain this using more detailed variable(subset)-specific shifts?" (How?). In
real-world experiments, we find that SHIFT identifies interpretable subgroups
affected by performance decay, and suggests targeted actions that effectively
mitigate the decay.

</details>


### [372] [Beyond Attention: Learning Spatio-Temporal Dynamics with Emergent Interpretable Topologies](https://arxiv.org/abs/2506.00770)
*Sai Vamsi Alisetti,Vikas Kalagi,Sanjukta Krishnagopal*

Main category: cs.LG

TL;DR: InterGAT是一种简化的图注意力网络替代方案，通过可学习的对称节点交互矩阵捕捉潜在空间关系，显著提升了预测精度和训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统的图注意力网络（GAT）依赖预定义的邻接结构和动态注意力分数，引入了归纳偏差和计算开销，影响了可解释性。

Method: 提出InterGAT，用完全可学习的对称节点交互矩阵替代掩码注意力，并结合GRU时间解码器构建InterGAT-GRU框架。

Result: 在SZ-Taxi和Los-Loop数据集上，InterGAT-GRU的预测精度分别提升21%和6%，训练时间减少60-70%。

Conclusion: InterGAT不仅提升了预测性能和效率，还通过可解释的交互矩阵揭示了动态图域中的功能拓扑结构。

Abstract: Spatio-temporal forecasting is critical in applications such as traffic
prediction, energy demand modeling, and weather monitoring. While Graph
Attention Networks (GATs) are popular for modeling spatial dependencies, they
rely on predefined adjacency structures and dynamic attention scores,
introducing inductive biases and computational overhead that can obscure
interpretability.
  We propose InterGAT, a simplified alternative to GAT that replaces masked
attention with a fully learnable, symmetric node interaction matrix, capturing
latent spatial relationships without relying on fixed graph topologies. Our
framework, InterGAT-GRU, which incorporates a GRU-based temporal decoder,
outperforms the baseline GAT-GRU in forecasting accuracy, achieving at least a
21% improvement on the SZ-Taxi dataset and a 6% improvement on the Los-Loop
dataset across all forecasting horizons (15 to 60 minutes). Additionally, we
observed reduction in training time by 60-70% compared to GAT-GRU baseline.
  Crucially, the learned interaction matrix reveals interpretable structure: it
recovers sparse, topology-aware attention patterns that align with community
structure. Spectral and clustering analyses show that the model captures both
localized and global dynamics, offering insights into the functional topology
driving predictions. This highlights how structure learning can simultaneously
support prediction, computational efficiency, and topological interpretabil-ity
in dynamic graph-based domains.

</details>


### [373] [Manipulating 3D Molecules in a Fixed-Dimensional SE(3)-Equivariant Latent Space](https://arxiv.org/abs/2506.00771)
*Zitao Chen,Yinjun Jia,Zitong Tian,Wei-Ying Ma,Yanyan Lan*

Main category: cs.LG

TL;DR: 提出了一种名为MolFLAE的零-shot分子操作方法，通过SE(3)-等变潜在空间实现3D分子编辑和优化。


<details>
  <summary>Details</summary>
Motivation: 传统药物化学优化依赖3D结构和关键特征保留，现有深度学习方法多为监督任务，缺乏灵活性。

Method: 使用SE(3)-等变变分自编码器（VAE）学习固定维度的潜在空间，结合贝叶斯流网络（BFN）重建分子结构。

Result: 在3D分子生成基准测试中表现优异，支持零-shot编辑（如原子数修改）和药物优化任务。

Conclusion: MolFLAE方法灵活、鲁棒，为分子编辑和优化提供了新途径。

Abstract: Medicinal chemists often optimize drugs considering their 3D structures and
designing structurally distinct molecules that retain key features, such as
shapes, pharmacophores, or chemical properties. Previous deep learning
approaches address this through supervised tasks like molecule inpainting or
property-guided optimization. In this work, we propose a flexible zero-shot
molecule manipulation method by navigating in a shared latent space of 3D
molecules. We introduce a Variational AutoEncoder (VAE) for 3D molecules, named
MolFLAE, which learns a fixed-dimensional, SE(3)-equivariant latent space
independent of atom counts. MolFLAE encodes 3D molecules using an
SE(3)-equivariant neural network into fixed number of latent nodes,
distinguished by learned embeddings. The latent space is regularized, and
molecular structures are reconstructed via a Bayesian Flow Network (BFN)
conditioned on the encoder's latent output. MolFLAE achieves competitive
performance on standard unconditional 3D molecule generation benchmarks.
Moreover, the latent space of MolFLAE enables zero-shot molecule manipulation,
including atom number editing, structure reconstruction, and coordinated latent
interpolation for both structure and properties. We further demonstrate our
approach on a drug optimization task for the human glucocorticoid receptor,
generating molecules with improved hydrophilicity while preserving key
interactions, under computational evaluations. These results highlight the
flexibility, robustness, and real-world utility of our method, opening new
avenues for molecule editing and optimization.

</details>


### [374] [LIFT the Veil for the Truth: Principal Weights Emerge after Rank Reduction for Reasoning-Focused Supervised Fine-Tuning](https://arxiv.org/abs/2506.00772)
*Zihang Liu,Tianyu Pang,Oleg Balabanov,Chaoqun Yang,Tianjin Huang,Lu Yin,Yaoqing Yang,Shiwei Liu*

Main category: cs.LG

TL;DR: 论文提出了一种名为LIFT的低秩稀疏微调方法，通过仅更新5%的主权重，在推理任务中表现优于全微调，同时保持内存效率。


<details>
  <summary>Details</summary>
Motivation: 全微调（Full FT）计算成本高且易过拟合，稀疏微调在LLM时代因难以识别关键参数而表现不佳。

Method: 提出LIFT方法，基于低秩近似识别主权重，仅更新5%的关键参数。

Result: LIFT在推理任务中表现优于Full FT，同时保留更多源领域知识。

Conclusion: LIFT是一种高效且有效的微调方法，适用于LLM的稀疏微调。

Abstract: Recent studies have shown that supervised fine-tuning of LLMs on a small
number of high-quality datasets can yield strong reasoning capabilities.
However, full fine-tuning (Full FT), while powerful, is computationally
expensive and susceptible to overfitting and catastrophic forgetting,
particularly when data is limited. Sparse fine-tuning, which previously
achieved notable success by updating only a small subset of model parameters,
offers a promising trade-off between efficiency and effectiveness. Yet, it has
lagged behind in the LLM era due to the difficulty of identifying parameters
truly critical for reasoning. In this work, we state that weights with the
largest magnitude after low-rank approximation are critical weights for
fine-tuning, which we call Principal Weights. Surprisingly, while
magnitude-based sparse fine-tuning performs poorly as a baseline on LLM
fine-tuning, it becomes highly effective after rank reduction. These insights
motivate our method: Low-rank Informed Sparse Fine-Tuning (LIFT). LIFT only
updates the top 5% Principal Weights throughout training and consistently
achieves better performance on reasoning tasks than Full FT, while maintaining
memory efficiency on par with popular parameter-efficient fine-tuning methods.
In addition to strong performance on target domains such as arithmetic
reasoning, LIFT also retains up to 20% more source-domain knowledge, compared
to Full FT and LoRA. Our code is available at:
https://github.com/zihanghliu/LIFT.

</details>


### [375] [Action Dependency Graphs for Globally Optimal Coordinated Reinforcement Learning](https://arxiv.org/abs/2506.00797)
*Jianglin Ding,Jingcheng Tang,Gangshan Jing*

Main category: cs.LG

TL;DR: 论文提出了一种非自回归形式的动作依赖策略，通过动作依赖图（ADG）建模多智能体间的动作依赖关系，证明了稀疏ADG在特定条件下可实现全局最优，并开发了具有全局最优保证的表格策略迭代算法。


<details>
  <summary>Details</summary>
Motivation: 现有自回归动作依赖策略在多智能体强化学习（MARL）中计算复杂度高，限制了可扩展性。

Method: 提出广义动作依赖策略，使用ADG建模动作依赖，结合协调图理论证明稀疏ADG的全局最优性，并开发表格策略迭代算法。

Result: 实验验证了该框架在复杂环境中的鲁棒性和适用性。

Conclusion: 该方法为更广泛的MARL问题提供了潜在解决方案。

Abstract: Action-dependent individual policies, which incorporate both environmental
states and the actions of other agents in decision-making, have emerged as a
promising paradigm for achieving global optimality in multi-agent reinforcement
learning (MARL). However, the existing literature often adopts auto-regressive
action-dependent policies, where each agent's policy depends on the actions of
all preceding agents. This formulation incurs substantial computational
complexity as the number of agents increases, thereby limiting scalability. In
this work, we consider a more generalized class of action-dependent policies,
which do not necessarily follow the auto-regressive form. We propose to use the
`action dependency graph (ADG)' to model the inter-agent action dependencies.
Within the context of MARL problems structured by coordination graphs, we prove
that an action-dependent policy with a sparse ADG can achieve global
optimality, provided the ADG satisfies specific conditions specified by the
coordination graph. Building on this theoretical foundation, we develop a
tabular policy iteration algorithm with guaranteed global optimality.
Furthermore, we integrate our framework into several SOTA algorithms and
conduct experiments in complex environments. The empirical results affirm the
robustness and applicability of our approach in more general scenarios,
underscoring its potential for broader MARL challenges.

</details>


### [376] [Unlearning Inversion Attacks for Graph Neural Networks](https://arxiv.org/abs/2506.00808)
*Jiahao Zhang,Yilong Wang,Zhiwei Zhang,Xiaorui Liu,Suhang Wang*

Main category: cs.LG

TL;DR: 论文提出了一种针对图神经网络（GNN）去学习方法的反转攻击（TrendAttack），通过利用模型置信度下降和自适应预测机制，成功重建了被删除的边，揭示了当前图去学习方法中的隐私漏洞。


<details>
  <summary>Details</summary>
Motivation: 挑战现有图去学习方法的假设，即删除的数据无法被恢复，通过反转攻击验证其隐私脆弱性。

Method: 提出TrendAttack，利用置信度下降模式（confidence pitfall）和自适应预测机制，结合现有成员推理技术，重建被删除的边。

Result: 在四个真实数据集上的实验表明，TrendAttack显著优于现有的GNN成员推理基线方法。

Conclusion: 当前图去学习方法存在严重的隐私漏洞，需要更鲁棒的去学习机制。

Abstract: Graph unlearning methods aim to efficiently remove the impact of sensitive
data from trained GNNs without full retraining, assuming that deleted
information cannot be recovered. In this work, we challenge this assumption by
introducing the graph unlearning inversion attack: given only black-box access
to an unlearned GNN and partial graph knowledge, can an adversary reconstruct
the removed edges? We identify two key challenges: varying
probability-similarity thresholds for unlearned versus retained edges, and the
difficulty of locating unlearned edge endpoints, and address them with
TrendAttack. First, we derive and exploit the confidence pitfall, a theoretical
and empirical pattern showing that nodes adjacent to unlearned edges exhibit a
large drop in model confidence. Second, we design an adaptive prediction
mechanism that applies different similarity thresholds to unlearned and other
membership edges. Our framework flexibly integrates existing membership
inference techniques and extends them with trend features. Experiments on four
real-world datasets demonstrate that TrendAttack significantly outperforms
state-of-the-art GNN membership inference baselines, exposing a critical
privacy vulnerability in current graph unlearning methods.

</details>


### [377] [Speech Unlearning](https://arxiv.org/abs/2506.00848)
*Jiali Cheng,Hadi Amiri*

Main category: cs.LG

TL;DR: 论文提出了一种针对语音任务的机器遗忘方法，旨在高效移除特定数据对语音模型的影响，而无需完全重新训练。


<details>
  <summary>Details</summary>
Motivation: 研究动机包括隐私保护、移除过时或噪声数据以及减轻偏见。语音数据的多维、时序和说话人依赖性使其成为未充分探索的领域。

Method: 定义了两种语音遗忘任务：样本遗忘（移除单个数据点）和类别遗忘（移除整个类别），同时保留剩余数据的性能。

Result: 实验表明，语音数据的遗忘比图像或文本数据更具挑战性。

Conclusion: 未来研究方向包括结构化训练、鲁棒评估、特征级遗忘、更广泛应用、可扩展方法和对抗鲁棒性。

Abstract: We introduce machine unlearning for speech tasks, a novel and underexplored
research problem that aims to efficiently and effectively remove the influence
of specific data from trained speech models without full retraining. This has
important applications in privacy preservation, removal of outdated or noisy
data, and bias mitigation. While machine unlearning has been studied in
computer vision and natural language processing, its application to speech is
largely unexplored due to the high-dimensional, sequential, and
speaker-dependent nature of speech data. We define two fundamental speech
unlearning tasks: sample unlearning, which removes individual data points
(e.g., a voice recording), and class unlearning, which removes an entire
category (e.g., all data from a speaker), while preserving performance on the
remaining data. Experiments on keyword spotting and speaker identification
demonstrate that unlearning speech data is significantly more challenging than
unlearning image or text data. We conclude with key future directions in this
area, including structured training, robust evaluation, feature-level
unlearning, broader applications, scalable methods, and adversarial robustness.

</details>


### [378] [Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity](https://arxiv.org/abs/2506.00245)
*Dang Nguyen,Ali Payani,Baharan Mirzasoleiman*

Main category: cs.LG

TL;DR: 提出了一种基于最近邻熵估计的黑盒不确定性量化方法，解决了语义熵在长句生成中的局限性，并在多个任务和模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型生成的长句响应使得语义熵（SE）在检测幻觉时效果下降，因其忽略了簇内和簇间相似性。

Method: 提出了一种简单的黑盒不确定性量化方法，基于最近邻熵估计，并可扩展至白盒设置（结合标记概率）。

Result: 在Phi3和Llama3模型及问答、文本摘要和机器翻译任务中，新方法优于语义熵。

Conclusion: 新方法通过改进熵估计，有效解决了语义熵的局限性，并展示了广泛的应用潜力。

Abstract: Hallucination in large language models (LLMs) can be detected by assessing
the uncertainty of model outputs, typically measured using entropy. Semantic
entropy (SE) enhances traditional entropy estimation by quantifying uncertainty
at the semantic cluster level. However, as modern LLMs generate longer
one-sentence responses, SE becomes less effective because it overlooks two
crucial factors: intra-cluster similarity (the spread within a cluster) and
inter-cluster similarity (the distance between clusters). To address these
limitations, we propose a simple black-box uncertainty quantification method
inspired by nearest neighbor estimates of entropy. Our approach can also be
easily extended to white-box settings by incorporating token probabilities.
Additionally, we provide theoretical results showing that our method
generalizes semantic entropy. Extensive empirical results demonstrate its
effectiveness compared to semantic entropy across two recent LLMs (Phi3 and
Llama3) and three common text generation tasks: question answering, text
summarization, and machine translation. Our code is available at
https://github.com/BigML-CS-UCLA/SNNE.

</details>


### [379] [Generalization in VAE and Diffusion Models: A Unified Information-Theoretic Analysis](https://arxiv.org/abs/2506.00849)
*Qi Chen,Jierui Zhu,Florian Shkurti*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，用于分析扩散模型（DMs）和变分自编码器（VAEs）的泛化性能，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型和变分自编码器在实证中表现良好，但其泛化性能的理论研究仍不充分，尤其是缺乏对共享编码器-生成器结构的全面考虑。

Method: 利用信息论工具，提出一个统一的理论框架，将编码器和生成器视为随机映射，为两者的泛化提供保证。

Result: 框架实现了对VAEs生成器泛化的精细分析，揭示了DMs中泛化与扩散时间T的权衡关系，并提供了基于训练数据的可计算边界。

Conclusion: 理论和实证结果验证了所提框架的有效性，为模型优化提供了理论支持。

Abstract: Despite the empirical success of Diffusion Models (DMs) and Variational
Autoencoders (VAEs), their generalization performance remains theoretically
underexplored, especially lacking a full consideration of the shared
encoder-generator structure. Leveraging recent information-theoretic tools, we
propose a unified theoretical framework that provides guarantees for the
generalization of both the encoder and generator by treating them as randomized
mappings. This framework further enables (1) a refined analysis for VAEs,
accounting for the generator's generalization, which was previously overlooked;
(2) illustrating an explicit trade-off in generalization terms for DMs that
depends on the diffusion time $T$; and (3) providing computable bounds for DMs
based solely on the training data, allowing the selection of the optimal $T$
and the integration of such bounds into the optimization process to improve
model performance. Empirical results on both synthetic and real datasets
illustrate the validity of the proposed theory.

</details>


### [380] [Local Manifold Approximation and Projection for Manifold-Aware Diffusion Planning](https://arxiv.org/abs/2506.00867)
*Kyowoon Lee,Jaesik Choi*

Main category: cs.LG

TL;DR: 论文提出了一种名为LoMAP的无训练方法，通过将引导样本投影到离线数据集近似的低秩子空间，解决了扩散生成模型中不可行轨迹的问题，提升了可靠性。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型在长时程稀疏奖励任务中表现良好，但由于采样过程中不准确的引导导致不可行轨迹，限制了其在安全关键应用中的适用性。

Method: 提出LoMAP方法，通过局部流形近似和投影，将引导样本投影到低秩子空间，避免生成不可行轨迹。

Result: 在标准离线强化学习基准测试中验证了LoMAP的有效性，并展示了其作为独立模块在分层扩散规划器中的性能提升。

Conclusion: LoMAP通过解决扩散生成模型中的流形偏差问题，显著提升了模型的可靠性和适用性。

Abstract: Recent advances in diffusion-based generative modeling have demonstrated
significant promise in tackling long-horizon, sparse-reward tasks by leveraging
offline datasets. While these approaches have achieved promising results, their
reliability remains inconsistent due to the inherent stochastic risk of
producing infeasible trajectories, limiting their applicability in
safety-critical applications. We identify that the primary cause of these
failures is inaccurate guidance during the sampling procedure, and demonstrate
the existence of manifold deviation by deriving a lower bound on the guidance
gap. To address this challenge, we propose Local Manifold Approximation and
Projection (LoMAP), a training-free method that projects the guided sample onto
a low-rank subspace approximated from offline datasets, preventing infeasible
trajectory generation. We validate our approach on standard offline
reinforcement learning benchmarks that involve challenging long-horizon
planning. Furthermore, we show that, as a standalone module, LoMAP can be
incorporated into the hierarchical diffusion planner, providing further
performance enhancements.

</details>


### [381] [ModuLM: Enabling Modular and Multimodal Molecular Relational Learning with Large Language Models](https://arxiv.org/abs/2506.00880)
*Zhuo Chen,Yizhen Zheng,Huan Yee Koh,Hongxin Xiang,Linjiang Chen,Wenjie Du,Yang Wang*

Main category: cs.LG

TL;DR: ModuLM是一个支持灵活LLM模型构建和多样化分子表示的框架，旨在解决分子关系学习（MRL）中模型空间扩展带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）和分子结构编码器的多样化，模型空间急剧扩大，缺乏支持灵活输入和动态架构切换的框架，导致冗余编码和不公平的模型比较。

Method: ModuLM提供模块化组件，包括8种2D分子图编码器、11种3D分子构象编码器、7种交互层和7种主流LLM骨干，支持动态构建超过50,000种模型配置。

Result: ModuLM在支持基于LLM的MRL任务中表现出高效性。

Conclusion: ModuLM通过灵活性和模块化设计，为MRL研究提供了标准化和高效的解决方案。

Abstract: Molecular Relational Learning (MRL) aims to understand interactions between
molecular pairs, playing a critical role in advancing biochemical research.
With the recent development of large language models (LLMs), a growing number
of studies have explored the integration of MRL with LLMs and achieved
promising results. However, the increasing availability of diverse LLMs and
molecular structure encoders has significantly expanded the model space,
presenting major challenges for benchmarking. Currently, there is no LLM
framework that supports both flexible molecular input formats and dynamic
architectural switching. To address these challenges, reduce redundant coding,
and ensure fair model comparison, we propose ModuLM, a framework designed to
support flexible LLM-based model construction and diverse molecular
representations. ModuLM provides a rich suite of modular components, including
8 types of 2D molecular graph encoders, 11 types of 3D molecular conformation
encoders, 7 types of interaction layers, and 7 mainstream LLM backbones. Owing
to its highly flexible model assembly mechanism, ModuLM enables the dynamic
construction of over 50,000 distinct model configurations. In addition, we
provide comprehensive results to demonstrate the effectiveness of ModuLM in
supporting LLM-based MRL tasks.

</details>


### [382] [Spectral Insights into Data-Oblivious Critical Layers in Large Language Models](https://arxiv.org/abs/2506.00382)
*Xuyuan Liu,Lei Hsiung,Yaoqing Yang,Yujun Yan*

Main category: cs.LG

TL;DR: 该论文提出了一种数据无关的方法，通过CKA分析预微调LLM中的关键层，发现这些层在微调时变化最大，且与语义转换相关。该方法在领域适应和后门防御中具有实用价值。


<details>
  <summary>Details</summary>
Motivation: 理解LLM中特征表示的演变对提高模型的可解释性和鲁棒性至关重要。现有方法依赖数据，限制了其应用范围。

Method: 使用Centered Kernel Alignment（CKA）分析预微调LLM的表示动态，识别关键层，并通过谱分析揭示其语义转换机制。

Result: 关键层在微调时变化最大，且与语义转换相关。在领域适应中微调关键层能显著减少损失，在后门防御中冻结关键层可降低攻击成功率40%。

Conclusion: 数据无关方法能有效识别LLM中的关键层，为模型优化和安全防御提供了新思路。

Abstract: Understanding how feature representations evolve across layers in large
language models (LLMs) is key to improving their interpretability and
robustness. While recent studies have identified critical layers linked to
specific functions or behaviors, these efforts typically rely on data-dependent
analyses of fine-tuned models, limiting their use to post-hoc settings. In
contrast, we introduce a data-oblivious approach to identify intrinsic critical
layers in pre-fine-tuned LLMs by analyzing representation dynamics via Centered
Kernel Alignment(CKA). We show that layers with significant shifts in
representation space are also those most affected during fine-tuning--a pattern
that holds consistently across tasks for a given model. Our spectral analysis
further reveals that these shifts are driven by changes in the top principal
components, which encode semantic transitions from rationales to conclusions.
We further apply these findings to two practical scenarios: efficient domain
adaptation, where fine-tuning critical layers leads to greater loss reduction
compared to non-critical layers; and backdoor defense, where freezing them
reduces attack success rates by up to 40%.

</details>


### [383] [FLoE: Fisher-Based Layer Selection for Efficient Sparse Adaptation of Low-Rank Experts](https://arxiv.org/abs/2506.00495)
*Xinyi Wang,Lirong Gao,Haobo Wang,Yiming Zhang,Junbo Zhao*

Main category: cs.LG

TL;DR: FLoE是一种新型PEFT框架，通过动态识别关键层和自动优化LoRA秩，显著提升了参数效率和适应性能。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法在所有层上统一部署LoRA适配器，忽略了层的异质性和任务需求，导致参数冗余和效率低下。

Method: FLoE引入Fisher信息评分机制动态识别关键层，并使用贝叶斯优化自动分配LoRA秩。

Result: 实验表明FLoE在多种LLM和任务上实现了高效的准确性与效率平衡。

Conclusion: FLoE在资源受限环境中具有显著优势，适合快速适应任务。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a widely
adopted strategy for adapting pre-trained Large Language Models (LLMs) to
downstream tasks, significantly reducing memory and computational costs.
However, most existing PEFT techniques uniformly deploy LoRA adapters across
all layers, disregarding the intrinsic heterogeneity of layer contributions and
task-specific rank requirements. This uniform paradigm leads to redundant
parameter allocation and suboptimal adaptation efficiency. To address these
limitations, we propose FLoE, a novel PEFT framework that introduces two key
innovations: (i) a Fisher information-guided importance scoring mechanism to
dynamically identify task-critical transformer layers for MoE-based low-rank
adaptation, enabling sparse adapter deployment; and (ii) a Bayesian
optimization-driven rank allocator that automatically determines optimal LoRA
ranks on specific datasets without exhaustive grid search. Extensive
experiments across diverse LLMs and benchmarks reveal that FLoE achieves
impressive efficiency-accuracy trade-offs, making FLoE particularly
advantageous in resource-constrained environments that necessitate rapid
adaptation.

</details>


### [384] [State-Covering Trajectory Stitching for Diffusion Planners](https://arxiv.org/abs/2506.00895)
*Kyowoon Lee,Jaesik Choi*

Main category: cs.LG

TL;DR: SCoTS是一种基于扩散模型的轨迹增强方法，通过拼接短轨迹段生成多样化的长轨迹，显著提升了离线目标条件RL的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在离线RL中的性能受限于训练数据的质量和多样性，难以泛化到训练分布之外的任务或长规划范围。

Method: SCoTS通过学习保留时间距离的潜在表示，并基于方向性探索和新颖性迭代拼接轨迹段，扩展潜在空间。

Result: SCoTS显著提升了扩散规划器在离线目标条件基准上的性能，并改善了广泛使用的离线RL算法的表现。

Conclusion: SCoTS通过轨迹增强有效解决了扩散模型在离线RL中的数据限制问题，提升了泛化能力和性能。

Abstract: Diffusion-based generative models are emerging as powerful tools for
long-horizon planning in reinforcement learning (RL), particularly with offline
datasets. However, their performance is fundamentally limited by the quality
and diversity of training data. This often restricts their generalization to
tasks outside their training distribution or longer planning horizons. To
overcome this challenge, we propose State-Covering Trajectory Stitching
(SCoTS), a novel reward-free trajectory augmentation method that incrementally
stitches together short trajectory segments, systematically generating diverse
and extended trajectories. SCoTS first learns a temporal distance-preserving
latent representation that captures the underlying temporal structure of the
environment, then iteratively stitches trajectory segments guided by
directional exploration and novelty to effectively cover and expand this latent
space. We demonstrate that SCoTS significantly improves the performance and
generalization capabilities of diffusion planners on offline goal-conditioned
benchmarks requiring stitching and long-horizon reasoning. Furthermore,
augmented trajectories generated by SCoTS significantly improve the performance
of widely used offline goal-conditioned RL algorithms across diverse
environments.

</details>


### [385] [PCoreSet: Effective Active Learning through Knowledge Distillation from Vision-Language Models](https://arxiv.org/abs/2506.00910)
*Seongjae Kang,Dong Bok Lee,Hyungjoon Jang,Dongseop Kim,Sung Ju Hwang*

Main category: cs.LG

TL;DR: ActiveKD结合主动学习（AL）与知识蒸馏（KD），利用视觉语言模型（VLMs）的零样本和少样本能力，提出Probabilistic CoreSet（PCoreSet）选择策略，优化样本选择效率。


<details>
  <summary>Details</summary>
Motivation: 现有KD方法假设有充足标注数据，而AL在数据稀缺场景下缺乏任务特定教师模型，因此需要探索KD与AL的结合。

Method: 提出ActiveKD框架，利用VLMs的结构化预测偏差作为教师模型的归纳偏置，设计PCoreSet策略在概率空间最大化覆盖。

Result: 在11个数据集上，PCoreSet在ActiveKD框架中优于现有选择方法。

Conclusion: ActiveKD通过结合AL与KD，利用VLMs特性，为数据稀缺场景下的高效知识迁移提供了新思路。

Abstract: Knowledge distillation (KD) is a widely used framework for training compact,
task-specific models by leveraging the knowledge of teacher models. However,
its application to active learning (AL), which aims to minimize annotation
costs through iterative sample selection, remains underexplored. This gap stems
from the fact that KD typically assumes access to sufficient labeled data,
whereas AL operates in data-scarce scenarios where task-specific teacher models
are often unavailable. In this paper, we introduce ActiveKD, a framework that
integrates AL with KD by leveraging the zero- and few-shot capabilities of
large vision-language models (VLMs). A key aspect of ActiveKD is the structured
prediction bias of VLMs -- i.e., their predictions form clusters in the
probability space. We regard this structure as an inductive bias of the teacher
model, capturing generalizable output patterns beneficial to student learning.
To exploit this bias, we propose Probabilistic CoreSet (PCoreSet), a selection
strategy that maximizes coverage in the probability space rather than the
feature space. PCoreSet strategically selects categorically diverse unlabeled
samples, facilitating more efficient transfer of teacher knowledge under
limited annotation budgets. Evaluations on 11 datasets show that PCoreSet
consistently outperforms existing selection methods within the ActiveKD
framework, advancing research at the intersection of AL and KD.

</details>


### [386] [Principled Input-Output-Conditioned Post-Hoc Uncertainty Estimation for Regression Networks](https://arxiv.org/abs/2506.00918)
*Lennart Bramlage,Cristóbal Curio*

Main category: cs.LG

TL;DR: 提出一种后验不确定性估计的理论框架，通过拟合辅助模型到原始输入和冻结模型输出来实现，无需采样或近似推理。


<details>
  <summary>Details</summary>
Motivation: 在安全敏感应用中，不确定性量化至关重要，但现成的神经网络常因性能影响而忽略。现有方法通常需要模型参数或梯度，限制了实用性。

Method: 基于最大似然估计和顺序参数拟合，提出精确的后验优化目标，恢复高斯参数的经典MLE。利用辅助数据和冻结模型输出支持准认知推理。

Result: 实验证明，使用多样化辅助数据显著提升OOD检测和性能指标。冻结模型输出包含模型误差和预测不确定性的可泛化潜在信息。

Conclusion: 该方法在不依赖基础模型预测的情况下，有效估计输入依赖性不确定性，并在多个基准测试中得到验证。

Abstract: Uncertainty quantification is critical in safety-sensitive applications but
is often omitted from off-the-shelf neural networks due to adverse effects on
predictive performance. Retrofitting uncertainty estimates post-hoc typically
requires access to model parameters or gradients, limiting feasibility in
practice. We propose a theoretically grounded framework for post-hoc
uncertainty estimation in regression tasks by fitting an auxiliary model to
both original inputs and frozen model outputs. Drawing from principles of
maximum likelihood estimation and sequential parameter fitting, we formalize an
exact post-hoc optimization objective that recovers the canonical MLE of
Gaussian parameters, without requiring sampling or approximation at inference.
While prior work has used model outputs to estimate uncertainty, we explicitly
characterize the conditions under which this is valid and demonstrate the
extent to which structured outputs can support quasi-epistemic inference. We
find that using diverse auxiliary data, such as augmented subsets of the
original training data, significantly enhances OOD detection and metric
performance. Our hypothesis that frozen model outputs contain generalizable
latent information about model error and predictive uncertainty is tested and
confirmed. Finally, we ensure that our method maintains proper estimation of
input-dependent uncertainty without relying exclusively on base model
forecasts. These findings are demonstrated in toy problems and adapted to both
UCI and depth regression benchmarks. Code: https://github.com/biggzlar/IO-CUE.

</details>


### [387] [Position as Probability: Self-Supervised Transformers that Think Past Their Training for Length Extrapolation](https://arxiv.org/abs/2506.00920)
*Philip Heejun Lee*

Main category: cs.LG

TL;DR: PRISM是一种新型位置编码机制，使Transformer模型能够准确外推至训练长度的10倍。


<details>
  <summary>Details</summary>
Motivation: 解决深度序列模型在测试序列长度显著超过训练长度时准确率下降的问题，尤其是在算法推理、多步算术和组合泛化等关键任务中。

Method: PRISM通过可微分直方图滤波更新学习连续相对位置，采用概率叠加而非确定性嵌入来保持位置不确定性。

Result: PRISM在算法基准测试（如算术、SCAN组合任务等）中实现了最先进的外推性能，成功泛化至之前难以处理的序列长度。

Conclusion: PRISM的随机位置编码保持了清晰可解释的内部状态，为可靠的序列长度泛化提供了理论基础，推动了神经网络序列模型在远超训练长度时的算法鲁棒性。

Abstract: Deep sequence models typically degrade in accuracy when test sequences
significantly exceed their training lengths, yet many critical tasks--such as
algorithmic reasoning, multi-step arithmetic, and compositional
generalization--require robust length extrapolation. We introduce PRISM, a
Probabilistic Relative-position Implicit Superposition Model, a novel
positional encoding mechanism that enables Transformers to extrapolate
accurately up to 10x beyond their training length. PRISM learns continuous
relative positions through a differentiable histogram-filter update, preserving
position uncertainty via a probabilistic superposition rather than conventional
deterministic embeddings. Empirically, PRISM achieves state-of-the-art length
extrapolation, successfully generalizing to previously intractable sequence
lengths across algorithmic benchmarks--including arithmetic (addition,
multiplication), SCAN compositionality tasks, and complex copy variants derived
from DeepMind's recent datasets. Our analysis demonstrates that PRISM's
stochastic positional encoding maintains sharp and interpretable internal
states, providing a theoretical basis for reliable length generalization. These
results advance the goal of neural sequence models that remain algorithmically
robust at lengths far exceeding their training horizon.

</details>


### [388] [Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms](https://arxiv.org/abs/2506.00732)
*Caio Corro,Mathieu Lacroix,Joseph Le Roux*

Main category: cs.LG

TL;DR: 提出了一种名为Bregman条件随机场（BCRF）的新型序列标记判别模型，支持基于迭代Bregman投影的快速并行推理算法，性能与CRF相当但更快，在受限场景下优于平均场方法。


<details>
  <summary>Details</summary>
Motivation: 标准线性链条件随机场（CRF）的推理速度较慢，需要更高效的并行化替代方案。

Method: 使用Fenchel-Young损失学习BCRF模型，支持部分标签学习，并基于迭代Bregman投影实现快速并行推理。

Result: 实验表明，BCRF性能与CRF相当但更快，在受限场景下优于平均场方法。

Conclusion: BCRF是一种高效且性能优越的序列标记模型，适用于需要快速并行推理的场景。

Abstract: We propose a novel discriminative model for sequence labeling called Bregman
conditional random fields (BCRF). Contrary to standard linear-chain conditional
random fields, BCRF allows fast parallelizable inference algorithms based on
iterative Bregman projections. We show how such models can be learned using
Fenchel-Young losses, including extension for learning from partial labels.
Experimentally, our approach delivers comparable results to CRF while being
faster, and achieves better results in highly constrained settings compared to
mean field, another parallelizable alternative.

</details>


### [389] [Uncertainty-Aware Metabolic Stability Prediction with Dual-View Contrastive Learning](https://arxiv.org/abs/2506.00936)
*Peijin Guo,Minghui Li,Hewen Pan,Bowen Chen,Yang Wu,Zikang Guo,Leo Yu Zhang,Shengshan Hu,Shengqing Hu*

Main category: cs.LG

TL;DR: TrustworthyMS提出了一种基于对比学习的不确定性感知代谢稳定性预测框架，解决了现有方法在分子建模和不确定性量化上的不足。


<details>
  <summary>Details</summary>
Motivation: 准确预测分子代谢稳定性对药物研发至关重要，但现有方法因原子中心的消息传递机制和缺乏不确定性量化而受限。

Method: 通过分子图拓扑重映射机制、对比拓扑-键对齐和Beta-Binomial不确定性量化，提升预测性能和可靠性。

Result: 实验表明，TrustworthyMS在预测性能上优于现有方法。

Conclusion: TrustworthyMS为代谢稳定性预测提供了一种更可靠和高效的方法。

Abstract: Accurate prediction of molecular metabolic stability (MS) is critical for
drug research and development but remains challenging due to the complex
interplay of molecular interactions. Despite recent advances in graph neural
networks (GNNs) for MS prediction, current approaches face two critical
limitations: (1) incomplete molecular modeling due to atom-centric
message-passing mechanisms that disregard bond-level topological features, and
(2) prediction frameworks that lack reliable uncertainty quantification. To
address these challenges, we propose TrustworthyMS, a novel contrastive
learning framework designed for uncertainty-aware metabolic stability
prediction. First, a molecular graph topology remapping mechanism synchronizes
atom-bond interactions through edge-induced feature propagation, capturing both
localized electronic effects and global conformational constraints. Second,
contrastive topology-bond alignment enforces consistency between molecular
topology views and bond patterns via feature alignment, enhancing
representation robustness. Third, uncertainty modeling through Beta-Binomial
uncertainty quantification enables simultaneous prediction and confidence
calibration under epistemic uncertainty. Through extensive experiments, our
results demonstrate that TrustworthyMS outperforms current state-of-the-art
methods in terms of predictive performance.

</details>


### [390] [Generalizable LLM Learning of Graph Synthetic Data with Reinforcement Learning](https://arxiv.org/abs/2506.00845)
*Yizhuo Zhang,Heng Wang,Shangbin Feng,Zhaoxuan Tan,Xinyun Liu,Yulia Tsvetkov*

Main category: cs.LG

TL;DR: 论文提出用强化学习（RL）提升LLMs在图数据上的泛化能力，通过设计基于解和基于过程的奖励机制，避免了直接微调导致的过拟合问题。实验表明，RL方法在5个数据集上显著优于基线，平均提升12.9%。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过监督微调提升LLMs在图算法任务上的表现，但缺乏对真实世界隐含图结构任务的泛化能力。因此，作者希望通过RL解锁图数据的通用学习能力。

Method: 设计基于解和基于过程的奖励机制，使用GRPO和DPO等RL算法对LLMs进行训练，并在合成任务和真实世界任务（如多跳QA、结构化规划）上进行对比实验。

Result: RL方法在5个数据集上显著优于基线，平均提升12.9%。基于过程的奖励表现更优，混合合成与真实数据有潜在收益，但可解释性和组合性仍是挑战。

Conclusion: RL能有效提升LLMs在图数据上的泛化能力，但需进一步解决组合性和可解释性问题。

Abstract: Previous research has sought to enhance the graph reasoning capabilities of
LLMs by supervised fine-tuning on synthetic graph data. While these led to
specialized LLMs better at solving graph algorithm problems, we don't need LLMs
for shortest path: we need generalization from synthetic graph data to
real-world tasks with implicit graph structures. In this work, we propose to
unlock generalizable learning of graph synthetic data with reinforcement
learning. We first design solution-based and process-based rewards for
synthetic graph problems: instead of rigid memorizing response patterns in
direct fine-tuning, we posit that RL would help LLMs grasp the essentials
underlying graph reasoning and alleviate overfitting. We employ RL algorithms
such as GRPO and DPO, aligning both off-the-shelf LLMs and LLMs fine-tuned on
synthetic graph data. We then compare them against existing settings on both
in-domain synthetic tasks and out-of-domain real-world tasks with implicit
graph structures such as multi-hop QA, structured planning, and more. Extensive
experiments demonstrate that our RL recipe leads to statistically significant
improvement on 5 datasets, with an average gain of 12.9\% over baseline
settings. Further analysis reveals that process-based rewards consistently
outperform solution-based rewards, mixing synthetic and real-world task data
yields potential gains, while compositionality and explainable intermediate
steps remains a critical challenge even after RL.

</details>


### [391] [Data Heterogeneity Modeling for Trustworthy Machine Learning](https://arxiv.org/abs/2506.00969)
*Jiashuo Liu,Peng Cui*

Main category: cs.LG

TL;DR: 该论文探讨了数据异质性对机器学习性能的影响，并提出了异构感知机器学习方法，以提升模型的鲁棒性、公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习算法通常优化平均性能，忽视了数据集的内在多样性，导致不可靠的决策、泛化能力不足、不公平结果和错误科学推断。因此，需要一种更细致的方法来建模数据异质性。

Method: 论文提出异构感知机器学习范式，将数据异质性考虑整合到整个机器学习流程中，包括数据收集、模型训练、评估和部署。

Result: 通过应用于医疗、农业、金融和推荐系统等领域，证明了异构感知机器学习的显著优势和潜力，提升了模型的鲁棒性、公平性和可靠性。

Conclusion: 论文总结了异构感知机器学习的重要性，并展望了未来研究方向，旨在推动该领域的发展。

Abstract: Data heterogeneity plays a pivotal role in determining the performance of
machine learning (ML) systems. Traditional algorithms, which are typically
designed to optimize average performance, often overlook the intrinsic
diversity within datasets. This oversight can lead to a myriad of issues,
including unreliable decision-making, inadequate generalization across
different domains, unfair outcomes, and false scientific inferences. Hence, a
nuanced approach to modeling data heterogeneity is essential for the
development of dependable, data-driven systems. In this survey paper, we
present a thorough exploration of heterogeneity-aware machine learning, a
paradigm that systematically integrates considerations of data heterogeneity
throughout the entire ML pipeline -- from data collection and model training to
model evaluation and deployment. By applying this approach to a variety of
critical fields, including healthcare, agriculture, finance, and recommendation
systems, we demonstrate the substantial benefits and potential of
heterogeneity-aware ML. These applications underscore how a deeper
understanding of data diversity can enhance model robustness, fairness, and
reliability and help model diagnosis and improvements. Moreover, we delve into
future directions and provide research opportunities for the whole data mining
community, aiming to promote the development of heterogeneity-aware ML.

</details>


### [392] [Attention Retrieves, MLP Memorizes: Disentangling Trainable Components in the Transformer](https://arxiv.org/abs/2506.01115)
*Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li*

Main category: cs.LG

TL;DR: 研究探讨了Transformer架构中自注意力机制的重要性，发现随机固定注意力的简化模型MixiT在某些任务中表现接近完整Transformer，但在检索任务中表现较差。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer架构中自注意力机制对性能提升的具体贡献，以及不同组件对任务解决的互补作用。

Method: 通过冻结MLP层或注意力投影器，并引入随机固定注意力的MixiT模型，对比标准Transformer的性能差异。

Result: MixiT在算术和记忆任务中表现接近完整Transformer，但在检索任务中表现较差；冻结查询和键投影器的注意力仍能形成关键电路并胜任语言建模。

Conclusion: 架构的异质性对不同任务至关重要，不同组件提供互补的归纳偏差。

Abstract: The Transformer architecture is central to the success of modern Large
Language Models (LLMs), in part due to its surprising ability to perform a wide
range of algorithmic tasks -- including mathematical reasoning, memorization,
and retrieval -- using only gradient-based training on next-token prediction.
While the core component of a Transformer is the self-attention mechanism, we
question how much, and which aspects, of the performance gains can be
attributed to it. To this end, we compare standard Transformers to variants in
which either the multi-layer perceptron (MLP) layers or the attention
projectors (queries and keys) are frozen at initialization. To further isolate
the contribution of attention, we introduce MixiT -- the Mixing Transformer --
a simplified, principled model in which the attention coefficients are entirely
random and fixed at initialization, eliminating any input-dependent computation
or learning in attention. Surprisingly, we find that MixiT matches the
performance of fully trained Transformers on various algorithmic tasks,
especially those involving basic arithmetic or focusing heavily on
memorization. For retrieval-based tasks, we observe that having input-dependent
attention coefficients is consistently beneficial, while MixiT underperforms.
We attribute this failure to its inability to form specialized circuits such as
induction heads -- a specific circuit known to be crucial for learning and
exploiting repeating patterns in input sequences. Even more interestingly, we
find that attention with frozen key and query projectors is not only able to
form induction heads, but can also perform competitively on language modeling.
Our results underscore the importance of architectural heterogeneity, where
distinct components contribute complementary inductive biases crucial for
solving different classes of tasks.

</details>


### [393] [Earley-Driven Dynamic Pruning for Efficient Structured Decoding](https://arxiv.org/abs/2506.01151)
*Xintong Sun,Chi Wei,Minghao Tian,Shiwen Ni*

Main category: cs.LG

TL;DR: ZapFormat是一种基于Earley算法的动态剪枝策略，显著减少内存占用并提升推理速度，适用于多种LLM架构。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）表现出色，但其输出在满足严格结构或语法约束方面仍具挑战性，尤其在函数调用和领域特定语言生成中。

Method: 提出ZapFormat，一种动态剪枝策略，结合Earley算法实时消除无效或冗余状态，并利用状态缓存加速结构化生成。

Result: Formatron（ZapFormat的实现）在结构化生成任务中保持高精度合规输出，推理速度提升高达2倍。

Conclusion: Formatron是一种高效且通用的约束解码引擎，适用于多种LLM架构，已开源。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities, yet ensuring
their outputs conform to strict structural or grammatical constraints remains
challenging, which is critical in function calls and domain-specific language
(DSL) generation. Constrained decoding with context-free grammar is a flexible
approach to guarantee LLMs' adherence to a specific format by dynamically
building a token logits mask. However, creating this mask requires checking the
validity of all tokens in the LLM vocabulary at every decoding step, which
often incurs significant overheads in existing constrained decoding engines. To
address this challenge, we propose $\textbf{ZapFormat}$, a novel
$\textbf{dynamic pruning}$ strategy based on the Earley algorithm that
identifies and eliminates invalid or redundant Earley states in real-time,
significantly reducing memory occupation of the Earley algorithm's states. This
further enables us to use a state cache to speed up structured generations on a
large number of queries. We implemented ZapFormat in a new constrained decoding
engine called Formatron which also incorporates existing optimizations. Through
comprehensive experiments on structured generation tasks, including JSON
generation, JSON Schema validation, and semantic parsing, we demonstrate that
Formatron not only $\textbf{consistently maintains}$ high-precision compliant
outputs but also achieves $\textbf{significant improvements}$ in inference
speed up to 2x compared to state-of-the-art implementations. More importantly,
Formatron is generally applicable across various LLM architectures. We release
Formatron as open source at https://github.com/Dan-wanna-M/formatron.

</details>


### [394] [Taming LLMs by Scaling Learning Rates with Gradient Grouping](https://arxiv.org/abs/2506.01049)
*Siyuan Li,Juanxi Tian,Zedong Wang,Xin Jin,Zicheng Liu,Wentao Zhang,Dan Xu*

Main category: cs.LG

TL;DR: SGG是一种优化器包装器，通过动态分组和组特定缩放改进自适应学习率估计，提升LLM训练的稳定性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLM）训练面临梯度变化和参数高效微调（PEFT）技术兼容性差的问题，现有自适应优化器如AdamW在参数级学习率估计上效率不足。

Method: SGG通过动态分组梯度统计信息并应用组特定缩放来校准学习率，既保持参数级适应性又引入组级约束。

Result: 实验表明，SGG与现有优化器兼容，在不同模型规模下均能实现更快的收敛和稳定的性能提升。

Conclusion: SGG是一种鲁棒的LLM优化选择，适用于不同批次大小和学习率场景。

Abstract: Training large language models (LLMs) poses challenges due to their massive
scale and heterogeneous architectures. While adaptive optimizers like AdamW
help address gradient variations, they still struggle with efficient and
effective parameter-wise learning rate estimation, resulting in training
instability, slow convergence, and poor compatibility with parameter-efficient
fine-tuning (PEFT) techniques. This work introduces Scaling with Gradient
Grouping (SGG), an optimizer wrapper that improves adaptive learning rate
estimation by dynamic grouping and group-specific scaling. SGG first groups
gradient statistics in each layer into clusters and then applies
cluster-specific scaling to calibrate learning rates for each parameter, thus
imposing collective group-wise constraints while maintaining precise
per-parameter adaptation. Experiments on diverse (M)LLM benchmarks show that
SGG integrates seamlessly with existing optimizers, and offers consistent gains
and faster convergence over baselines, with various model sizes. Its stability
across varying batch sizes and learning rates establishes SGG as a robust
choice for LLM optimization.

</details>


### [395] [XAI-Units: Benchmarking Explainability Methods with Unit Tests](https://arxiv.org/abs/2506.01059)
*Jun Rui Lee,Sadegh Emami,Michael David Hollins,Timothy C. H. Wong,Carlos Ignacio Villalobos Sánchez,Francesca Toni,Dekai Zhang,Adam Dejl*

Main category: cs.LG

TL;DR: 论文介绍了XAI-Units基准测试，用于评估特征归因（FA）方法在不同模型行为中的表现，旨在提供客观比较。


<details>
  <summary>Details</summary>
Motivation: 当前FA方法在解释机器学习模型时存在分歧，缺乏统一标准评估其适用性。

Method: 提出XAI-Units基准测试，包含已知内部机制的模型和数据集，并提供内置评估指标。

Result: 通过合成数据和模型，实现了对FA方法的客观比较，揭示了其在不同模型行为中的表现。

Conclusion: XAI-Units为FA方法的评估提供了标准化工具，推动了可解释AI的发展。

Abstract: Feature attribution (FA) methods are widely used in explainable AI (XAI) to
help users understand how the inputs of a machine learning model contribute to
its outputs. However, different FA models often provide disagreeing importance
scores for the same model. In the absence of ground truth or in-depth knowledge
about the inner workings of the model, it is often difficult to meaningfully
determine which of the different FA methods produce more suitable explanations
in different contexts. As a step towards addressing this issue, we introduce
the open-source XAI-Units benchmark, specifically designed to evaluate FA
methods against diverse types of model behaviours, such as feature
interactions, cancellations, and discontinuous outputs. Our benchmark provides
a set of paired datasets and models with known internal mechanisms,
establishing clear expectations for desirable attribution scores. Accompanied
by a suite of built-in evaluation metrics, XAI-Units streamlines systematic
experimentation and reveals how FA methods perform against distinct, atomic
kinds of model reasoning, similar to unit tests in software engineering.
Crucially, by using procedurally generated models tied to synthetic datasets,
we pave the way towards an objective and reliable comparison of FA methods.

</details>


### [396] [MUDI: A Multimodal Biomedical Dataset for Understanding Pharmacodynamic Drug-Drug Interactions](https://arxiv.org/abs/2506.01478)
*Tung-Lam Ngo,Ba-Hoang Tran,Duy-Cat Can,Trung-Hieu Do,Oliver Y. Chén,Hoang-Quynh Le*

Main category: cs.LG

TL;DR: 论文介绍了MUDI，一个多模态生物医学数据集，用于研究药物相互作用（DDI），并评估了学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有DDI数据集主要关注文本信息，忽视了反映复杂药物机制的多模态数据。

Method: 引入MUDI数据集，结合药理学文本、化学公式、分子结构图和图像，标注了310,532对药物组合。测试集包含未见过的药物对。

Result: 评估了基于晚期融合投票和中期融合策略的基准模型。

Conclusion: MUDI为药物相互作用研究提供了全面的多模态表示，并公开了数据、注释和基准模型。

Abstract: Understanding the interaction between different drugs (drug-drug interaction
or DDI) is critical for ensuring patient safety and optimizing therapeutic
outcomes. Existing DDI datasets primarily focus on textual information,
overlooking multimodal data that reflect complex drug mechanisms. In this
paper, we (1) introduce MUDI, a large-scale Multimodal biomedical dataset for
Understanding pharmacodynamic Drug-drug Interactions, and (2) benchmark
learning methods to study it. In brief, MUDI provides a comprehensive
multimodal representation of drugs by combining pharmacological text, chemical
formulas, molecular structure graphs, and images across 310,532 annotated drug
pairs labeled as Synergism, Antagonism, or New Effect. Crucially, to
effectively evaluate machine-learning based generalization, MUDI consists of
unseen drug pairs in the test set. We evaluate benchmark models using both late
fusion voting and intermediate fusion strategies. All data, annotations,
evaluation scripts, and baselines are released under an open research license.

</details>


### [397] [Reconsidering LLM Uncertainty Estimation Methods in the Wild](https://arxiv.org/abs/2506.01114)
*Yavuz Bakman,Duygu Nur Yaldiz,Sungmin Kang,Tuo Zhang,Baturalp Buyukates,Salman Avestimehr,Sai Praneeth Karimireddy*

Main category: cs.LG

TL;DR: 本文系统评估了大型语言模型（LLM）不确定性估计（UE）方法在实际部署中的四个关键方面，发现现有方法在阈值选择敏感性和对抗提示脆弱性方面存在问题，但在长文本生成和多分数集成方面有改进潜力。


<details>
  <summary>Details</summary>
Motivation: 现有UE方法主要在孤立短问答环境中评估，而实际部署面临阈值选择、查询变换、长文本生成和多分数处理等挑战，需系统性研究。

Method: 评估了19种UE方法在阈值敏感性、查询变换（如拼写错误、对抗提示、聊天历史）、长文本生成适应性和多分数集成策略的表现。

Result: 多数UE方法对阈值选择敏感且易受对抗提示影响，但对聊天历史和拼写错误鲁棒；长文本生成适应性有限，多分数集成显著提升性能。

Conclusion: UE方法在实际部署中需改进阈值鲁棒性和对抗提示防御，长文本生成和多分数集成是未来研究方向。

Abstract: Large Language Model (LLM) Uncertainty Estimation (UE) methods have become a
crucial tool for detecting hallucinations in recent years. While numerous UE
methods have been proposed, most existing studies evaluate them in isolated
short-form QA settings using threshold-independent metrics such as AUROC or
PRR. However, real-world deployment of UE methods introduces several
challenges. In this work, we systematically examine four key aspects of
deploying UE methods in practical settings. Specifically, we assess (1) the
sensitivity of UE methods to decision threshold selection, (2) their robustness
to query transformations such as typos, adversarial prompts, and prior chat
history, (3) their applicability to long-form generation, and (4) strategies
for handling multiple UE scores for a single query. Our evaluations on 19 UE
methods reveal that most of them are highly sensitive to threshold selection
when there is a distribution shift in the calibration dataset. While these
methods generally exhibit robustness against previous chat history and typos,
they are significantly vulnerable to adversarial prompts. Additionally, while
existing UE methods can be adapted for long-form generation through various
strategies, there remains considerable room for improvement. Lastly, ensembling
multiple UE scores at test time provides a notable performance boost, which
highlights its potential as a practical improvement strategy. Code is available
at: https://github.com/duygunuryldz/uncertainty_in_the_wild.

</details>


### [398] [Neuro-Symbolic Generative Diffusion Models for Physically Grounded, Robust, and Safe Generation](https://arxiv.org/abs/2506.01121)
*Jacob K. Christopher,Michael Cardei,Jinhao Liang,Ferdinando Fioretto*

Main category: cs.LG

TL;DR: 论文提出Neuro-Symbolic Diffusion (NSD)框架，结合扩散模型与符号优化，生成符合用户定义约束的样本，适用于连续和离散输出。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在安全关键或科学严谨应用中因需满足严格约束而受限，NSD旨在解决这一问题。

Method: NSD框架通过交替扩散步骤与符号优化，确保生成样本在功能和逻辑约束下的一致性。

Result: NSD在安全性、数据稀缺性和域外泛化等任务中表现优异，如生成无毒分子和无碰撞轨迹。

Conclusion: NSD为扩散模型在约束条件下的应用提供了新思路，扩展了其适用范围。

Abstract: Despite the remarkable generative capabilities of diffusion models, their
integration into safety-critical or scientifically rigorous applications
remains hindered by the need to ensure compliance with stringent physical,
structural, and operational constraints. To address this challenge, this paper
introduces Neuro-Symbolic Diffusion (NSD), a novel framework that interleaves
diffusion steps with symbolic optimization, enabling the generation of
certifiably consistent samples under user-defined functional and logic
constraints. This key feature is provided for both standard and discrete
diffusion models, enabling, for the first time, the generation of both
continuous (e.g., images and trajectories) and discrete (e.g., molecular
structures and natural language) outputs that comply with constraints. This
ability is demonstrated on tasks spanning three key challenges: (1) Safety, in
the context of non-toxic molecular generation and collision-free trajectory
optimization; (2) Data scarcity, in domains such as drug discovery and
materials engineering; and (3) Out-of-domain generalization, where enforcing
symbolic constraints allows adaptation beyond the training distribution.

</details>


### [399] [Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability](https://arxiv.org/abs/2506.01789)
*Genta Indra Winata,David Anugraha,Emmy Liu,Alham Fikri Aji,Shou-Yi Hung,Aditya Parashar,Patrick Amadeus Irawan,Ruochen Zhang,Zheng-Xin Yong,Jan Christian Blaise Cruz,Niklas Muennighoff,Seungone Kim,Hanyang Zhao,Sudipta Kar,Kezia Erina Suryoraharjo,M. Farid Adilazuarda,En-Shiun Annie Lee,Ayu Purwarianti,Derry Tanti Wijaya,Monojit Choudhury*

Main category: cs.LG

TL;DR: 论文提出DataRubrics框架，通过系统化、标准化的评估指标改进数据集质量审查，并探索合成数据生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前数据集论文缺乏原创性、多样性和质量控制，且审查过程中常忽略这些问题。现有工具如datasheets虽促进透明度，但缺乏标准化评估方法。

Method: 提出DataRubrics框架，结合LLM评估方法，提供可重复、可扩展的数据集质量评估方案。

Result: DataRubrics为数据集质量评估提供了结构化、可操作的解决方案，支持更高效的数据生成与评估。

Conclusion: 论文呼吁在数据集审查中采用系统化评估指标，并开源代码以支持LLM评估的可重复性。

Abstract: High-quality datasets are fundamental to training and evaluating machine
learning models, yet their creation-especially with accurate human
annotations-remains a significant challenge. Many dataset paper submissions
lack originality, diversity, or rigorous quality control, and these
shortcomings are often overlooked during peer review. Submissions also
frequently omit essential details about dataset construction and properties.
While existing tools such as datasheets aim to promote transparency, they are
largely descriptive and do not provide standardized, measurable methods for
evaluating data quality. Similarly, metadata requirements at conferences
promote accountability but are inconsistently enforced. To address these
limitations, this position paper advocates for the integration of systematic,
rubric-based evaluation metrics into the dataset review process-particularly as
submission volumes continue to grow. We also explore scalable, cost-effective
methods for synthetic data generation, including dedicated tools and
LLM-as-a-judge approaches, to support more efficient evaluation. As a call to
action, we introduce DataRubrics, a structured framework for assessing the
quality of both human- and model-generated datasets. Leveraging recent advances
in LLM-based evaluation, DataRubrics offers a reproducible, scalable, and
actionable solution for dataset quality assessment, enabling both authors and
reviewers to uphold higher standards in data-centric research. We also release
code to support reproducibility of LLM-based evaluations at
https://github.com/datarubrics/datarubrics.

</details>


### [400] [Unified Scaling Laws for Compressed Representations](https://arxiv.org/abs/2506.01863)
*Andrei Panferov,Alexandra Volkova,Ionut-Vlad Modoranu,Vage Egiazarian,Mher Safaryan,Dan Alistarh*

Main category: cs.LG

TL;DR: 本文研究了扩展定律与压缩格式之间的相互作用，验证了一个通用的扩展定律框架，并提出了一个简单的“容量”指标，用于预测多种压缩表示下的参数效率。


<details>
  <summary>Details</summary>
Motivation: 随着AI计算成本的上升，模型压缩技术（如量化和稀疏化）的需求增加，但扩展定律与压缩格式的关系尚不明确。本文旨在探索统一的扩展框架是否能准确预测不同压缩表示下的模型性能。

Method: 通过理论分析和实证研究，验证通用扩展定律框架，并提出基于随机高斯数据拟合能力的“容量”指标。

Result: 研究发现，该“容量”指标能稳健预测多种压缩表示下的参数效率，并扩展了公式以比较不同压缩格式的精度潜力。

Conclusion: 本文证明了扩展定律与压缩格式的兼容性，并提供了实用的算法改进，特别是在稀疏量化格式的训练中。

Abstract: Scaling laws have shaped recent advances in machine learning by enabling
predictable scaling of model performance based on model size, computation, and
data volume. Concurrently, the rise in computational cost for AI has motivated
model compression techniques, notably quantization and sparsification, which
have emerged to mitigate the steep computational demands associated with
large-scale training and inference. This paper investigates the interplay
between scaling laws and compression formats, exploring whether a unified
scaling framework can accurately predict model performance when training occurs
over various compressed representations, such as sparse, scalar-quantized,
sparse-quantized or even vector-quantized formats. Our key contributions
include validating a general scaling law formulation and showing that it is
applicable both individually but also composably across compression types.
Based on this, our main finding is demonstrating both theoretically and
empirically that there exists a simple "capacity" metric -- based on the
representation's ability to fit random Gaussian data -- which can robustly
predict parameter efficiency across multiple compressed representations. On the
practical side, we extend our formulation to directly compare the accuracy
potential of different compressed formats, and to derive better algorithms for
training over sparse-quantized formats.

</details>


### [401] [FORT: Forward-Only Regression Training of Normalizing Flows](https://arxiv.org/abs/2506.01158)
*Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose*

Main category: cs.LG

TL;DR: 论文提出了一种无需模拟的训练框架FORT，通过简单的L2回归目标训练一步生成模型，避免了传统最大似然训练中的昂贵计算，并在分子系统平衡采样等应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统生成模型在高质量样本生成和似然计算时需要昂贵的数值模拟，限制了其在科学应用中的推广。

Method: 提出Forward-Only Regression Training (FORT)，一种L2回归目标，将先验样本映射到特定目标，避免了传统最大似然训练中的变量变换计算。

Result: FORT支持多种目标（如最优传输目标和预训练CNF目标），训练的一步生成模型在性能和稳定性上优于最大似然训练，并适用于更广泛的架构。

Conclusion: FORT框架在分子系统平衡采样等任务中表现出色，为生成模型训练提供了高效且可扩展的替代方案。

Abstract: Simulation-free training frameworks have been at the forefront of the
generative modelling revolution in continuous spaces, leading to neural
dynamical systems that encompass modern large-scale diffusion and flow matching
models. Despite the scalability of training, the generation of high-quality
samples and their corresponding likelihood under the model requires expensive
numerical simulation -- inhibiting adoption in numerous scientific applications
such as equilibrium sampling of molecular systems. In this paper, we revisit
classical normalizing flows as one-step generative models with exact
likelihoods and propose a novel, scalable training objective that does not
require computing the expensive change of variable formula used in conventional
maximum likelihood training. We propose Forward-Only Regression Training
(FORT), a simple $\ell_2$-regression objective that maps prior samples under
our flow to specifically chosen targets. We demonstrate that FORT supports a
wide class of targets, such as optimal transport targets and targets from
pre-trained continuous-time normalizing flows (CNF). We further demonstrate
that by using CNF targets, our one-step flows allow for larger-scale training
that exceeds the performance and stability of maximum likelihood training,
while unlocking a broader class of architectures that were previously
challenging to train. Empirically, we elucidate that our trained flows can
perform equilibrium conformation sampling in Cartesian coordinates of alanine
dipeptide, alanine tripeptide, and alanine tetrapeptide.

</details>


### [402] [Bridging Quantum and Classical Computing in Drug Design: Architecture Principles for Improved Molecule Generation](https://arxiv.org/abs/2506.01177)
*Andrew Smith,Erhan Guven*

Main category: cs.LG

TL;DR: 论文提出了一种优化量子-经典混合生成对抗网络（BO-QGAN）的方法，用于药物发现，性能显著优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 利用嘈杂中等规模量子（NISQ）设备进行药物发现，但现有模型架构不明确，需优化量子-经典桥接架构。

Method: 采用多目标贝叶斯优化方法，系统优化量子-经典混合GAN的架构。

Result: 优化后的BO-QGAN性能显著提升，药物候选评分（DCS）比量子混合基准高2.27倍，比经典基准高2.21倍，且参数减少60%以上。

Conclusion: 研究首次提供了基于实证的混合模型架构指南，有助于更有效地将量子计算机整合到药物研发流程中。

Abstract: Hybrid quantum-classical machine learning offers a path to leverage noisy
intermediate-scale quantum (NISQ) devices for drug discovery, but optimal model
architectures remain unclear. We systematically optimize the quantum-classical
bridge architecture for generative adversarial networks (GANs) in molecular
discovery using multi-objective Bayesian optimization. Our optimized model
(BO-QGAN) significantly improves performance, achieving a 2.27-fold higher Drug
Candidate Score (DCS) than prior quantum-hybrid benchmarks and 2.21-fold higher
than the classical baseline, using over 60% fewer parameters. Key findings
favor layering multiple (3-4) shallow (4-8 qubit) quantum circuits
sequentially, while classical architecture shows less sensitivity above a
minimum capacity. This work provides the first empirically grounded
architectural guidelines for hybrid models, enabling more effective integration
of current quantum computers into pharmaceutical research pipelines.

</details>


### [403] [Doubly Robust Alignment for Large Language Models](https://arxiv.org/abs/2506.01183)
*Erhan Xu,Kai Ye,Hongyi Zhou,Luhan Zhu,Francesco Quinzan,Chengchun Shi*

Main category: cs.LG

TL;DR: 本文提出了一种双稳健偏好优化算法（DRPO），用于解决强化学习从人类反馈（RLHF）中的模型错误设定问题，该算法在偏好模型或参考策略中任一正确设定时均能保持一致。


<details>
  <summary>Details</summary>
Motivation: RLHF在调整大型语言模型与人类偏好方面表现出潜力，但现有算法对偏好模型、参考策略或奖励函数的错误设定高度敏感，导致微调效果不佳。

Method: 提出了一种双稳健偏好优化算法（DRPO），该算法在偏好模型或参考策略中任一正确设定时均能保持一致。

Result: DRPO在理论和实践中均优于现有最先进算法，表现出更优且更稳健的性能。

Conclusion: DRPO为解决RLHF中的模型错误设定问题提供了一种有效且稳健的解决方案。

Abstract: This paper studies reinforcement learning from human feedback (RLHF) for
aligning large language models with human preferences. While RLHF has
demonstrated promising results, many algorithms are highly sensitive to
misspecifications in the underlying preference model (e.g., the Bradley-Terry
model), the reference policy, or the reward function, resulting in undesirable
fine-tuning. To address model misspecification, we propose a doubly robust
preference optimization algorithm that remains consistent when either the
preference model or the reference policy is correctly specified (without
requiring both). Our proposal demonstrates superior and more robust performance
than state-of-the-art algorithms, both in theory and in practice. The code is
available at https://github.com/DRPO4LLM/DRPO4LLM

</details>


### [404] [Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution](https://arxiv.org/abs/2506.01231)
*Wenhao Song,Xuan Wu,Bo Yang,You Zhou,Yubin Xiao,Yanchun Liang,Hongwei Ge,Heow Pueh Lee,Chunguo Wu*

Main category: cs.LG

TL;DR: 论文提出了一种新的梯度贡献（GC）方法，通过分析梯度方向冲突来解决权重耦合问题，并提出了统一的图神经架构搜索（UGAS）框架，实验表明GC在超网划分质量和时间效率上达到最优，UGAS+GC搜索的架构优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有少样本神经架构搜索（NAS）方法在解决权重耦合问题时存在计算效率低和划分方案次优的问题，需要更有效的解决方案。

Method: 提出梯度贡献（GC）方法，通过计算梯度方向的余弦相似性来分配模块到子超网，并设计UGAS框架以统一搜索图神经网络（MPNNs和GTs）的最优组合。

Result: GC在超网划分质量和时间效率上达到SOTA性能，UGAS+GC搜索的架构优于手动设计的GNNs和现有NAS方法。

Conclusion: GC和UGAS方法有效解决了权重耦合问题，并在图神经架构搜索中表现出优越性能。

Abstract: To address the weight coupling problem, certain studies introduced few-shot
Neural Architecture Search (NAS) methods, which partition the supernet into
multiple sub-supernets. However, these methods often suffer from computational
inefficiency and tend to provide suboptimal partitioning schemes. To address
this problem more effectively, we analyze the weight coupling problem from a
novel perspective, which primarily stems from distinct modules in succeeding
layers imposing conflicting gradient directions on the preceding layer modules.
Based on this perspective, we propose the Gradient Contribution (GC) method
that efficiently computes the cosine similarity of gradient directions among
modules by decomposing the Vector-Jacobian Product during supernet
backpropagation. Subsequently, the modules with conflicting gradient directions
are allocated to distinct sub-supernets while similar ones are grouped
together. To assess the advantages of GC and address the limitations of
existing Graph Neural Architecture Search methods, which are limited to
searching a single type of Graph Neural Networks (Message Passing Neural
Networks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph
Neural Architecture Search (UGAS) framework, which explores optimal
combinations of MPNNs and GTs. The experimental results demonstrate that GC
achieves state-of-the-art (SOTA) performance in supernet partitioning quality
and time efficiency. In addition, the architectures searched by UGAS+GC
outperform both the manually designed GNNs and those obtained by existing NAS
methods. Finally, ablation studies further demonstrate the effectiveness of all
proposed methods.

</details>


### [405] [TSRating: Rating Quality of Diverse Time Series Data by Meta-learning from LLM Judgment](https://arxiv.org/abs/2506.01290)
*Shunyu Wu,Dan Li,Haozheng Ye,Zhuomin Chen,Jiahui Zhou,Jian Lou,Zibin Zheng,See-Kiong Ng*

Main category: cs.LG

TL;DR: TSRating是一个基于LLMs的统一框架，用于评估多领域时间序列数据质量，通过元学习和signSGD优化训练效率，实验证明其在准确性、效率和跨领域适应性上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单一领域内表现良好，但无法有效处理多领域时间序列数据的多样性，因此需要一种统一且高效的质量评估框架。

Method: 提出TSRating框架，利用LLMs的知识设计提示词对样本进行质量比较，并通过元学习和signSGD训练专用模型TSRater。

Result: 在11个基准数据集和3个时间序列任务上的实验表明，TSRating在准确性、效率和跨领域适应性上优于基线方法。

Conclusion: TSRating通过结合LLMs和元学习，为多领域时间序列数据质量评估提供了一种高效且统一的解决方案。

Abstract: High-quality time series (TS) data are essential for ensuring TS model
performance, rendering research on rating TS data quality indispensable.
Existing methods have shown promising rating accuracy within individual
domains, primarily by extending data quality rating techniques such as
influence functions and Shapley values to account for temporal characteristics.
However, they neglect the fact that real-world TS data can span vastly
different domains and exhibit distinct properties, hampering the accurate and
efficient rating of diverse TS data. In this paper, we propose TSRating, a
novel and unified framework for rating the quality of time series data crawled
from diverse domains. TSRating is built on the assumption that LLMs inherit
ample knowledge, acquired during their extensive pretraining, enabling them to
comprehend and discern quality differences in diverse TS data. We verify this
assumption by devising a series of prompts to elicit quality comparisons from
LLMs for pairs of TS samples. We then fit a dedicated rating model, termed
TSRater, to convert the LLMs' judgments into efficient quality predictions via
TSRater's inference on future TS samples. To ensure cross-domain adaptability,
we develop a meta-learning scheme to train TSRater on quality comparisons
collected from nine distinct domains. To improve training efficiency, we employ
signSGD for inner-loop updates, thus circumventing the demanding computation of
hypergradients. Extensive experimental results on eleven benchmark datasets
across three time series tasks, each using both conventional TS models and TS
foundation models, demonstrate that TSRating outperforms baselines in terms of
estimation accuracy, efficiency, and domain adaptability.

</details>


### [406] [T-SHIRT: Token-Selective Hierarchical Data Selection for Instruction Tuning](https://arxiv.org/abs/2506.01317)
*Yanjun Fu,Faisal Hamman,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: T-SHIRT是一种新的数据选择框架，通过评估令牌级信息量和样本鲁棒性，显著提升指令调优效率，仅用5%数据即可超越完整数据集训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有指令调优数据选择方法仅关注样本级质量，忽略令牌级信息量和评分方法的鲁棒性，导致数据冗余和效率低下。

Method: 提出T-SHIRT框架，结合令牌级信息量评估和样本邻域质量一致性，选择高质量数据。

Result: 在8个基准测试中，T-SHIRT选出的5%数据训练模型平均性能提升5.48分，优于完整数据集训练效果。

Conclusion: T-SHIRT高效且成本低，适用于不同规模的LLM，显著提升指令调优性能。

Abstract: Instruction tuning is essential for Large Language Models (LLMs) to
effectively follow user instructions. To improve training efficiency and reduce
data redundancy, recent works use LLM-based scoring functions, e.g.,
Instruction-Following Difficulty (IFD), to select high-quality
instruction-tuning data with scores above a threshold. While these data
selection methods often lead to models that can match or even exceed the
performance of models trained on the full datasets, we identify two key
limitations: (i) they assess quality at the sample level, ignoring token-level
informativeness; and (ii) they overlook the robustness of the scoring method,
often selecting a sample due to superficial lexical features instead of its
true quality. In this work, we propose Token-Selective HIeRarchical Data
Selection for Instruction Tuning (T-SHIRT), a novel data selection framework
that introduces a new scoring method to include only informative tokens in
quality evaluation and also promotes robust and reliable samples whose
neighbors also show high quality with less local inconsistencies. We
demonstrate that models instruction-tuned on a curated dataset (only 5% of the
original size) using T-SHIRT can outperform those trained on the entire
large-scale dataset by up to 5.48 points on average across eight benchmarks.
Across various LLMs and training set scales, our method consistently surpasses
existing state-of-the-art data selection techniques, while also remaining both
cost-effective and highly efficient. For instance, by using GPT-2 for score
computation, we are able to process a dataset of 52k samples using 40 minutes
on a single GPU.

</details>


### [407] [Unlearning's Blind Spots: Over-Unlearning and Prototypical Relearning Attack](https://arxiv.org/abs/2506.01318)
*SeungBum Ha,Saerom Park,Sung Whan Yoon*

Main category: cs.LG

TL;DR: 论文提出了一种名为Spotter的方法，解决了机器学习中遗忘学习（MU）的两个盲点：过度遗忘和事后重新学习攻击。Spotter通过掩码知识蒸馏和类内分散损失，有效减少了过度遗忘并阻止了重新学习攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘学习技术忽视了过度遗忘和重新学习攻击这两个关键问题，导致模型性能下降或遗忘知识被恢复。

Method: 提出Spotter方法，结合掩码知识蒸馏惩罚和类内分散损失，抑制过度遗忘并分散遗忘类嵌入。

Result: 在CIFAR-10上，Spotter显著减少了过度遗忘，遗忘准确率降至0%，保留集准确率接近原始模型，并成功阻止了重新学习攻击。

Conclusion: Spotter是一种实用的解决方案，有效解决了遗忘学习的盲点。

Abstract: Machine unlearning (MU) aims to expunge a designated forget set from a
trained model without costly retraining, yet the existing techniques overlook
two critical blind spots: "over-unlearning" that deteriorates retained data
near the forget set, and post-hoc "relearning" attacks that aim to resurrect
the forgotten knowledge. We first derive the over-unlearning metric
OU@{\epsilon}, which represents the collateral damage to the nearby region of
the forget set, where the over-unlearning mainly appears. Next, we expose an
unforeseen relearning threat on MU, i.e., the Prototypical Relearning Attack,
which exploits the per-class prototype of the forget class with just a few
samples, and easily restores the pre-unlearning performance. To counter both
blind spots, we introduce Spotter, a plug-and-play objective that combines (i)
a masked knowledge-distillation penalty on the nearby region of forget set to
suppress OU@{\epsilon}, and (ii) an intra-class dispersion loss that scatters
forget-class embeddings, neutralizing prototypical relearning attacks. On
CIFAR-10, as one of validations, Spotter reduces OU@{\epsilon}by below the
0.05X of the baseline, drives forget accuracy to 0%, preserves accuracy of the
retain set within 1% of difference with the original, and denies the
prototype-attack by keeping the forget set accuracy within <1%, without
accessing retained data. It confirms that Spotter is a practical remedy of the
unlearning's blind spots.

</details>


### [408] [$Ψ$-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models](https://arxiv.org/abs/2506.01320)
*Taehoon Yoon,Yunhong Min,Kyeongmin Yeo,Minhyuk Sung*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce $\Psi$-Sampler, an SMC-based framework incorporating pCNL-based
initial particle sampling for effective inference-time reward alignment with a
score-based generative model. Inference-time reward alignment with score-based
generative models has recently gained significant traction, following a broader
paradigm shift from pre-training to post-training optimization. At the core of
this trend is the application of Sequential Monte Carlo (SMC) to the denoising
process. However, existing methods typically initialize particles from the
Gaussian prior, which inadequately captures reward-relevant regions and results
in reduced sampling efficiency. We demonstrate that initializing from the
reward-aware posterior significantly improves alignment performance. To enable
posterior sampling in high-dimensional latent spaces, we introduce the
preconditioned Crank-Nicolson Langevin (pCNL) algorithm, which combines
dimension-robust proposals with gradient-informed dynamics. This approach
enables efficient and scalable posterior sampling and consistently improves
performance across various reward alignment tasks, including layout-to-image
generation, quantity-aware generation, and aesthetic-preference generation, as
demonstrated in our experiments.

</details>


### [409] [STSA: Federated Class-Incremental Learning via Spatial-Temporal Statistics Aggregation](https://arxiv.org/abs/2506.01327)
*Zenghao Guan,Guojun Zhu,Yucan Zhou,Wu Liu,Weiping Wang,Jiebo Luo,Xiaoyan Gu*

Main category: cs.LG

TL;DR: 论文提出了一种名为STSA的新方法，通过空间-时间统计聚合解决联邦类增量学习中的数据异构性和计算通信开销问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦类增量学习方法无法避免数据异构性导致的空间-时间客户端漂移，且计算和通信开销大，限制了实际应用。

Method: 提出STSA框架，通过空间（跨客户端）和时间（跨阶段）聚合特征统计量，避免数据异构性影响，并以闭式更新分类器。同时提出通信高效的STSA-E变体。

Result: 在三个广泛使用的FCIL数据集上，STSA在性能、灵活性、计算和通信效率方面优于现有方法。

Conclusion: STSA和STSA-E有效解决了FCIL中的挑战，具有实际部署潜力。

Abstract: Federated Class-Incremental Learning (FCIL) enables Class-Incremental
Learning (CIL) from distributed data. Existing FCIL methods typically integrate
old knowledge preservation into local client training. However, these methods
cannot avoid spatial-temporal client drift caused by data heterogeneity and
often incur significant computational and communication overhead, limiting
practical deployment. To address these challenges simultaneously, we propose a
novel approach, Spatial-Temporal Statistics Aggregation (STSA), which provides
a unified framework to aggregate feature statistics both spatially (across
clients) and temporally (across stages). The aggregated feature statistics are
unaffected by data heterogeneity and can be used to update the classifier in
closed form at each stage. Additionally, we introduce STSA-E, a
communication-efficient variant with theoretical guarantees, achieving similar
performance to STSA-E with much lower communication overhead. Extensive
experiments on three widely used FCIL datasets, with varying degrees of data
heterogeneity, show that our method outperforms state-of-the-art FCIL methods
in terms of performance, flexibility, and both communication and computation
efficiency.

</details>


### [410] [NoiseAR: AutoRegressing Initial Noise Prior for Diffusion Models](https://arxiv.org/abs/2506.01337)
*Zeming Li,Xiangyue Liu,Xiangyu Zhang,Ping Tan,Heung-Yeung Shum*

Main category: cs.LG

TL;DR: NoiseAR是一种自回归初始噪声先验方法，用于扩散模型，通过学习动态可控的初始噪声分布，提升样本质量和条件输入一致性。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型的初始噪声通常来自简单固定分布，缺乏结构和外部控制机制。现有方法多为确定性或启发式，表达力不足且难以扩展。

Method: NoiseAR将初始噪声先验参数生成建模为空间块或标记的自回归概率任务，捕捉复杂空间依赖并引入学习结构。

Result: 实验表明，NoiseAR生成的初始噪声先验能提高样本质量，增强与条件输入的一致性。

Conclusion: NoiseAR为扩散模型提供了一种概率化的、可学习的初始噪声生成方法，支持与概率框架的无缝集成。

Abstract: Diffusion models have emerged as powerful generative frameworks, creating
data samples by progressively denoising an initial random state. Traditionally,
this initial state is sampled from a simple, fixed distribution like isotropic
Gaussian, inherently lacking structure and a direct mechanism for external
control. While recent efforts have explored ways to introduce controllability
into the diffusion process, particularly at the initialization stage, they
often rely on deterministic or heuristic approaches. These methods can be
suboptimal, lack expressiveness, and are difficult to scale or integrate into
more sophisticated optimization frameworks. In this paper, we introduce
NoiseAR, a novel method for AutoRegressive Initial Noise Prior for Diffusion
Models. Instead of a static, unstructured source, NoiseAR learns to generate a
dynamic and controllable prior distribution for the initial noise. We formulate
the generation of the initial noise prior's parameters as an autoregressive
probabilistic modeling task over spatial patches or tokens. This approach
enables NoiseAR to capture complex spatial dependencies and introduce learned
structure into the initial state. Crucially, NoiseAR is designed to be
conditional, allowing text prompts to directly influence the learned prior,
thereby achieving fine-grained control over the diffusion initialization. Our
experiments demonstrate that NoiseAR can generate initial noise priors that
lead to improved sample quality and enhanced consistency with conditional
inputs, offering a powerful, learned alternative to traditional random
initialization. A key advantage of NoiseAR is its probabilistic formulation,
which naturally supports seamless integration into probabilistic frameworks
like Markov Decision Processes and Reinforcement Learning. Our code will be
available at https://github.com/HKUST-SAIL/NoiseAR/

</details>


### [411] [Unraveling Spatio-Temporal Foundation Models via the Pipeline Lens: A Comprehensive Review](https://arxiv.org/abs/2506.01364)
*Yuchen Fang,Hao Miao,Yuxuan Liang,Liwei Deng,Yue Cui,Ximu Zeng,Yuyang Xia,Yan Zhao,Torben Bach Pedersen,Christian S. Jensen,Xiaofang Zhou,Kai Zheng*

Main category: cs.LG

TL;DR: 该论文综述了时空基础模型的整体流程，包括数据预处理、嵌入技术、模型设计与选择、训练目标及适应技术，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习模型需针对不同任务单独训练的问题，探索时空基础模型的统一框架及其设计、预训练和适应方法。

Method: 从流程角度综述时空基础模型，包括数据类型、预处理、嵌入技术、模型分类、训练目标和适应技术。

Result: 提出了清晰的时空基础模型流程框架，帮助研究者快速入门，并指出多目标训练等新兴机会。

Conclusion: 该综述为时空基础模型的研究提供了系统化的指导，并展望了未来发展方向。

Abstract: Spatio-temporal deep learning models aims to utilize useful patterns in such
data to support tasks like prediction. However, previous deep learning models
designed for specific tasks typically require separate training for each use
case, leading to increased computational and storage costs. To address this
issue, spatio-temporal foundation models have emerged, offering a unified
framework capable of solving multiple spatio-temporal tasks. These foundation
models achieve remarkable success by learning general knowledge with
spatio-temporal data or transferring the general capabilities of pre-trained
language models. While previous surveys have explored spatio-temporal data and
methodologies separately, they have ignored a comprehensive examination of how
foundation models are designed, selected, pre-trained, and adapted. As a
result, the overall pipeline for spatio-temporal foundation models remains
unclear. To bridge this gap, we innovatively provide an up-to-date review of
previous spatio-temporal foundation models from the pipeline perspective. The
pipeline begins with an introduction to different types of spatio-temporal
data, followed by details of data preprocessing and embedding techniques. The
pipeline then presents a novel data property taxonomy to divide existing
methods according to data sources and dependencies, providing efficient and
effective model design and selection for researchers. On this basis, we further
illustrate the training objectives of primitive models, as well as the
adaptation techniques of transferred models. Overall, our survey provides a
clear and structured pipeline to understand the connection between core
elements of spatio-temporal foundation models while guiding researchers to get
started quickly. Additionally, we introduce emerging opportunities such as
multi-objective training in the field of spatio-temporal foundation models.

</details>


### [412] [Incentivizing LLMs to Self-Verify Their Answers](https://arxiv.org/abs/2506.01369)
*Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An*

Main category: cs.LG

TL;DR: 论文提出了一种自验证框架，通过统一生成和验证过程，提升大语言模型在推理任务中的表现，无需依赖外部验证器。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部奖励模型指导生成，但效果有限，主要因生成器与奖励模型分布不一致。

Method: 提出自验证框架，通过强化学习统一生成和验证，训练模型自我评估答案正确性。

Result: 在多个数学推理基准测试中，模型不仅提升了训练后性能，还能在推理时有效扩展。

Conclusion: 自验证框架解决了分布差异问题，显著提升了模型性能，且无需外部验证器。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in complex
reasoning tasks through both post-training and test-time scaling laws. While
prevalent test-time scaling approaches are often realized by using external
reward models to guide the model generation process, we find only marginal
gains can be acquired when scaling a model post-trained on specific reasoning
tasks. We identify that the limited improvement stems from distribution
discrepancies between the specific post-trained generator and the general
reward model. To address this, we propose a framework that incentivizes LLMs to
self-verify their own answers. By unifying answer generation and verification
within a single reinforcement learning (RL) process, we train models that can
effectively assess the correctness of their own solutions. The trained model
can further scale its performance during inference time by verifying its
generations, without the need for external verifiers. We train our
self-verification models based on Qwen2.5-Math-7B and
DeepSeek-R1-Distill-Qwen-1.5B, demonstrating its capabilities across varying
reasoning context lengths. Experiments on multiple mathematical reasoning
benchmarks show that our models can not only improve post-training performance
but also enable effective test-time scaling. Our code is available at
https://github.com/mansicer/self-verification.

</details>


### [413] [Compiler Optimization via LLM Reasoning for Efficient Model Serving](https://arxiv.org/abs/2506.01374)
*Sujun Tang,Christopher Priebe,Rohan Mahapatra,Lianhui Qin,Hadi Esmaeilzadeh*

Main category: cs.LG

TL;DR: 论文提出了一种基于大型语言模型（LLM）和蒙特卡洛树搜索（MCTS）的编译器优化框架（REASONING COMPILER），显著提高了样本效率，并实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 大规模模型的高成本是普及和快速创新的主要障碍，现有编译器难以处理神经工作负载的复杂优化空间。

Method: 结合LLM和MCTS，将优化问题转化为上下文感知的序列决策过程，LLM生成硬件感知的转换建议，MCTS平衡探索与利用。

Result: 该方法在样本效率上显著优于现有神经编译器，实现了性能的显著提升。

Conclusion: LLM引导的推理在编译器优化领域具有变革潜力。

Abstract: While model serving has unlocked unprecedented capabilities, the high cost of
serving large-scale models continues to be a significant barrier to widespread
accessibility and rapid innovation. Compiler optimizations have long driven
substantial performance improvements, but existing compilers struggle with
neural workloads due to the exponentially large and highly interdependent space
of possible transformations. Although existing stochastic search techniques can
be effective, they are often sample-inefficient and fail to leverage the
structural context underlying compilation decisions. We set out to investigate
the research question of whether reasoning with large language models (LLMs),
without any retraining, can leverage the context-aware decision space of
compiler optimization to significantly improve sample efficiency. To that end,
we introduce a novel compilation framework (dubbed REASONING COMPILER) that
formulates optimization as a sequential, context-aware decision process, guided
by a large language model and structured Monte Carlo tree search (MCTS). The
LLM acts as a proposal mechanism, suggesting hardware-aware transformations
that reflect the current program state and accumulated performance feedback.
Monte Carlo tree search (MCTS) incorporates the LLM-generated proposals to
balance exploration and exploitation, facilitating structured,
context-sensitive traversal of the expansive compiler optimization space. By
achieving substantial speedups with markedly fewer samples than leading neural
compilers, our approach demonstrates the potential of LLM-guided reasoning to
transform the landscape of compiler optimization.

</details>


### [414] [ShaTS: A Shapley-based Explainability Method for Time Series Artificial Intelligence Models applied to Anomaly Detection in Industrial Internet of Things](https://arxiv.org/abs/2506.01450)
*Manuel Franco de la Peña,Ángel Luis Perales Gómez,Lorenzo Fernández Maimó*

Main category: cs.LG

TL;DR: ShaTS是一种模型无关的可解释AI方法，通过保留时间依赖性提升Shapley值解释的精度，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 工业物联网环境中，传统解释方法常忽略时间结构，导致解释不精确或不可操作。

Method: ShaTS采用先验特征分组策略，保留时间依赖性，生成更连贯且可操作的见解。

Result: 在SWaT数据集上，ShaTS能准确识别关键时间点、受影响的传感器和执行器，并在解释性和资源效率上优于SHAP。

Conclusion: ShaTS满足工业环境的实时需求，提供更精确和可操作的解释。

Abstract: Industrial Internet of Things environments increasingly rely on advanced
Anomaly Detection and explanation techniques to rapidly detect and mitigate
cyberincidents, thereby ensuring operational safety. The sequential nature of
data collected from these environments has enabled improvements in Anomaly
Detection using Machine Learning and Deep Learning models by processing time
windows rather than treating the data as tabular. However, conventional
explanation methods often neglect this temporal structure, leading to imprecise
or less actionable explanations. This work presents ShaTS (Shapley values for
Time Series models), which is a model-agnostic explainable Artificial
Intelligence method designed to enhance the precision of Shapley value
explanations for time series models. ShaTS addresses the shortcomings of
traditional approaches by incorporating an a priori feature grouping strategy
that preserves temporal dependencies and produces both coherent and actionable
insights. Experiments conducted on the SWaT dataset demonstrate that ShaTS
accurately identifies critical time instants, precisely pinpoints the sensors,
actuators, and processes affected by anomalies, and outperforms SHAP in terms
of both explainability and resource efficiency, fulfilling the real-time
requirements of industrial environments.

</details>


### [415] [Automatic Stage Lighting Control: Is it a Rule-Driven Process or Generative Task?](https://arxiv.org/abs/2506.01482)
*Zijian Zhao,Dian Jin,Zijing Zhou,Xiaoyu Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为Skip-BART的端到端解决方案，用于自动舞台灯光控制（ASLC），通过直接从经验丰富的灯光工程师学习，将ASLC视为生成任务而非分类问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将音乐分类为有限类别并映射到预定义灯光模式，导致公式化和单调的结果，缺乏合理性。

Method: 改进BART模型，以音频音乐为输入，输出灯光色调和强度，并引入新的跳跃连接机制以增强音乐与灯光之间的关系。

Result: Skip-BART在定量分析和人类评估中均优于传统基于规则的方法，与真实灯光工程师的差距较小（p值为0.72）。

Conclusion: Skip-BART在自动舞台灯光控制中表现出色，接近人类灯光工程师的水平，为后续研究提供了数据集和代码支持。

Abstract: Stage lighting plays an essential role in live music performances,
influencing the engaging experience of both musicians and audiences. Given the
high costs associated with hiring or training professional lighting engineers,
Automatic Stage Lighting Control (ASLC) has gained increasing attention.
However, most existing approaches only classify music into limited categories
and map them to predefined light patterns, resulting in formulaic and
monotonous outcomes that lack rationality. To address this issue, this paper
presents an end-to-end solution that directly learns from experienced lighting
engineers -- Skip-BART. To the best of our knowledge, this is the first work to
conceptualize ASLC as a generative task rather than merely a classification
problem. Our method modifies the BART model to take audio music as input and
produce light hue and value (intensity) as output, incorporating a novel skip
connection mechanism to enhance the relationship between music and light within
the frame grid.We validate our method through both quantitative analysis and an
human evaluation, demonstrating that Skip-BART outperforms conventional
rule-based methods across all evaluation metrics and shows only a limited gap
compared to real lighting engineers.Specifically, our method yields a p-value
of 0.72 in a statistical comparison based on human evaluations with human
lighting engineers, suggesting that the proposed approach closely matches human
lighting engineering performance. To support further research, we have made our
self-collected dataset, code, and trained model parameters available at
https://github.com/RS2002/Skip-BART .

</details>


### [416] [Learning of Population Dynamics: Inverse Optimization Meets JKO Scheme](https://arxiv.org/abs/2506.01502)
*Mikhail Persiianov,Jiawei Chen,Petr Mokrov,Alexander Tyurin,Evgeny Burnaev,Alexander Korotin*

Main category: cs.LG

TL;DR: 论文提出了一种结合JKO框架和逆优化技术的方法$	exttt{iJKOnet}$，用于学习群体动力学，通过对抗训练实现，无需限制性架构选择，并展示了优于现有JKO方法的性能。


<details>
  <summary>Details</summary>
Motivation: 学习群体动力学需要从离散时间点的样本演化快照中恢复潜在过程，现有方法将其视为概率空间中的能量最小化问题，并利用JKO方案进行高效时间离散化。

Method: 提出$	exttt{iJKOnet}$方法，结合JKO框架和逆优化技术，采用端到端的对抗训练，避免输入凸神经网络等限制性架构。

Result: 理论证明了方法的有效性，实验表明其性能优于现有的JKO方法。

Conclusion: $	exttt{iJKOnet}$是一种高效且灵活的群体动力学学习方法，具有理论保证和实际优势。

Abstract: Learning population dynamics involves recovering the underlying process that
governs particle evolution, given evolutionary snapshots of samples at discrete
time points. Recent methods frame this as an energy minimization problem in
probability space and leverage the celebrated JKO scheme for efficient time
discretization. In this work, we introduce $\texttt{iJKOnet}$, an approach that
combines the JKO framework with inverse optimization techniques to learn
population dynamics. Our method relies on a conventional $\textit{end-to-end}$
adversarial training procedure and does not require restrictive architectural
choices, e.g., input-convex neural networks. We establish theoretical
guarantees for our methodology and demonstrate improved performance over prior
JKO-based methods.

</details>


### [417] [A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments](https://arxiv.org/abs/2506.01533)
*Yuchen Ma,Jonas Schweisthal,Hengrui Zhang,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 论文提出了一种名为DIME的扩散方法，用于学习医疗治疗中多维结果的联合分布，解决了现有方法仅关注单结果的局限性。


<details>
  <summary>Details</summary>
Motivation: 医疗治疗通常影响多个相互依赖的结果，但现有机器学习方法多关注单结果预测，无法满足临床需求。

Method: DIME通过因果掩码和条件分布分解，学习多维结果的联合分布，支持混合类型数据并捕获结果间的依赖关系。

Result: 实验表明DIME能有效学习联合分布并捕捉多结果间的共享信息。

Conclusion: DIME是首个专注于医疗治疗多结果联合分布的神经方法，为临床决策提供了更全面的不确定性量化。

Abstract: In medicine, treatments often influence multiple, interdependent outcomes,
such as primary endpoints, complications, adverse events, or other secondary
endpoints. Hence, to make optimal treatment decisions, clinicians are
interested in learning the distribution of multi-dimensional treatment
outcomes. However, the vast majority of machine learning methods for predicting
treatment effects focus on single-outcome settings, despite the fact that
medical data often include multiple, interdependent outcomes. To address this
limitation, we propose a novel diffusion-based method called DIME to learn the
joint distribution of multiple outcomes of medical treatments. We addresses
three challenges relevant in medical practice: (i)it is tailored to learn the
joint interventional distribution of multiple medical outcomes, which enables
reliable decision-making with uncertainty quantification rather than relying
solely on point estimates; (ii)it explicitly captures the dependence structure
between outcomes; (iii)it can handle outcomes of mixed type, including binary,
categorical, and continuous variables. In DIME, we take into account the
fundamental problem of causal inference through causal masking. For training,
our method decomposes the joint distribution into a series of conditional
distributions with a customized conditional masking to account for the
dependence structure across outcomes. For inference, our method
auto-regressively generates predictions. This allows our method to move beyond
point estimates of causal quantities and thus learn the joint interventional
distribution. To the best of our knowledge, DIME is the first neural method
tailored to learn the joint, multi-outcome distribution of medical treatments.
Across various experiments, we demonstrate that our method effectively learns
the joint distribution and captures shared information among multiple outcomes.

</details>


### [418] [VirnyFlow: A Design Space for Responsible Model Development](https://arxiv.org/abs/2506.01584)
*Denys Herasymuk,Nazar Protsiv,Julia Stoyanovich*

Main category: cs.LG

TL;DR: VirnyFlow是一个负责任模型开发的设计空间，支持数据科学家根据问题上下文定制ML管道，显著优于现有AutoML系统。


<details>
  <summary>Details</summary>
Motivation: 现实问题本质上是多目标的，需要一种能够支持定制优化标准并适应实际约束的ML开发框架。

Method: VirnyFlow整合了评估协议定义、多目标贝叶斯优化、成本感知多臂老虎机、查询优化和分布式并行技术。

Result: 在五个真实基准测试中，VirnyFlow在优化质量和可扩展性上显著优于现有AutoML系统。

Conclusion: VirnyFlow为ML开发提供了灵活、高效且负责任的替代方案，优于黑盒自动化方法。

Abstract: Developing machine learning (ML) models requires a deep understanding of
real-world problems, which are inherently multi-objective. In this paper, we
present VirnyFlow, the first design space for responsible model development,
designed to assist data scientists in building ML pipelines that are tailored
to the specific context of their problem. Unlike conventional AutoML
frameworks, VirnyFlow enables users to define customized optimization criteria,
perform comprehensive experimentation across pipeline stages, and iteratively
refine models in alignment with real-world constraints. Our system integrates
evaluation protocol definition, multi-objective Bayesian optimization,
cost-aware multi-armed bandits, query optimization, and distributed parallelism
into a unified architecture. We show that VirnyFlow significantly outperforms
state-of-the-art AutoML systems in both optimization quality and scalability
across five real-world benchmarks, offering a flexible, efficient, and
responsible alternative to black-box automation in ML development.

</details>


### [419] [Understanding and Improving Laplacian Positional Encodings For Temporal GNNs](https://arxiv.org/abs/2506.01596)
*Yaniv Galron,Fabrizio Frasca,Haggai Maron,Eran Treister,Moshe Eliasof*

Main category: cs.LG

TL;DR: 论文提出了一种解决时序图中位置编码问题的方法，包括理论框架、计算优化和实验验证。


<details>
  <summary>Details</summary>
Motivation: 时序图学习在推荐系统、交通预测等领域有广泛应用，但现有方法在位置编码方面存在计算成本高、理论不清晰等问题。

Method: 通过理论框架连接超拉普拉斯编码与时间片编码，提出降低计算开销的新方法，并进行实验验证。

Result: 实现了56倍的速度提升，支持5万个活动节点的图，实验表明编码效果因模型和任务而异。

Conclusion: 位置编码在某些场景下能显著提升性能，但其有效性因模型和任务不同而变化。

Abstract: Temporal graph learning has applications in recommendation systems, traffic
forecasting, and social network analysis. Although multiple architectures have
been introduced, progress in positional encoding for temporal graphs remains
limited. Extending static Laplacian eigenvector approaches to temporal graphs
through the supra-Laplacian has shown promise, but also poses key challenges:
high eigendecomposition costs, limited theoretical understanding, and ambiguity
about when and how to apply these encodings. In this paper, we address these
issues by (1) offering a theoretical framework that connects supra-Laplacian
encodings to per-time-slice encodings, highlighting the benefits of leveraging
additional temporal connectivity, (2) introducing novel methods to reduce the
computational overhead, achieving up to 56x faster runtimes while scaling to
graphs with 50,000 active nodes, and (3) conducting an extensive experimental
study to identify which models, tasks, and datasets benefit most from these
encodings. Our findings reveal that while positional encodings can
significantly boost performance in certain scenarios, their effectiveness
varies across different models.

</details>


### [420] [Policy Newton Algorithm in Reproducing Kernel Hilbert Space](https://arxiv.org/abs/2506.01597)
*Yixian Zhang,Huaze Tang,Chao Wang,Wenbo Ding*

Main category: cs.LG

TL;DR: 论文提出了一种在RKHS中实现二阶优化的新方法Policy Newton，解决了传统一阶方法的局限性，并通过理论和实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前基于RKHS的强化学习策略优化仅限于一阶方法，因为无限维Hessian算子的显式计算和求逆不可行。

Method: 通过优化一个立方正则化的辅助目标函数，避免直接计算逆Hessian算子，并利用Representer Theorem将无限维问题转化为有限维问题。

Result: 理论证明该方法局部收敛且具有二次收敛速率，实验验证其在收敛速度和奖励上优于一阶方法和参数化二阶方法。

Conclusion: Policy Newton填补了非参数策略表示与二阶优化方法之间的关键空白。

Abstract: Reinforcement learning (RL) policies represented in Reproducing Kernel
Hilbert Spaces (RKHS) offer powerful representational capabilities. While
second-order optimization methods like Newton's method demonstrate faster
convergence than first-order approaches, current RKHS-based policy optimization
remains constrained to first-order techniques. This limitation stems primarily
from the intractability of explicitly computing and inverting the
infinite-dimensional Hessian operator in RKHS. We introduce Policy Newton in
RKHS, the first second-order optimization framework specifically designed for
RL policies represented in RKHS. Our approach circumvents direct computation of
the inverse Hessian operator by optimizing a cubic regularized auxiliary
objective function. Crucially, we leverage the Representer Theorem to transform
this infinite-dimensional optimization into an equivalent, computationally
tractable finite-dimensional problem whose dimensionality scales with the
trajectory data volume. We establish theoretical guarantees proving convergence
to a local optimum with a local quadratic convergence rate. Empirical
evaluations on a toy financial asset allocation problem validate these
theoretical properties, while experiments on standard RL benchmarks demonstrate
that Policy Newton in RKHS achieves superior convergence speed and higher
episodic rewards compared to established first-order RKHS approaches and
parametric second-order methods. Our work bridges a critical gap between
non-parametric policy representations and second-order optimization methods in
reinforcement learning.

</details>


### [421] [Contrastive Learning for Efficient Transaction Validation in UTXO-based Blockchains](https://arxiv.org/abs/2506.01614)
*Hamid Attar,Luigi Lunardon,Alessio Pagani*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的UTXO区块链扩展方法，通过优化UTXO分片和交易路由，显著减少了跨分片通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有UTXO分片方法在有效分配UTXO和减少交易依赖导致的通信开销方面存在不足，影响了交易处理速度。

Method: 结合对比学习和无监督学习，构建交易输出的嵌入空间，通过历史交易数据训练模型，优化UTXO分片和交易路由。

Result: 模型能够高效地将交易路由到包含父UTXO的分片，减少实时查找需求，显著提升吞吐量和可扩展性。

Conclusion: 该方法通过机器学习优化UTXO分片和交易路由，为UTXO区块链的扩展性提供了有效解决方案。

Abstract: This paper introduces a Machine Learning (ML) approach for scalability of
UTXO-based blockchains, such as Bitcoin. Prior approaches to UTXO set sharding
struggle with distributing UTXOs effectively across validators, creating
substantial communication overhead due to child-parent transaction
dependencies. This overhead, which arises from the need to locate parent UTXOs,
significantly hampers transaction processing speeds. Our solution uses ML to
optimize not only UTXO set sharding but also the routing of incoming
transactions, ensuring that transactions are directed to shards containing
their parent UTXOs. At the heart of our approach is a framework that combines
contrastive and unsupervised learning to create an embedding space for
transaction outputs. This embedding allows the model to group transaction
outputs based on spending relationships, making it possible to route
transactions efficiently to the correct validation microservices. Trained on
historical transaction data with triplet loss and online semi-hard negative
mining, the model embeds parent-child spending patterns directly into its
parameters, thus eliminating the need for costly, real-time parent transaction
lookups. This significantly reduces cross-shard communication overhead,
boosting throughput and scalability.

</details>


### [422] [Robust Satisficing Gaussian Process Bandits Under Adversarial Attacks](https://arxiv.org/abs/2506.01625)
*Artun Saday,Yaşar Cahit Yıldırım,Cem Tekin*

Main category: cs.LG

TL;DR: 论文提出了一种针对高斯过程优化中未知对抗扰动的鲁棒满足方法，通过两种新算法实现预定义性能阈值，并在不同对抗条件下提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 解决传统鲁棒优化方法在对抗扰动下无法保证性能阈值的问题，提出更灵活的鲁棒满足目标。

Method: 提出两种基于鲁棒满足目标的新算法，并证明其属于通用鲁棒满足框架，分别针对不同对抗条件提供理论保证。

Result: 实验表明，新方法在满足性能阈值方面优于传统鲁棒优化方法，尤其在模糊集不准确时表现更优。

Conclusion: 鲁棒满足方法为高斯过程优化中的对抗扰动问题提供了更有效的解决方案，尤其在性能阈值要求明确时表现突出。

Abstract: We address the problem of Gaussian Process (GP) optimization in the presence
of unknown and potentially varying adversarial perturbations. Unlike
traditional robust optimization approaches that focus on maximizing performance
under worst-case scenarios, we consider a robust satisficing objective, where
the goal is to consistently achieve a predefined performance threshold $\tau$,
even under adversarial conditions. We propose two novel algorithms based on
distinct formulations of robust satisficing, and show that they are instances
of a general robust satisficing framework. Further, each algorithm offers
different guarantees depending on the nature of the adversary. Specifically, we
derive two regret bounds: one that is sublinear over time, assuming certain
conditions on the adversary and the satisficing threshold $\tau$, and another
that scales with the perturbation magnitude but requires no assumptions on the
adversary. Through extensive experiments, we demonstrate that our approach
outperforms the established robust optimization methods in achieving the
satisficing objective, particularly when the ambiguity set of the robust
optimization framework is inaccurately specified.

</details>


### [423] [Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification](https://arxiv.org/abs/2506.01631)
*Zehao Wu,Yanjie Zhao,Haoyu Wang*

Main category: cs.LG

TL;DR: TensorGuard是一种基于梯度的指纹框架，用于检测LLM的相似性和家族分类，填补了LLM溯源和许可证合规的技术空白。


<details>
  <summary>Details</summary>
Motivation: 随着LLM成为现代应用的关键组件，未经授权的模型衍生（如微调、合并和重新分发）成为软件工程的挑战。目前缺乏有效机制检测模型谱系和执行许可证协议。

Method: TensorGuard通过分析梯度响应随机输入扰动的行为特征，提取模型内在签名，独立于训练数据或水印。支持safetensors格式，并通过统计梯度特征构建高维指纹。

Result: 实验评估显示，TensorGuard在58个模型（8个基础模型和50个衍生模型）上实现了94%的分类准确率。

Conclusion: TensorGuard为LLM的溯源和许可证合规提供了有效的技术手段，填补了现有空白。

Abstract: As Large Language Models (LLMs) become integral software components in modern
applications, unauthorized model derivations through fine-tuning, merging, and
redistribution have emerged as critical software engineering challenges. Unlike
traditional software where clone detection and license compliance are
well-established, the LLM ecosystem lacks effective mechanisms to detect model
lineage and enforce licensing agreements. This gap is particularly problematic
when open-source model creators, such as Meta's LLaMA, require derivative works
to maintain naming conventions for attribution, yet no technical means exist to
verify compliance.
  To fill this gap, treating LLMs as software artifacts requiring provenance
tracking, we present TensorGuard, a gradient-based fingerprinting framework for
LLM similarity detection and family classification. Our approach extracts
model-intrinsic behavioral signatures by analyzing gradient responses to random
input perturbations across tensor layers, operating independently of training
data, watermarks, or specific model formats. TensorGuard supports the
widely-adopted safetensors format and constructs high-dimensional fingerprints
through statistical analysis of gradient features. These fingerprints enable
two complementary capabilities: direct pairwise similarity assessment between
arbitrary models through distance computation, and systematic family
classification of unknown models via the K-Means clustering algorithm with
domain-informed centroid initialization using known base models. Experimental
evaluation on 58 models comprising 8 base models and 50 derivatives across five
model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94%
classification accuracy under our centroid-initialized K-Means clustering.

</details>


### [424] [Bidirectional Soft Actor-Critic: Leveraging Forward and Reverse KL Divergence for Efficient Reinforcement Learning](https://arxiv.org/abs/2506.01639)
*Yixian Zhang,Huaze Tang,Changxu Wei,Wenbo Ding*

Main category: cs.LG

TL;DR: 论文提出Bidirectional SAC算法，结合正向和反向KL散度的优势，显著提升SAC的性能和样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统SAC算法使用反向KL散度更新策略，存在不稳定性和样本效率低的问题，论文探索正向KL散度的替代方案。

Method: 在SAC中引入正向KL散度，为高斯策略提供显式最优投影策略，并结合反向KL散度优化，提出Bidirectional SAC算法。

Result: 在连续控制基准测试中，Bidirectional SAC比标准SAC和其他基线方法表现更好，奖励提升高达30%，样本效率更高。

Conclusion: Bidirectional SAC通过结合两种KL散度的优势，显著提升了SAC算法的性能和稳定性。

Abstract: The Soft Actor-Critic (SAC) algorithm, a state-of-the-art method in maximum
entropy reinforcement learning, traditionally relies on minimizing reverse
Kullback-Leibler (KL) divergence for policy updates. However, this approach
leads to an intractable optimal projection policy, necessitating gradient-based
approximations that can suffer from instability and poor sample efficiency.
This paper investigates the alternative use of forward KL divergence within
SAC. We demonstrate that for Gaussian policies, forward KL divergence yields an
explicit optimal projection policy -- corresponding to the mean and variance of
the target Boltzmann distribution's action marginals. Building on the distinct
advantages of both KL directions, we propose Bidirectional SAC, an algorithm
that first initializes the policy using the explicit forward KL projection and
then refines it by optimizing the reverse KL divergence. Comprehensive
experiments on continuous control benchmarks show that Bidirectional SAC
significantly outperforms standard SAC and other baselines, achieving up to a
$30\%$ increase in episodic rewards, alongside enhanced sample efficiency.

</details>


### [425] [Provably Safe Reinforcement Learning from Analytic Gradients](https://arxiv.org/abs/2506.01665)
*Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff*

Main category: cs.LG

TL;DR: 本文提出了首个用于分析梯度强化学习的有效安全保障方法，填补了该领域的空白。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中部署自主机器人需要安全保证，但目前缺乏适用于分析梯度强化学习的安全保障方法。

Method: 通过分析现有的可微分安全保障方法，改进其映射和梯度公式，并将其与最先进的学习算法和可微分模拟相结合。

Result: 在两个经典控制任务上的数值实验表明，安全保障训练不会影响性能。

Conclusion: 本文成功开发了适用于分析梯度强化学习的有效安全保障方法，为安全关键应用提供了新的解决方案。

Abstract: Deploying autonomous robots in safety-critical applications requires safety
guarantees. Provably safe reinforcement learning is an active field of research
which aims to provide such guarantees using safeguards. These safeguards should
be integrated during training to prevent a large sim-to-real gap. While there
are several approaches for safeguarding sampling-based reinforcement learning,
analytic gradient-based reinforcement learning often achieves superior
performance and sample efficiency. However, there is no safeguarding approach
for this learning paradigm yet. Our work addresses this gap by developing the
first effective safeguard for analytic gradient-based reinforcement learning.
We analyse existing, differentiable safeguards, adapt them through modified
mappings and gradient formulations, and integrate them with a state-of-the-art
learning algorithm and a differentiable simulation. We evaluate how different
safeguards affect policy optimisation using numerical experiments on two
classical control tasks. The results demonstrate safeguarded training without
compromising performance.

</details>


### [426] [Principled data augmentation for learning to solve quadratic programming problems](https://arxiv.org/abs/2506.01728)
*Chendi Qian,Christopher Morris*

Main category: cs.LG

TL;DR: 本文提出了一种针对二次规划问题（QPs）的数据增强方法，结合对比学习框架，提升图神经网络（MPNNs）在数据稀缺情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺的情况下，学习优化方法（L2O）在处理复杂优化问题（如QPs）时表现不佳，需要一种有效的数据增强方法。

Method: 通过理论支持的数据增强技术生成多样且保持最优性的实例，并结合对比学习的自监督框架预训练MPNNs。

Result: 实验表明，该方法在监督场景中提升了泛化能力，并支持有效的迁移学习。

Conclusion: 该方法为数据稀缺环境下的L2O任务提供了一种有效的解决方案。

Abstract: Linear and quadratic optimization are crucial in numerous real-world
applications, from training machine learning models to integer-linear
optimization. Recently, learning-to-optimize methods (L2O) for linear (LPs) or
quadratic programs (QPs) using message-passing graph neural networks (MPNNs)
have gained traction, promising lightweight, data-driven proxies for solving
such optimization problems. For example, they replace the costly computation of
strong branching scores in branch-and-bound solvers, requiring solving many
such optimization problems. However, robust L2O MPNNs remain challenging in
data-scarce settings, especially when addressing complex optimization problems
such as QPs. This work introduces a principled approach to data augmentation
tailored for QPs via MPNNs. Our method leverages theoretically justified data
augmentation techniques to generate diverse yet optimality-preserving
instances. Furthermore, we integrate these augmentations into a self-supervised
learning framework based on contrastive learning, thereby pretraining MPNNs for
enhanced performance on L2O tasks. Extensive experiments demonstrate that our
approach improves generalization in supervised scenarios and facilitates
effective transfer learning to related optimization problems.

</details>


### [427] [Enhancing Customer Service Chatbots with Context-Aware NLU through Selective Attention and Multi-task Learning](https://arxiv.org/abs/2506.01781)
*Subhadip Nandi,Neeraj Agrawal,Anshika Singh,Priyanka Bhatt*

Main category: cs.LG

TL;DR: 论文提出了一种结合客户查询和订单状态上下文的上下文感知NLU模型（MTL-CNLU-SAWC），通过选择性注意力模块和多任务学习，显著提高了意图分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类模型仅依赖客户查询，导致对模糊查询的处理效果不佳。结合上下文信息（如订单状态）可以更准确地识别意图。

Method: 提出MTL-CNLU-SAWC模型，利用选择性注意力模块提取相关上下文特征，并采用多任务学习充分利用训练数据中的不同标签类型。

Result: 模型在Top 2准确率上比仅使用查询的基线模型提高了4.8%，比现有结合查询和上下文的最优模型提高了3.5%。

Conclusion: MTL-CNLU-SAWC显著提升了意图分类的准确性，减少了人工干预，为公司节省了每年近百万美元的成本。

Abstract: Customer service chatbots are conversational systems aimed at addressing
customer queries, often by directing them to automated workflows. A crucial
aspect of this process is the classification of the customer's intent.
Presently, most intent classification models for customer care utilise only
customer query for intent prediction. This may result in low-accuracy models,
which cannot handle ambiguous queries. An ambiguous query like "I didn't
receive my package" could indicate a delayed order, or an order that was
delivered but the customer failed to receive it. Resolution of each of these
scenarios requires the execution of very different sequence of steps. Utilizing
additional information, such as the customer's order delivery status, in the
right manner can help identify the intent for such ambiguous queries. In this
paper, we have introduced a context-aware NLU model that incorporates both, the
customer query and contextual information from the customer's order status for
predicting customer intent. A novel selective attention module is used to
extract relevant context features. We have also proposed a multi-task learning
paradigm for the effective utilization of different label types available in
our training data. Our suggested method, Multi-Task Learning Contextual NLU
with Selective Attention Weighted Context (MTL-CNLU-SAWC), yields a 4.8%
increase in top 2 accuracy score over the baseline model which only uses user
queries, and a 3.5% improvement over existing state-of-the-art models that
combine query and context. We have deployed our model to production for
Walmart's customer care domain. Accurate intent prediction through
MTL-CNLU-SAWC helps to better direct customers to automated workflows, thereby
significantly reducing escalations to human agents, leading to almost a million
dollars in yearly savings for the company.

</details>


### [428] [Frugal Machine Learning for Energy-efficient, and Resource-aware Artificial Intelligence](https://arxiv.org/abs/2506.01869)
*John Violos,Konstantina-Christina Diamanti,Ioannis Kompatsiaris,Symeon Papadopoulos*

Main category: cs.LG

TL;DR: Frugal Machine Learning (FML) 旨在设计高效、经济且资源受限的机器学习模型，通过输入、学习过程和模型三个层面的节俭策略减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 应对边缘计算和物联网设备在带宽、能源和延迟方面的严格限制，实现资源高效利用。

Method: 采用模型压缩、节能硬件、数据高效学习等技术，结合参数正则化、知识蒸馏和动态架构设计等方法。

Result: 提出了节俭方法的全面分类，并通过跨领域案例研究验证其有效性。

Conclusion: FML 在智能环境中具有重要应用前景，未来需进一步研究以推动创新。

Abstract: Frugal Machine Learning (FML) refers to the practice of designing Machine
Learning (ML) models that are efficient, cost-effective, and mindful of
resource constraints. This field aims to achieve acceptable performance while
minimizing the use of computational resources, time, energy, and data for both
training and inference. FML strategies can be broadly categorized into input
frugality, learning process frugality, and model frugality, each focusing on
reducing resource consumption at different stages of the ML pipeline. This
chapter explores recent advancements, applications, and open challenges in FML,
emphasizing its importance for smart environments that incorporate edge
computing and IoT devices, which often face strict limitations in bandwidth,
energy, or latency. Technological enablers such as model compression,
energy-efficient hardware, and data-efficient learning techniques are
discussed, along with adaptive methods including parameter regularization,
knowledge distillation, and dynamic architecture design that enable incremental
model updates without full retraining. Furthermore, it provides a comprehensive
taxonomy of frugal methods, discusses case studies across diverse domains, and
identifies future research directions to drive innovation in this evolving
field.

</details>


### [429] [Learning to Explore: An In-Context Learning Approach for Pure Exploration](https://arxiv.org/abs/2506.01876)
*Alessio Russo,Ryan Welch,Aldo Pacchiano*

Main category: cs.LG

TL;DR: 本文提出了一种基于上下文学习的纯探索方法（ICPE），通过结合监督学习和强化学习，直接从经验中学习探索策略，无需先验假设，并在多种场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在自适应探索策略设计中的局限性，如强化学习方法因信息结构表示不足而表现不佳，而复杂方法（如BAI）依赖显式建模假设且难以设计。

Method: 引入ICPE方法，利用Transformer进行上下文学习，结合监督学习和强化学习，直接从经验中学习探索策略。

Result: 在多种合成和半合成基准测试中，ICPE在确定性、随机和结构化场景中均表现出稳健性能，能够匹配最优实例依赖算法。

Conclusion: ICPE是一种实用且通用的数据高效探索方法，仅依赖深度学习技术即可实现高性能。

Abstract: In this work, we study the active sequential hypothesis testing problem, also
known as pure exploration, where the goal is to actively control a data
collection process to efficiently identify the correct hypothesis underlying a
decision problem. While relevant across multiple domains, devising adaptive
exploration strategies remains challenging, particularly due to difficulties in
encoding appropriate inductive biases. Existing Reinforcement Learning
(RL)-based methods often underperform when relevant information structures are
inadequately represented, whereas more complex methods, like Best Arm
Identification (BAI) techniques, may be difficult to devise and typically rely
on explicit modeling assumptions. To address these limitations, we introduce
In-Context Pure Exploration (ICPE), an in-context learning approach that uses
Transformers to learn exploration strategies directly from experience. ICPE
combines supervised learning and reinforcement learning to identify and exploit
latent structure across related tasks, without requiring prior assumptions.
Numerical results across diverse synthetic and semi-synthetic benchmarks
highlight ICPE's capability to achieve robust performance performance in
deterministic, stochastic, and structured settings. These results demonstrate
ICPE's ability to match optimal instance-dependent algorithms using only deep
learning techniques, making it a practical and general approach to
data-efficient exploration.

</details>


### [430] [scDataset: Scalable Data Loading for Deep Learning on Large-Scale Single-Cell Omics](https://arxiv.org/abs/2506.01883)
*Davide D'Ascenzo,Sebastiano Cultrera di Montesano*

Main category: cs.LG

TL;DR: scDataset是一种直接在AnnData文件上操作的PyTorch IterableDataset，通过块采样和批量获取技术，显著提高了单细胞数据加载效率。


<details>
  <summary>Details</summary>
Motivation: 现代单细胞数据集规模庞大，现有数据加载方案存在内存占用高、存储需求大或随机磁盘访问慢等问题，限制了深度学习模型的训练效率。

Method: scDataset结合块采样和批量获取技术，直接在AnnData文件上操作，无需格式转换，平衡了随机性和I/O效率。

Result: 在Tahoe 100M数据集上，scDataset比AnnLoader快48倍，比HuggingFace Datasets快27倍，比BioNeMo快18倍。

Conclusion: scDataset为研究社区提供了高效的大规模单细胞模型训练工具，推动了该领域的进步。

Abstract: Modern single-cell datasets now comprise hundreds of millions of cells,
presenting significant challenges for training deep learning models that
require shuffled, memory-efficient data loading. While the AnnData format is
the community standard for storing single-cell datasets, existing data loading
solutions for AnnData are often inadequate: some require loading all data into
memory, others convert to dense formats that increase storage demands, and many
are hampered by slow random disk access. We present scDataset, a PyTorch
IterableDataset that operates directly on one or more AnnData files without the
need for format conversion. The core innovation is a combination of block
sampling and batched fetching, which together balance randomness and I/O
efficiency. On the Tahoe 100M dataset, scDataset achieves up to a 48$\times$
speed-up over AnnLoader, a 27$\times$ speed-up over HuggingFace Datasets, and
an 18$\times$ speed-up over BioNeMo in single-core settings. These advances
democratize large-scale single-cell model training for the broader research
community.

</details>


### [431] [Agnostic Reinforcement Learning: Foundations and Algorithms](https://arxiv.org/abs/2506.01884)
*Gene Li*

Main category: cs.LG

TL;DR: 该论文研究了强化学习（RL）在大状态空间环境中的统计复杂性，重点关注了无保证策略学习（agnostic policy learning）的理论框架。


<details>
  <summary>Details</summary>
Motivation: 尽管RL在许多领域取得了成功，但大状态空间环境中函数逼近的统计复杂性缺乏理论理解。论文旨在填补这一空白。

Method: 论文从学习理论的角度，系统地研究了无保证策略学习的三个关键维度：环境访问、覆盖条件和表示条件，并设计了新算法。

Result: 研究揭示了无保证策略学习的统计分离，展示了其能力和局限性，并提供了理论保证的算法和性能界限。

Conclusion: 论文为RL在大状态空间环境中的统计复杂性提供了理论支持，并指出了未来研究方向。

Abstract: Reinforcement Learning (RL) has demonstrated tremendous empirical success
across numerous challenging domains. However, we lack a strong theoretical
understanding of the statistical complexity of RL in environments with large
state spaces, where function approximation is required for sample-efficient
learning. This thesis addresses this gap by rigorously examining the
statistical complexity of RL with function approximation from a learning
theoretic perspective. Departing from a long history of prior work, we consider
the weakest form of function approximation, called agnostic policy learning, in
which the learner seeks to find the best policy in a given class $\Pi$, with no
guarantee that $\Pi$ contains an optimal policy for the underlying task.
  We systematically explore agnostic policy learning along three key axes:
environment access -- how a learner collects data from the environment;
coverage conditions -- intrinsic properties of the underlying MDP measuring the
expansiveness of state-occupancy measures for policies in the class $\Pi$, and
representational conditions -- structural assumptions on the class $\Pi$
itself. Within this comprehensive framework, we (1) design new learning
algorithms with theoretical guarantees and (2) characterize fundamental
performance bounds of any algorithm. Our results reveal significant statistical
separations that highlight the power and limitations of agnostic policy
learning.

</details>


### [432] [CogniAlign: Word-Level Multimodal Speech Alignment with Gated Cross-Attention for Alzheimer's Detection](https://arxiv.org/abs/2506.01890)
*David Ortiz-Perez,Manuel Benavent-Lledo,Javier Rodriguez-Juan,Jose Garcia-Rodriguez,David Tomás*

Main category: cs.LG

TL;DR: CogniAlign是一种多模态架构，通过音频和文本模态的细粒度对齐及交叉注意力融合，提升了阿尔茨海默病的检测准确率至90.36%。


<details>
  <summary>Details</summary>
Motivation: 早期检测阿尔茨海默病对临床干预至关重要，现有方法在模态融合上较为粗糙，无法充分利用互补信息。

Method: 提出词级时间对齐策略，结合门控交叉注意力融合机制，并引入韵律特征（如停顿标记）以丰富模态信息。

Result: 在ADReSSo数据集上达到90.36%的准确率，优于现有方法。

Conclusion: 细粒度对齐、注意力融合及韵律建模显著提升了检测性能，为认知障碍早期诊断提供了新思路。

Abstract: Early detection of cognitive disorders such as Alzheimer's disease is
critical for enabling timely clinical intervention and improving patient
outcomes. In this work, we introduce CogniAlign, a multimodal architecture for
Alzheimer's detection that integrates audio and textual modalities, two
non-intrusive sources of information that offer complementary insights into
cognitive health. Unlike prior approaches that fuse modalities at a coarse
level, CogniAlign leverages a word-level temporal alignment strategy that
synchronizes audio embeddings with corresponding textual tokens based on
transcription timestamps. This alignment supports the development of
token-level fusion techniques, enabling more precise cross-modal interactions.
To fully exploit this alignment, we propose a Gated Cross-Attention Fusion
mechanism, where audio features attend over textual representations, guided by
the superior unimodal performance of the text modality. In addition, we
incorporate prosodic cues, specifically interword pauses, by inserting pause
tokens into the text and generating audio embeddings for silent intervals,
further enriching both streams. We evaluate CogniAlign on the ADReSSo dataset,
where it achieves an accuracy of 90.36%, outperforming existing
state-of-the-art methods. A detailed ablation study confirms the advantages of
our alignment strategy, attention-based fusion, and prosodic modeling.

</details>


### [433] [Transformers as Multi-task Learners: Decoupling Features in Hidden Markov Models](https://arxiv.org/abs/2506.01919)
*Yifan Hao,Chenlu Ye,Chi Han,Tong Zhang*

Main category: cs.LG

TL;DR: 本文研究了Transformer模型的分层行为，揭示了其多任务泛化能力的机制，并通过理论分析支持了其高效性。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型在序列学习中表现出色，但其理论理解仍有限。本文旨在揭示其分层行为和多任务泛化能力的机制。

Method: 通过研究典型的序列模型（如隐马尔可夫模型），观察Transformer的分层行为，并进行理论分析。

Result: 发现低层主要提取特征表示（受邻近标记影响），高层特征解耦（时间解缠）。理论分析支持了Transformer的高效性。

Conclusion: 研究为Transformer在序列学习中的有效性和效率提供了理论支持。

Abstract: Transformer based models have shown remarkable capabilities in sequence
learning across a wide range of tasks, often performing well on specific task
by leveraging input-output examples. Despite their empirical success, a
comprehensive theoretical understanding of this phenomenon remains limited. In
this work, we investigate the layerwise behavior of Transformers to uncover the
mechanisms underlying their multi-task generalization ability. Taking
explorations on a typical sequence model, i.e, Hidden Markov Models, which are
fundamental to many language tasks, we observe that: first, lower layers of
Transformers focus on extracting feature representations, primarily influenced
by neighboring tokens; second, on the upper layers, features become decoupled,
exhibiting a high degree of time disentanglement. Building on these empirical
insights, we provide theoretical analysis for the expressiveness power of
Transformers. Our explicit constructions align closely with empirical
observations, providing theoretical support for the Transformer's effectiveness
and efficiency on sequence learning across diverse tasks.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [434] [Unfolding Boxes with Local Constraints](https://arxiv.org/abs/2506.01079)
*Long Qian,Eric Wang,Bernardo Subercaseaux,Marijn J. H. Heule*

Main category: cs.CG

TL;DR: 提出了一种新的基于SAT的方法，通过替换全局约束为局部约束，显著提高了计算和枚举多面体折叠问题的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因全局约束（如图连通性或无环性）难以有效编码和求解，无法实现大规模计算。

Method: 提出新的SAT编码方法，用具有更好传播性质的局部约束替代全局约束。

Result: 新方法将计算和枚举能力大幅提升：从面积88提升至150，枚举从30提升至60，并否定了Xu等人的猜想。

Conclusion: 新方法显著提升了多面体折叠问题的可扩展性，解决了现有方法的局限性。

Abstract: We consider the problem of finding and enumerating polyominos that can be
folded into multiple non-isomorphic boxes. While several computational
approaches have been proposed, including SAT, randomized algorithms, and
decision diagrams, none has been able to perform at scale. We argue that
existing SAT encodings are hindered by the presence of global constraints
(e.g., graph connectivity or acyclicity), which are generally hard to encode
effectively and hard for solvers to reason about. In this work, we propose a
new SAT-based approach that replaces these global constraints with simple local
constraints that have substantially better propagation properties. Our approach
dramatically improves the scalability of both computing and enumerating common
box unfoldings: (i) while previous approaches could only find common unfoldings
of two boxes up to area 88, ours easily scales beyond 150, and (ii) while
previous approaches were only able to enumerate common unfoldings up to area
30, ours scales up to 60. This allows us to rule out 46, 54, and 58 as the
smallest areas allowing a common unfolding of three boxes, thereby refuting a
conjecture of Xu et al. (2017).

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [435] [Enabling Secure and Ephemeral AI Workloads in Data Mesh Environments](https://arxiv.org/abs/2506.00352)
*Chinkit Patel,Kee Siong Ng*

Main category: cs.DC

TL;DR: 论文提出了一种基于容器和基础设施即代码的按需自服务数据平台，用于快速搭建和销毁数据与计算基础设施，支持数据团队高效实验和部署数据产品。


<details>
  <summary>Details</summary>
Motivation: 大型企业在复杂ICT环境中缺乏高效支持数据与AI团队快速搭建和销毁基础设施的方法，阻碍了数据产品的实验和部署。

Method: 利用不可变容器操作系统和基础设施即代码方法，创建供应商中立、短生命周期的Kubernetes集群，支持本地和云端环境。

Result: 提出了一种可重复、便携且成本高效的解决方案，可作为商业PaaS的替代或补充，特别适用于复杂数据网格环境。

Conclusion: 该方案为分散的数据团队提供了灵活的基础设施支持，提升了数据产品开发的效率和互操作性。

Abstract: Many large enterprises that operate highly governed and complex ICT
environments have no efficient and effective way to support their Data and AI
teams in rapidly spinning up and tearing down self-service data and compute
infrastructure, to experiment with new data analytic tools, and deploy data
products into operational use. This paper proposes a key piece of the solution
to the overall problem, in the form of an on-demand self-service data-platform
infrastructure to empower de-centralised data teams to build data products on
top of centralised templates, policies and governance. The core innovation is
an efficient method to leverage immutable container operating systems and
infrastructure-as-code methodologies for creating, from scratch, vendor-neutral
and short-lived Kubernetes clusters on-premises and in any cloud environment.
Our proposed approach can serve as a repeatable, portable and cost-efficient
alternative or complement to commercial Platform-as-a-Service (PaaS) offerings,
and this is particularly important in supporting interoperability in complex
data mesh environments with a mix of modern and legacy compute infrastructure.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [436] [A Topological Semantics of Dialogue: Nerve Structures and Logical Extraction](https://arxiv.org/abs/2506.00615)
*Andreu Ballus Santacana*

Main category: cs.LO

TL;DR: 该论文提出了一种基于拓扑学的对话语义框架，通过将话语映射到语义空间中的开集，构建神经复合体，并提取组合不变量，以实现对话的逻辑分析和一致性检测。


<details>
  <summary>Details</summary>
Motivation: 旨在为有限对话提供一种简洁且拓扑学驱动的语义表示方法，以支持对话的逻辑分析和一致性合并。

Method: 将每个话语映射到固定语义空间的开集，构建神经复合体，提取负神经和全局解释子空间等不变量，并通过Wolfram语言实现算法。

Result: 提出了负神经和全局解释子空间等组合不变量，展示了计算可行性，并提供了检测不一致性和逻辑后果的方法。

Conclusion: 该框架结合了经典拓扑语义学和现代拓扑数据分析，为对话语义提供了理论基础和实用工具。

Abstract: We introduce a concise, topologically-motivated semantics for finite
dialogues by mapping each utterance to an open set in a fixed semantic space,
building the corresponding nerve complex of joint satisfiability, and
extracting fundamental combinatorial invariants:
  1. The negative nerve, which enumerates all finite collections of utterances
whose
  opens have empty intersection, providing a straightforward criterion for
merging
  separate transcripts without contradiction.
  2. The global interpretation subspace, the unique minimal open in which all
asserted
  utterances hold simultaneously, enabling effective enumeration of all logical
  consequences of the entire dialogue.
  3. A practical demonstration in the Wolfram Language, with algorithms for
constructing
  nerves, detecting inconsistencies, and computing the global interpretation,
thereby
  illustrating computational feasibility.
  Our framework is grounded in classical duality and topological semantics
(Stone duality, Priestley duality, Tarski's semantics, coherence-space methods,
Scott domains, topos semantics, and homotopy type theory) while drawing on
recent advances in topological data analysis and dialogue-based semantics.

</details>


### [437] [Thinking Out of the Box: Hybrid SAT Solving by Unconstrained Continuous Optimization](https://arxiv.org/abs/2506.00674)
*Zhiwei Zhang,Samy Wu Fung,Anastasios Kyrillidis,Stanley Osher,Moshe Y. Vardi*

Main category: cs.LO

TL;DR: 提出了一种基于无约束连续优化的混合SAT求解方法，通过惩罚项处理非CNF约束，提升了求解效率。


<details>
  <summary>Details</summary>
Motivation: 混合约束（如XOR、基数约束）在SAT问题中常见，但现有方法依赖盒约束，限制了无约束优化器的使用。

Method: 采用无约束连续优化和惩罚项处理混合约束，结合理论分析和实验验证。

Result: 实验证明无约束优化器（如Adam）能有效提升混合SAT求解性能。

Conclusion: 结合连续优化和机器学习方法，为混合SAT求解提供了新思路。

Abstract: The Boolean satisfiability (SAT) problem lies at the core of many
applications in combinatorial optimization, software verification,
cryptography, and machine learning. While state-of-the-art solvers have
demonstrated high efficiency in handling conjunctive normal form (CNF)
formulas, numerous applications require non-CNF (hybrid) constraints, such as
XOR, cardinality, and Not-All-Equal constraints. Recent work leverages
polynomial representations to represent such hybrid constraints, but it relies
on box constraints that can limit the use of powerful unconstrained optimizers.
In this paper, we propose unconstrained continuous optimization formulations
for hybrid SAT solving by penalty terms. We provide theoretical insights into
when these penalty terms are necessary and demonstrate empirically that
unconstrained optimizers (e.g., Adam) can enhance SAT solving on hybrid
benchmarks. Our results highlight the potential of combining continuous
optimization and machine-learning-based methods for effective hybrid SAT
solving.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [438] [Diff-SPORT: Diffusion-based Sensor Placement Optimization and Reconstruction of Turbulent flows in urban environments](https://arxiv.org/abs/2506.00214)
*Abhijeet Vishwasrao,Sai Bharath Chandra Gutha,Andres Cremades,Klas Wijk,Aakash Patil,Catherine Gorle,Beverley J McKeon,Hossein Azizpour,Ricardo Vinuesa*

Main category: physics.flu-dyn

TL;DR: Diff-SPORT是一种基于扩散模型的框架，用于高保真流场重建和城市环境中的最优传感器布置，结合了生成扩散模型、MAP推理和Shapley值框架，显著提升了速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 城市化快速发展需要高效监测湍流风模式以支持空气质量、气候适应性和基础设施设计，传统方法在实践约束下精度不足。

Method: 结合生成扩散模型、最大后验概率（MAP）推理和Shapley值框架，提出可扩展且可解释的解决方案。

Result: 相比传统数值方法，Diff-SPORT在保持统计和瞬时流场保真度的同时显著加速。

Conclusion: Diff-SPORT为零样本模块化方法，支持极端稀疏条件下的快速可靠城市流场监测，为可持续城市智能中生成模型与可解释性的结合铺平道路。

Abstract: Rapid urbanization demands accurate and efficient monitoring of turbulent
wind patterns to support air quality, climate resilience and infrastructure
design. Traditional sparse reconstruction and sensor placement strategies face
major accuracy degradations under practical constraints. Here, we introduce
Diff-SPORT, a diffusion-based framework for high-fidelity flow reconstruction
and optimal sensor placement in urban environments. Diff-SPORT combines a
generative diffusion model with a maximum a posteriori (MAP) inference scheme
and a Shapley-value attribution framework to propose a scalable and
interpretable solution. Compared to traditional numerical methods, Diff-SPORT
achieves significant speedups while maintaining both statistical and
instantaneous flow fidelity. Our approach offers a modular, zero-shot
alternative to retraining-intensive strategies, supporting fast and reliable
urban flow monitoring under extreme sparsity. Diff-SPORT paves the way for
integrating generative modeling and explainability in sustainable urban
intelligence.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [439] [The Folly of AI for Age Verification](https://arxiv.org/abs/2506.00038)
*Reid McIlroy-Young*

Main category: cs.CY

TL;DR: 政府若允许企业使用AI进行年龄验证，系统将容易被绕过且对少数群体和低收入用户分类不公，类似系统（如面部识别和远程监考软件）已证明此问题难以解决。


<details>
  <summary>Details</summary>
Motivation: 探讨AI用于年龄验证的潜在问题，尤其是对少数群体和低收入用户的不公平影响。

Method: 通过分析类似系统（如面部识别和远程监考软件）的偏见问题，预测AI年龄验证系统的缺陷。

Result: AI年龄验证系统存在技术限制和硬件问题，难以克服偏见，成本效益不如政府ID验证。

Conclusion: 近期部署AI年龄验证系统是不明智的。

Abstract: In the near future a governmental body will be asked to allow companies to
use AI for age verification. If they allow it the resulting system will both be
easily circumvented and disproportionately misclassify minorities and low
socioeconomic status users. This is predictable by showing that other very
similar systems (facial recognition and remote proctoring software) have
similar issues despite years of efforts to mitigate their biases. These biases
are due to technical limitations both of the AI models themselves and the
physical hardware they are running on that will be difficult to overcome below
the cost of government ID-based age verification. Thus in, the near future,
deploying an AI system for age verification is folly.

</details>


### [440] [Risks of AI-driven product development and strategies for their mitigation](https://arxiv.org/abs/2506.00047)
*Jan Göpfert,Jann M. Weinand,Patrick Kuckertz,Noah Pflugradt,Jochen Linßen*

Main category: cs.CY

TL;DR: 本文讨论了AI驱动的产品开发中的风险及缓解策略，提出了强调人类监督、责任和可解释设计的原则。


<details>
  <summary>Details</summary>
Motivation: 随着自动化产品开发的推进，依赖非人类代理带来了技术和社会风险，需要平衡机遇与风险。

Method: 提出了一套安全AI驱动产品开发的原则，涵盖技术和社会的风险评估。

Result: 明确了AI驱动产品开发中的技术和社会风险，并提出了缓解策略。

Conclusion: 早期讨论有助于平衡AI驱动产品开发的机遇与风险，推动理解、规范制定和监管。

Abstract: Humanity is progressing towards automated product development, a trend that
promises faster creation of better products and thus the acceleration of
technological progress. However, increasing reliance on non-human agents for
this process introduces many risks. This perspective aims to initiate a
discussion on these risks and appropriate mitigation strategies. To this end,
we outline a set of principles for safer AI-driven product development which
emphasize human oversight, accountability, and explainable design, among
others. The risk assessment covers both technical risks which affect product
quality and safety, and sociotechnical risks which affect society. While
AI-driven product development is still in its early stages, this discussion
will help balance its opportunities and risks without delaying essential
progress in understanding, norm-setting, and regulation.

</details>


### [441] [Prompt Engineer: Analyzing Skill Requirements in the AI Job Market](https://arxiv.org/abs/2506.00058)
*An Vu,Jonas Oppenlaender*

Main category: cs.CY

TL;DR: 分析了20,662个LinkedIn职位，发现提示工程师职位稀少（0.5%），但具备独特的技能要求，如AI知识、提示设计、沟通和创造性问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 研究提示工程师这一新兴职位的技能需求和市场现状。

Method: 分析LinkedIn上的20,662个职位发布，包括72个提示工程师职位。

Result: 提示工程师职位稀少，但技能要求独特，与数据科学家和机器学习工程师不同。

Conclusion: 提示工程师正成为独立职业，研究结果有助于求职者、雇主和教育机构理解这一新兴领域。

Abstract: The rise of large language models (LLMs) has created a new job role: the
Prompt Engineer. Despite growing interest in this position, we still do not
fully understand what skills this new job role requires or how common these
jobs are. We analyzed 20,662 job postings on LinkedIn, including 72 prompt
engineer positions, to learn more about this emerging role. We found that
prompt engineering is still rare (less than 0.5% of sampled job postings) but
has a unique skill profile. Prompt engineers need AI knowledge (22.8%), prompt
design skills (18.7%), good communication (21.9%), and creative problem-solving
(15.8%) skills. These requirements significantly differ from those of
established roles, such as data scientists and machine learning engineers,
showing that prompt engineering is becoming its own profession. Our findings
help job seekers, employers, and educational institutions in better
understanding the emerging field of prompt engineering.

</details>


### [442] [Comparative analysis of privacy-preserving open-source LLMs regarding extraction of diagnostic information from clinical CMR imaging reports](https://arxiv.org/abs/2506.00060)
*Sina Amirrajab,Volker Vehof,Michael Bietenbeck,Ali Yilmaz*

Main category: cs.CY

TL;DR: 研究评估了开源大语言模型（LLMs）在心血管磁共振（CMR）报告中的诊断信息提取能力，发现多个模型表现优异，甚至超过专业心脏病专家。


<details>
  <summary>Details</summary>
Motivation: 探索隐私保护、本地部署的开源LLMs在临床环境中自动化分析影像报告的可行性。

Method: 评估了9个开源LLMs在109份临床CMR报告中的诊断分类能力，使用准确性、精确率、召回率和F1分数等指标。

Result: Gemma2模型表现最佳（F1分数0.98），多个模型超过心脏病专家（F1分数0.94）。

Conclusion: 开源LLMs可用于临床影像报告的自动化分析，提供高效、准确的诊断分类。

Abstract: Purpose: We investigated the utilization of privacy-preserving,
locally-deployed, open-source Large Language Models (LLMs) to extract
diagnostic information from free-text cardiovascular magnetic resonance (CMR)
reports. Materials and Methods: We evaluated nine open-source LLMs on their
ability to identify diagnoses and classify patients into various cardiac
diagnostic categories based on descriptive findings in 109 clinical CMR
reports. Performance was quantified using standard classification metrics
including accuracy, precision, recall, and F1 score. We also employed confusion
matrices to examine patterns of misclassification across models. Results: Most
open-source LLMs demonstrated exceptional performance in classifying reports
into different diagnostic categories. Google's Gemma2 model achieved the
highest average F1 score of 0.98, followed by Qwen2.5:32B and DeepseekR1-32B
with F1 scores of 0.96 and 0.95, respectively. All other evaluated models
attained average scores above 0.93, with Mistral and DeepseekR1-7B being the
only exceptions. The top four LLMs outperformed our board-certified
cardiologist (F1 score of 0.94) across all evaluation metrics in analyzing CMR
reports. Conclusion: Our findings demonstrate the feasibility of implementing
open-source, privacy-preserving LLMs in clinical settings for automated
analysis of imaging reports, enabling accurate, fast and resource-efficient
diagnostic categorization.

</details>


### [443] [Evaluating Prompt Engineering Techniques for Accuracy and Confidence Elicitation in Medical LLMs](https://arxiv.org/abs/2506.00072)
*Nariman Naderi,Zahra Atf,Peter R Lewis,Aref Mahjoub far,Seyed Amir Ahmad Safavi-Naini,Ali Soroush*

Main category: cs.CY

TL;DR: 研究了提示工程技术对大型语言模型（LLMs）在医学任务中准确性和置信度的影响，发现Chain-of-Thought提示提高准确性但导致过度自信，情感提示进一步加剧置信度问题。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过提示工程技术优化LLMs在医学任务中的表现，尤其是准确性和置信度的平衡。

Method: 使用波斯医学考试数据集，评估五种LLMs在不同温度设置、提示风格和置信度尺度下的表现，采用AUC-ROC、Brier Score和ECE等指标。

Result: Chain-of-Thought提示提高准确性但引发过度自信；情感提示进一步增加置信度风险；小型模型表现较差，专有模型准确性高但置信度校准不足。

Conclusion: 提示工程技术需同时优化准确性和不确定性校准，以适用于高风险的医学任务。

Abstract: This paper investigates how prompt engineering techniques impact both
accuracy and confidence elicitation in Large Language Models (LLMs) applied to
medical contexts. Using a stratified dataset of Persian board exam questions
across multiple specialties, we evaluated five LLMs - GPT-4o, o3-mini,
Llama-3.3-70b, Llama-3.1-8b, and DeepSeek-v3 - across 156 configurations. These
configurations varied in temperature settings (0.3, 0.7, 1.0), prompt styles
(Chain-of-Thought, Few-Shot, Emotional, Expert Mimicry), and confidence scales
(1-10, 1-100). We used AUC-ROC, Brier Score, and Expected Calibration Error
(ECE) to evaluate alignment between confidence and actual performance.
Chain-of-Thought prompts improved accuracy but also led to overconfidence,
highlighting the need for calibration. Emotional prompting further inflated
confidence, risking poor decisions. Smaller models like Llama-3.1-8b
underperformed across all metrics, while proprietary models showed higher
accuracy but still lacked calibrated confidence. These results suggest prompt
engineering must address both accuracy and uncertainty to be effective in
high-stakes medical tasks.

</details>


### [444] [Whose Name Comes Up? Auditing LLM-Based Scholar Recommendations](https://arxiv.org/abs/2506.00074)
*Daniele Barolo,Chiara Valentin,Fariba Karimi,Luis Galárraga,Gonzalo G. Méndez,Lisette Espín-Noboa*

Main category: cs.CY

TL;DR: 本文评估了六种开源LLM在物理领域专家推荐任务中的表现，发现模型存在不一致性、偏见和格式化问题，尤其是对资深学者和特定群体的偏好。


<details>
  <summary>Details</summary>
Motivation: 研究开源LLM在学术推荐任务中的表现，揭示其潜在的不一致性和偏见，以推动更可靠和公平的推荐系统。

Method: 使用美国物理学会和OpenAlex的真实数据作为基准，评估六种LLM在五个任务中的表现，分析一致性、事实性和偏见。

Result: mixtral-8x7b表现最稳定，llama3.1-70b变异性最高；模型普遍存在重复、格式化错误，且对资深学者和特定群体（如男性、白人学者）有偏好。

Conclusion: LLM在学术推荐中存在显著偏见和不一致性，需改进以实现更公平和可靠的推荐。

Abstract: This paper evaluates the performance of six open-weight LLMs (llama3-8b,
llama3.1-8b, gemma2-9b, mixtral-8x7b, llama3-70b, llama3.1-70b) in recommending
experts in physics across five tasks: top-k experts by field, influential
scientists by discipline, epoch, seniority, and scholar counterparts. The
evaluation examines consistency, factuality, and biases related to gender,
ethnicity, academic popularity, and scholar similarity. Using ground-truth data
from the American Physical Society and OpenAlex, we establish scholarly
benchmarks by comparing model outputs to real-world academic records. Our
analysis reveals inconsistencies and biases across all models. mixtral-8x7b
produces the most stable outputs, while llama3.1-70b shows the highest
variability. Many models exhibit duplication, and some, particularly gemma2-9b
and llama3.1-8b, struggle with formatting errors. LLMs generally recommend real
scientists, but accuracy drops in field-, epoch-, and seniority-specific
queries, consistently favoring senior scholars. Representation biases persist,
replicating gender imbalances (reflecting male predominance),
under-representing Asian scientists, and over-representing White scholars.
Despite some diversity in institutional and collaboration networks, models
favor highly cited and productive scholars, reinforcing the rich-getricher
effect while offering limited geographical representation. These findings
highlight the need to improve LLMs for more reliable and equitable scholarly
recommendations.

</details>


### [445] [Optimizing Storytelling, Improving Audience Retention, and Reducing Waste in the Entertainment Industry](https://arxiv.org/abs/2506.00076)
*Andrew Cornfeld,Ashley Miller,Mercedes Mora-Figueroa,Kurt Samuels,Anthony Palomba*

Main category: cs.CY

TL;DR: 论文提出了一种结合NLP特征与传统收视数据的机器学习框架，用于提升电视节目收视率的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 电视网络在节目决策中面临高财务风险，通常依赖有限的历史数据预测收视率。

Method: 利用NLP从25000多集电视节目对话中提取情感基调、认知复杂度和叙事结构，结合SARIMAX、滚动XGBoost和特征选择模型进行预测。

Result: NLP特征对部分剧集的预测有显著提升，同时提出了一种基于欧几里得距离的节目内容相似性评分方法。

Conclusion: 该框架在不同类型节目中表现出色，为编剧、高管和营销人员提供了可解释的数据驱动见解。

Abstract: Television networks face high financial risk when making programming
decisions, often relying on limited historical data to forecast episodic
viewership. This study introduces a machine learning framework that integrates
natural language processing (NLP) features from over 25000 television episodes
with traditional viewership data to enhance predictive accuracy. By extracting
emotional tone, cognitive complexity, and narrative structure from episode
dialogue, we evaluate forecasting performance using SARIMAX, rolling XGBoost,
and feature selection models. While prior viewership remains a strong baseline
predictor, NLP features contribute meaningful improvements for some series. We
also introduce a similarity scoring method based on Euclidean distance between
aggregate dialogue vectors to compare shows by content. Tested across diverse
genres, including Better Call Saul and Abbott Elementary, our framework reveals
genre-specific performance and offers interpretable metrics for writers,
executives, and marketers seeking data-driven insight into audience behavior.

</details>


### [446] [Who Gets the Kidney? Human-AI Alignment, Indecision, and Moral Values](https://arxiv.org/abs/2506.00079)
*John P. Dickerson,Hadi Hosseini,Samarth Khanna,Leona Pierce*

Main category: cs.CY

TL;DR: 论文研究了大型语言模型（LLMs）在高风险决策（如肾脏分配）中与人类道德价值观的对齐问题，发现LLMs在属性优先级和决策确定性上与人类存在显著差异，但通过少量样本的监督微调可以改善。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在高风险决策中是否与人类道德价值观对齐，特别是在稀缺资源分配场景中。

Method: 系统评估多个LLMs在肾脏分配场景中的行为，并与人类偏好对比，同时测试低秩监督微调的效果。

Result: LLMs在属性优先级上与人类价值观存在显著偏差，且决策更倾向于确定性而非犹豫；少量样本的微调可改善一致性和犹豫建模。

Conclusion: 在道德/伦理领域，LLMs需要明确的价值观对齐策略，少量样本的监督微调是一种有效方法。

Abstract: The rapid integration of Large Language Models (LLMs) in high-stakes
decision-making -- such as allocating scarce resources like donor organs --
raises critical questions about their alignment with human moral values. We
systematically evaluate the behavior of several prominent LLMs against human
preferences in kidney allocation scenarios and show that LLMs: i) exhibit stark
deviations from human values in prioritizing various attributes, and ii) in
contrast to humans, LLMs rarely express indecision, opting for deterministic
decisions even when alternative indecision mechanisms (e.g., coin flipping) are
provided. Nonetheless, we show that low-rank supervised fine-tuning with few
samples is often effective in improving both decision consistency and
calibrating indecision modeling. These findings illustrate the necessity of
explicit alignment strategies for LLMs in moral/ethical domains.

</details>


### [447] [Bottom-Up Perspectives on AI Governance: Insights from User Reviews of AI Products](https://arxiv.org/abs/2506.00080)
*Stefan Pasch*

Main category: cs.CY

TL;DR: 论文通过分析用户评论，采用自下而上的方法探索AI治理的实际问题，发现与技术与非技术领域相关的治理主题，并指出需要更多基于实证的用户中心方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI治理框架多为高层指导，未能充分反映实际操作中的用户关切，研究旨在填补这一空白。

Method: 利用BERTopic分析G2.com上10万条AI产品用户评论，提取与AI治理相关的潜在主题。

Result: 发现治理主题涵盖技术和非技术领域，与现有框架有重叠但也揭示被忽视的问题（如项目管理、客户互动）。

Conclusion: 研究强调需结合实证与用户中心方法，推动更具操作性的AI治理框架。

Abstract: With the growing importance of AI governance, numerous high-level frameworks
and principles have been articulated by policymakers, institutions, and expert
communities to guide the development and application of AI. While such
frameworks offer valuable normative orientation, they may not fully capture the
practical concerns of those who interact with AI systems in organizational and
operational contexts. To address this gap, this study adopts a bottom-up
approach to explore how governance-relevant themes are expressed in user
discourse. Drawing on over 100,000 user reviews of AI products from G2.com, we
apply BERTopic to extract latent themes and identify those most semantically
related to AI governance. The analysis reveals a diverse set of
governance-relevant topics spanning both technical and non-technical domains.
These include concerns across organizational processes-such as planning,
coordination, and communication-as well as stages of the AI value chain,
including deployment infrastructure, data handling, and analytics. The findings
show considerable overlap with institutional AI governance and ethics
frameworks on issues like privacy and transparency, but also surface overlooked
areas such as project management, strategy development, and customer
interaction. This highlights the need for more empirically grounded,
user-centered approaches to AI governance-approaches that complement normative
models by capturing how governance unfolds in applied settings. By
foregrounding how governance is enacted in practice, this study contributes to
more inclusive and operationally grounded approaches to AI governance and
digital policy.

</details>


### [448] [TRAPDOC: Deceiving LLM Users by Injecting Imperceptible Phantom Tokens into Documents](https://arxiv.org/abs/2506.00089)
*Hyundong Jin,Sicheol Sung,Shinwoo Park,SeungYeop Baik,Yo-Sub Han*

Main category: cs.CY

TL;DR: 论文提出了一种通过注入不可察觉的幻影标记来欺骗过度依赖大型语言模型（LLMs）用户的方法，并介绍了TRAPDOC框架，旨在减少对LLMs的滥用。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs功能的增强，用户过度依赖和滥用LLMs（如作业代写或处理敏感文件）已成为社会问题。论文旨在通过技术手段解决这一问题。

Method: 提出了一种方法，通过向文档中注入不可察觉的幻影标记，使LLMs生成看似合理但实际错误的输出，并开发了TRAPDOC框架。

Result: 通过实验验证，TRAPDOC在专有LLMs上表现出色，能够有效欺骗过度依赖的用户。

Conclusion: TRAPDOC为促进更负责任和深思熟虑的LLMs使用提供了有力工具，代码已开源。

Abstract: The reasoning, writing, text-editing, and retrieval capabilities of
proprietary large language models (LLMs) have advanced rapidly, providing users
with an ever-expanding set of functionalities. However, this growing utility
has also led to a serious societal concern: the over-reliance on LLMs. In
particular, users increasingly delegate tasks such as homework, assignments, or
the processing of sensitive documents to LLMs without meaningful engagement.
This form of over-reliance and misuse is emerging as a significant social
issue. In order to mitigate these issues, we propose a method injecting
imperceptible phantom tokens into documents, which causes LLMs to generate
outputs that appear plausible to users but are in fact incorrect. Based on this
technique, we introduce TRAPDOC, a framework designed to deceive over-reliant
LLM users. Through empirical evaluation, we demonstrate the effectiveness of
our framework on proprietary LLMs, comparing its impact against several
baselines. TRAPDOC serves as a strong foundation for promoting more responsible
and thoughtful engagement with language models. Our code is available at
https://github.com/jindong22/TrapDoc.

</details>


### [449] [Feeling Guilty Being a c(ai)borg: Navigating the Tensions Between Guilt and Empowerment in AI Use](https://arxiv.org/abs/2506.00094)
*Konstantin Aal,Tanja Aal,Vasil Navumau,David Unbehaun,Claudia Müller,Volker Wulf,Sarah Rüller*

Main category: cs.CY

TL;DR: 论文探讨了AI融入工作流程的情感、伦理和实践维度，提出“c(ai)borg”概念，强调从内疚到赋能的过程。


<details>
  <summary>Details</summary>
Motivation: 受Donna Haraway的《赛博格宣言》启发，研究AI如何挑战创造力、原创性和智力劳动的传统观念。

Method: 采用自民族志方法，作者反思了一年内使用AI工具的经历。

Result: 研究发现基础学术技能、高级AI素养和诚实面对AI结果的重要性，提倡将AI视为协作伙伴。

Conclusion: 通过将内疚重构为成长，论文呼吁以深思熟虑和包容的方式整合AI。

Abstract: This paper explores the emotional, ethical and practical dimensions of
integrating Artificial Intelligence (AI) into personal and professional
workflows, focusing on the concept of feeling guilty as a 'c(ai)borg' - a human
augmented by AI. Inspired by Donna Haraway's Cyborg Manifesto, the study
explores how AI challenges traditional notions of creativity, originality and
intellectual labour. Using an autoethnographic approach, the authors reflect on
their year-long experiences with AI tools, revealing a transition from initial
guilt and reluctance to empowerment through skill-building and transparency.
Key findings highlight the importance of basic academic skills, advanced AI
literacy and honest engagement with AI results. The c(ai)borg vision advocates
for a future where AI is openly embraced as a collaborative partner, fostering
innovation and equity while addressing issues of access and agency. By
reframing guilt as growth, the paper calls for a thoughtful and inclusive
approach to AI integration.

</details>


### [450] [ClinBench-HPB: A Clinical Benchmark for Evaluating LLMs in Hepato-Pancreato-Biliary Diseases](https://arxiv.org/abs/2506.00095)
*Yuchong Li,Xiaojun Zeng,Chihua Fang,Jian Yang,Lei Zhang*

Main category: cs.CY

TL;DR: 该论文建立了一个针对肝胰胆（HPB）疾病的评估基准ClinBench-HBP，包含3535道选择题和337个真实诊断案例，揭示了当前大型语言模型（LLM）在HPB疾病诊断中的局限性。


<details>
  <summary>Details</summary>
Motivation: HPB疾病的高发病率和死亡率使其成为全球公共卫生挑战，但现有LLM评估基准缺乏HPB覆盖和真实临床案例。

Method: 系统构建了涵盖ICD-10中33个主要类别和465个子类别的HPB疾病评估基准，包括选择题和真实诊断案例。

Result: 商业和开源LLM在HPB诊断任务中表现不佳，尤其在复杂临床案例中性能显著下降。

Conclusion: 当前LLM在HPB疾病领域存在明显局限，未来需改进以处理真实复杂的临床诊断任务。

Abstract: Hepato-pancreato-biliary (HPB) disorders represent a global public health
challenge due to their high morbidity and mortality. Although large language
models (LLMs) have shown promising performance in general medical
question-answering tasks, the current evaluation benchmarks are mostly derived
from standardized examinations or manually designed questions, lacking HPB
coverage and clinical cases. To address these issues, we systematically
eatablish an HPB disease evaluation benchmark comprising 3,535 closed-ended
multiple-choice questions and 337 open-ended real diagnosis cases, which
encompasses all the 33 main categories and 465 subcategories of HPB diseases
defined in the International Statistical Classification of Diseases, 10th
Revision (ICD-10). The multiple-choice questions are curated from public
datasets and synthesized data, and the clinical cases are collected from
prestigious medical journals, case-sharing platforms, and collaborating
hospitals. By evalauting commercial and open-source general and medical LLMs on
our established benchmark, namely ClinBench-HBP, we find that while commercial
LLMs perform competently on medical exam questions, they exhibit substantial
performance degradation on HPB diagnosis tasks, especially on complex,
inpatient clinical cases. Those medical LLMs also show limited generalizability
to HPB diseases. Our results reveal the critical limitations of current LLMs in
the domain of HPB diseases, underscoring the imperative need for future medical
LLMs to handle real, complex clinical diagnostics rather than simple medical
exam questions. The benchmark will be released at the homepage.

</details>


### [451] [Children's Voice Privacy: First Steps And Emerging Challenges](https://arxiv.org/abs/2506.00100)
*Ajinkya Kulkarni,Francisco Teixeira,Enno Hermann,Thomas Rolland,Isabel Trancoso,Mathew Magimai Doss*

Main category: cs.CY

TL;DR: 本文研究了针对儿童语音的匿名化技术，评估了现有成人语音匿名化方法在儿童语音上的适用性，发现其虽能保护隐私但实用性下降明显。


<details>
  <summary>Details</summary>
Motivation: 儿童在语音技术中代表性不足且隐私保护需求高，但针对儿童的语音匿名化技术研究较少。

Method: 使用三个儿童数据集和六种匿名化方法，结合主客观评价指标进行评估。

Result: 现有成人匿名化方法能保护儿童隐私，但实用性显著降低，且自动评估方法在儿童语音质量上存在挑战。

Conclusion: 需进一步研究儿童语音匿名化技术，改进评估方法。

Abstract: Children are one of the most under-represented groups in speech technologies,
as well as one of the most vulnerable in terms of privacy. Despite this,
anonymization techniques targeting this population have received little
attention. In this study, we seek to bridge this gap, and establish a baseline
for the use of voice anonymization techniques designed for adult speech when
applied to children's voices. Such an evaluation is essential, as children's
speech presents a distinct set of challenges when compared to that of adults.
This study comprises three children's datasets, six anonymization methods, and
objective and subjective utility metrics for evaluation. Our results show that
existing systems for adults are still able to protect children's voice privacy,
but suffer from much higher utility degradation. In addition, our subjective
study displays the challenges of automatic evaluation methods for speech
quality in children's speech, highlighting the need for further research.

</details>


### [452] [The World As Large Language Models See It: Exploring the reliability of LLMs in representing geographical features](https://arxiv.org/abs/2506.00203)
*Omid Reza Abbasi,Franz Welscher,Georg Weinberger,Johannes Scholz*

Main category: cs.CY

TL;DR: 论文评估了GPT-4o和Gemini 2.0 Flash在三个地理空间任务中的表现，发现其准确性和可靠性不一致，需进一步优化以提高地理信息科学中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的发展，其在地理信息表示中的可信度问题日益突出，本研究旨在评估LLMs在地理任务中的表现。

Method: 研究通过三个地理空间任务（地理编码、高程估计和反向地理编码）评估GPT-4o和Gemini 2.0 Flash的性能。

Result: GPT-4o在地理编码中偏差较大，Gemini 2.0 Flash更精确但有系统性偏移；两者在高程估计中均低估，但Gemini在东部表现更好；反向地理编码中Gemini整体更优。

Conclusion: LLMs可近似地理信息，但准确性和可靠性不足，需针对地理信息进行优化以提高实用性。

Abstract: As large language models (LLMs) continue to evolve, questions about their
trustworthiness in delivering factual information have become increasingly
important. This concern also applies to their ability to accurately represent
the geographic world. With recent advancements in this field, it is relevant to
consider whether and to what extent LLMs' representations of the geographical
world can be trusted. This study evaluates the performance of GPT-4o and Gemini
2.0 Flash in three key geospatial tasks: geocoding, elevation estimation, and
reverse geocoding. In the geocoding task, both models exhibited systematic and
random errors in estimating the coordinates of St. Anne's Column in Innsbruck,
Austria, with GPT-4o showing greater deviations and Gemini 2.0 Flash
demonstrating more precision but a significant systematic offset. For elevation
estimation, both models tended to underestimate elevations across Austria,
though they captured overall topographical trends, and Gemini 2.0 Flash
performed better in eastern regions. The reverse geocoding task, which involved
identifying Austrian federal states from coordinates, revealed that Gemini 2.0
Flash outperformed GPT-4o in overall accuracy and F1-scores, demonstrating
better consistency across regions. Despite these findings, neither model
achieved an accurate reconstruction of Austria's federal states, highlighting
persistent misclassifications. The study concludes that while LLMs can
approximate geographic information, their accuracy and reliability are
inconsistent, underscoring the need for fine-tuning with geographical
information to enhance their utility in GIScience and Geoinformatics.

</details>


### [453] [MythTriage: Scalable Detection of Opioid Use Disorder Myths on a Video-Sharing Platform](https://arxiv.org/abs/2506.00308)
*Hayoung Jung,Shravika Mittal,Ananya Aatreya,Navreet Kaur,Munmun De Choudhury,Tanushree Mitra*

Main category: cs.CY

TL;DR: 该论文提出了一种名为MythTriage的高效标注方法，用于大规模测量YouTube上与阿片类药物使用障碍（OUD）相关的错误信息，并分析了这些错误信息的传播情况。


<details>
  <summary>Details</summary>
Motivation: 在线健康信息中的错误信息可能影响公共健康政策，但目前缺乏针对高关注度但研究不足的主题（如OUD）的大规模测量方法。

Method: 研究通过与临床专家合作验证了8种常见错误信息，并开发了MythTriage标注流程，结合轻量级模型和大型语言模型（LLM）以提高效率。

Result: MythTriage在保持高准确率（0.86宏F1分数）的同时，预计减少76%的标注时间和成本。研究分析了2.9K搜索结果和343K推荐内容，揭示了错误信息的传播模式。

Conclusion: 该研究为公共健康干预和平台内容审核提供了可行的见解，同时展示了高效标注方法的潜力。

Abstract: Understanding the prevalence of misinformation in health topics online can
inform public health policies and interventions. However, measuring such
misinformation at scale remains a challenge, particularly for high-stakes but
understudied topics like opioid-use disorder (OUD)--a leading cause of death in
the U.S. We present the first large-scale study of OUD-related myths on
YouTube, a widely-used platform for health information. With clinical experts,
we validate 8 pervasive myths and release an expert-labeled video dataset. To
scale labeling, we introduce MythTriage, an efficient triage pipeline that uses
a lightweight model for routine cases and defers harder ones to a
high-performing, but costlier, large language model (LLM). MythTriage achieves
up to 0.86 macro F1-score while estimated to reduce annotation time and
financial cost by over 76% compared to experts and full LLM labeling. We
analyze 2.9K search results and 343K recommendations, uncovering how myths
persist on YouTube and offering actionable insights for public health and
platform moderation.

</details>


### [454] [Wide Reflective Equilibrium in LLM Alignment: Bridging Moral Epistemology and AI Safety](https://arxiv.org/abs/2506.00415)
*Matthew Brophy*

Main category: cs.CY

TL;DR: 论文提出用广泛反思平衡法（MWRE）改进大语言模型（LLM）对齐技术，强调动态修订和伦理基础。


<details>
  <summary>Details</summary>
Motivation: 现有对齐技术（如CAI）复杂且缺乏动态修订和伦理合法性，需更优框架。

Method: 采用广泛反思平衡法（MWRE），结合道德判断、原则和背景理论，提升动态修订和合法性。

Result: MWRE能更全面地改进LLM对齐的动态修订、程序合法性和伦理基础。

Conclusion: MWRE是分析和改进LLM对齐的有力启发式工具，未来可推动更伦理化的AI系统。

Abstract: As large language models (LLMs) become more powerful and pervasive across
society, ensuring these systems are beneficial, safe, and aligned with human
values is crucial. Current alignment techniques, like Constitutional AI (CAI),
involve complex iterative processes. This paper argues that the Method of Wide
Reflective Equilibrium (MWRE) -- a well-established coherentist moral
methodology -- offers a uniquely apt framework for understanding current LLM
alignment efforts. Moreover, this methodology can substantively augment these
processes by providing concrete pathways for improving their dynamic
revisability, procedural legitimacy, and overall ethical grounding. Together,
these enhancements can help produce more robust and ethically defensible
outcomes. MWRE, emphasizing the achievement of coherence between our considered
moral judgments, guiding moral principles, and relevant background theories,
arguably better represents the intricate reality of LLM alignment and offers a
more robust path to justification than prevailing foundationalist models or
simplistic input-output evaluations. While current methods like CAI bear a
structural resemblance to MWRE, they often lack its crucial emphasis on
dynamic, bi-directional revision of principles and the procedural legitimacy
derived from such a process. While acknowledging various disanalogies (e.g.,
consciousness, genuine understanding in LLMs), the paper demonstrates that MWRE
serves as a valuable heuristic for critically analyzing current alignment
efforts and for guiding the future development of more ethically sound and
justifiably aligned AI systems.

</details>


### [455] [SafeCOMM: What about Safety Alignment in Fine-Tuned Telecom Large Language Models?](https://arxiv.org/abs/2506.00062)
*Aladin Djuhera,Swanand Ravindra Kadhe,Farhan Ahmed,Syed Zawad,Holger Boche,Walid Saad*

Main category: cs.CY

TL;DR: 本文研究了电信领域微调大型语言模型（LLMs）时可能引发的安全性退化问题，并提出三种防御方法（SafeInstruct、SafeLoRA、SafeMERGE）以恢复模型安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管微调LLMs以适应电信任务是常见做法，但这一过程可能损害模型的安全性，导致对有害或非伦理查询的响应。本文旨在探讨这一问题并提出解决方案。

Method: 使用GenAINet计划中的三个代表性数据集分析电信微调LLMs的安全性退化问题，并评估三种安全性再对齐防御方法。

Result: 实验表明，即使在结构化且看似无害的数据集（如3GPP标准和表格记录）上，安全性退化仍然存在。提出的防御方法能有效恢复安全性且不影响下游任务性能。

Conclusion: 本文为电信微调LLMs的安全性再对齐提供了诊断研究和实用指南，强调了安全感知的指令和微调在电信LLMs实际部署中的重要性。

Abstract: Fine-tuning large language models (LLMs) for telecom tasks and datasets is a
common practice to adapt general-purpose models to the telecom domain. However,
little attention has been paid to how this process may compromise model safety.
Recent research has shown that even benign fine-tuning can degrade the safety
alignment of LLMs, causing them to respond to harmful or unethical user
queries. In this paper, we investigate this issue for telecom-tuned LLMs using
three representative datasets featured by the GenAINet initiative. We show that
safety degradation persists even for structured and seemingly harmless datasets
such as 3GPP standards and tabular records, indicating that telecom-specific
data is not immune to safety erosion during fine-tuning. We further extend our
analysis to publicly available Telecom LLMs trained via continual pre-training,
revealing that safety alignment is often severely lacking, primarily due to the
omission of safety-focused instruction tuning. To address these issues in both
fine-tuned and pre-trained models, we conduct extensive experiments and
evaluate three safety realignment defenses (SafeInstruct, SafeLoRA, and
SafeMERGE) using established red-teaming benchmarks. The results show that,
across all settings, the proposed defenses can effectively restore safety after
harmful degradation without compromising downstream task performance, leading
to Safe teleCOMMunication (SafeCOMM) models. In a nutshell, our work serves as
a diagnostic study and practical guide for safety realignment in telecom-tuned
LLMs, and emphasizes the importance of safety-aware instruction and fine-tuning
for real-world deployments of Telecom LLMs.

</details>


### [456] [AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions](https://arxiv.org/abs/2506.01671)
*Adriana Eufrosina Bora,Akshatha Arodi,Duoyi Zhang,Jordan Bannister,Mirko Bronzi,Arsene Fansi Tchango,Md Abul Bashar,Richi Nayak,Kerrie Mengersen*

Main category: cs.CY

TL;DR: 论文提出了AIMS.uk和AIMS.ca两个新标注数据集，以及AIMSCheck框架，用于跨司法管辖区验证现代奴隶法案的合规性。


<details>
  <summary>Details</summary>
Motivation: 现代奴隶法案要求企业披露其反奴隶制措施，但验证这些声明的复杂性高且缺乏标注数据，同时需研究工具在不同司法管辖区的通用性。

Method: 与领域专家合作，构建跨司法管辖区数据集（AIMS.uk和AIMS.ca），并提出AIMSCheck框架，将合规评估任务分解为三个层次。

Result: 实验表明，基于澳大利亚数据集训练的模型在英加司法管辖区表现良好，验证了工具的跨司法适用性。

Conclusion: 论文通过公开数据集和框架，推动了AI在合规评估中的应用，并为未来研究提供了基础。

Abstract: Modern Slavery Acts mandate that corporations disclose their efforts to
combat modern slavery, aiming to enhance transparency and strengthen practices
for its eradication. However, verifying these statements remains challenging
due to their complex, diversified language and the sheer number of statements
that must be reviewed. The development of NLP tools to assist in this task is
also difficult due to a scarcity of annotated data. Furthermore, as modern
slavery transparency legislation has been introduced in several countries, the
generalizability of such tools across legal jurisdictions must be studied. To
address these challenges, we work with domain experts to make two key
contributions. First, we present AIMS.uk and AIMS.ca, newly annotated datasets
from the UK and Canada to enable cross-jurisdictional evaluation. Second, we
introduce AIMSCheck, an end-to-end framework for compliance validation.
AIMSCheck decomposes the compliance assessment task into three levels,
enhancing interpretability and practical applicability. Our experiments show
that models trained on an Australian dataset generalize well across UK and
Canadian jurisdictions, demonstrating the potential for broader application in
compliance monitoring. We release the benchmark datasets and AIMSCheck to the
public to advance AI-adoption in compliance assessment and drive further
research in this field.

</details>


### [457] [Explainable AI Systems Must Be Contestable: Here's How to Make It Happen](https://arxiv.org/abs/2506.01662)
*Catarina Moreira,Anna Palatkina,Dacia Braca,Dylan M. Walsh,Peter J. Leihn,Fang Chen,Nina C. Hubig*

Main category: cs.CY

TL;DR: 本文首次在可解释AI中提出了严格的‘可争议性’定义，并设计了一个模块化框架和评估量表，以帮助实践者满足监管要求。


<details>
  <summary>Details</summary>
Motivation: 随着全球AI监管对系统安全性的关注增加，‘可争议性’成为一项强制性但定义模糊的保障措施。目前缺乏正式定义、算法保证和实践指导。

Method: 通过系统性文献综述，提出首个严格的可争议性定义，并设计了一个模块化框架，涵盖人机界面、技术架构、法律流程和组织工作流。提出‘可争议性评估量表’作为复合指标。

Result: 通过多个案例研究，揭示了现有系统的不足，并展示了框架如何推动针对性改进。

Conclusion: 将可争议性从监管理论转化为实践框架，为AI系统提供了真正的追责和问责工具。

Abstract: As AI regulations around the world intensify their focus on system safety,
contestability has become a mandatory, yet ill-defined, safeguard. In XAI,
"contestability" remains an empty promise: no formal definition exists, no
algorithm guarantees it, and practitioners lack concrete guidance to satisfy
regulatory requirements. Grounded in a systematic literature review, this paper
presents the first rigorous formal definition of contestability in explainable
AI, directly aligned with stakeholder requirements and regulatory mandates. We
introduce a modular framework of by-design and post-hoc mechanisms spanning
human-centered interfaces, technical architectures, legal processes, and
organizational workflows. To operationalize our framework, we propose the
Contestability Assessment Scale, a composite metric built on more than twenty
quantitative criteria. Through multiple case studies across diverse application
domains, we reveal where state-of-the-art systems fall short and show how our
framework drives targeted improvements. By converting contestability from
regulatory theory into a practical framework, our work equips practitioners
with the tools to embed genuine recourse and accountability into AI systems.

</details>


### [458] [Systematic Hazard Analysis for Frontier AI using STPA](https://arxiv.org/abs/2506.01782)
*Simon Mylius*

Main category: cs.CY

TL;DR: 论文探讨了STPA方法在提升前沿AI系统安全性方面的潜力，通过系统化分析识别潜在危险，弥补现有AI治理技术的不足。


<details>
  <summary>Details</summary>
Motivation: 前沿AI公司缺乏详细的结构化方法来识别和分析危险，STPA作为一种系统化方法，可能提升AI系统的安全性和可追溯性。

Method: 应用STPA方法分析AI系统的威胁模型和场景，识别不安全控制行为及其潜在损失场景。

Result: STPA能够发现非结构化危险分析方法可能遗漏的因果因素，从而提升安全性分析的鲁棒性。

Conclusion: STPA可作为现有AI治理技术的补充，增强安全性保障，并支持通过LLMs实现分析的可扩展性。

Abstract: All of the frontier AI companies have published safety frameworks where they
define capability thresholds and risk mitigations that determine how they will
safely develop and deploy their models. Adoption of systematic approaches to
risk modelling, based on established practices used in safety-critical
industries, has been recommended, however frontier AI companies currently do
not describe in detail any structured approach to identifying and analysing
hazards. STPA (Systems-Theoretic Process Analysis) is a systematic methodology
for identifying how complex systems can become unsafe, leading to hazards. It
achieves this by mapping out controllers and controlled processes then
analysing their interactions and feedback loops to understand how harmful
outcomes could occur (Leveson & Thomas, 2018). We evaluate STPA's ability to
broaden the scope, improve traceability and strengthen the robustness of safety
assurance for frontier AI systems. Applying STPA to the threat model and
scenario described in 'A Sketch of an AI Control Safety Case' (Korbak et al.,
2025), we derive a list of Unsafe Control Actions. From these we select a
subset and explore the Loss Scenarios that lead to them if left unmitigated. We
find that STPA is able to identify causal factors that may be missed by
unstructured hazard analysis methodologies thereby improving robustness. We
suggest STPA could increase the safety assurance of frontier AI when used to
complement or check coverage of existing AI governance techniques including
capability thresholds, model evaluations and emergency procedures. The
application of a systematic methodology supports scalability by increasing the
proportion of the analysis that could be conducted by LLMs, reducing the burden
on human domain experts.

</details>


### [459] [Red Teaming AI Policy: A Taxonomy of Avoision and the EU AI Act](https://arxiv.org/abs/2506.01931)
*Rui-Jie Yew,Bill Marino,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 本文提出了一个框架和分类法，用于分析企业在面对欧盟AI法案（AIA）时可能采取的“规避”行为，即介于合法避税和非法逃税之间的行为。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨企业如何通过规避策略减轻AIA带来的监管负担，并为监管机构提供对抗性框架以应对这些策略。

Method: 方法包括构建一个三层分类框架，根据企业受AIA监管的程度（在范围内、豁免或高监管类别）分析可能的规避策略及其表现形式。

Result: 研究结果展示了不同监管层级下企业可能采取的规避策略及其技术和组织表现形式。

Conclusion: 结论是为监管机构提供了一个对抗性框架，以“红队”方式测试AIA及未来AI法规的漏洞。

Abstract: The shape of AI regulation is beginning to emerge, most prominently through
the EU AI Act (the "AIA"). By 2027, the AIA will be in full effect, and firms
are starting to adjust their behavior in light of this new law. In this paper,
we present a framework and taxonomy for reasoning about "avoision" -- conduct
that walks the line between legal avoidance and evasion -- that firms might
engage in so as to minimize the regulatory burden the AIA poses. We organize
these avoision strategies around three "tiers" of increasing AIA exposure that
regulated entities face depending on: whether their activities are (1) within
scope of the AIA, (2) exempted from provisions of the AIA, or are (3) placed in
a category with higher regulatory scrutiny. In each of these tiers and for each
strategy, we specify the organizational and technological forms through which
avoision may manifest. Our goal is to provide an adversarial framework for "red
teaming" the AIA and AI regulation on the horizon.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [460] [Pushing the Limits of Beam Search Decoding for Transducer-based ASR models](https://arxiv.org/abs/2506.00185)
*Lilit Grigoryan,Vladimir Bataev,Andrei Andrusenko,Hainan Xu,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

TL;DR: 提出了一种加速Transducer模型束搜索的通用方法，显著缩小了束搜索与贪婪解码的速度差距，并提升了识别准确率。


<details>
  <summary>Details</summary>
Motivation: Transducer模型的束搜索速度较慢，限制了实际应用，因此需要一种加速方法。

Method: 采用批量操作、树状假设结构、新颖的空白评分和CUDA图执行技术，优化了ALSD++和AES++算法。

Result: 束搜索与贪婪解码的速度差距缩小至10-20%，WER相对提升14-30%，低资源场景下浅融合提升11%。

Conclusion: 该方法显著提升了Transducer模型的实用性和性能，所有算法已开源。

Abstract: Transducer models have emerged as a promising choice for end-to-end ASR
systems, offering a balanced trade-off between recognition accuracy, streaming
capabilities, and inference speed in greedy decoding. However, beam search
significantly slows down Transducers due to repeated evaluations of key network
components, limiting practical applications. This paper introduces a universal
method to accelerate beam search for Transducers, enabling the implementation
of two optimized algorithms: ALSD++ and AES++. The proposed method utilizes
batch operations, a tree-based hypothesis structure, novel blank scoring for
enhanced shallow fusion, and CUDA graph execution for efficient GPU inference.
This narrows the speed gap between beam and greedy modes to only 10-20% for the
whole system, achieves 14-30% relative improvement in WER compared to greedy
decoding, and improves shallow fusion for low-resource up to 11% compared to
existing implementations. All the algorithms are open sourced.

</details>


### [461] [Confidence intervals for forced alignment boundaries using model ensembles](https://arxiv.org/abs/2506.01256)
*Matthew C. Kelley*

Main category: eess.AS

TL;DR: 本文提出了一种通过神经网络集成技术为强制对齐边界生成置信区间的方法，相比单一模型略有改进，并将结果集成到Praat TextGrids中。


<details>
  <summary>Details</summary>
Motivation: 现有的强制对齐工具通常只提供单一的边界估计，缺乏对边界不确定性的量化。

Method: 使用10个不同的分段分类器神经网络进行对齐，通过集成技术确定边界的中位数，并构建97.85%的置信区间。

Result: 在Buckeye和TIMIT语料库上，集成边界比单一模型略有改进。

Conclusion: 该方法为研究者提供了边界的不确定性信息，可集成到Praat TextGrids中或单独分析。

Abstract: Forced alignment is a common tool to align audio with orthographic and
phonetic transcriptions. Most forced alignment tools provide only a single
estimate of a boundary. The present project introduces a method of deriving
confidence intervals for these boundaries using a neural network ensemble
technique. Ten different segment classifier neural networks were previously
trained, and the alignment process is repeated with each model. The alignment
ensemble is then used to place the boundary at the median of the boundaries in
the ensemble, and 97.85% confidence intervals are constructed using order
statistics. On the Buckeye and TIMIT corpora, the ensemble boundaries show a
slight improvement over using just a single model. The confidence intervals are
incorporated into Praat TextGrids using a point tier, and they are also output
as a table for researchers to analyze separately as diagnostics or to
incorporate uncertainty into their analyses.

</details>


### [462] [LinearVC: Linear transformations of self-supervised features through the lens of voice conversion](https://arxiv.org/abs/2506.01510)
*Herman Kamper,Benjamin van Niekerk,Julian Zaïdi,Marc-André Carbonneau*

Main category: eess.AS

TL;DR: LinearVC是一种简单的语音转换方法，通过线性变换自监督特征实现高质量的语音转换，并揭示了特征空间的结构。


<details>
  <summary>Details</summary>
Motivation: 研究自监督表示的结构，并探索如何通过简单的线性变换实现高效的语音转换。

Method: 使用线性变换自监督特征，并通过约束变换集（如旋转）探索特征空间的几何结构；进一步提出基于奇异值分解的方法，显式分解内容和说话者信息。

Result: 仅旋转特征即可实现高质量的语音转换，表明内容信息嵌入在低维子空间中；基于奇异值分解的线性投影（秩为100）取得了竞争性的转换结果。

Conclusion: LinearVC不仅为语音转换提供了实用方法，还深化了对自监督语音表示结构的理解。

Abstract: We introduce LinearVC, a simple voice conversion method that sheds light on
the structure of self-supervised representations. First, we show that simple
linear transformations of self-supervised features effectively convert voices.
Next, we probe the geometry of the feature space by constraining the set of
allowed transformations. We find that just rotating the features is sufficient
for high-quality voice conversion. This suggests that content information is
embedded in a low-dimensional subspace which can be linearly transformed to
produce a target voice. To validate this hypothesis, we finally propose a
method that explicitly factorizes content and speaker information using
singular value decomposition; the resulting linear projection with a rank of
just 100 gives competitive conversion results. Our work has implications for
both practical voice conversion and a broader understanding of self-supervised
speech representations. Samples and code: https://www.kamperh.com/linearvc/.

</details>


### [463] [Unsupervised Rhythm and Voice Conversion to Improve ASR on Dysarthric Speech](https://arxiv.org/abs/2506.01618)
*Karl El Hajal,Enno Hermann,Sevada Hovsepyan,Mathew Magimai. -Doss*

Main category: eess.AS

TL;DR: 论文探索了通过将构音障碍语音转换为健康语音来提升ASR性能，采用音节节奏建模方法，实验显示LF-MMI模型显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 构音障碍语音的高说话者间变异性和缓慢语速导致ASR系统性能不佳，因此研究语音转换以改善ASR表现。

Method: 扩展了Rhythm and Voice（RnV）转换框架，引入适合构音障碍语音的音节节奏建模方法，并评估其对ASR的影响。

Result: 在Torgo语料库上的实验表明，LF-MMI模型显著降低了词错误率，尤其是对严重构音障碍病例，而Whisper模型的微调效果有限。

Conclusion: 无监督节奏和语音转换对构音障碍ASR具有潜力，代码已开源。

Abstract: Automatic speech recognition (ASR) systems struggle with dysarthric speech
due to high inter-speaker variability and slow speaking rates. To address this,
we explore dysarthric-to-healthy speech conversion for improved ASR
performance. Our approach extends the Rhythm and Voice (RnV) conversion
framework by introducing a syllable-based rhythm modeling method suited for
dysarthric speech. We assess its impact on ASR by training LF-MMI models and
fine-tuning Whisper on converted speech. Experiments on the Torgo corpus reveal
that LF-MMI achieves significant word error rate reductions, especially for
more severe cases of dysarthria, while fine-tuning Whisper on converted data
has minimal effect on its performance. These results highlight the potential of
unsupervised rhythm and voice conversion for dysarthric ASR. Code available at:
https://github.com/idiap/RnV

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [464] [Beyond Winning: Margin of Victory Relative to Expectation Unlocks Accurate Skill Ratings](https://arxiv.org/abs/2506.00348)
*Shivam Shorewala,Zihao Yang*

Main category: stat.ML

TL;DR: MOVDA是一种新框架，通过利用真实胜利分差与模型预期分差的差异来改进传统评分系统，显著优于ELO和贝叶斯基线。


<details>
  <summary>Details</summary>
Motivation: 传统评分系统（如ELO）仅关注二元结果，忽略了胜利分差等关键信息。MOVDA旨在通过更全面地利用比赛数据来提高评分准确性。

Method: MOVDA通过域特定的非线性函数（如缩放的双曲正切函数）预测预期胜利分差，并利用真实与预期分差的差异作为评分更新的信号。

Result: 在NBA数据上的实验表明，MOVDA显著优于ELO和贝叶斯方法，降低了预测误差，提高了准确性，并加速了评分收敛。

Conclusion: MOVDA提供了一种理论合理、实证优越且计算高效的评分方法，适用于NBA等竞争环境。

Abstract: Knowledge of accurate relative skills in any competitive system is essential,
but foundational approaches such as ELO discard extremely relevant performance
data by concentrating exclusively on binary outcomes. While margin of victory
(MOV) extensions exist, they often lack a definitive method for incorporating
this information. We introduce Margin of Victory Differential Analysis (MOVDA),
a framework that enhances traditional rating systems by using the deviation
between the true MOV and a $\textit{modeled expectation}$. MOVDA learns a
domain-specific, non-linear function (a scaled hyperbolic tangent that captures
saturation effects and home advantage) to predict expected MOV based on rating
differentials. Crucially, the $\textit{difference}$ between the true and
expected MOV provides a subtle and weighted signal for rating updates,
highlighting informative deviations in all levels of contests. Extensive
experiments on professional NBA basketball data (from 2013 to 2023, with 13,619
games) show that MOVDA significantly outperforms standard ELO and Bayesian
baselines. MOVDA reduces Brier score prediction error by $1.54\%$ compared to
TrueSkill, increases outcome accuracy by $0.58\%$, and most importantly
accelerates rating convergence by $13.5\%$, while maintaining the computational
efficiency of the original ELO updates. MOVDA offers a theoretically motivated,
empirically superior, and computationally lean approach to integrating
performance magnitude into skill rating for competitive environments like the
NBA.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [465] [Trilevel Memetic Algorithm for the Electric Vehicle Routing Problem](https://arxiv.org/abs/2506.01065)
*Ivan Milinović,Leon Stjepan Uroić,Marko Đurasević*

Main category: cs.NE

TL;DR: 本文提出了一种三层次模因算法（TMA），用于解决电动汽车路径问题（EVRP），结合遗传算法和动态编程，在小规模案例中表现优异。


<details>
  <summary>Details</summary>
Motivation: 电动汽车路径问题（EVRP）因电池限制和充电站的引入而更具挑战性，需要高效的优化方法。

Method: 采用三层次模因算法（TMA），分层次优化客户序列、路径分配和充电站插入，结合遗传算法与动态编程。

Result: 在WCCI2020测试中表现优异，小规模案例达到已知最佳结果，但计算需求限制了可扩展性。

Conclusion: TMA在可持续物流规划中展现出潜力，尽管计算复杂度限制了其在大规模问题中的应用。

Abstract: The Electric Vehicle Routing Problem (EVRP) extends the capacitated vehicle
routing problem by incorporating battery constraints and charging stations,
posing significant optimization challenges. This paper introduces a Trilevel
Memetic Algorithm (TMA) that hierarchically optimizes customer sequences, route
assignments, and charging station insertions. The method combines genetic
algorithms with dynamic programming, ensuring efficient and high-quality
solutions. Benchmark tests on WCCI2020 instances show competitive performance,
matching best-known results for small-scale cases. While computational demands
limit scalability, TMA demonstrates strong potential for sustainable logistics
planning.

</details>


### [466] [Speeding Up Hyper-Heuristics With Markov-Chain Operator Selection and the Only-Worsening Acceptance Operator](https://arxiv.org/abs/2506.01107)
*Abderrahim Bendahi,Benjamin Doerr,Adrien Fradin,Johannes F. Lutzeyer*

Main category: cs.NE

TL;DR: 本文提出两种改进的移动接受超启发式算法，通过马尔可夫链和仅接受恶化解的算子，显著提升了在多种基准函数上的性能。


<details>
  <summary>Details</summary>
Motivation: 改进现有的移动接受超启发式算法，以更高效地逃离局部最优解，提升在复杂优化问题中的性能。

Method: 1. 使用两状态马尔可夫链选择仅改进或任意移动接受算子；2. 引入仅接受恶化解的新算子。

Result: 改进后的算法在Jump_m函数上的运行时间从Ω(n^{2m-1})降至O(n^{m+1})，在Jump函数上降至O(n^3 log n)。

Conclusion: 新算法在包含多种复杂函数的SEQOPT_k类上表现出色，运行时间为O(n^{k+1} log n)。

Abstract: The move-acceptance hyper-heuristic was recently shown to be able to leave
local optima with astonishing efficiency (Lissovoi et al., Artificial
Intelligence (2023)). In this work, we propose two modifications to this
algorithm that demonstrate impressive performances on a large class of
benchmarks including the classic Cliff$_d$ and Jump$_m$ function classes. (i)
Instead of randomly choosing between the only-improving and any-move acceptance
operator, we take this choice via a simple two-state Markov chain. This
modification alone reduces the runtime on Jump$_m$ functions with gap parameter
$m$ from $\Omega(n^{2m-1})$ to $O(n^{m+1})$. (ii) We then replace the all-moves
acceptance operator with the operator that only accepts worsenings. Such a,
counter-intuitive, operator has not been used before in the literature.
However, our proofs show that our only-worsening operator can greatly help in
leaving local optima, reducing, e.g., the runtime on Jump functions to $O(n^3
\log n)$ independent of the gap size. In general, we prove a remarkably good
runtime of $O(n^{k+1} \log n)$ for our Markov move-acceptance hyper-heuristic
on all members of a new benchmark class SEQOPT$_k$, which contains a large
number of functions having $k$ successive local optima, and which contains the
commonly studied Jump$_m$ and Cliff$_d$ functions for $k=2$.

</details>


### [467] [Engram Memory Encoding and Retrieval: A Neurocomputational Perspective](https://arxiv.org/abs/2506.01659)
*Daniel Szelogowski*

Main category: cs.NE

TL;DR: 该论文结合细胞神经科学和计算模型，探讨了记忆的编码、存储和检索机制，重点研究了稀疏神经元群体（engram）的作用，并提出了一个整合生物学发现与计算模型的理论框架。


<details>
  <summary>Details</summary>
Motivation: 尽管对记忆的生物学基础已有大量研究，但其精确机制仍不完全清楚。论文旨在通过整合神经生物学和计算视角，解决engram研究中的关键问题，如神经元识别、突触可塑性机制和稀疏性的作用。

Method: 论文综合了细胞神经科学的发现和计算建模方法，如稀疏正则化、engram门控，以及生物启发的架构（如稀疏分布式记忆和脉冲神经网络）。

Result: 研究发现，记忆的效率、容量和稳定性源于可塑性和稀疏性约束的相互作用。

Conclusion: 论文为engram研究提供了全面的理论基础，并提出了未来研究记忆机制的路线图，对记忆相关疾病的诊断和治疗具有潜在意义。

Abstract: Despite substantial research into the biological basis of memory, the precise
mechanisms by which experiences are encoded, stored, and retrieved in the brain
remain incompletely understood. A growing body of evidence supports the engram
theory, which posits that sparse populations of neurons undergo lasting
physical and biochemical changes to support long-term memory. Yet, a
comprehensive computational framework that integrates biological findings with
mechanistic models remains elusive. This work synthesizes insights from
cellular neuroscience and computational modeling to address key challenges in
engram research: how engram neurons are identified and manipulated; how
synaptic plasticity mechanisms contribute to stable memory traces; and how
sparsity promotes efficient, interference-resistant representations. Relevant
computational approaches -- such as sparse regularization, engram gating, and
biologically inspired architectures like Sparse Distributed Memory and spiking
neural networks -- are also examined. Together, these findings suggest that
memory efficiency, capacity, and stability emerge from the interaction of
plasticity and sparsity constraints. By integrating neurobiological and
computational perspectives, this paper provides a comprehensive theoretical
foundation for engram research and proposes a roadmap for future inquiry into
the mechanisms underlying memory, with implications for the diagnosis and
treatment of memory-related disorders.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [468] [Using LLMs to Advance the Cognitive Science of Collectives](https://arxiv.org/abs/2506.00052)
*Ilia Sucholutsky,Katherine M. Collins,Nori Jacoby,Bill D. Thompson,Robert D. Hawkins*

Main category: q-bio.NC

TL;DR: LLMs在集体认知研究中的应用尚不充分，本文探讨了其潜力与风险。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在集体认知研究中的潜力，解决现有研究的复杂性。

Method: 提出LLMs如何应用于集体认知研究，并讨论相关风险。

Result: LLMs有望解决集体认知研究的复杂性，但需注意新风险。

Conclusion: LLMs为集体认知研究提供了新方向，但需开发新方法应对风险。

Abstract: LLMs are already transforming the study of individual cognition, but their
application to studying collective cognition has been underexplored. We lay out
how LLMs may be able to address the complexity that has hindered the study of
collectives and raise possible risks that warrant new methods.

</details>


### [469] [Human sensory-musculoskeletal modeling and control of whole-body movements](https://arxiv.org/abs/2506.00071)
*Chenhui Zuo,Guohao Lin,Chen Zhang,Shanning Zhuang,Yanan Sui*

Main category: q-bio.NC

TL;DR: SMS-Human模型整合了精确的解剖结构和多模态感官输入，通过分层强化学习模拟人类运动行为，结果与自然行为高度相似。


<details>
  <summary>Details</summary>
Motivation: 理解人类运动控制需要动态建模感官-肌肉骨骼系统，以研究行为并设计智能系统。

Method: 开发了SMS-Human模型，结合解剖结构和多感官输入，采用分层强化学习框架模拟运动任务。

Result: 模拟的运动行为与自然行为高度相似，并揭示了无法直接测量的肌肉骨骼动态。

Conclusion: 该研究深入揭示了人类运动的感官-肌肉骨骼动态，为行为理解和智能系统设计提供了新视角。

Abstract: Coordinated human movement depends on the integration of multisensory inputs,
sensorimotor transformation, and motor execution, as well as sensory feedback
resulting from body-environment interaction. Building dynamic models of the
sensory-musculoskeletal system is essential for understanding movement control
and investigating human behaviours. Here, we report a human
sensory-musculoskeletal model, termed SMS-Human, that integrates precise
anatomical representations of bones, joints, and muscle-tendon units with
multimodal sensory inputs involving visual, vestibular, proprioceptive, and
tactile components. A stage-wise hierarchical deep reinforcement learning
framework was developed to address the inherent challenges of high-dimensional
control in musculoskeletal systems with integrated multisensory information.
Using this framework, we demonstrated the simulation of three representative
movement tasks, including bipedal locomotion, vision-guided object
manipulation, and human-machine interaction during bicycling. Our results
showed a close resemblance between natural and simulated human motor
behaviours. The simulation also revealed musculoskeletal dynamics that could
not be directly measured. This work sheds deeper insights into the sensorimotor
dynamics of human movements, facilitates quantitative understanding of human
behaviours in interactive contexts, and informs the design of systems with
embodied intelligence.

</details>


### [470] [Autonomous Behavior and Whole-Brain Dynamics Emerge in Embodied Zebrafish Agents with Model-based Intrinsic Motivation](https://arxiv.org/abs/2506.00138)
*Reece Keller,Alyn Tornell,Felix Pei,Xaq Pitkow,Leo Kozachkov,Aran Nayebi*

Main category: q-bio.NC

TL;DR: 论文提出了一种新型模型驱动内驱力（3M-Progress），旨在模拟动物自主探索行为，填补了现有强化学习方法在稀疏奖励和无奖励环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在自主探索行为上表现不一致，且神经科学领域对自主性的神经机制研究不足。论文旨在填补这些空白。

Method: 提出3M-Progress方法，通过追踪智能体当前世界模型与行为学先验之间的差异，驱动自然行为。

Result: 实验表明，3M-Progress训练的智能体能捕捉自主行为斑马鱼的神经-胶质动态，建立了首个目标驱动的群体神经-胶质计算模型。

Conclusion: 该研究为构建具有动物自主性的人工智能体提供了计算框架，连接了模型驱动内驱力与自然行为。

Abstract: Autonomy is a hallmark of animal intelligence, enabling adaptive and
intelligent behavior in complex environments without relying on external reward
or task structure. Existing reinforcement learning approaches to exploration in
sparse reward and reward-free environments, including class of methods known as
intrinsic motivation, exhibit inconsistent exploration patterns and thus fail
to produce robust autonomous behaviors observed in animals. Moreover, systems
neuroscience has largely overlooked the neural basis of autonomy, focusing
instead on experimental paradigms where animals are motivated by external
reward rather than engaging in unconstrained, naturalistic and task-independent
behavior. To bridge these gaps, we introduce a novel model-based intrinsic
drive explicitly designed to capture robust autonomous exploration observed in
animals. Our method (3M-Progress) motivates naturalistic behavior by tracking
divergence between the agent's current world model and an ethological prior. We
demonstrate that artificial embodied agents trained with 3M-Progress capture
the explainable variance in behavioral patterns and whole-brain neural-glial
dynamics recorded from autonomously-behaving larval zebrafish, introducing the
first goal-driven, population-level model of neural-glial computation. Our
findings establish a computational framework connecting model-based intrinsic
motivation to naturalistic behavior, providing a foundation for building
artificial agents with animal-like autonomy.

</details>


<div id='q-bio.OT'></div>

# q-bio.OT [[Back]](#toc)

### [471] [Artificial Empathy: AI based Mental Health](https://arxiv.org/abs/2506.00081)
*Aditya Naik,Jovi Thomas,Teja Sree,Himavant Reddy*

Main category: q-bio.OT

TL;DR: AI聊天机器人被用作“五分钟心理治疗师”或非评判性伴侣，用户喜欢其匿名性，但也担心隐私问题。LLM聊天机器人测试显示其有局限性，如不一致的语气和缺乏危机敏感性。


<details>
  <summary>Details</summary>
Motivation: 研究AI聊天机器人在心理健康支持中的使用情况，以改进技术并更好地支持用户。

Method: 通过参与者访谈和基于场景的LLM聊天机器人测试。

Result: AI聊天机器人被用于短期情感支持，但存在隐私问题和功能局限性。

Conclusion: 研究结果可为技术和心理健康行业提供改进AI聊天机器人的方向。

Abstract: Many people suffer from mental health problems but not everyone seeks
professional help or has access to mental health care. AI chatbots have
increasingly become a go-to for individuals who either have mental disorders or
simply want someone to talk to. This paper presents a study on participants who
have previously used chatbots and a scenario-based testing of large language
model (LLM) chatbots. Our findings indicate that AI chatbots were primarily
utilized as a "Five minute therapist" or as a non-judgmental companion.
Participants appreciated the anonymity and lack of judgment from chatbots.
However, there were concerns about privacy and the security of sensitive
information. The scenario-based testing of LLM chatbots highlighted additional
issues. Some chatbots were consistently reassuring, used emojis and names to
add a personal touch, and were quick to suggest seeking professional help.
However, there were limitations such as inconsistent tone, occasional
inappropriate responses (e.g., casual or romantic), and a lack of crisis
sensitivity, particularly in recognizing red flag language and escalating
responses appropriately. These findings can inform both the technology and
mental health care industries on how to better utilize AI chatbots to support
individuals during challenging emotional periods.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [472] [Neural Network-based Information-Theoretic Transceivers for High-Order Modulation Schemes](https://arxiv.org/abs/2506.00368)
*Ngoc Long Pham,Tri Nhu Do*

Main category: eess.SP

TL;DR: 本文提出了一种基于神经网络的比特级接收器，提高了计算效率，同时性能与基线解映射器相当。进一步，引入了一种新颖的符号级自编码器端到端系统，联合优化物理层的发射器和接收器。实验表明，该系统在高阶调制方案中优于基线架构，且训练信噪比对系统性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探索基于神经网络的端到端通信系统，以开发人工智能原生的端到端系统，同时提高计算效率和性能。

Method: 提出基于神经网络的比特级接收器，并引入符号级自编码器端到端系统，联合优化发射器和接收器。通过误码率分析评估性能。

Result: 实验结果显示，基于自编码器的系统在高阶调制方案中优于基线架构，且训练信噪比对性能有显著影响。

Conclusion: 基于神经网络的端到端通信系统在高阶调制中表现优异，训练信噪比是关键性能影响因素。

Abstract: Neural network (NN)-based end-to-end (E2E) communication systems, in which
each system component may consist of a portion of a neural network, have been
investigated as potential tools for developing artificial intelligence
(Al)-native E2E systems. In this paper, we propose an NN-based bitwise receiver
that improves computational efficiency while maintaining performance comparable
to baseline demappers. Building on this foundation, we introduce a novel
symbol-wise autoencoder (AE)-based E2E system that jointly optimizes the
transmitter and receiver at the physical layer. We evaluate the proposed
NN-based receiver using bit-error rate (BER) analysis to confirm that the
numerical BER achieved by NN-based receivers or transceivers is accurate.
Results demonstrate that the AE-based system outperforms baseline
architectures, particularly for higher-order modulation schemes. We further
show that the training signal-to-noise ratio (SNR) significantly affects the
performance of the systems when inference is conducted at different SNR levels.

</details>


### [473] [Attention-Aided MMSE for OFDM Channel Estimation: Learning Linear Filters with Attention](https://arxiv.org/abs/2506.00452)
*TaeJun Ha,Chaehyun Jung,Hyeonuk Kim,Jeongwoo Park,Jeonghun Park*

Main category: eess.SP

TL;DR: 论文提出了一种基于注意力机制的MMSE（A-MMSE）方法，通过Transformer学习最优MMSE滤波器，简化计算复杂度，并在性能与复杂度之间实现灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 传统MMSE方法需要难以获取的二阶统计信息，而现有深度学习方法复杂度高，因此需要一种高效且低复杂度的信道估计方法。

Method: 提出A-MMSE框架，利用注意力Transformer学习最优MMSE滤波器，采用两阶段注意力编码器捕捉信道相关性，并支持秩自适应扩展。

Result: 在3GPP TDL信道模型下，A-MMSE在多种SNR条件下均优于基线方法，性能与复杂度权衡达到新水平。

Conclusion: A-MMSE及其秩自适应扩展为信道估计方法设定了新标准，兼具高效性与灵活性。

Abstract: In orthogonal frequency division multiplexing (OFDM), accurate channel
estimation is crucial. Classical signal processing based approaches, such as
minimum mean-squared error (MMSE) estimation, often require second-order
statistics that are difficult to obtain in practice. Recent deep neural
networks based methods have been introduced to address this; yet they often
suffer from high complexity. This paper proposes an Attention-aided MMSE
(A-MMSE), a novel model-based DNN framework that learns the optimal MMSE filter
via the Attention Transformer. Once trained, the A-MMSE estimates the channel
through a single linear operation for channel estimation, eliminating nonlinear
activations during inference and thus reducing computational complexity. To
enhance the learning efficiency of the A-MMSE, we develop a two-stage Attention
encoder, designed to effectively capture the channel correlation structure.
Additionally, a rank-adaptive extension of the proposed A-MMSE allows flexible
trade-offs between complexity and channel estimation accuracy. Extensive
simulations with 3GPP TDL channel models demonstrate that the proposed A-MMSE
consistently outperforms other baseline methods in terms of normalized MSE
across a wide range of SNR conditions. In particular, the A-MMSE and its
rank-adaptive extension establish a new frontier in the performance complexity
trade-off, redefining the standard for practical channel estimation methods.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [474] [PathGene: Benchmarking Driver Gene Mutations and Exon Prediction Using Multicenter Lung Cancer Histopathology Image Dataset](https://arxiv.org/abs/2506.00096)
*Liangrui Pan,Qingchun Liang,Shen Zhao,Songqing Fan,Shaoliang Peng*

Main category: q-bio.GN

TL;DR: 利用人工智能从常规病理图像预测肺癌基因突变、亚型和外显子变异，以支持精准治疗。


<details>
  <summary>Details</summary>
Motivation: 解决医疗资源不均和基因组检测成本高的问题，提升早期筛查和精准肿瘤学的效果。

Method: 构建PathGene数据集，结合病理图像和测序报告，评估11种多实例学习方法。

Result: PathGene数据集为早期基因筛查和个性化治疗提供了新工具。

Conclusion: PathGene及实验方法为肺癌精准治疗提供了有价值的支持。

Abstract: Accurately predicting gene mutations, mutation subtypes and their exons in
lung cancer is critical for personalized treatment planning and prognostic
assessment. Faced with regional disparities in medical resources and the high
cost of genomic assays, using artificial intelligence to infer these mutations
and exon variants from routine histopathology images could greatly facilitate
precision therapy. Although some prior studies have shown that deep learning
can accelerate the prediction of key gene mutations from lung cancer pathology
slides, their performance remains suboptimal and has so far been limited mainly
to early screening tasks. To address these limitations, we have assembled
PathGene, which comprises histopathology images paired with next-generation
sequencing reports from 1,576 patients at the Second Xiangya Hospital, Central
South University, and 448 TCGA-LUAD patients. This multi-center dataset links
whole-slide images to driver gene mutation status, mutation subtypes, exon, and
tumor mutational burden (TMB) status, with the goal of leveraging pathology
images to predict mutations, subtypes, exon locations, and TMB for early
genetic screening and to advance precision oncology. Unlike existing datasets,
we provide molecular-level information related to histopathology images in
PathGene to facilitate the development of biomarker prediction models. We
benchmarked 11 multiple-instance learning methods on PathGene for mutation,
subtype, exon, and TMB prediction tasks. These experimental methods provide
valuable alternatives for early genetic screening of lung cancer patients and
assisting clinicians to quickly develop personalized precision targeted
treatment plans for patients. Code and data are available at
https://github.com/panliangrui/NIPS2025/.

</details>


### [475] [GenDMR: A dynamic multimodal role-swapping network for identifying risk gene phenotypes](https://arxiv.org/abs/2506.01456)
*Lina Qin,Cheng Zhu,Chuqi Zhou,Yukun Huang,Jiayi Zhu,Ping Liang,Jinju Wang,Yixing Huang,Cheng Luo,Dezhong Yao,Ying Tan*

Main category: q-bio.GN

TL;DR: 本文提出了一种动态多模态角色交换网络（GenDMR），用于解决当前多模态数据融合技术在阿尔茨海默病（AD）研究中忽视遗传特征价值的问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在遗传信息选择和编码上存在不足，且多模态融合中过度依赖成像特征，弱化了遗传特征的独特价值。

Method: GenDMR通过编码单核苷酸多态性（SNPs）的空间组织、多实例注意力模块、主导模态选择模块和对比自蒸馏模块，实现动态角色交换机制。

Result: GenDMR在ADNI数据集上达到最先进性能，并识别出12个潜在高风险基因，包括APOE。

Conclusion: GenDMR为多模态数据融合技术的发展提供了新的见解，增强了遗传特征的可解释性分析能力。

Abstract: Recent studies have shown that integrating multimodal data fusion techniques
for imaging and genetic features is beneficial for the etiological analysis and
predictive diagnosis of Alzheimer's disease (AD). However, there are several
critical flaws in current deep learning methods. Firstly, there has been
insufficient discussion and exploration regarding the selection and encoding of
genetic information. Secondly, due to the significantly superior classification
value of AD imaging features compared to genetic features, many studies in
multimodal fusion emphasize the strengths of imaging features, actively
mitigating the influence of weaker features, thereby diminishing the learning
of the unique value of genetic features. To address this issue, this study
proposes the dynamic multimodal role-swapping network (GenDMR). In GenDMR, we
develop a novel approach to encode the spatial organization of single
nucleotide polymorphisms (SNPs), enhancing the representation of their genomic
context. Additionally, to adaptively quantify the disease risk of SNPs and
brain region, we propose a multi-instance attention module to enhance model
interpretability. Furthermore, we introduce a dominant modality selection
module and a contrastive self-distillation module, combining them to achieve a
dynamic teacher-student role exchange mechanism based on dominant and auxiliary
modalities for bidirectional co-updating of different modal data. Finally,
GenDMR achieves state-of-the-art performance on the ADNI public dataset and
visualizes attention to different SNPs, focusing on confirming 12 potential
high-risk genes related to AD, including the most classic APOE and recently
highlighted significant risk genes. This demonstrates GenDMR's interpretable
analytical capability in exploring AD genetic features, providing new insights
and perspectives for the development of multimodal data fusion techniques.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [476] [From Initial Data to Boundary Layers: Neural Networks for Nonlinear Hyperbolic Conservation Laws](https://arxiv.org/abs/2506.01453)
*Igor Ciril,Khalil Haddaoui,Yohann Tendero*

Main category: math.AP

TL;DR: 论文提出了一种使用神经网络近似非线性严格双曲守恒律初边值问题熵解的方法，并设计了一个高效可靠的学习算法框架。


<details>
  <summary>Details</summary>
Motivation: 解决非线性严格双曲守恒律初边值问题的熵解近似问题，为复杂工业场景提供潜在应用。

Method: 引入了一个通用的系统框架，结合快速收敛和准确预测，设计高效可靠的学习算法。

Result: 通过一系列一维标量测试案例验证了方法的有效性。

Conclusion: 该方法展示了在更复杂工业场景中的潜在适用性。

Abstract: We address the approximation of entropy solutions to initial-boundary value
problems for nonlinear strictly hyperbolic conservation laws using neural
networks. A general and systematic framework is introduced for the design of
efficient and reliable learning algorithms, combining fast convergence during
training with accurate predictions. The methodology is assessed through a
series of one-dimensional scalar test cases, highlighting its potential
applicability to more complex industrial scenarios.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [477] [Robot-R1: Reinforcement Learning for Enhanced Embodied Reasoning in Robotics](https://arxiv.org/abs/2506.00070)
*Dongyoung Kim,Sumin Park,Huiwon Jang,Jinwoo Shin,Jaehyung Kim,Younggyo Seo*

Main category: cs.RO

TL;DR: 论文提出了一种名为Robot-R1的新框架，利用强化学习优化机器人控制中的具身推理任务，解决了传统监督微调（SFT）方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统SFT方法在机器人控制任务中存在数据集构造不优化、灾难性遗忘和泛化性能下降等问题。

Method: Robot-R1通过强化学习预测任务完成所需的下一个关键点状态，结合当前场景图像和环境元数据，并采样推理响应以强化准确预测。

Result: 实验表明，Robot-R1在具身推理任务中优于SFT方法，甚至在低级别动作控制任务中超越GPT-4o。

Conclusion: Robot-R1为机器人控制中的具身推理提供了一种更高效的解决方案。

Abstract: Large Vision-Language Models (LVLMs) have recently shown great promise in
advancing robotics by combining embodied reasoning with robot control. A common
approach involves training on embodied reasoning tasks related to robot control
using Supervised Fine-Tuning (SFT). However, SFT datasets are often
heuristically constructed and not explicitly optimized for improving robot
control. Furthermore, SFT often leads to issues such as catastrophic forgetting
and reduced generalization performance. To address these limitations, we
introduce Robot-R1, a novel framework that leverages reinforcement learning to
enhance embodied reasoning specifically for robot control. Robot-R1 learns to
predict the next keypoint state required for task completion, conditioned on
the current scene image and environment metadata derived from expert
demonstrations. Inspired by the DeepSeek-R1 learning approach, Robot-R1 samples
reasoning-based responses and reinforces those that lead to more accurate
predictions. Our experiments show that models trained with Robot-R1 outperform
SFT methods on embodied reasoning tasks. Despite having only 7B parameters,
Robot-R1 even surpasses GPT-4o on reasoning tasks related to low-level action
control, such as spatial and primitive movement reasoning.

</details>


### [478] [Reducing Latency in LLM-Based Natural Language Commands Processing for Robot Navigation](https://arxiv.org/abs/2506.00075)
*Diego Pollini,Bruna V. Guterres,Rodrigo S. Guerra,Ricardo B. Grando*

Main category: cs.RO

TL;DR: 研究探讨了将ChatGPT与ROS 2集成以减少交互延迟，提升机器人系统控制效率，实验结果显示通信延迟平均降低7.01%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（如GPT）在工业机器人中的应用虽提升效率，但其计算复杂性和规模常导致请求与响应延迟问题。

Method: 提出一种无需中间件传输平台的架构，将ChatGPT与ROS 2集成，模拟移动机器人对文本和语音命令的响应。

Result: 实验表明，该集成提高了执行速度、可用性和人机交互的可访问性，通信延迟平均降低7.01%。

Conclusion: 这种集成优化了实时机器人操作，对工业自动化和精密任务至关重要。

Abstract: The integration of Large Language Models (LLMs), such as GPT, in industrial
robotics enhances operational efficiency and human-robot collaboration.
However, the computational complexity and size of these models often provide
latency problems in request and response times. This study explores the
integration of the ChatGPT natural language model with the Robot Operating
System 2 (ROS 2) to mitigate interaction latency and improve robotic system
control within a simulated Gazebo environment. We present an architecture that
integrates these technologies without requiring a middleware transport
platform, detailing how a simulated mobile robot responds to text and voice
commands. Experimental results demonstrate that this integration improves
execution speed, usability, and accessibility of the human-robot interaction by
decreasing the communication latency by 7.01\% on average. Such improvements
facilitate smoother, real-time robot operations, which are crucial for
industrial automation and precision tasks.

</details>


### [479] [Hi-Dyna Graph: Hierarchical Dynamic Scene Graph for Robotic Autonomy in Human-Centric Environments](https://arxiv.org/abs/2506.00083)
*Jiawei Hou,Xiangyang Xue,Taiping Zeng*

Main category: cs.RO

TL;DR: Hi-Dyna Graph是一种分层动态场景图架构，结合全局布局与动态语义，用于服务机器人在动态环境中的自主操作。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如拓扑地图）无法建模瞬态对象关系，而密集神经表示（如NeRF）计算成本过高。

Method: 构建全局拓扑图与动态子图，通过语义和空间约束将子图锚定到全局拓扑中，利用LLM代理生成可执行指令。

Result: 实验验证了Hi-Dyna Graph在场景表示上的优越性，实际部署中机器人能自主完成复杂任务。

Conclusion: Hi-Dyna Graph为动态环境中的机器人自主操作提供了高效且实用的解决方案。

Abstract: Autonomous operation of service robotics in human-centric scenes remains
challenging due to the need for understanding of changing environments and
context-aware decision-making. While existing approaches like topological maps
offer efficient spatial priors, they fail to model transient object
relationships, whereas dense neural representations (e.g., NeRF) incur
prohibitive computational costs. Inspired by the hierarchical scene
representation and video scene graph generation works, we propose Hi-Dyna
Graph, a hierarchical dynamic scene graph architecture that integrates
persistent global layouts with localized dynamic semantics for embodied robotic
autonomy. Our framework constructs a global topological graph from posed RGB-D
inputs, encoding room-scale connectivity and large static objects (e.g.,
furniture), while environmental and egocentric cameras populate dynamic
subgraphs with object position relations and human-object interaction patterns.
A hybrid architecture is conducted by anchoring these subgraphs to the global
topology using semantic and spatial constraints, enabling seamless updates as
the environment evolves. An agent powered by large language models (LLMs) is
employed to interpret the unified graph, infer latent task triggers, and
generate executable instructions grounded in robotic affordances. We conduct
complex experiments to demonstrate Hi-Dyna Grap's superior scene representation
effectiveness. Real-world deployments validate the system's practicality with a
mobile manipulator: robotics autonomously complete complex tasks with no
further training or complex rewarding in a dynamic scene as cafeteria
assistant. See https://anonymous.4open.science/r/Hi-Dyna-Graph-B326 for video
demonstration and more details.

</details>


### [480] [LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks](https://arxiv.org/abs/2506.00411)
*Yi Yang,Jiaxuan Sun,Siqi Kou,Yihan Wang,Zhijie Deng*

Main category: cs.RO

TL;DR: LoHoVLA是一个统一的视觉语言动作框架，用于解决长时程任务中的规划和动作控制问题，通过共享表示和分层闭环控制机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的具身智能体需要处理长时程任务，但现有方法在任务规划和动作控制方面存在不足，限制了性能。

Method: LoHoVLA利用预训练的视觉语言模型作为主干，联合生成语言和动作令牌，并采用分层闭环控制机制减少错误。

Result: 实验结果表明，LoHoVLA在长时程任务中显著优于分层和标准VLA方法。

Conclusion: 统一架构在提升具身智能体的通用性方面具有潜力。

Abstract: Real-world embodied agents face long-horizon tasks, characterized by
high-level goals demanding multi-step solutions beyond single actions.
Successfully navigating these requires both high-level task planning (i.e.,
decomposing goals into sub-tasks) and low-level motion control (i.e.,
generating precise robot actions). While existing vision language action (VLA)
models and hierarchical architectures offer potential in embodied tasks, the
former often falter in planning, and the latter can suffer from coordination
issues, both hampering performance. We introduce a new unified VLA framework
for long-horizon tasks, dubbed LoHoVLA, to overcome these limitations. LoHoVLA
leverages a large pretrained vision language model (VLM) as the backbone to
jointly generate language and action tokens for sub-task generation and robot
action prediction, respectively. This shared representation promotes better
generalization across tasks. Additionally, LoHoVLA embraces a hierarchical
closed-loop control mechanism to mitigate errors originating from both
high-level planning and low-level control. To train LoHoVLA, we introduce
LoHoSet, a dataset built on the Ravens simulator, containing 20 long-horizon
tasks, each with 1,000 expert demonstrations composed of visual observations,
linguistic goals, sub-tasks, and robot actions. Experimental results show that
LoHoVLA significantly surpasses both hierarchical and standard VLA approaches
on long-horizon embodied tasks in the Ravens simulator. These findings
underscore the promise of unified architectures for advancing generalizable
embodied intelligence.

</details>


### [481] [Diffusion Models for Increasing Accuracy in Olfaction Sensors and Datasets](https://arxiv.org/abs/2506.00455)
*Kordel K. France,Ovidiu Daescu*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的机器学习方法，用于提高机器人气味源定位的准确性，结合视觉语言模型和分子生成技术。


<details>
  <summary>Details</summary>
Motivation: 当前气味源定位方法因嗅觉数据集和传感器分辨率的限制存在模糊性，机器人常将气味错误归因于不正确的物体。

Method: 采用扩散模型生成分子，扩展化学空间，结合视觉语言模型和电子传感器阵列验证生成分子。

Result: 通过视觉分析、语言处理和分子生成，提高了机器人嗅觉-视觉模型准确关联气味与源的能力。

Conclusion: 该方法为机器人嗅觉领域提供了可扩展的解决方案，解决了嗅觉数据和传感器模糊性的挑战。

Abstract: Robotic odour source localization (OSL) is a critical capability for
autonomous systems operating in complex environments. However, current OSL
methods often suffer from ambiguities, particularly when robots misattribute
odours to incorrect objects due to limitations in olfactory datasets and sensor
resolutions. To address this challenge, we introduce a novel machine learning
method using diffusion-based molecular generation to enhance odour localization
accuracy that can be used by itself or with automated olfactory dataset
construction pipelines with vision-language models (VLMs) This generative
process of our diffusion model expands the chemical space beyond the
limitations of both current olfactory datasets and the training data of VLMs,
enabling the identification of potential odourant molecules not previously
documented. The generated molecules can then be more accurately validated using
advanced olfactory sensors which emulate human olfactory recognition through
electronic sensor arrays. By integrating visual analysis, language processing,
and molecular generation, our framework enhances the ability of
olfaction-vision models on robots to accurately associate odours with their
correct sources, thereby improving navigation and decision-making in
environments where olfactory cues are essential. Our methodology represents a
foundational advancement in the field of robotic olfaction, offering a scalable
solution to the challenges posed by limited olfactory data and sensor
ambiguities.

</details>


### [482] [Multi-Objective Neural Network Assisted Design Optimization of Soft Fin-Ray Grippers for Enhanced Grasping Performance](https://arxiv.org/abs/2506.00494)
*Ali Ghanizadeh,Ali Ahmadi,Arash Bahrami*

Main category: cs.RO

TL;DR: 该论文研究了软Fin-Ray夹持器的多目标优化问题，通过有限元方法（FEM）和机器学习（MLP）预测接触力和位移，并使用NSGA-II算法优化设计。


<details>
  <summary>Details</summary>
Motivation: Fin-Ray夹持器在柔性和高力操作之间存在矛盾，需要平衡这两种性能。

Method: 使用FEM模拟Fin-Ray夹持器的变形和接触力，构建MLP模型预测性能，并采用NSGA-II进行多目标优化。

Result: 研究展示了如何通过优化设计参数实现柔性和高力操作的平衡。

Conclusion: 该方法可提升软机器人夹持器的设计性能，适用于不同应用场景。

Abstract: Soft Fin-Ray grippers can perform delicate and careful manipulation, which
has caused notable attention in different fields. These grippers can handle
objects of various forms and sizes safely. The internal structure of the
Fin-Ray finger plays a significant role in its adaptability and grasping
performance. However, modeling the non-linear grasp force and deformation
behaviors for design purposes is challenging. Moreover, when the Fin-Ray finger
becomes more rigid and capable of exerting higher forces, it becomes less
delicate in handling objects. The contrast between these two objectives gives
rise to a multi-objective optimization problem. In this study, we employ finite
element method (FEM) to estimate the deflections and contact forces of the
Fin-Ray, grasping cylindrical objects. This dataset is then used to construct a
multilayer perception (MLP) for prediction of the contact force and the tip
displacement. The FEM dataset consists of three input and four target features.
The three input features of the MLP and optimization design variables are the
thickness of the front and supporting beams, the thickness of the cross beams,
and the equal spacing between the cross beams. In addition, the target features
are the maximum contact forces and maximum tip displacements in x- and
y-directions. The magnitude of maximum contact force and magnitude of maximum
tip displacement are the two objectives, showing the trade-off between force
and delicate manipulation in soft Fin-Ray grippers. Furthermore, the optimized
set of solutions are found using multi-objective optimal techniques. We use
non-dominated sorting genetic algorithm (NSGA-II) method for this purpose. Our
findings demonstrate that our methodologies can be used to improve the design
and gripping performance of soft robotic grippers, helping us to choose a
design not only for delicate grasping but also for high-force applications.

</details>


### [483] [Evaluating Robot Policies in a World Model](https://arxiv.org/abs/2506.00613)
*Julian Quevedo,Percy Liang,Sherry Yang*

Main category: cs.RO

TL;DR: 本文提出了一种基于世界模型的策略评估方法（WPE），通过训练动作条件视频生成模型模拟真实环境，并采用块自回归扩散变换器减少误差积累。实验表明，WPE能有效保留策略的相对排名，但在模拟复杂物体交互时仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 机器人策略评估在真实环境中成本高昂，而手工模拟往往无法准确反映真实条件，导致模拟与真实结果相关性差。

Method: 训练动作条件视频生成模型作为环境代理，提出块自回归扩散变换器以减少误差积累，并使用视觉语言模型（VLM）作为奖励函数进行蒙特卡洛模拟。

Result: WPE在策略评估中能保留相对排名，但对分布内动作低估，对分布外动作高估。模拟机器人动作时表现良好，但复杂物体交互仍有挑战。

Conclusion: 尽管存在局限性，世界模型可作为机器人策略部署前的有效评估起点。

Abstract: Robotics has broad applications from automating house chores to taking care
of patients. However, evaluating robot control policies is challenging, as
real-world testing is expensive, while handcrafted simulations often fail to
accurately reflect real-world conditions, resulting in poor correlation between
simulated evaluation and real-world outcomes. In this work, we investigate
World-model-based Policy Evaluation (WPE). We first train an action-conditioned
video generation model as a proxy to real-world environments. To enable
efficient rollouts of hundreds of interactive steps while mitigating error
accumulation in the world model, we propose an inference scheme which we call
Blockwise-Autoregressive Diffusion Transformer with adjustable context and
decoding horizon lengths. To ensure that the world model indeed follows action
input, we propose metrics based on the agreement between the ground truth video
and generated video conditioned on the same sequence of actions to evaluate the
world model. We then use the world model for policy evaluation by performing
Monte Carlo rollouts in the world model while employing a vision-language model
(VLM) as a reward function. Interestingly, we found that WPE tends to
underestimate the policy values for in-distribution actions and overestimate
policy values for out-of-distribution actions. Nevertheless, WPE preserves the
relative rankings of different policies. In emulating real robot executions,
WPE achieves high fidelity in mimicing robot arm movements as in real videos,
while emulating highly realistic object interaction remains challenging.
Despite this limitation, we show that a world model can serve as a starting
point for evaluating robot policies before real-world deployment.

</details>


### [484] [DriveMind: A Dual-VLM based Reinforcement Learning Framework for Autonomous Driving](https://arxiv.org/abs/2506.00819)
*Dawood Wasif,Terrence J Moore,Chandan K Reddy,Jin-Hee Cho*

Main category: cs.RO

TL;DR: DriveMind是一个端到端自动驾驶系统，通过语义奖励框架提升透明度和安全性，结合视觉语言模型和动态提示生成，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统缺乏透明性和安全性保证，且静态提示和固定目标限制了动态场景的适应性。

Method: DriveMind整合了对比视觉语言模型编码器、动态提示生成、分层安全模块和预测世界模型。

Result: 在CARLA Town 2中，DriveMind平均速度19.4 km/h，路线完成率0.98，碰撞率接近零，零样本泛化到真实数据。

Conclusion: DriveMind展示了跨域对齐的潜力，适用于实际部署。

Abstract: End-to-end autonomous driving systems map sensor data directly to control
commands, but remain opaque, lack interpretability, and offer no formal safety
guarantees. While recent vision-language-guided reinforcement learning (RL)
methods introduce semantic feedback, they often rely on static prompts and
fixed objectives, limiting adaptability to dynamic driving scenes. We present
DriveMind, a unified semantic reward framework that integrates: (i) a
contrastive Vision-Language Model (VLM) encoder for stepwise semantic
anchoring; (ii) a novelty-triggered VLM encoder-decoder, fine-tuned via
chain-of-thought (CoT) distillation, for dynamic prompt generation upon
semantic drift; (iii) a hierarchical safety module enforcing kinematic
constraints (e.g., speed, lane centering, stability); and (iv) a compact
predictive world model to reward alignment with anticipated ideal states.
DriveMind achieves 19.4 +/- 2.3 km/h average speed, 0.98 +/- 0.03 route
completion, and near-zero collisions in CARLA Town 2, outperforming baselines
by over 4% in success rate. Its semantic reward generalizes zero-shot to real
dash-cam data with minimal distributional shift, demonstrating robust
cross-domain alignment and potential for real-world deployment.

</details>


### [485] [RoboMoRe: LLM-based Robot Co-design via Joint Optimization of Morphology and Reward](https://arxiv.org/abs/2506.00276)
*Jiawei Fang,Yuxuan Sun,Chengtian Ma,Qiuyu Lu,Lining Yao*

Main category: cs.RO

TL;DR: RoboMoRe是一个基于大型语言模型（LLM）的框架，通过双阶段优化（粗优化和细优化）联合优化机器人形态和奖励函数，显著优于人工设计和其他方法。


<details>
  <summary>Details</summary>
Motivation: 传统机器人协同设计方法因使用固定奖励函数而容易收敛到次优设计，无法探索适合不同形态的多样化运动模式。

Method: RoboMoRe采用双阶段优化：粗优化阶段通过LLM生成多样化的形态-奖励对并探索其分布；细优化阶段通过交替的LLM引导奖励和形态梯度更新迭代优化候选设计。

Result: 在八项任务中，RoboMoRe无需任务特定提示或预定义模板，显著优于人工设计和其他方法。

Conclusion: RoboMoRe通过LLM驱动的奖励和形态联合优化，为机器人协同设计提供了高效且多样化的解决方案。

Abstract: Robot co-design, jointly optimizing morphology and control policy, remains a
longstanding challenge in the robotics community, where many promising robots
have been developed. However, a key limitation lies in its tendency to converge
to sub-optimal designs due to the use of fixed reward functions, which fail to
explore the diverse motion modes suitable for different morphologies. Here we
propose RoboMoRe, a large language model (LLM)-driven framework that integrates
morphology and reward shaping for co-optimization within the robot co-design
loop. RoboMoRe performs a dual-stage optimization: in the coarse optimization
stage, an LLM-based diversity reflection mechanism generates both diverse and
high-quality morphology-reward pairs and efficiently explores their
distribution. In the fine optimization stage, top candidates are iteratively
refined through alternating LLM-guided reward and morphology gradient updates.
RoboMoRe can optimize both efficient robot morphologies and their suited motion
behaviors through reward shaping. Results demonstrate that without any
task-specific prompting or predefined reward/morphology templates, RoboMoRe
significantly outperforms human-engineered designs and competing methods across
eight different tasks.

</details>


### [486] [Humanoid World Models: Open World Foundation Models for Humanoid Robotics](https://arxiv.org/abs/2506.01182)
*Muhammad Qasim Ali,Aditya Sridhar,Shahbuland Matiana,Alex Wong,Mohammad Al-Sharman*

Main category: cs.RO

TL;DR: 论文提出了一种轻量级开源视频预测模型HWM，用于人形机器人在人类环境中的任务规划。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要强大的预测模型来推理其动作的结果，以在人类中心环境中执行复杂任务。

Method: 训练了两种生成模型（Masked Transformers和FlowMatching），并探索了不同注意力机制和参数共享策略的架构变体。

Result: 参数共享技术将模型大小减少了33%至53%，且对性能或视觉保真度影响最小。HWM适用于1至2个GPU的学术和小型实验室环境。

Conclusion: HWM为轻量级视频预测模型提供了实用解决方案，适合资源有限的场景。

Abstract: Humanoid robots have the potential to perform complex tasks in human centered
environments but require robust predictive models to reason about the outcomes
of their actions. We introduce Humanoid World Models (HWM) a family of
lightweight open source video based models that forecast future egocentric
observations conditioned on actions. We train two types of generative models
Masked Transformers and FlowMatching on 100 hours of humanoid demonstrations.
Additionally we explore architectural variants with different attention
mechanisms and parameter sharing strategies. Our parameter sharing techniques
reduce model size by 33 to 53 with minimal impact on performance or visual
fidelity. HWM is designed to be trained and deployed in practical academic and
small lab settings such as 1 to 2 GPUs.

</details>


### [487] [OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation](https://arxiv.org/abs/2506.01196)
*Ishika Singh,Ankit Goyal,Stan Birchfield,Dieter Fox,Animesh Garg,Valts Blukis*

Main category: cs.RO

TL;DR: OG-VLA结合了视觉语言动作模型（VLA）的泛化能力和3D感知策略的鲁棒性，通过多视角RGBD观测和自然语言指令生成机器人动作。


<details>
  <summary>Details</summary>
Motivation: 解决3D感知策略在未见指令、场景和物体上泛化能力不足，以及VLA对相机和机器人姿态变化敏感的问题。

Method: 将多视角观测投影为点云并渲染为正交视图，利用视觉骨干网络、大语言模型和图像扩散模型生成末端执行器的位置和方向。

Result: 在Arnold和Colosseum基准测试中，未见环境下的泛化性能提升40%以上，同时在已知场景中保持鲁棒性。

Conclusion: OG-VLA在泛化和鲁棒性上取得显著进展，适用于真实世界任务。

Abstract: We introduce OG-VLA, a novel architecture and learning framework that
combines the generalization strengths of Vision Language Action models (VLAs)
with the robustness of 3D-aware policies. We address the challenge of mapping
natural language instructions and multi-view RGBD observations to quasi-static
robot actions. 3D-aware robot policies achieve state-of-the-art performance on
precise robot manipulation tasks, but struggle with generalization to unseen
instructions, scenes, and objects. On the other hand, VLAs excel at
generalizing across instructions and scenes, but can be sensitive to camera and
robot pose variations. We leverage prior knowledge embedded in language and
vision foundation models to improve generalization of 3D-aware keyframe
policies. OG-VLA projects input observations from diverse views into a point
cloud which is then rendered from canonical orthographic views, ensuring input
view invariance and consistency between input and output spaces. These
canonical views are processed with a vision backbone, a Large Language Model
(LLM), and an image diffusion model to generate images that encode the next
position and orientation of the end-effector on the input scene. Evaluations on
the Arnold and Colosseum benchmarks demonstrate state-of-the-art generalization
to unseen environments, with over 40% relative improvements while maintaining
robust performance in seen settings. We also show real-world adaption in 3 to 5
demonstrations along with strong generalization. Videos and resources at
https://og-vla.github.io/

</details>


### [488] [Sparse Imagination for Efficient Visual World Model Planning](https://arxiv.org/abs/2506.01392)
*Junha Chun,Youngjoon Jeong,Taesup Kim*

Main category: cs.RO

TL;DR: 提出了一种稀疏想象的视觉世界模型规划方法，通过减少前向预测中的令牌数量提升计算效率，适用于资源受限的实时决策场景。


<details>
  <summary>Details</summary>
Motivation: 世界模型在复杂环境中提升决策能力，但高计算资源需求限制了实时应用，尤其在机器人领域。

Method: 基于稀疏训练的视觉世界模型，采用随机分组注意力策略，动态调整处理的令牌数量。

Result: 稀疏想象显著加速规划过程，同时保持高控制精度，实验验证了其高效性和性能。

Conclusion: 该方法为世界模型在实时决策中的部署提供了可行方案。

Abstract: World model based planning has significantly improved decision-making in
complex environments by enabling agents to simulate future states and make
informed choices. However, ensuring the prediction accuracy of world models
often demands substantial computational resources, posing a major challenge for
real-time applications. This computational burden is particularly restrictive
in robotics, where resources are severely constrained. To address this
limitation, we propose a Sparse Imagination for Efficient Visual World Model
Planning, which enhances computational efficiency by reducing the number of
tokens processed during forward prediction. Our method leverages a sparsely
trained vision-based world model based on transformers with randomized grouped
attention strategy, allowing the model to adaptively adjust the number of
tokens processed based on the computational resource. By enabling sparse
imagination (rollout), our approach significantly accelerates planning while
maintaining high control fidelity. Experimental results demonstrate that sparse
imagination preserves task performance while dramatically improving inference
efficiency, paving the way for the deployment of world models in real-time
decision-making scenarios.

</details>


### [489] [LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation](https://arxiv.org/abs/2506.01538)
*Guobin Zhu,Rui Zhou,Wenkang Ji,Shiyu Zhao*

Main category: cs.RO

TL;DR: 论文提出了一种结合大语言模型（LLM）与多智能体强化学习（MARL）的新方法LAMARL，显著提高了样本效率并避免了手动设计。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在复杂任务中有效，但样本效率低且需手动调整奖励函数。LLM在单机器人任务中表现优异，但在多机器人系统中应用较少。

Method: LAMARL包含两个模块：1）利用LLM自动生成先验策略和奖励函数；2）MARL利用生成的函数指导策略训练。

Result: 在形状组装任务中，LAMARL显著提升了样本效率（平均185.9%）和任务完成率。基于Chain-of-Thought的结构化提示将LLM输出成功率提高了28.5%-67.5%。

Conclusion: LAMARL展示了LLM与MARL结合的潜力，为多机器人系统提供了一种高效且自动化的解决方案。

Abstract: Although Multi-Agent Reinforcement Learning (MARL) is effective for complex
multi-robot tasks, it suffers from low sample efficiency and requires iterative
manual reward tuning. Large Language Models (LLMs) have shown promise in
single-robot settings, but their application in multi-robot systems remains
largely unexplored. This paper introduces a novel LLM-Aided MARL (LAMARL)
approach, which integrates MARL with LLMs, significantly enhancing sample
efficiency without requiring manual design. LAMARL consists of two modules: the
first module leverages LLMs to fully automate the generation of prior policy
and reward functions. The second module is MARL, which uses the generated
functions to guide robot policy training effectively. On a shape assembly
benchmark, both simulation and real-world experiments demonstrate the unique
advantages of LAMARL. Ablation studies show that the prior policy improves
sample efficiency by an average of 185.9% and enhances task completion, while
structured prompts based on Chain-of-Thought (CoT) and basic APIs improve LLM
output success rates by 28.5%-67.5%. Videos and code are available at
https://guobin-zhu.github.io/LLM-MARL

</details>


### [490] [FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens](https://arxiv.org/abs/2506.01583)
*Yiming Zhong,Yumeng Liu,Chuyang Xiao,Zemin Yang,Youzhuo Wang,Yufei Zhu,Ye Shi,Yujing Sun,Xinge Zhu,Yuexin Ma*

Main category: cs.RO

TL;DR: 提出了一种基于频域表示和连续潜在表征的视觉运动策略学习方法，显著提升了机器人操作的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动作表示和网络架构上存在固有局限性，频域表示能更有效地捕捉动作的结构性特征，且不同复杂度的任务需要不同频段的建模精度。

Method: 提出了一种渐进式建模分层频域组件的范式，并引入连续潜在表征以保持动作空间的平滑性和连续性。

Result: 在多种2D和3D机器人操作基准测试中，该方法在精度和效率上均优于现有方法。

Conclusion: 频域自回归框架结合连续表征在通用机器人操作中具有潜力。

Abstract: Learning effective visuomotor policies for robotic manipulation is
challenging, as it requires generating precise actions while maintaining
computational efficiency. Existing methods remain unsatisfactory due to
inherent limitations in the essential action representation and the basic
network architectures. We observe that representing actions in the frequency
domain captures the structured nature of motion more effectively: low-frequency
components reflect global movement patterns, while high-frequency components
encode fine local details. Additionally, robotic manipulation tasks of varying
complexity demand different levels of modeling precision across these frequency
bands. Motivated by this, we propose a novel paradigm for visuomotor policy
learning that progressively models hierarchical frequency components. To
further enhance precision, we introduce continuous latent representations that
maintain smoothness and continuity in the action space. Extensive experiments
across diverse 2D and 3D robotic manipulation benchmarks demonstrate that our
approach outperforms existing methods in both accuracy and efficiency,
showcasing the potential of a frequency-domain autoregressive framework with
continuous tokens for generalized robotic manipulation.

</details>


### [491] [WoMAP: World Models For Embodied Open-Vocabulary Object Localization](https://arxiv.org/abs/2506.01600)
*Tenny Yin,Zhiting Mei,Tao Sun,Lihan Zha,Emily Zhou,Jeremy Bao,Miyu Yamane,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.RO

TL;DR: WoMAP是一种用于训练开放词汇对象定位策略的方法，通过高斯点云生成数据、开放词汇检测器提取奖励信号，并结合潜在世界模型实现高效探索。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在泛化性和物理动作生成上的不足，如模仿学习方法泛化能力差，视觉语言模型无法生成物理动作。

Method: 使用高斯点云实现真实到仿真再到真实的数据生成，从开放词汇检测器提取密集奖励信号，利用潜在世界模型预测动态和奖励。

Result: 在零样本对象定位任务中表现优异，成功率比基线方法高9倍和2倍，并在TidyBot上实现强泛化和仿真到真实的迁移。

Conclusion: WoMAP通过创新的数据生成和奖励提取方法，显著提升了对象定位的性能和泛化能力。

Abstract: Language-instructed active object localization is a critical challenge for
robots, requiring efficient exploration of partially observable environments.
However, state-of-the-art approaches either struggle to generalize beyond
demonstration datasets (e.g., imitation learning methods) or fail to generate
physically grounded actions (e.g., VLMs). To address these limitations, we
introduce WoMAP (World Models for Active Perception): a recipe for training
open-vocabulary object localization policies that: (i) uses a Gaussian
Splatting-based real-to-sim-to-real pipeline for scalable data generation
without the need for expert demonstrations, (ii) distills dense rewards signals
from open-vocabulary object detectors, and (iii) leverages a latent world model
for dynamics and rewards prediction to ground high-level action proposals at
inference time. Rigorous simulation and hardware experiments demonstrate
WoMAP's superior performance in a broad range of zero-shot object localization
tasks, with more than 9x and 2x higher success rates compared to VLM and
diffusion policy baselines, respectively. Further, we show that WoMAP achieves
strong generalization and sim-to-real transfer on a TidyBot.

</details>


### [492] [Feel the Force: Contact-Driven Learning from Humans](https://arxiv.org/abs/2506.01944)
*Ademi Adeniji,Zhuoran Chen,Vincent Liu,Venkatesh Pattabiraman,Raunaq Bhirangi,Siddhant Haldar,Pieter Abbeel,Lerrel Pinto*

Main category: cs.RO

TL;DR: 论文提出了一种名为FeelTheForce（FTF）的机器人学习系统，通过模拟人类触觉行为来学习对力敏感的操控。


<details>
  <summary>Details</summary>
Motivation: 机器人从人类演示中学习操控技能具有可扩展性，但仅凭视觉演示无法推断精确的接触力。

Method: 使用触觉手套测量接触力，结合视觉模型估计手部姿态，训练闭环策略预测操控所需的力，并将其迁移到机器人上。

Result: 在5个对力敏感的操控任务中，成功率达到77%。

Conclusion: FTF通过结合人类监督和触觉数据，实现了精确的低级力控制。

Abstract: Controlling fine-grained forces during manipulation remains a core challenge
in robotics. While robot policies learned from robot-collected data or
simulation show promise, they struggle to generalize across the diverse range
of real-world interactions. Learning directly from humans offers a scalable
solution, enabling demonstrators to perform skills in their natural embodiment
and in everyday environments. However, visual demonstrations alone lack the
information needed to infer precise contact forces. We present FeelTheForce
(FTF): a robot learning system that models human tactile behavior to learn
force-sensitive manipulation. Using a tactile glove to measure contact forces
and a vision-based model to estimate hand pose, we train a closed-loop policy
that continuously predicts the forces needed for manipulation. This policy is
re-targeted to a Franka Panda robot with tactile gripper sensors using shared
visual and action representations. At execution, a PD controller modulates
gripper closure to track predicted forces-enabling precise, force-aware
control. Our approach grounds robust low-level force control in scalable human
supervision, achieving a 77% success rate across 5 force-sensitive manipulation
tasks. Code and videos are available at https://feel-the-force-ftf.github.io.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [493] [Recover Experimental Data with Selection Bias using Counterfactual Logic](https://arxiv.org/abs/2506.00335)
*Jingyang He,Shuai Wang,Ang Li*

Main category: stat.ME

TL;DR: 论文提出了一种在存在选择偏差的情况下，利用实验数据恢复无偏因果效应的方法，并通过结构因果模型和图形化标准验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 选择偏差会严重影响因果推断的有效性，现有方法依赖观测数据且复杂度高，限制了实际应用。本文旨在解决这一问题。

Method: 通过结构因果模型构建反事实世界，分析选择机制在反事实域的传播，并提出图形化和理论化标准。

Result: 推导出实验分布不受选择偏差影响的完整标准，并提出利用部分无偏观测数据恢复因果效应的方法。

Conclusion: 模拟实验验证了方法的实用性，为实际因果推断中减轻选择偏差提供了具体指导。

Abstract: Selection bias, arising from the systematic inclusion or exclusion of certain
samples, poses a significant challenge to the validity of causal inference.
While Bareinboim et al. introduced methods for recovering unbiased
observational and interventional distributions from biased data using partial
external information, the complexity of the backdoor adjustment and the
method's strong reliance on observational data limit its applicability in many
practical settings. In this paper, we formally discover the recoverability of
$P(Y^*_{x^*})$ under selection bias with experimental data. By explicitly
constructing counterfactual worlds via Structural Causal Models (SCMs), we
analyze how selection mechanisms in the observational world propagate to the
counterfactual domain. We derive a complete set of graphical and theoretical
criteria to determine that the experimental distribution remain unaffected by
selection bias. Furthermore, we propose principled methods for leveraging
partially unbiased observational data to recover $P(Y^*_{x^*})$ from biased
experimental datasets. Simulation studies replicating realistic research
scenarios demonstrate the practical utility of our approach, offering concrete
guidance for mitigating selection bias in applied causal inference.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [494] [$\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time](https://arxiv.org/abs/2506.00358)
*Sarthak Kumar Maharana,Saksham Singh Kushwaha,Baoming Zhang,Adrian Rodriguez,Songtao Wei,Yapeng Tian,Yunhui Guo*

Main category: cs.SD

TL;DR: 论文提出了一个名为AVROBUSTBENCH的基准测试，用于评估音频-视觉模型在测试时的鲁棒性，并发现现有模型在双模态损坏下性能下降。


<details>
  <summary>Details</summary>
Motivation: 现实场景中音频和视觉模态可能同时发生分布偏移，而现有基准测试主要关注单模态，无法全面评估音频-视觉模型的鲁棒性。

Method: 设计了包含四个数据集（AUDIOSET-2C、VGGSOUND-2C、KINETICS-2C和EPICKITCHENS-2C）的AVROBUSTBENCH，每个数据集包含75种双模态损坏。

Result: 实验表明，现有音频-视觉模型在损坏严重性增加时鲁棒性下降，且在线测试时适应方法（TTA）对双模态损坏改进有限。

Conclusion: AVROBUSTBENCH有助于推动更有效的音频-视觉TTA方法的发展，并提出了AV2C方法，在VGGSOUND-2C上表现有所提升。

Abstract: While recent audio-visual models have demonstrated impressive performance,
their robustness to distributional shifts at test-time remains not fully
understood. Existing robustness benchmarks mainly focus on single modalities,
making them insufficient for thoroughly assessing the robustness of
audio-visual models. Motivated by real-world scenarios where shifts can occur
$\textit{simultaneously}$ in both audio and visual modalities, we introduce
$\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the
test-time robustness of audio-visual recognition models.
$\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets,
$\texttt{AUDIOSET-2C}$, $\texttt{VGGSOUND-2C}$, $\texttt{KINETICS-2C}$, and
$\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual
corruptions that are $\textit{co-occurring}$ and $\textit{correlated}$. Through
extensive evaluations, we observe that state-of-the-art supervised and
self-supervised audio-visual models exhibit declining robustness as corruption
severity increases. Furthermore, online test-time adaptation (TTA) methods, on
$\texttt{VGGSOUND-2C}$ and $\texttt{KINETICS-2C}$, offer minimal improvements
in performance under bimodal corruptions. We further propose $\texttt{AV2C}$, a
simple TTA approach enabling on-the-fly cross-modal fusion by penalizing
high-entropy samples, which achieves improvements on $\texttt{VGGSOUND-2C}$. We
hope that $\texttt{AVROBUSTBENCH}$ will steer the development of more effective
and robust audio-visual TTA approaches. Our code is available
$\href{https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark}{here}$.

</details>


### [495] [MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity Reconstruction and Generation](https://arxiv.org/abs/2506.00385)
*Yakun Song,Jiawei Chen,Xiaobin Zhuang,Chenpeng Du,Ziyang Ma,Jian Wu,Jian Cong,Dongya Jia,Zhuo Chen,Yuping Wang,Yuxuan Wang,Xie Chen*

Main category: cs.SD

TL;DR: MagiCodec是一种新型的基于Transformer的音频编解码器，通过多阶段训练管道（包括高斯噪声注入和潜在正则化）优化语义表达和重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有音频编解码器主要优化重建质量，但牺牲了下游任务中编码令牌的模型化能力。MagiCodec旨在解决这一问题。

Method: 采用单层流式Transformer架构，结合高斯噪声注入和潜在正则化的多阶段训练方法。

Result: MagiCodec在重建质量和下游任务中均优于现有技术，生成的令牌具有类似自然语言的Zipf分布。

Conclusion: MagiCodec通过噪声注入和正则化显著提升了语义表达和重建质量，适用于基于语言模型的生成架构。

Abstract: Neural audio codecs have made significant strides in efficiently mapping raw
audio waveforms into discrete token representations, which are foundational for
contemporary audio generative models. However, most existing codecs are
optimized primarily for reconstruction quality, often at the expense of the
downstream modelability of the encoded tokens. Motivated by the need to
overcome this bottleneck, we introduce $\textbf{MagiCodec}$, a novel
single-layer, streaming Transformer-based audio codec. MagiCodec is designed
with a multistage training pipeline that incorporates Gaussian noise injection
and latent regularization, explicitly targeting the enhancement of semantic
expressiveness in the generated codes while preserving high reconstruction
fidelity. We analytically derive the effect of noise injection in the frequency
domain, demonstrating its efficacy in attenuating high-frequency components and
fostering robust tokenization. Extensive experimental evaluations show that
MagiCodec surpasses state-of-the-art codecs in both reconstruction quality and
downstream tasks. Notably, the tokens produced by MagiCodec exhibit Zipf-like
distributions, as observed in natural languages, thereby improving
compatibility with language-model-based generative architectures. The code and
pre-trained models are available at https://github.com/Ereboas/MagiCodec.

</details>


### [496] [XMAD-Bench: Cross-Domain Multilingual Audio Deepfake Benchmark](https://arxiv.org/abs/2506.00462)
*Ioan-Paul Ciobanu,Andrei-Iulian Hiji,Nicolae-Catalin Ristea,Paul Irofti,Cristian Rusu,Radu Tudor Ionescu*

Main category: cs.SD

TL;DR: 论文提出了XMAD-Bench，一个跨域多语言音频深度伪造基准测试，揭示了现有检测器在跨域场景下性能显著下降的问题。


<details>
  <summary>Details</summary>
Motivation: 音频深度伪造技术快速发展，导致公众面临金融诈骗、身份盗窃等风险。现有检测器在相同生成模型下表现优异，但在跨域场景中效果不佳。

Method: 引入XMAD-Bench基准测试，包含668.8小时的真实和伪造语音，训练集和测试集在说话者、生成方法和音频来源上完全独立。

Result: 实验显示，检测器在域内性能接近100%，但在跨域场景下性能可能接近随机猜测。

Conclusion: 研究强调了开发具有跨语言、说话者和生成方法泛化能力的鲁棒音频深度伪造检测器的必要性。

Abstract: Recent advances in audio generation led to an increasing number of deepfakes,
making the general public more vulnerable to financial scams, identity theft,
and misinformation. Audio deepfake detectors promise to alleviate this issue,
with many recent studies reporting accuracy rates close to 99%. However, these
methods are typically tested in an in-domain setup, where the deepfake samples
from the training and test sets are produced by the same generative models. To
this end, we introduce XMAD-Bench, a large-scale cross-domain multilingual
audio deepfake benchmark comprising 668.8 hours of real and deepfake speech. In
our novel dataset, the speakers, the generative methods, and the real audio
sources are distinct across training and test splits. This leads to a
challenging cross-domain evaluation setup, where audio deepfake detectors can
be tested ``in the wild''. Our in-domain and cross-domain experiments indicate
a clear disparity between the in-domain performance of deepfake detectors,
which is usually as high as 100%, and the cross-domain performance of the same
models, which is sometimes similar to random chance. Our benchmark highlights
the need for the development of robust audio deepfake detectors, which maintain
their generalization capacity across different languages, speakers, generative
methods, and data sources. Our benchmark is publicly released at
https://github.com/ristea/xmad-bench/.

</details>


### [497] [Probing Audio-Generation Capabilities of Text-Based Language Models](https://arxiv.org/abs/2506.00003)
*Arjun Prasaath Anbazhagan,Parteek Kumar,Ujjwal Kaur,Aslihan Akalin,Kevin Zhu,Sean O'Brien*

Main category: cs.SD

TL;DR: 研究探讨了大型语言模型（LLMs）如何通过文本表示生成音频，发现其能力随音频复杂度增加而下降。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs能否通过文本数据生成音频，尽管其主要训练基于文本。

Method: 采用三阶段方法（音符、环境音、人声），通过代码作为中介生成音频，并用FAD和CLAP评分评估质量。

Result: LLMs能生成基本音频，但性能随复杂度增加而下降。

Conclusion: LLMs对音频世界有潜在理解，但生成能力有限，需进一步研究提升质量与多样性。

Abstract: How does textual representation of audio relate to the Large Language Model's
(LLMs) learning about the audio world? This research investigates the extent to
which LLMs can be prompted to generate audio, despite their primary training in
textual data. We employ a three-tier approach, progressively increasing the
complexity of audio generation: 1) Musical Notes, 2) Environmental Sounds, and
3) Human Speech. To bridge the gap between text and audio, we leverage code as
an intermediary, prompting LLMs to generate code that, when executed, produces
the desired audio output. To evaluate the quality and accuracy of the generated
audio, we employ FAD and CLAP scores. Our findings reveal that while LLMs can
generate basic audio features, their performance deteriorates as the complexity
of the audio increases. This suggests that while LLMs possess a latent
understanding of the auditory world, their ability to translate this
understanding into tangible audio output remains rudimentary. Further research
into techniques that can enhance the quality and diversity of LLM-generated
audio can lead to an improvement in the performance of text-based LLMs in
generating audio.

</details>


### [498] [Counterfactual Activation Editing for Post-hoc Prosody and Mispronunciation Correction in TTS Models](https://arxiv.org/abs/2506.00832)
*Kyowoon Lee,Artyom Stitsyuk,Gunu Jho,Inchul Hwang,Jaesik Choi*

Main category: cs.SD

TL;DR: 提出了一种名为Counterfactual Activation Editing的模型无关方法，用于在预训练的TTS模型中通过编辑内部表征实现事后控制和发音纠正。


<details>
  <summary>Details</summary>
Motivation: 现有方法在韵律控制和发音纠正上依赖专用模块或额外训练，限制了事后调整的能力，且传统发音纠正方法在低资源环境下不实用。

Method: 通过编辑预训练TTS模型的内部表征，实现事后韵律控制和发音纠正。

Result: 实验表明，该方法能有效调整韵律特征并纠正发音，同时保持合成质量。

Conclusion: 该方法为无需重新训练的TTS输出推理时优化提供了可能，填补了预训练TTS模型与可编辑语音合成之间的空白。

Abstract: Recent advances in Text-to-Speech (TTS) have significantly improved speech
naturalness, increasing the demand for precise prosody control and
mispronunciation correction. Existing approaches for prosody manipulation often
depend on specialized modules or additional training, limiting their capacity
for post-hoc adjustments. Similarly, traditional mispronunciation correction
relies on grapheme-to-phoneme dictionaries, making it less practical in
low-resource settings. We introduce Counterfactual Activation Editing, a
model-agnostic method that manipulates internal representations in a
pre-trained TTS model to achieve post-hoc control of prosody and pronunciation.
Experimental results show that our method effectively adjusts prosodic features
and corrects mispronunciations while preserving synthesis quality. This opens
the door to inference-time refinement of TTS outputs without retraining,
bridging the gap between pre-trained TTS models and editable speech synthesis.

</details>


### [499] [CoVoMix2: Advancing Zero-Shot Dialogue Generation with Fully Non-Autoregressive Flow Matching](https://arxiv.org/abs/2506.00885)
*Leying Zhang,Yao Qian,Xiaofei Wang,Manthan Thakker,Dongmei Wang,Jianwei Yu,Haibin Wu,Yuxuan Hu,Jinyu Li,Yanmin Qian,Sheng Zhao*

Main category: cs.SD

TL;DR: CoVoMix2是一个非自回归框架，用于零样本多说话人对话生成，通过流匹配生成模型直接预测mel频谱图，支持可控对话生成。


<details>
  <summary>Details</summary>
Motivation: 现有系统在多说话人对话生成中难以保持说话人一致性、模拟重叠语音并高效合成连贯对话，因此需要改进。

Method: 采用流匹配生成模型直接从多流转录预测mel频谱图，引入转录级说话人分离、句子级对齐和提示级随机掩码策略。

Result: CoVoMix2在语音质量、说话人一致性和推理速度上优于MoonCast和Sesame等基线模型。

Conclusion: CoVoMix2无需提示转录即可运行，支持可控对话生成，具有强泛化能力。

Abstract: Generating natural-sounding, multi-speaker dialogue is crucial for
applications such as podcast creation, virtual agents, and multimedia content
generation. However, existing systems struggle to maintain speaker consistency,
model overlapping speech, and synthesize coherent conversations efficiently. In
this paper, we introduce CoVoMix2, a fully non-autoregressive framework for
zero-shot multi-talker dialogue generation. CoVoMix2 directly predicts
mel-spectrograms from multi-stream transcriptions using a flow-matching-based
generative model, eliminating the reliance on intermediate token
representations. To better capture realistic conversational dynamics, we
propose transcription-level speaker disentanglement, sentence-level alignment,
and prompt-level random masking strategies. Our approach achieves
state-of-the-art performance, outperforming strong baselines like MoonCast and
Sesame in speech quality, speaker consistency, and inference speed. Notably,
CoVoMix2 operates without requiring transcriptions for the prompt and supports
controllable dialogue generation, including overlapping speech and precise
timing control, demonstrating strong generalizability to real-world speech
generation scenarios.

</details>


### [500] [In-the-wild Audio Spatialization with Flexible Text-guided Localization](https://arxiv.org/abs/2506.00927)
*Tianrui Pan,Jie Liu,Zewen Huang,Jie Tang,Gangshan Wu*

Main category: cs.SD

TL;DR: 提出了一种基于文本提示的音频空间化框架（TAS），通过构建大规模数据集和评估模型，实现了高质量和语义一致的音频生成。


<details>
  <summary>Details</summary>
Motivation: 现有音频空间化方法在复杂交互环境中缺乏灵活控制，需改进以支持多对象交互。

Method: 利用文本提示和3D空间位置引导，结合翻转声道音频训练模型，并开发基于Llama-3.1-8B的评估模型。

Result: 模型在模拟和真实数据集上表现优异，生成音频质量高且语义一致。

Conclusion: TAS框架通过文本提示实现了灵活交互控制，为音频空间化提供了新方向。

Abstract: To enhance immersive experiences, binaural audio offers spatial awareness of
sounding objects in AR, VR, and embodied AI applications. While existing audio
spatialization methods can generally map any available monaural audio to
binaural audio signals, they often lack the flexible and interactive control
needed in complex multi-object user-interactive environments. To address this,
we propose a Text-guided Audio Spatialization (TAS) framework that utilizes
flexible text prompts and evaluates our model from unified generation and
comprehension perspectives. Due to the limited availability of premium and
large-scale stereo data, we construct the SpatialTAS dataset, which encompasses
376,000 simulated binaural audio samples to facilitate the training of our
model. Our model learns binaural differences guided by 3D spatial location and
relative position prompts, augmented by flipped-channel audio. It outperforms
existing methods on both simulated and real-recorded datasets, demonstrating
superior generalization and accuracy. Besides, we develop an assessment model
based on Llama-3.1-8B, which evaluates the spatial semantic coherence between
our generated binaural audio and text prompts through a spatial reasoning task.
Results demonstrate that text prompts provide flexible and interactive control
to generate binaural audio with excellent quality and semantic consistency in
spatial locations. Dataset is available at
\href{https://github.com/Alice01010101/TASU}

</details>


### [501] [General-purpose audio representation learning for real-world sound scenes](https://arxiv.org/abs/2506.00934)
*Goksenin Yuksel,Marcel van Gerven,Kiki van der Heijden*

Main category: cs.SD

TL;DR: 提出了一种自监督训练方法GRAM，用于提升音频基础模型在真实世界场景中的表现，尤其在空间音频表示学习上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音频基础模型在干燥、非空间、单源音频上表现良好，但在真实场景中表现受限，缺乏空间感知能力。

Method: 提出GRAM自监督训练方法，适用于任何基于掩码的深度学习模型，并测试了基于Transformer和Mamba的两种模型。

Result: GRAM在自然声音场景和空间音频任务中表现优异，缩小了与干燥音频场景的性能差距，并在声音定位任务中超越现有监督模型。

Conclusion: GRAM是迈向真实世界音频基础模型的重要进展，在自然声音场景和空间音频学习上达到最先进水平。

Abstract: While audio foundation models perform well on myriad of tasks from sound
classification to speech analysis, these models are trained and tested on dry,
non-spatial, single-source audio clips. This limits their success in real-world
situations and results in spatially unaware audio embeddings. To address these
limitations, we propose a novel self-supervised training approach for
General-Purpose, Real-world Audio Models (GRAMs). The GRAM training approach
enables robust spatial audio representation learning for naturalistic, noisy
sound scenes and can be applied to any masking-based deep learning model. We
demonstrate the success of our approach by training two state-of-the-art
models, one with a transformer and one with a mamba backbone. We assess the
quality of the extracted audio representations from GRAMs using the original
version of the HEAR benchmark, a newly synthesized, naturalistic version of the
HEAR benchmark, and novel sound localization tasks based on HEAR benchmark
datasets. The results show that our approach minimizes the performance gap
between dry, non-spatial, single-source sound scenes and naturalistic sound
scenes for crucial tasks such as auditory scene analysis, outperforming
existing state-of-the-art audio foundation models at a fraction of the training
steps. Moreover, GRAMs show state-of-the-art performance on sound localization
tasks, exceeding even supervised sound localization models. In sum, the
proposed approach represents a significant advancement towards robust audio
foundation models for real-world applications with state-of-the-art performance
on naturalistic sound scenes as well as spatial audio representation learning.

</details>


### [502] [A Two-Stage Hierarchical Deep Filtering Framework for Real-Time Speech Enhancement](https://arxiv.org/abs/2506.01023)
*Shenghui Lu,Hukai Huang,Jinanglong Yao,Kaidi Wang,Qingyang Hong,Lin Li*

Main category: cs.SD

TL;DR: 提出了一种结合子带处理和深度滤波的模型（HDF-Net），通过利用目标时频（TF）点及其周围信息提升单通道语音增强效果。


<details>
  <summary>Details</summary>
Motivation: 充分利用目标TF点及其周围信息以提升语音增强性能。

Method: 结合子带模块和深度滤波模块，分阶段解耦滤波，并引入TAConv模块增强特征提取。

Result: HDF-Net在减少资源使用的同时，性能优于其他先进系统。

Conclusion: HDF-Net通过分层深度滤波有效利用周围TF信息，实现了高效且高性能的语音增强。

Abstract: This paper proposes a model that integrates sub-band processing and deep
filtering to fully exploit information from the target time-frequency (TF) bin
and its surrounding TF bins for single-channel speech enhancement. The sub-band
module captures surrounding frequency bin information at the input, while the
deep filtering module applies filtering at the output to both the target TF bin
and its surrounding TF bins. To further improve the model performance, we
decouple deep filtering into temporal and frequency components and introduce a
two-stage framework, reducing the complexity of filter coefficient prediction
at each stage. Additionally, we propose the TAConv module to strengthen
convolutional feature extraction. Experimental results demonstrate that the
proposed hierarchical deep filtering network (HDF-Net) effectively utilizes
surrounding TF bin information and outperforms other advanced systems while
using fewer resources.

</details>


### [503] [Attention Is Not Always the Answer: Optimizing Voice Activity Detection with Simple Feature Fusion](https://arxiv.org/abs/2506.01365)
*Kumud Tripathi,Chowdam Venkata Kumar,Pankaj Wasnik*

Main category: cs.SD

TL;DR: FusionVAD框架结合MFCC和预训练模型特征，通过简单融合策略（如加法）在语音活动检测中优于复杂方法（如交叉注意力），性能超越当前最优模型。


<details>
  <summary>Details</summary>
Motivation: 研究MFCC和预训练模型特征在语音活动检测中的有效性，探索融合策略以提升性能。

Method: 提出FusionVAD框架，采用三种融合策略（拼接、加法、交叉注意力）结合MFCC和预训练模型特征。

Result: 简单融合（加法）优于复杂方法，融合模型性能超越单特征模型和当前最优模型（Pyannote），平均提升2.04%。

Conclusion: 简单特征融合能增强语音活动检测的鲁棒性，同时保持计算效率。

Abstract: Voice Activity Detection (VAD) plays a key role in speech processing, often
utilizing hand-crafted or neural features. This study examines the
effectiveness of Mel-Frequency Cepstral Coefficients (MFCCs) and pre-trained
model (PTM) features, including wav2vec 2.0, HuBERT, WavLM, UniSpeech, MMS, and
Whisper. We propose FusionVAD, a unified framework that combines both feature
types using three fusion strategies: concatenation, addition, and
cross-attention (CA). Experimental results reveal that simple fusion
techniques, particularly addition, outperform CA in both accuracy and
efficiency. Fusion-based models consistently surpass single-feature models,
highlighting the complementary nature of MFCCs and PTM features. Notably, our
best-performing fusion model exceeds the state-of-the-art Pyannote across
multiple datasets, achieving an absolute average improvement of 2.04%. These
results confirm that simple feature fusion enhances VAD robustness while
maintaining computational efficiency.

</details>


### [504] [FusionAudio-1.2M: Towards Fine-grained Audio Captioning with Multimodal Contextual Fusion](https://arxiv.org/abs/2506.01111)
*Shunian Chen,Xinyuan Xie,Zheshu Chen,Liyan Zhao,Owen Lee,Zhan Su,Qilin Sun,Benyou Wang*

Main category: cs.SD

TL;DR: 提出了一种两阶段自动化流程，结合多模态信息生成细粒度的音频字幕，并发布了大规模数据集FusionAudio。


<details>
  <summary>Details</summary>
Motivation: 当前音频字幕方法缺乏细节和上下文准确性，受限于单模态或浅层多模态信息。

Method: 使用预训练模型提取多模态上下文线索，再通过大语言模型合成生成详细字幕。

Result: 提出了可扩展的细粒度音频字幕生成方法，发布了FusionAudio数据集，并改进了音频模型。

Conclusion: 为复杂音频环境的自动化理解提供了更细致和准确的方法。

Abstract: High-quality, large-scale audio captioning is crucial for advancing audio
understanding, yet current automated methods often generate captions that lack
fine-grained detail and contextual accuracy, primarily due to their reliance on
limited unimodal or superficial multimodal information. Drawing inspiration
from human auditory perception, which adeptly integrates cross-modal cues and
performs sophisticated auditory scene analysis, we introduce a novel two-stage
automated pipeline. This pipeline first employs specialized pretrained models
to extract diverse contextual cues (e.g., speech, music, general sounds, and
visual information from associated video). A large language model (LLM) then
synthesizes these rich, multimodal inputs to generate detailed and
context-aware audio captions. Key contributions of this work include: (1) the
proposed scalable method for fine-grained audio caption generation; (2)
FusionAudio, a new large-scale dataset comprising 1.2 million such detailed
captions, combined with 6 million QA pairs; and (3) enhanced audio models
developed using FusionAudio, specifically a CLAP-based audio encoder with
superior audio-text alignment and instruction following. This paper paves the
way for more nuanced and accurate automated understanding of complex audio
environments. Code and data can be found in
https://github.com/satsuki2486441738/FusionAudio.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [505] [Synthesis of discrete-continuous quantum circuits with multimodal diffusion models](https://arxiv.org/abs/2506.01666)
*Florian Fürrutter,Zohim Chandani,Ikko Hamamura,Hans J. Briegel,Gorka Muñoz-Gil*

Main category: quant-ph

TL;DR: 论文提出了一种多模态去噪扩散模型，用于高效编译量子操作，解决了现有方法运行时间长、依赖硬件的问题。


<details>
  <summary>Details</summary>
Motivation: 当前量子操作编译方法效率低、成本高，限制了量子计算的扩展。机器学习模型虽为替代方案，但受限于离散门集。

Method: 采用多模态去噪扩散模型，同时生成电路结构和连续参数，利用两个独立的扩散过程分别处理离散门选择和参数预测。

Result: 模型在不同量子比特数、电路深度和参数化门比例下表现出高准确性，并能快速生成电路数据集。

Conclusion: 该方法为量子电路合成提供了新思路，并有助于提取启发式规则以优化量子编译。

Abstract: Efficiently compiling quantum operations remains a major bottleneck in
scaling quantum computing. Today's state-of-the-art methods achieve low
compilation error by combining search algorithms with gradient-based parameter
optimization, but they incur long runtimes and require multiple calls to
quantum hardware or expensive classical simulations, making their scaling
prohibitive. Recently, machine-learning models have emerged as an alternative,
though they are currently restricted to discrete gate sets. Here, we introduce
a multimodal denoising diffusion model that simultaneously generates a
circuit's structure and its continuous parameters for compiling a target
unitary. It leverages two independent diffusion processes, one for discrete
gate selection and one for parameter prediction. We benchmark the model over
different experiments, analyzing the method's accuracy across varying qubit
counts, circuit depths, and proportions of parameterized gates. Finally, by
exploiting its rapid circuit generation, we create large datasets of circuits
for particular operations and use these to extract valuable heuristics that can
help us discover new insights into quantum circuit synthesis.

</details>


### [506] [A Quantum Information Theoretic Approach to Tractable Probabilistic Models](https://arxiv.org/abs/2506.01824)
*Pedro Zuidberg Dos Martires*

Main category: quant-ph

TL;DR: 论文提出了一种基于量子信息理论的概率电路扩展——正单位电路（PUnCs），将概率电路的正实值概率评估推广到半正定矩阵评估。


<details>
  <summary>Details</summary>
Motivation: 研究概率电路在量子信息理论框架下的扩展，以增强其表达能力并统一现有电路模型。

Method: 通过递归嵌套求和与乘积，将概率电路的正实值概率评估推广到半正定矩阵评估，提出正单位电路（PUnCs）。

Result: PUnCs严格推广了概率电路和PSD电路等现有电路模型。

Conclusion: PUnCs为概率电路提供了更广泛的框架，并统一了多种电路模型。

Abstract: By recursively nesting sums and products, probabilistic circuits have emerged
in recent years as an attractive class of generative models as they enjoy, for
instance, polytime marginalization of random variables. In this work we study
these machine learning models using the framework of quantum information
theory, leading to the introduction of positive unital circuits (PUnCs), which
generalize circuit evaluations over positive real-valued probabilities to
circuit evaluations over positive semi-definite matrices. As a consequence,
PUnCs strictly generalize probabilistic circuits as well as recently introduced
circuit classes such as PSD circuits.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [507] [Overcoming Data Scarcity in Scanning Tunnelling Microscopy Image Segmentation](https://arxiv.org/abs/2506.01678)
*Nikola L. Kolev,Max Trouton,Filippo Federici Canova,Geoff Thornton,David Z. Gao,Neil J. Curson,Taylor J. Z. Stock*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种结合少样本学习和无监督学习的自动化STM图像分割方法，减少了对大量标注数据的需求，并在多种表面上展示了高准确性和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: STM图像分析中手动标注特征耗时费力，需要一种更灵活且高效的自动化方法。

Method: 结合少样本学习和无监督学习，减少对标注数据的依赖，适应新表面时仅需少量额外标注。

Result: 在Si(001)、Ge(001)和TiO2(110)等表面上成功识别原子特征，展示了高准确性和泛化能力。

Conclusion: 该方法为高效且材料无关的STM图像自动分割迈出了重要一步。

Abstract: Scanning tunnelling microscopy (STM) is a powerful technique for imaging
surfaces with atomic resolution, providing insight into physical and chemical
processes at the level of single atoms and molecules. A regular task of STM
image analysis is the identification and labelling of features of interest
against a uniform background. Performing this manually is a labour-intensive
task, requiring significant human effort. To reduce this burden, we propose an
automated approach to the segmentation of STM images that uses both few-shot
learning and unsupervised learning. Our technique offers greater flexibility
compared to previous supervised methods; it removes the requirement for large
manually annotated datasets and is thus easier to adapt to an unseen surface
while still maintaining a high accuracy. We demonstrate the effectiveness of
our approach by using it to recognise atomic features on three distinct
surfaces: Si(001), Ge(001), and TiO$_2$(110), including adsorbed AsH$_3$
molecules on the silicon and germanium surfaces. Our model exhibits strong
generalisation capabilities, and following initial training, can be adapted to
unseen surfaces with as few as one additional labelled data point. This work is
a significant step towards efficient and material-agnostic, automatic
segmentation of STM images.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [508] [Heterogeneous Graph Backdoor Attack](https://arxiv.org/abs/2506.00191)
*Jiawei Chen,Lusi Li,Daniel Takabi,Masha Sosonkina,Rui Ning*

Main category: cs.CR

TL;DR: 本文首次研究了异构图神经网络（HGNNs）对后门攻击的脆弱性，提出了HGBA攻击方法，通过关系型触发器实现高效隐蔽的后门注入，并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 异构图神经网络在多领域建模复杂关系方面表现出色，但其对后门攻击的脆弱性尚未被探索。

Method: 提出HGBA攻击方法，采用关系型触发器，通过后门元路径连接触发节点与污染节点，支持两种灵活的攻击策略。

Result: HGBA在低攻击预算下高效攻击HGNNs，优于现有方法，并对防御机制表现出强鲁棒性。

Conclusion: HGBA不仅威胁HGNNs，还可扩展到同构图任务，对安全关键领域构成严重威胁。

Abstract: Heterogeneous Graph Neural Networks (HGNNs) excel in modeling complex,
multi-typed relationships across diverse domains, yet their vulnerability to
backdoor attacks remains unexplored. To address this gap, we conduct the first
investigation into the susceptibility of HGNNs to existing graph backdoor
attacks, revealing three critical issues: (1) high attack budget required for
effective backdoor injection, (2) inefficient and unreliable backdoor
activation, and (3) inaccurate attack effectiveness evaluation. To tackle these
issues, we propose the Heterogeneous Graph Backdoor Attack (HGBA), the first
backdoor attack specifically designed for HGNNs, introducing a novel
relation-based trigger mechanism that establishes specific connections between
a strategically selected trigger node and poisoned nodes via the backdoor
metapath. HGBA achieves efficient and stealthy backdoor injection with minimal
structural modifications and supports easy backdoor activation through two
flexible strategies: Self-Node Attack and Indiscriminate Attack. Additionally,
we improve the ASR measurement protocol, enabling a more accurate assessment of
attack effectiveness. Extensive experiments demonstrate that HGBA far surpasses
multiple state-of-the-art graph backdoor attacks in black-box settings,
efficiently attacking HGNNs with low attack budgets. Ablation studies show that
the strength of HBGA benefits from our trigger node selection method and
backdoor metapath selection strategy. In addition, HGBA shows superior
robustness against node feature perturbations and multiple types of existing
graph backdoor defense mechanisms. Finally, extension experiments demonstrate
that the relation-based trigger mechanism can effectively extend to tasks in
homogeneous graph scenarios, thereby posing severe threats to broader
security-critical domains.

</details>


### [509] [Chances and Challenges of the Model Context Protocol in Digital Forensics and Incident Response](https://arxiv.org/abs/2506.00274)
*Jan-Niclas Hilgert,Carlo Jakobs,Michael Külper,Martin Lambertz,Axel Mahr,Elmar Padilla*

Main category: cs.CR

TL;DR: 本文探讨了模型上下文协议（MCP）如何解决大语言模型（LLMs）在数字取证中的透明度、可解释性和可重复性问题，并展示了其广泛应用潜力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数字取证中具有潜力，但缺乏透明度、可解释性和可重复性阻碍了其广泛应用。

Method: 通过理论分析，研究MCP如何整合到多种取证场景中，并探讨其技术和概念部署。

Result: MCP不仅能增强现有取证流程，还能扩展LLMs的应用范围，同时通过推理约束级别提升可审计性和可追溯性。

Conclusion: MCP作为LLM辅助取证的基础组件潜力巨大，但也面临未来挑战。

Abstract: Large language models hold considerable promise for supporting forensic
investigations, but their widespread adoption is hindered by a lack of
transparency, explainability, and reproducibility. This paper explores how the
emerging Model Context Protocol can address these challenges and support the
meaningful use of LLMs in digital forensics. Through a theoretical analysis, we
examine how MCP can be integrated across various forensic scenarios - ranging
from artifact analysis to the generation of interpretable reports. We also
outline both technical and conceptual considerations for deploying an MCP
server in forensic environments. Our analysis reveals a wide range of use cases
in which MCP not only strengthens existing forensic workflows but also
facilitates the application of LLMs to areas of forensics where their use was
previously limited. Furthermore, we introduce the concept of the inference
constraint level - a way of characterizing how specific MCP design choices can
deliberately constrain model behavior, thereby enhancing both auditability and
traceability. Our insights demonstrate that MCP has significant potential as a
foundational component for developing LLM-assisted forensic workflows that are
not only more transparent, reproducible, and legally defensible, but also
represent a step toward increased automation in digital forensic analysis.
However, we also highlight potential challenges that the adoption of MCP may
pose for digital forensics in the future.

</details>


### [510] [Adversarial Threat Vectors and Risk Mitigation for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2506.00281)
*Chris M. Ward,Josh Harguess*

Main category: cs.CR

TL;DR: 本文分析了检索增强生成（RAG）系统的安全漏洞，提出了针对提示注入、数据污染和对抗性查询操纵的防御措施。


<details>
  <summary>Details</summary>
Motivation: RAG系统在行业中的广泛应用使其成为攻击目标，研究其安全威胁至关重要。

Method: 通过风险管理的视角分析威胁，并提出包括输入验证、对抗训练和实时监控的优先控制清单。

Result: 识别了RAG系统的主要攻击向量，并提出了相应的风险缓解措施。

Conclusion: RAG系统的安全性需通过多层次的防御策略来保障，以应对日益复杂的攻击手段。

Abstract: Retrieval-Augmented Generation (RAG) systems, which integrate Large Language
Models (LLMs) with external knowledge sources, are vulnerable to a range of
adversarial attack vectors. This paper examines the importance of RAG systems
through recent industry adoption trends and identifies the prominent attack
vectors for RAG: prompt injection, data poisoning, and adversarial query
manipulation. We analyze these threats under risk management lens, and propose
robust prioritized control list that includes risk-mitigating actions like
input validation, adversarial training, and real-time monitoring.

</details>


### [511] [dpmm: Differentially Private Marginal Models, a Library for Synthetic Tabular Data Generation](https://arxiv.org/abs/2506.00322)
*Sofiane Mahiou,Amir Dizche,Reza Nazari,Xinmin Wu,Ralph Abbey,Jorge Silva,Georgi Ganev*

Main category: cs.CR

TL;DR: dpmm是一个开源库，用于生成具有差分隐私（DP）保证的合成数据，包含三种流行的边际模型，提供高实用性和丰富功能。


<details>
  <summary>Details</summary>
Motivation: 目标是满足广泛用户需求，提供易于安装、高度可定制且鲁棒的模型实现，同时确保端到端的DP保证。

Method: 采用三种边际模型（PrivBayes、MST和AIM），并应用最佳实践以确保DP安全性。

Result: dpmm在实用性和功能丰富性上优于其他实现，同时解决了已知的DP漏洞。

Conclusion: dpmm是一个功能强大且安全的合成数据生成工具，适合广泛用户使用。

Abstract: We propose dpmm, an open-source library for synthetic data generation with
Differentially Private (DP) guarantees. It includes three popular marginal
models -- PrivBayes, MST, and AIM -- that achieve superior utility and offer
richer functionality compared to alternative implementations. Additionally, we
adopt best practices to provide end-to-end DP guarantees and address well-known
DP-related vulnerabilities. Our goal is to accommodate a wide audience with
easy-to-install, highly customizable, and robust model implementations.
  Our codebase is available from https://github.com/sassoftware/dpmm.

</details>


### [512] [The Security Threat of Compressed Projectors in Large Vision-Language Models](https://arxiv.org/abs/2506.00534)
*Yudong Zhang,Ruobing Xie,Xingwu Sun,Jiansheng Chen,Zhanhui Kang,Di Wang,Yu Wang*

Main category: cs.CR

TL;DR: 压缩型视觉语言投影器（VLP）存在显著安全漏洞，而未经压缩的VLP表现出更强的安全性，为选择VLP提供了关键指导。


<details>
  <summary>Details</summary>
Motivation: 研究主流VLP（压缩与未经压缩）的安全影响，填补现有研究空白。

Method: 通过全面评估比较压缩与未经压缩VLP的安全性能。

Result: 压缩型VLP易受攻击，未经压缩型VLP安全性更强。

Conclusion: 研究结果为选择安全可靠的VLP提供了重要依据，代码将公开。

Abstract: The choice of a suitable visual language projector (VLP) is critical to the
successful training of large visual language models (LVLMs). Mainstream VLPs
can be broadly categorized into compressed and uncompressed projectors, and
each offering distinct advantages in performance and computational efficiency.
However, their security implications have not been thoroughly examined. Our
comprehensive evaluation reveals significant differences in their security
profiles: compressed projectors exhibit substantial vulnerabilities, allowing
adversaries to successfully compromise LVLMs even with minimal knowledge of
structural information. In stark contrast, uncompressed projectors demonstrate
robust security properties and do not introduce additional vulnerabilities.
These findings provide critical guidance for researchers in selecting optimal
VLPs that enhance the security and reliability of visual language models. The
code will be released.

</details>


### [513] [SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models](https://arxiv.org/abs/2506.00821)
*Huixin Zhan,Jason H. Moore*

Main category: cs.CR

TL;DR: SafeGenes框架通过对抗攻击评估基因组基础模型的鲁棒性，发现其存在显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 基因组基础模型（如ESM）在变异效应预测中表现优异，但其对抗鲁棒性尚未充分研究。

Method: 采用Fast Gradient Sign Method（FGSM）和软提示攻击两种方法，评估模型对对抗性操作的敏感性。

Result: 软提示攻击导致ESM1b和ESM1v等大型模型性能显著下降。

Conclusion: 研究揭示了当前基础模型的关键漏洞，为提升其在高风险基因组应用中的安全性提供了新方向。

Abstract: Genomic Foundation Models (GFMs), such as Evolutionary Scale Modeling (ESM),
have demonstrated significant success in variant effect prediction. However,
their adversarial robustness remains largely unexplored. To address this gap,
we propose SafeGenes: a framework for Secure analysis of genomic foundation
models, leveraging adversarial attacks to evaluate robustness against both
engineered near-identical adversarial Genes and embedding-space manipulations.
In this study, we assess the adversarial vulnerabilities of GFMs using two
approaches: the Fast Gradient Sign Method (FGSM) and a soft prompt attack. FGSM
introduces minimal perturbations to input sequences, while the soft prompt
attack optimizes continuous embeddings to manipulate model predictions without
modifying the input tokens. By combining these techniques, SafeGenes provides a
comprehensive assessment of GFM susceptibility to adversarial manipulation.
Targeted soft prompt attacks led to substantial performance degradation, even
in large models such as ESM1b and ESM1v. These findings expose critical
vulnerabilities in current foundation models, opening new research directions
toward improving their security and robustness in high-stakes genomic
applications such as variant effect prediction.

</details>


### [514] [A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems](https://arxiv.org/abs/2506.00831)
*M Sabbir Salek,Mashrur Chowdhury,Muhaimin Bin Munir,Yuchen Cai,Mohammad Imtiaz Hasan,Jean-Michel Tine,Latifur Khan,Mizanur Rahman*

Main category: cs.CR

TL;DR: TraCR-TMF是一个基于大语言模型（LLM）的交通网络安全威胁建模框架，减少了对专家干预的依赖，通过三种LLM方法识别威胁、攻击技术和应对措施，并在实际场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有交通CPS威胁建模框架范围有限、资源密集且依赖专家知识，TraCR-TMF旨在填补这些空白。

Method: TraCR-TMF利用MITRE ATT&CK矩阵，通过三种LLM方法（RAG、上下文学习、监督微调）识别威胁和攻击路径，并分析漏洞。

Result: 在两种场景中验证：识别攻击技术（90%精确度）和预测真实网络攻击事件中的多种利用行为。

Conclusion: TraCR-TMF在CPS威胁建模中表现高效，减少了对专业知识的依赖，并具有跨领域适应性。

Abstract: Modern transportation systems rely on cyber-physical systems (CPS), where
cyber systems interact seamlessly with physical systems like
transportation-related sensors and actuators to enhance safety, mobility, and
energy efficiency. However, growing automation and connectivity increase
exposure to cyber vulnerabilities. Existing threat modeling frameworks for
transportation CPS are often limited in scope, resource-intensive, and
dependent on significant cybersecurity expertise. To address these gaps, we
present TraCR-TMF (Transportation Cybersecurity and Resiliency Threat Modeling
Framework), a large language model (LLM)-based framework that minimizes expert
intervention. TraCR-TMF identifies threats, potential attack techniques, and
corresponding countermeasures by leveraging the MITRE ATT&CK matrix through
three LLM-based approaches: (i) a retrieval-augmented generation (RAG) method
requiring no expert input, (ii) an in-context learning approach requiring low
expert input, and (iii) a supervised fine-tuning method requiring moderate
expert input. TraCR-TMF also maps attack paths to critical assets by analyzing
vulnerabilities using a customized LLM. The framework was evaluated in two
scenarios. First, it identified relevant attack techniques across
transportation CPS applications, with 90% precision as validated by experts.
Second, using a fine-tuned LLM, it successfully predicted multiple
exploitations including lateral movement, data exfiltration, and
ransomware-related encryption that occurred during a major real-world
cyberattack incident. These results demonstrate TraCR-TMF's effectiveness in
CPS threat modeling, its reduced reliance on cybersecurity expertise, and its
adaptability across CPS domains.

</details>


### [515] [Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities](https://arxiv.org/abs/2506.00548)
*Jiahui Geng,Thy Thy Tran,Preslav Nakov,Iryna Gurevych*

Main category: cs.CR

TL;DR: 论文提出了一种名为Con Instruction的新型攻击方法，通过对抗性图像或音频绕过多模态语言模型的安全机制，无需训练数据或文本预处理，攻击成功率显著提高。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法主要通过文本和对抗性图像结合，而本研究利用多模态语言模型对非文本指令的理解能力，揭示其潜在的安全隐患。

Method: 优化对抗性示例以在嵌入空间中与目标指令对齐，无需训练数据或文本预处理。提出ARC框架评估攻击效果。

Result: 在多个模型（如LLaVA-v1.5、InternVL等）上实现高攻击成功率（81.3%和86.6%），并发现现有防御技术存在性能差距。

Conclusion: Con Instruction有效揭示了多模态语言模型的安全漏洞，同时为防御研究提供了新方向。

Abstract: Existing attacks against multimodal language models (MLLMs) primarily
communicate instructions through text accompanied by adversarial images. In
contrast, we exploit the capabilities of MLLMs to interpret non-textual
instructions, specifically, adversarial images or audio generated by our novel
method, Con Instruction. We optimize these adversarial examples to align
closely with target instructions in the embedding space, revealing the
detrimental implications of MLLMs' sophisticated understanding. Unlike prior
work, our method does not require training data or preprocessing of textual
instructions. While these non-textual adversarial examples can effectively
bypass MLLM safety mechanisms, their combination with various text inputs
substantially amplifies attack success. We further introduce a new Attack
Response Categorization (ARC) framework, which evaluates both the quality of
the model's response and its relevance to the malicious instructions.
Experimental results demonstrate that Con Instruction effectively bypasses
safety mechanisms in multiple vision- and audio-language models, including
LLaVA-v1.5, InternVL, Qwen-VL, and Qwen-Audio, evaluated on two standard
benchmarks: AdvBench and SafeBench. Specifically, our method achieves the
highest attack success rates, reaching 81.3% and 86.6% on LLaVA-v1.5 (13B). On
the defense side, we explore various countermeasures against our attacks and
uncover a substantial performance gap among existing techniques. Our
implementation is made publicly available.

</details>


### [516] [Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution](https://arxiv.org/abs/2506.01055)
*Meysam Alizadeh,Zeynab Samei,Daria Stetsenko,Fabrizio Gilardi*

Main category: cs.CR

TL;DR: 论文研究了提示注入攻击如何导致工具调用代理泄露任务执行中的个人数据，通过虚构银行代理和AgentDojo基准测试，发现攻击成功率约20%，部分防御措施可降至零。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试对复杂威胁（如数据泄露）的洞察有限，论文旨在填补这一空白。

Method: 使用虚构银行代理开发基于数据流的攻击，并扩展AgentDojo基准测试，创建合成数据集。

Result: 攻击导致LLM效用下降15-50%，平均攻击成功率约20%，部分防御措施有效；密码泄露风险在特定条件下增加。

Conclusion: 任务类型与防御效果密切相关，现有防御措施无法完全防止数据泄露。

Abstract: Previous benchmarks on prompt injection in large language models (LLMs) have
primarily focused on generic tasks and attacks, offering limited insights into
more complex threats like data exfiltration. This paper examines how prompt
injection can cause tool-calling agents to leak personal data observed during
task execution. Using a fictitious banking agent, we develop data flow-based
attacks and integrate them into AgentDojo, a recent benchmark for agentic
security. To enhance its scope, we also create a richer synthetic dataset of
human-AI banking conversations. In 16 user tasks from AgentDojo, LLMs show a
15-50 percentage point drop in utility under attack, with average attack
success rates (ASR) around 20 percent; some defenses reduce ASR to zero. Most
LLMs, even when successfully tricked by the attack, avoid leaking highly
sensitive data like passwords, likely due to safety alignments, but they remain
vulnerable to disclosing other personal data. The likelihood of password
leakage increases when a password is requested along with one or two additional
personal details. In an extended evaluation across 48 tasks, the average ASR is
around 15 percent, with no built-in AgentDojo defense fully preventing leakage.
Tasks involving data extraction or authorization workflows, which closely
resemble the structure of exfiltration attacks, exhibit the highest ASRs,
highlighting the interaction between task type, agent performance, and defense
efficacy.

</details>


### [517] [SPEAR: Security Posture Evaluation using AI Planner-Reasoning on Attack-Connectivity Hypergraphs](https://arxiv.org/abs/2506.01227)
*Rakesh Podder,Turgay Caglar,Shadaab Kawnain Bashir,Sarath Sreedharan,Indrajit Ray,Indrakshi Ray*

Main category: cs.CR

TL;DR: SPEAR是一个基于AI规划的形式化框架，用于网络安全态势评估和分析，支持管理员通过多样化的安全加固策略进行系统化探索和比较。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的网络安全框架在攻击图推理、不完全信息处理、管理员建议的可理解性以及场景分析方面存在不足。

Method: SPEAR利用AI规划的因果形式化建模网络漏洞和配置，自动将网络配置和漏洞描述转换为PDDL规划模型。

Result: SPEAR生成多样化的安全加固策略，并以可理解的方式呈现，支持管理员进行系统化探索和解决方案比较。

Conclusion: SPEAR填补了现有网络安全框架的不足，通过形式化方法和工具支持，实现了高效的安全态势评估和分析。

Abstract: Graph-based frameworks are often used in network hardening to help a cyber
defender understand how a network can be attacked and how the best defenses can
be deployed. However, incorporating network connectivity parameters in the
attack graph, reasoning about the attack graph when we do not have access to
complete information, providing system administrator suggestions in an
understandable format, and allowing them to do what-if analysis on various
scenarios and attacker motives is still missing. We fill this gap by presenting
SPEAR, a formal framework with tool support for security posture evaluation and
analysis that keeps human-in-the-loop. SPEAR uses the causal formalism of AI
planning to model vulnerabilities and configurations in a networked system. It
automatically converts network configurations and vulnerability descriptions
into planning models expressed in the Planning Domain Definition Language
(PDDL). SPEAR identifies a set of diverse security hardening strategies that
can be presented in a manner understandable to the domain expert. These allow
the administrator to explore the network hardening solution space in a
systematic fashion and help evaluate the impact and compare the different
solutions.

</details>


### [518] [Align is not Enough: Multimodal Universal Jailbreak Attack against Multimodal Large Language Models](https://arxiv.org/abs/2506.01307)
*Youze Wang,Wenbo Hu,Yinpeng Dong,Jing Liu,Hanwang Zhang,Richang Hong*

Main category: cs.CR

TL;DR: 该论文提出了一种多模态通用越狱攻击框架，利用图像-文本交互和迁移策略生成通用对抗后缀和图像，揭示了多模态模型的安全对齐问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）的安全风险，尤其是文本越狱攻击的漏洞，促使研究者探索多模态攻击的潜在威胁。

Method: 提出了一种统一的多模态通用越狱攻击框架，通过迭代图像-文本交互和迁移策略生成对抗性后缀和图像。

Result: 实验验证了多模态通用越狱攻击能产生更高质量的负面生成，并揭示了当前安全机制在多模态攻击下的不足。

Conclusion: 研究强调了加强MLLMs安全措施的紧迫性，呼吁全面审查和增强安全协议以应对多模态能力带来的风险。

Abstract: Large Language Models (LLMs) have evolved into Multimodal Large Language
Models (MLLMs), significantly enhancing their capabilities by integrating
visual information and other types, thus aligning more closely with the nature
of human intelligence, which processes a variety of data forms beyond just
text. Despite advancements, the undesirable generation of these models remains
a critical concern, particularly due to vulnerabilities exposed by text-based
jailbreak attacks, which have represented a significant threat by challenging
existing safety protocols. Motivated by the unique security risks posed by the
integration of new and old modalities for MLLMs, we propose a unified
multimodal universal jailbreak attack framework that leverages iterative
image-text interactions and transfer-based strategy to generate a universal
adversarial suffix and image. Our work not only highlights the interaction of
image-text modalities can be used as a critical vulnerability but also
validates that multimodal universal jailbreak attacks can bring higher-quality
undesirable generations across different MLLMs. We evaluate the undesirable
context generation of MLLMs like LLaVA, Yi-VL, MiniGPT4, MiniGPT-v2, and
InstructBLIP, and reveal significant multimodal safety alignment issues,
highlighting the inadequacy of current safety mechanisms against sophisticated
multimodal attacks. This study underscores the urgent need for robust safety
measures in MLLMs, advocating for a comprehensive review and enhancement of
security protocols to mitigate potential risks associated with multimodal
capabilities.

</details>


### [519] [ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based Access Control](https://arxiv.org/abs/2506.01333)
*Manish Bhatt,Vineeth Sai Narajala,Idan Habler*

Main category: cs.CR

TL;DR: 论文提出ETDI，一种增强MCP安全性的扩展，通过加密身份验证、不可变工具定义和权限管理，结合动态策略控制，提升LLM与外部工具交互的安全性。


<details>
  <summary>Details</summary>
Motivation: 标准MCP存在安全漏洞（如工具污染和Rug Pull攻击），需要更安全的解决方案以支持LLM与外部工具的可靠集成。

Method: 引入ETDI，结合加密验证、版本化工具定义和OAuth 2.0权限管理，并扩展动态策略引擎以实现细粒度访问控制。

Result: ETDI显著提升了MCP的安全性，建立了更可信、可控的AI应用生态系统。

Conclusion: ETDI为LLM与外部工具的交互提供了更安全的框架，未来可进一步优化动态策略的灵活性。

Abstract: The Model Context Protocol (MCP) plays a crucial role in extending the
capabilities of Large Language Models (LLMs) by enabling integration with
external tools and data sources. However, the standard MCP specification
presents significant security vulnerabilities, notably Tool Poisoning and Rug
Pull attacks. This paper introduces the Enhanced Tool Definition Interface
(ETDI), a security extension designed to fortify MCP. ETDI incorporates
cryptographic identity verification, immutable versioned tool definitions, and
explicit permission management, often leveraging OAuth 2.0. We further propose
extending MCP with fine-grained, policy-based access control, where tool
capabilities are dynamically evaluated against explicit policies using a
dedicated policy engine, considering runtime context beyond static OAuth
scopes. This layered approach aims to establish a more secure, trustworthy, and
controllable ecosystem for AI applications interacting with LLMs and external
tools.

</details>


### [520] [System Calls for Malware Detection and Classification: Methodologies and Applications](https://arxiv.org/abs/2506.01412)
*Bishwajit Prasad Gond,Durga Prasad Mohapatra*

Main category: cs.CR

TL;DR: 论文探讨了利用系统调用和API调用来检测和分类恶意软件的方法，结合静态与动态分析、沙箱技术及机器学习等先进手段，以区分正常与恶意行为。


<details>
  <summary>Details</summary>
Motivation: 随着恶意软件日益复杂且难以检测，需要持续改进恶意软件分析方法以保持领先。系统调用和API调用作为用户应用与操作系统内核的核心通信方式，为检测可疑行为提供了重要线索。

Method: 结合静态分析、动态分析、沙箱技术，并运用机器学习、统计分析和异常检测等先进技术，分析系统调用模式。

Result: 通过分析系统调用模式，能够有效区分正常与恶意行为，并在Windows、Linux和Android等系统中应用。

Conclusion: 系统调用分析是恶意软件检测和分类的有效工具，但需应对高级恶意软件的规避手段。

Abstract: As malware continues to become more complex and harder to detect, Malware
Analysis needs to continue to evolve to stay one step ahead. One promising key
area approach focuses on using system calls and API Calls, the core
communication between user applications and the operating system and their
kernels. These calls provide valuable insight into how software or programs
behaves, making them an useful tool for spotting suspicious or harmful activity
of programs and software. This chapter takes a deep down look at how system
calls are used in malware detection and classification, covering techniques
like static and dynamic analysis, as well as sandboxing. By combining these
methods with advanced techniques like machine learning, statistical analysis,
and anomaly detection, researchers can analyze system call patterns to tell the
difference between normal and malicious behavior. The chapter also explores how
these techniques are applied across different systems, including Windows,
Linux, and Android, while also looking at the ways sophisticated malware tries
to evade detection.

</details>


### [521] [ReGA: Representation-Guided Abstraction for Model-based Safeguarding of LLMs](https://arxiv.org/abs/2506.01770)
*Zeming Wei,Chengcan Wu,Meng Sun*

Main category: cs.CR

TL;DR: ReGA是一个基于表示引导抽象的模型分析框架，旨在保护大型语言模型免受有害提示和生成的影响，解决了可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成有害内容和易受越狱攻击方面存在安全风险，现有模型分析方法在扩展到LLMs时面临可扩展性问题。

Method: ReGA利用安全关键表示（隐藏状态中指示安全相关概念的低维方向），构建抽象模型进行安全建模。

Result: ReGA在区分安全与有害输入方面表现优异，提示级别和对话级别的AUROC分别达到0.975和0.985，且对现实攻击具有鲁棒性。

Conclusion: ReGA通过结合表示工程和模型抽象，为提升LLM安全性提供了高效且可扩展的解决方案，为AI安全开辟了新范式。

Abstract: Large Language Models (LLMs) have achieved significant success in various
tasks, yet concerns about their safety and security have emerged. In
particular, they pose risks in generating harmful content and vulnerability to
jailbreaking attacks. To analyze and monitor machine learning models,
model-based analysis has demonstrated notable potential in stateful deep neural
networks, yet suffers from scalability issues when extending to LLMs due to
their vast feature spaces. In this paper, we propose ReGA, a model-based
analysis framework with representation-guided abstraction, to safeguard LLMs
against harmful prompts and generations. By leveraging safety-critical
representations, which are low-dimensional directions emerging in hidden states
that indicate safety-related concepts, ReGA effectively addresses the
scalability issue when constructing the abstract model for safety modeling. Our
comprehensive evaluation shows that ReGA performs sufficiently well in
distinguishing between safe and harmful inputs, achieving an AUROC of 0.975 at
the prompt level and 0.985 at the conversation level. Additionally, ReGA
exhibits robustness to real-world attacks and generalization across different
safety perspectives, outperforming existing safeguard paradigms in terms of
interpretability and scalability. Overall, ReGA serves as an efficient and
scalable solution to enhance LLM safety by integrating representation
engineering with model-based abstraction, paving the way for new paradigms to
utilize software insights for AI safety. Our code is available at
https://github.com/weizeming/ReGA.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [522] [Improving statistical learning methods via features selection without replacement sampling and random projection](https://arxiv.org/abs/2506.00053)
*Sulaiman khan,Muhammad Ahmad,Fida Ullah,Carlos Aguilar Ibañez,José Eduardo Valdez Rodriguez*

Main category: q-bio.QM

TL;DR: 该论文提出了一种结合FSWOR技术和投影方法的机器学习方法，用于提高高维基因表达数据的分类准确性，并在脑癌数据集中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 癌症是一种基因疾病，高维微阵列数据分类面临'小n大p'问题，导致过拟合。本研究旨在解决这一问题。

Method: 1) 结合FSWOR和投影方法；2) 使用Kendall统计测试筛选显著基因；3) 应用集成分类器和LDA投影及朴素贝叶斯模型。

Result: 模型在测试中达到96%的准确率，优于现有方法9.09%，显著减少了特征空间。

Conclusion: 该方法有效提高了高维基因表达数据的分类准确性，为癌症生物标志物发现提供了有力工具。

Abstract: Cancer is fundamentally a genetic disease characterized by genetic and
epigenetic alterations that disrupt normal gene expression, leading to
uncontrolled cell growth and metastasis. High-dimensional microarray datasets
pose challenges for classification models due to the "small n, large p"
problem, resulting in overfitting. This study makes three different key
contributions: 1) we propose a machine learning-based approach integrating the
Feature Selection Without Re-placement (FSWOR) technique and a projection
method to improve classification accuracy. 2) We apply the Kendall statistical
test to identify the most significant genes from the brain cancer mi-croarray
dataset (GSE50161), reducing the feature space from 54,675 to 20,890 genes.3)
we apply machine learning models using k-fold cross validation techniques in
which our model incorpo-rates ensemble classifiers with LDA projection and
Na\"ive Bayes, achieving a test score of 96%, outperforming existing methods by
9.09%. The results demonstrate the effectiveness of our ap-proach in
high-dimensional gene expression analysis, improving classification accuracy
while mitigating overfitting. This study contributes to cancer biomarker
discovery, offering a robust computational method for analyzing microarray
data.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [523] [MolTextNet: A Two-Million Molecule-Text Dataset for Multimodal Molecular Learning](https://arxiv.org/abs/2506.00009)
*Yihan Zhu,Gang Liu,Eric Inae,Meng Jiang*

Main category: q-bio.BM

TL;DR: MolTextNet是一个包含250万高质量分子-文本对的数据集，旨在解决现有数据集规模小和信息不足的问题，支持多模态模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有分子-文本数据集规模小且信息有限，限制了多模态模型的泛化能力。

Method: 通过合成文本生成流程整合分子结构特征、计算属性、生物活性数据和合成复杂性，利用GPT-4o-mini为ChEMBL35中的250万分子生成长文本描述。

Result: MolTextNet的文本长度是之前数据集的10倍以上，支持多种下游任务（如属性预测和结构检索），预训练模型性能显著提升。

Conclusion: MolTextNet为分子科学中的多模态建模提供了重要资源，具有推动基础研究的潜力。

Abstract: Small molecules are essential to drug discovery, and graph-language models
hold promise for learning molecular properties and functions from text.
However, existing molecule-text datasets are limited in scale and
informativeness, restricting the training of generalizable multimodal models.
We present MolTextNet, a dataset of 2.5 million high-quality molecule-text
pairs designed to overcome these limitations. To construct it, we propose a
synthetic text generation pipeline that integrates structural features,
computed properties, bioactivity data, and synthetic complexity. Using
GPT-4o-mini, we create structured descriptions for 2.5 million molecules from
ChEMBL35, with text over 10 times longer than prior datasets. MolTextNet
supports diverse downstream tasks, including property prediction and structure
retrieval. Pretraining CLIP-style models with Graph Neural Networks and
ModernBERT on MolTextNet yields improved performance, highlighting its
potential for advancing foundational multimodal modeling in molecular science.
Our dataset is available at
https://huggingface.co/datasets/liuganghuggingface/moltextnet.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [524] [FlexiSAGA: A Flexible Systolic Array GEMM Accelerator for Sparse and Dense Processing](https://arxiv.org/abs/2506.01566)
*Mika Markus Müller,Konstantin Lübeck,Alexander Louis-Ferdinand Jung,Jannik Steinmetz,Oliver Bringmann*

Main category: cs.PF

TL;DR: FlexiSAGA是一种可配置的AI硬件加速器，支持稀疏和密集数据处理，通过优化的DNN剪枝方法实现高效推理，性能优于现有平台。


<details>
  <summary>Details</summary>
Motivation: DNN推理的计算复杂度高，尤其在资源受限的边缘设备上，稀疏性利用是解决这一挑战的有效方法。

Method: 提出FlexiSAGA加速器，支持七种数据流，并结合专为其设计的DNN剪枝方法，实现DNN/HW协同设计。

Result: 实验显示稀疏推理速度提升1.41至4.28倍，优于商业和文献报道的加速器。

Conclusion: FlexiSAGA通过灵活的数据流和剪枝方法，显著提升了DNN推理效率，适用于边缘设备。

Abstract: Artificial Intelligence (AI) algorithms, such as Deep Neural Networks (DNNs),
have become an important tool for a wide range of applications, from computer
vision to natural language processing. However, the computational complexity of
DNN inference poses a significant challenge, particularly for processing on
resource-constrained edge devices. One promising approach to address this
challenge is the exploitation of sparsity in DNN operator weights.
  In this work, we present FlexiSAGA, an architecturally configurable and
dataflow-flexible AI hardware accelerator for the sparse and dense processing
of general matrix multiplications (GEMMs). FlexiSAGA supports seven different
sparse and dense dataflows, enabling efficient processing of resource intensive
DNN operators. Additionally, we propose a DNN pruning method specifically
tailored towards the FlexiSAGA architecture, allowing for near-optimal
processing of dense and sparse convolution and fully-connected operators,
facilitating a DNN/HW co-design flow. Our results show a whole DNN
sparse-over-dense inference speedup ranging from 1.41 up to 4.28, outperforming
commercial and literature-reported accelerator platforms.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [525] [A Reinforcement Learning-Based Telematic Routing Protocol for the Internet of Underwater Things](https://arxiv.org/abs/2506.00133)
*Mohammadhossein Homaei,Mehran Tarif,Agustin Di Bartolo,Oscar Mogollon Gutierrez,Mar Avila*

Main category: cs.NI

TL;DR: 论文提出了一种基于强化学习的路由协议RL-RPL-UA，用于改善水下物联网（IoUT）中的通信性能，相比传统方法显著提升了数据包传输效率、能量利用率和网络寿命。


<details>
  <summary>Details</summary>
Motivation: 水下物联网面临带宽低、延迟高、移动性强和能量有限等挑战，传统路由协议（如RPL）在水下环境中表现不佳，因此需要一种更高效的解决方案。

Method: RL-RPL-UA协议在每个节点中嵌入轻量级强化学习代理，根据本地信息（如数据包投递率、缓冲区水平、链路质量和剩余能量）动态选择最佳父节点，同时保持与标准RPL协议的兼容性。

Result: 仿真实验显示，RL-RPL-UA将数据包投递率提高了9.2%，每数据包能耗降低14.8%，网络寿命延长80秒。

Conclusion: RL-RPL-UA是一种高效且节能的水下网络路由解决方案，具有实际应用潜力。

Abstract: The Internet of Underwater Things (IoUT) faces major challenges such as low
bandwidth, high latency, mobility, and limited energy resources. Traditional
routing protocols like RPL, which were designed for land-based networks, do not
perform well in these underwater conditions. This paper introduces RL-RPL-UA, a
new routing protocol that uses reinforcement learning to improve performance in
underwater environments. Each node includes a lightweight RL agent that selects
the best parent node based on local information such as packet delivery ratio,
buffer level, link quality, and remaining energy. RL-RPL-UA keeps full
compatibility with standard RPL messages and adds a dynamic objective function
to support real-time decision-making. Simulations using Aqua-Sim show that
RL-RPL-UA increases packet delivery by up to 9.2%, reduces energy use per
packet by 14.8%, and extends network lifetime by 80 seconds compared to
traditional methods. These results suggest that RL-RPL-UA is a promising and
energy-efficient routing solution for underwater networks.

</details>


### [526] [Bridging Subjective and Objective QoE: Operator-Level Aggregation Using LLM-Based Comment Analysis and Network MOS Comparison](https://arxiv.org/abs/2506.00924)
*Parsa Hassani Shariat Panahi,Amir Hossein Jalilvand,M. Hasan Najafi*

Main category: cs.NI

TL;DR: 本文提出了一种双层的网络运营商侧体验质量（QoE）评估框架，结合了客观网络建模和从直播平台提取的主观用户感知。


<details>
  <summary>Details</summary>
Motivation: 通过结合客观网络参数和用户反馈，提供更全面的QoE评估，帮助运营商实时监测和改善服务质量。

Method: 1. 客观侧：基于ITU-T P.1203的机器学习模型预测视频质量；2. 主观侧：利用大语言模型处理直播评论，提取QoE相关反馈并评分。

Result: 构建了包含47,894条评论的数据集，34,000条与QoE相关；提出delta MOS指标检测局部服务质量下降。

Conclusion: 该框架能有效通过评论趋势识别服务中断，为运营商提供实时性能偏差分析和客观QoE估计对比。

Abstract: This paper introduces a dual-layer framework for network operator-side
quality of experience (QoE) assessment that integrates both objective network
modeling and subjective user perception extracted from live-streaming
platforms. On the objective side, we develop a machine learning model trained
on mean opinion scores (MOS) computed via the ITU-T P.1203 reference
implementation, allowing accurate prediction of user-perceived video quality
using only network parameters such as packet loss, delay, jitter, and
throughput without reliance on video content or client-side instrumentation. On
the subjective side, we present a semantic filtering and scoring pipeline that
processes user comments from live streams to extract performance-related
feedback. A large language model is used to assign scalar MOS scores to
filtered comments in a deterministic and reproducible manner. To support
scalable and interpretable analysis, we construct a labeled dataset of 47,894
live-stream comments, of which about 34,000 are identified as QoE-relevant
through multi-layer semantic filtering. Each comment is enriched with simulated
Internet Service Provider attribution and temporally aligned using synthetic
timestamps in 5-min intervals. The resulting dataset enables operator-level
aggregation and time-series analysis of user-perceived quality. A delta MOS
metric is proposed to measure each Internet service provider's deviation from
platform-wide sentiment, allowing detection of localized degradations even in
the absence of direct network telemetry. A controlled outage simulation
confirms the framework's effectiveness in identifying service disruptions
through comment-based trends alone. The system provides each operator with its
own subjective MOS and the global platform average per interval, enabling
real-time interpretation of performance deviations and comparison with
objective network-based QoE estimates.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [527] [Advancing AI-assisted Hardware Design with Hierarchical Decentralized Training and Personalized Inference-Time Optimization](https://arxiv.org/abs/2506.00002)
*Hao Mark Chen,Zehuan Zhang,Wanru Zhao,Nicholas Lane,Hongxiang Fan*

Main category: cs.AR

TL;DR: 论文提出了一种两阶段框架，通过去中心化训练和个性化推理解决LLM辅助硬件设计中的三大挑战，显著提升了生成质量和效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM生成的硬件设计质量不足，主要受限于数据可用性、质量和推理效率。

Method: 采用两阶段框架：1) 去中心化训练解决数据共享问题；2) 个性化推理优化速度和生成质量。

Result: 实验表明，框架在语义准确性和速度上分别提升33%~50%和2.3倍。

Conclusion: 该框架为LLM辅助硬件设计提供了有效解决方案，显著提升了实用性和效率。

Abstract: Recent years have witnessed a significant increase in the adoption of AI
techniques to enhance electronic design automation. In particular, the
emergence of Large Language Models (LLMs) has sparked significant interest in
LLM-assisted hardware design generation, spanning applications from classical
digital circuits to quantum computing. Despite substantial progress in this
direction, the quality of LLM-generated hardware design still cannot meet the
requirements for practical deployment. In this work, we identify three critical
challenges hindering the development of LLM-assisted hardware design
generation: 1) limited data availability, 2) varied data quality, 3) inadequate
inference-time efficiency. To address these fundamental challenges, this paper
introduces a two-stage framework for AI-assisted hardware design by exploring
decentralized training and personalized inference. In the first stage, we
propose to harness private domain design sources through a hierarchical
decentralized training mechanism that addresses data-sharing constraints. To
mitigate the impact of low-quality data, we identify optimization opportunities
in hardware generation tasks, using user-defined metrics for model aggregation.
The second stage focuses on client personalization to enhance both speed and
quality. We introduce a new metric, Trueput, to analyze LLM-assisted hardware
generation efficiency. To optimize Trueput, we implement personalized
inference-time acceleration and customized sampling strategies. Evaluating both
classical and quantum benchmarks, our experimental results demonstrate that the
proposed two-stage framework can significantly improve the model capability for
hardware design generation. As orthogonal enhancements to existing methods, our
framework can achieve $33\% \sim 50\%$ semantic accuracy improvement and $2.3$
times speedup, depending on the difficulty of the generation tasks.

</details>


### [528] [Rapid yet accurate Tile-circuit and device modeling for Analog In-Memory Computing](https://arxiv.org/abs/2506.00004)
*J. Luquin,C. Mackin,S. Ambrogio,A. Chen,F. Baldi,G. Miralles,M. J. Rasch,J. Büchel,M. Lalwani,W. Ponghiran,P. Solomon,H. Tsai,G. W. Burr,P. Narayanan*

Main category: cs.AR

TL;DR: 论文研究了模拟内存计算（AIMC）中设备和电路的非理想性对神经网络任务精度的影响，提出了数学模型和训练方法以提高硬件适应性。


<details>
  <summary>Details</summary>
Motivation: AIMC能显著提高深度学习的能效，但模拟域的非理想性会降低任务精度，因此需要量化这些影响并开发适应性方法。

Method: 开发了数学模型来捕捉电路非理想性（如瞬时电流IR-drop和ADC量化效应），并基于PyTorch框架评估对BERT和ALBERT网络的影响。

Result: 硬件感知微调对ADC量化和PCM噪声有效，但对IR-drop效果有限，因其非线性和并行依赖性。

Conclusion: 需要更复杂的训练方法（如结合电路模型）以提升AIMC硬件上大型神经网络的鲁棒性。

Abstract: Analog In-Memory Compute (AIMC) can improve the energy efficiency of Deep
Learning by orders of magnitude. Yet analog-domain device and circuit
non-idealities -- within the analog ``Tiles'' performing Matrix-Vector Multiply
(MVM) operations -- can degrade neural-network task accuracy. We quantify the
impact of low-level distortions and noise, and develop a mathematical model for
Multiply-ACcumulate (MAC) operations mapped to analog tiles.
Instantaneous-current IR-drop (the most significant circuit non-ideality), and
ADC quantization effects are fully captured by this model, which can predict
MVM tile-outputs both rapidly and accurately, as compared to much slower
rigorous circuit simulations. A statistical model of PCM read noise at
nanosecond timescales is derived from -- and matched against -- experimental
measurements. We integrate these (statistical) device and (deterministic)
circuit effects into a PyTorch-based framework to assess the accuracy impact on
the BERT and ALBERT Transformer networks. We show that hardware-aware
fine-tuning using simple Gaussian noise provides resilience against ADC
quantization and PCM read noise effects, but is less effective against IR-drop.
This is because IR-drop -- although deterministic -- is non-linear, is changing
significantly during the time-integration window, and is ultimately dependent
on all the excitations being introduced in parallel into the analog tile. The
apparent inability of simple Gaussian noise applied during training to properly
prepare a DNN network for IR-drop during inference implies that more complex
training approaches -- incorporating advances such as the Tile-circuit model
introduced here -- will be critical for resilient deployment of large neural
networks onto AIMC hardware.

</details>


### [529] [Enhancing Finite State Machine Design Automation with Large Language Models and Prompt Engineering Techniques](https://arxiv.org/abs/2506.00001)
*Qun-Kai Lin,Cheng Hsu,Tian-Sheuan Chang*

Main category: cs.AR

TL;DR: 论文研究了三种大型语言模型（Claude 3 Opus、ChatGPT-4和ChatGPT-4o）在设计有限状态机（FSM）中的表现，并探讨了提示优化方法（TOP Patch）对其成功率的影响。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在硬件描述语言（HDL）设计中的显著兼容性，研究其在FSM设计中的性能表现及优化方法具有重要意义。

Method: 通过HDLBits提供的教学内容，评估模型的稳定性、局限性及优化方法，并测试提示优化方法（TOP Patch）的效果。

Result: 系统化格式提示方法和新颖的提示优化方法在FSM设计中表现出潜力，未来可能扩展到其他领域。

Conclusion: 研究结果表明，这些方法不仅适用于HDL设计自动化，还可能与其他提示工程技术结合应用于更广泛的领域。

Abstract: Large Language Models (LLMs) have attracted considerable attention in recent
years due to their remarkable compatibility with Hardware Description Language
(HDL) design. In this paper, we examine the performance of three major LLMs,
Claude 3 Opus, ChatGPT-4, and ChatGPT-4o, in designing finite state machines
(FSMs). By utilizing the instructional content provided by HDLBits, we evaluate
the stability, limitations, and potential approaches for improving the success
rates of these models. Furthermore, we explore the impact of using the
prompt-refining method, To-do-Oriented Prompting (TOP) Patch, on the success
rate of these LLM models in various FSM design scenarios. The results show that
the systematic format prompt method and the novel prompt refinement method have
the potential to be applied to other domains beyond HDL design automation,
considering its possible integration with other prompt engineering techniques
in the future.

</details>


### [530] [VUSA: Virtually Upscaled Systolic Array Architecture to Exploit Unstructured Sparsity in AI Acceleration](https://arxiv.org/abs/2506.01166)
*Shereef Helal,Alberto Garcia-Ortiz,Lennart Bamberg*

Main category: cs.AR

TL;DR: VUSA是一种基于稀疏性的脉动阵列架构，通过虚拟扩展实现更大规模的矩阵乘法，节省37%面积和68%功耗，适用于通用AI加速。


<details>
  <summary>Details</summary>
Motivation: 利用非结构化稀疏性提升DNN加速器效率，尤其适用于边缘AI应用。

Method: 提出VUSA架构，根据稀疏性虚拟扩展脉动阵列，使用相同数量的物理MAC单元完成更大规模的矩阵乘法。

Result: 在16纳米工艺下，相比基线架构，面积和功耗效率分别提升37%和68%，同时支持任何稀疏度的DNN加速。

Conclusion: VUSA是一种通用、高效的AI加速架构，适用于各种稀疏度的DNN应用。

Abstract: Leveraging high degrees of unstructured sparsity is a promising approach to
enhance the efficiency of deep neural network DNN accelerators - particularly
important for emerging Edge-AI applications. We introduce VUSA, a
systolic-array architecture that virtually grows based on the present sparsity
to perform larger matrix multiplications with the same number of physical
multiply-accumulate MAC units. The proposed architecture achieves saving by 37%
and 68% in area and power efficiency, respectively, at the same
peak-performance, compared to a baseline systolic array architecture in a
commercial 16-nm technology. Still, the proposed architecture supports
acceleration for any DNN with any sparsity - even no sparsity at all. Thus, the
proposed architecture is application-independent, making it viable for
general-purpose AI acceleration.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [531] [Pro3D-Editor : A Progressive-Views Perspective for Consistent and Precise 3D Editing](https://arxiv.org/abs/2506.00512)
*Yang Zheng,Mengqi Huang,Nan Chen,Zhendong Mao*

Main category: cs.GR

TL;DR: 本文提出了一种基于渐进视图范式的3D编辑方法Pro3D-Editor，通过动态采样主视图、传播编辑语义并多视图优化，显著提升了编辑的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有3D编辑方法忽视跨视图依赖性，导致多视图编辑不一致，本文旨在解决这一问题。

Method: 提出Pro3D-Editor框架，包括主视图采样器、关键视图渲染器和全视图优化器，通过MoVE-LoRA技术传播编辑语义。

Result: 实验表明，该方法在编辑准确性和空间一致性上优于现有方法。

Conclusion: 渐进视图范式能够实现理想的3D编辑一致性，Pro3D-Editor为3D编辑提供了高效解决方案。

Abstract: Text-guided 3D editing aims to precisely edit semantically relevant local 3D
regions, which has significant potential for various practical applications
ranging from 3D games to film production. Existing methods typically follow a
view-indiscriminate paradigm: editing 2D views indiscriminately and projecting
them back into 3D space. However, they overlook the different cross-view
interdependencies, resulting in inconsistent multi-view editing. In this study,
we argue that ideal consistent 3D editing can be achieved through a
\textit{progressive-views paradigm}, which propagates editing semantics from
the editing-salient view to other editing-sparse views. Specifically, we
propose \textit{Pro3D-Editor}, a novel framework, which mainly includes
Primary-view Sampler, Key-view Render, and Full-view Refiner. Primary-view
Sampler dynamically samples and edits the most editing-salient view as the
primary view. Key-view Render accurately propagates editing semantics from the
primary view to other key views through its Mixture-of-View-Experts Low-Rank
Adaption (MoVE-LoRA). Full-view Refiner edits and refines the 3D object based
on the edited multi-views. Extensive experiments demonstrate that our method
outperforms existing methods in editing accuracy and spatial consistency.

</details>


### [532] [Image Generation from Contextually-Contradictory Prompts](https://arxiv.org/abs/2506.01929)
*Saar Huberman,Or Patashnik,Omer Dahary,Ron Mokady,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: 提出了一种阶段感知的提示分解框架，通过代理提示序列引导去噪过程，解决文本到图像扩散模型在概念矛盾时的语义准确性不足问题。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在生成高质量图像时，对于包含矛盾概念的提示往往无法生成语义准确的结果。

Method: 使用大型语言模型分析目标提示，识别矛盾并生成代理提示序列，确保去噪过程中语义内容与阶段匹配。

Result: 实验表明，该方法在多种挑战性提示下显著提升了图像与文本提示的对齐度。

Conclusion: 通过阶段感知的提示分解，实现了对语义的细粒度控制，解决了上下文矛盾问题。

Abstract: Text-to-image diffusion models excel at generating high-quality, diverse
images from natural language prompts. However, they often fail to produce
semantically accurate results when the prompt contains concept combinations
that contradict their learned priors. We define this failure mode as contextual
contradiction, where one concept implicitly negates another due to entangled
associations learned during training. To address this, we propose a stage-aware
prompt decomposition framework that guides the denoising process using a
sequence of proxy prompts. Each proxy prompt is constructed to match the
semantic content expected to emerge at a specific stage of denoising, while
ensuring contextual coherence. To construct these proxy prompts, we leverage a
large language model (LLM) to analyze the target prompt, identify
contradictions, and generate alternative expressions that preserve the original
intent while resolving contextual conflicts. By aligning prompt information
with the denoising progression, our method enables fine-grained semantic
control and accurate image generation in the presence of contextual
contradictions. Experiments across a variety of challenging prompts show
substantial improvements in alignment to the textual prompt.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [533] [Designing AI Tools for Clinical Care Teams to Support Serious Illness Conversations with Older Adults in the Emergency Department](https://arxiv.org/abs/2506.00241)
*Menglin Zhao,Zhuorui Yong,Ruijia Guan,Kai-Wei Chang,Adrian Haimovich,Kei Ouchi,Timothy Bickmore,Bingsheng Yao,Dakuo Wang,Smit Desai*

Main category: cs.HC

TL;DR: 研究分析了急诊科（ED）中与老年患者进行严重疾病对话（SICs）的现状，提出了四阶段工作流程，并探讨了AI工具在支持这些对话中的潜在作用。


<details>
  <summary>Details</summary>
Motivation: 严重疾病对话（SICs）对患者为中心的护理至关重要，但在急诊科环境中存在诸多障碍，如数据碎片化、时间压力和情感负担。研究旨在了解现状并探索AI支持的可能性。

Method: 通过访谈两位领域专家和九名急诊科临床团队成员，采用主题分析法，确定了SICs的四阶段工作流程（识别、准备、进行、记录）及各阶段的需求与挑战。

Result: 研究发现临床团队面临数据访问困难、时间限制、情感准备需求和记录负担等问题，但对AI工具在信息整合、对话支持和自动记录方面的应用表示兴趣。

Conclusion: 研究提出了支持SICs工作流程的AI工具设计指南，强调保持人际联系和临床自主性，为高风险临床环境中的AI应用提供了实证基础和设计参考。

Abstract: Serious illness conversations (SICs), discussions between clinical care teams
and patients with serious, life-limiting illnesses about their values, goals,
and care preferences, are critical for patient-centered care. Without these
conversations, patients often receive aggressive interventions that may not
align with their goals. Clinical care teams face significant barriers when
conducting serious illness conversations with older adult patients in Emergency
Department (ED) settings, where most older adult patients lack documented
treatment goals. To understand current practices and identify AI support
opportunities, we conducted interviews with two domain experts and nine ED
clinical care team members. Through thematic analysis, we characterized a
four-phase serious illness conversation workflow (identification, preparation,
conduction, documentation) and identified key needs and challenges at each
stage. Clinical care teams struggle with fragmented EHR data access, time
constraints, emotional preparation demands, and documentation burdens. While
participants expressed interest in AI tools for information synthesis,
conversational support, and automated documentation, they emphasized preserving
human connection and clinical autonomy. We present design guidelines for AI
tools supporting SIC workflows that fit within existing clinical practices.
This work contributes empirical understanding of ED-based serious illness
conversations and provides design considerations for AI in high-stakes clinical
environments.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [534] [Retrieval-Augmented Generation of Ontologies from Relational Databases](https://arxiv.org/abs/2506.01232)
*Mojtaba Nayyeri,Athish A Yogi,Nadeen Fathallah,Ratan Bahadur Thapa,Hans-Michael Tautenhahn,Anton Schnurpel,Steffen Staab*

Main category: cs.DB

TL;DR: RIGOR是一种LLM驱动的方法，通过结合数据库模式、文档、领域本体库和核心本体，自动生成丰富的OWL本体，显著减少人工努力并提高本体质量。


<details>
  <summary>Details</summary>
Motivation: 提升关系数据库到知识图谱的转换效率和质量，解决以往方法需要大量人工或生成基础本体的问题。

Method: 结合RAG技术，利用数据库模式、文档、领域本体库和核心本体，通过生成LLM和判断LLM迭代生成并优化本体片段，按外键约束逐步覆盖所有表。

Result: 生成的OWL本体在准确性、完整性、简洁性、适应性、清晰性和一致性等标准质量维度上得分高，同时大幅减少人工干预。

Conclusion: RIGOR方法有效解决了关系数据库到知识图谱转换中的本体生成问题，显著提升了语义互操作性和自动化水平。

Abstract: Transforming relational databases into knowledge graphs with enriched
ontologies enhances semantic interoperability and unlocks advanced graph-based
learning and reasoning over data. However, previous approaches either demand
significant manual effort to derive an ontology from a database schema or
produce only a basic ontology. We present RIGOR, Retrieval-augmented Iterative
Generation of RDB Ontologies, an LLM-driven approach that turns relational
schemas into rich OWL ontologies with minimal human effort. RIGOR combines
three sources via RAG, the database schema and its documentation, a repository
of domain ontologies, and a growing core ontology, to prompt a generative LLM
for producing successive, provenance-tagged delta ontology fragments. Each
fragment is refined by a judge-LLM before being merged into the core ontology,
and the process iterates table-by-table following foreign key constraints until
coverage is complete. Applied to real-world databases, our approach outputs
ontologies that score highly on standard quality dimensions such as accuracy,
completeness, conciseness, adaptability, clarity, and consistency, while
substantially reducing manual effort.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [535] [Literature Review Of Multi-Agent Debate For Problem-Solving](https://arxiv.org/abs/2506.00066)
*Arne Tillmann*

Main category: cs.MA

TL;DR: 本文综述了多智能体大语言模型（MA-LLMs）的研究进展，比较了其与单智能体模型的性能差异，并探讨了智能体配置、通信结构和决策过程对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 解决MA-LLMs领域缺乏直接比较的问题，揭示多智能体方法的优势与挑战。

Method: 通过文献综述，结合传统多智能体系统和最新MA-LLM研究，分析智能体配置、通信结构和决策过程。

Result: 多智能体方法表现更优，但面临计算成本高和独特挑战未被充分探索的问题。

Conclusion: 为开发高效多智能体AI解决方案提供了研究路线图。

Abstract: Multi-agent large language models (MA-LLMs) are a rapidly growing research
area that leverages multiple interacting language agents to tackle complex
tasks, outperforming single-agent large language models. This literature review
synthesizes the latest research on agent profiles, communication structures,
and decision-making processes, drawing insights from both traditional
multi-agent systems and state-of-the-art MA-LLM studies. In doing so, it aims
to address the lack of direct comparisons in the field, illustrating how
factors like scalability, communication structure, and decision-making
processes influence MA-LLM performance. By examining frequent practices and
outlining current challenges, the review reveals that multi-agent approaches
can yield superior results but also face elevated computational costs and
under-explored challenges unique to MA-LLM. Overall, these findings provide
researchers and practitioners with a roadmap for developing robust and
efficient multi-agent AI solutions.

</details>


### [536] [Agentic AI and Multiagentic: Are We Reinventing the Wheel?](https://arxiv.org/abs/2506.01463)
*V. Botti*

Main category: cs.MA

TL;DR: 文章批判性地分析了‘Agentic AI’和‘Multiagentic AI’等流行术语与AI文献中已有的‘智能代理’和‘多代理系统’概念的混淆，主张使用已有术语以避免重复研究。


<details>
  <summary>Details</summary>
Motivation: 探讨当前对‘Agentic AI’和‘Multiagentic AI’的滥用，强调回归已有AI术语的重要性，以避免忽视多年研究成果。

Method: 回顾社会科学的‘agentic’理论起源和哲学意向性概念，总结智能代理和多代理系统的基础研究，分析经典代理架构，并讨论基于LLM的代理平台发展。

Result: 指出‘Agentic AI’和‘Multiagentic AI’实质上是已有的智能代理和多代理系统，混淆术语可能导致重复研究。

Conclusion: 主张在LLM驱动的AI代理研究中采用已有术语和知识，避免‘重新发明轮子’。

Abstract: The terms Agentic AI and Multiagentic AI have recently gained popularity in
discussions on generative artificial intelligence, often used to describe
autonomous software agents and systems composed of such agents. However, the
use of these terms confuses these buzzwords with well-established concepts in
AI literature: intelligent agents and multi-agent systems. This article offers
a critical analysis of this conceptual misuse. We review the theoretical
origins of "agentic" in the social sciences (Bandura, 1986) and philosophical
notions of intentionality (Dennett, 1971), and then summarise foundational
works on intelligent agents and multi-agent systems by Wooldridge, Jennings and
others. We examine classic agent architectures, from simple reactive agents to
Belief-Desire-Intention (BDI) models, and highlight key properties (autonomy,
reactivity, proactivity, social capability) that define agency in AI. We then
discuss recent developments in large language models (LLMs) and agent platforms
based on LLMs, including the emergence of LLM-powered AI agents and open-source
multi-agent orchestration frameworks. We argue that the term AI Agentic is
often used as a buzzword for what are essentially AI agents, and AI
Multiagentic for what are multi-agent systems. This confusion overlooks decades
of research in the field of autonomous agents and multi-agent systems. The
article advocates for scientific and technological rigour and the use of
established terminology from the state of the art in AI, incorporating the
wealth of existing knowledge, including standards for multi-agent system
platforms, communication languages and coordination and cooperation algorithms,
agreement technologies (automated negotiation, argumentation, virtual
organisations, trust, reputation, etc.), into the new and promising wave of
LLM-based AI agents, so as not to end up reinventing the wheel.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [537] [Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks](https://arxiv.org/abs/2506.00856)
*Qiang Chen,Tianyang Han,Jin Li,Ye Luo,Yuxiao Wu,Xiaowei Zhang,Tuo Zhou*

Main category: econ.EM

TL;DR: 本文评估了一种基于MetaGPT框架的‘计量经济学AI代理’，其在计量经济分析任务中表现出色，显著优于通用AI和大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 探讨AI是否能有效完成传统上需要人类专业知识的复杂计量经济分析。

Method: 开发了一个基于MetaGPT框架的计量经济学AI代理，通过战略规划、代码生成与执行、错误反思和多轮对话迭代优化其性能。

Result: 该代理在学术课程材料和已发表论文构建的数据集上表现优异，显著优于通用AI和大型语言模型。

Conclusion: 该研究为探索AI对社会科学研究的影响提供了测试平台，并提升了计量经济学的教学和研究可重复性。

Abstract: Can AI effectively perform complex econometric analysis traditionally
requiring human expertise? This paper evaluates an agentic AI's capability to
master econometrics, focusing on empirical analysis performance. We develop an
``Econometrics AI Agent'' built on the open-source MetaGPT framework. This
agent exhibits outstanding performance in: (1) planning econometric tasks
strategically, (2) generating and executing code, (3) employing error-based
reflection for improved robustness, and (4) allowing iterative refinement
through multi-round conversations. We construct two datasets from academic
coursework materials and published research papers to evaluate performance
against real-world challenges. Comparative testing shows our domain-specialized
agent significantly outperforms both benchmark large language models (LLMs) and
general-purpose AI agents. This work establishes a testbed for exploring AI's
impact on social science research and enables cost-effective integration of
domain expertise, making advanced econometric methods accessible to users with
minimal coding expertise. Furthermore, our agent enhances research
reproducibility and offers promising pedagogical applications for econometrics
teaching.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [538] [Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models](https://arxiv.org/abs/2506.00049)
*Arjun Rao,Hanieh Alipour,Nick Pendar*

Main category: cs.IR

TL;DR: 比较了MiniLM-v6和BGE-Large在RAG系统中的三模态混合检索性能，发现MiniLM-v6在LLM重排序下表现更优。


<details>
  <summary>Details</summary>
Motivation: 探讨嵌入模型在多模态融合中的性能差异，优化RAG系统的检索效率与准确性。

Method: 融合稠密语义、稀疏词法和图嵌入，测试MiniLM-v6和BGE-Large在SciFact等数据集上的表现。

Result: MiniLM-v6在LLM重排序下优于BGE-Large，尤其在代理重排序场景中表现突出。

Conclusion: 选择嵌入模型应注重多信号融合和LLM对齐，而非单纯依赖大模型，可提升效率与准确性。

Abstract: This paper presents a comparison of embedding models in tri-modal hybrid
retrieval for Retrieval-Augmented Generation (RAG) systems. We investigate the
fusion of dense semantic, sparse lexical, and graph-based embeddings, focusing
on the performance of the MiniLM-v6 and BGE-Large architectures. Contrary to
conventional assumptions, our results show that the compact MiniLM-v6
outperforms the larger BGE-Large when integrated with LLM-based re-ranking
within our tri-modal hybrid framework. Experiments conducted on the SciFact,
FIQA, and NFCorpus datasets demonstrate significant improvements in retrieval
quality with the MiniLM-v6 configuration. The performance difference is
particularly pronounced in agentic re-ranking scenarios, indicating better
alignment between MiniLM-v6's embedding space and LLM reasoning. Our findings
suggest that embedding model selection for RAG systems should prioritize
compatibility with multi-signal fusion and LLM alignment, rather than relying
solely on larger models. This approach may reduce computational requirements
while improving retrieval accuracy and efficiency.

</details>


### [539] [Gated Multimodal Graph Learning for Personalized Recommendation](https://arxiv.org/abs/2506.00107)
*Sibei Liu,Yuanzhe Zhang,Xiang Li,Yunbo Liu,Chengwei Feng,Hao Yang*

Main category: cs.IR

TL;DR: RLMultimodalRec是一个轻量级的多模态推荐框架，通过动态融合视觉和文本模态以及图神经网络捕捉高阶协同信号，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态推荐中异构模态融合的挑战，避免固定融合策略或复杂架构的不足。

Method: 结合图用户建模与自适应多模态项目编码，使用门控融合模块动态平衡模态贡献，并采用LightGCN捕捉协同信号。

Result: 在真实数据集上优于多种基线方法，显著提升Top-K推荐指标，同时保持可扩展性和可解释性。

Conclusion: RLMultimodalRec是一种高效且实用的多模态推荐解决方案。

Abstract: Multimodal recommendation has emerged as a promising solution to alleviate
the cold-start and sparsity problems in collaborative filtering by
incorporating rich content information, such as product images and textual
descriptions. However, effectively integrating heterogeneous modalities into a
unified recommendation framework remains a challenge. Existing approaches often
rely on fixed fusion strategies or complex architectures , which may fail to
adapt to modality quality variance or introduce unnecessary computational
overhead.
  In this work, we propose RLMultimodalRec, a lightweight and modular
recommendation framework that combines graph-based user modeling with adaptive
multimodal item encoding. The model employs a gated fusion module to
dynamically balance the contribution of visual and textual modalities, enabling
fine-grained and content-aware item representations. Meanwhile, a two-layer
LightGCN encoder captures high-order collaborative signals by propagating
embeddings over the user-item interaction graph without relying on nonlinear
transformations.
  We evaluate our model on a real-world dataset from the Amazon product domain.
Experimental results demonstrate that RLMultimodalRec consistently outperforms
several competitive baselines, including collaborative filtering, visual-aware,
and multimodal GNN-based methods. The proposed approach achieves significant
improvements in top-K recommendation metrics while maintaining scalability and
interpretability, making it suitable for practical deployment.

</details>


### [540] [GLEN: Generative Retrieval via Lexical Index Learning](https://arxiv.org/abs/2311.03057)
*Sunkyung Lee,Minjin Choi,Jongwuk Lee*

Main category: cs.IR

TL;DR: GLEN是一种新的生成式检索方法，通过动态词汇标识符和两阶段索引学习策略解决现有方法的挑战，并在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 生成式检索避免了构建辅助索引结构，但面临预训练语言模型与标识符知识不匹配以及训练与推理之间的差距问题。

Method: GLEN采用动态词汇标识符和两阶段索引学习策略，学习有意义的词汇标识符和查询与文档之间的相关性信号。推理时使用无冲突推断和标识符权重排序。

Result: GLEN在NQ320k、MS MARCO和BEIR等基准数据集上达到或优于现有生成式检索方法的性能。

Conclusion: GLEN通过创新的索引学习和推理策略，有效解决了生成式检索的挑战，并在实验中表现出色。

Abstract: Generative retrieval shed light on a new paradigm of document retrieval,
aiming to directly generate the identifier of a relevant document for a query.
While it takes advantage of bypassing the construction of auxiliary index
structures, existing studies face two significant challenges: (i) the
discrepancy between the knowledge of pre-trained language models and
identifiers and (ii) the gap between training and inference that poses
difficulty in learning to rank. To overcome these challenges, we propose a
novel generative retrieval method, namely Generative retrieval via LExical
iNdex learning (GLEN). For training, GLEN effectively exploits a dynamic
lexical identifier using a two-phase index learning strategy, enabling it to
learn meaningful lexical identifiers and relevance signals between queries and
documents. For inference, GLEN utilizes collision-free inference, using
identifier weights to rank documents without additional overhead. Experimental
results prove that GLEN achieves state-of-the-art or competitive performance
against existing generative retrieval methods on various benchmark datasets,
e.g., NQ320k, MS MARCO, and BEIR. The code is available at
https://github.com/skleee/GLEN.

</details>


### [541] [Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers](https://arxiv.org/abs/2506.00054)
*Chaitanya Sharma*

Main category: cs.IR

TL;DR: 本文综述了检索增强生成（RAG）的最新进展，分析了其架构分类、优化方法、性能评估及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: RAG通过结合外部检索增强语言模型生成能力，解决了参数化知识存储的局限性，但面临检索质量、效率等新挑战。

Method: 文章提出RAG系统的分类法（检索器中心、生成器中心、混合和鲁棒性设计），并系统分析了检索优化、上下文过滤、解码控制等改进方法。

Result: 通过短形式和多跳问答任务的比较分析，揭示了检索精度与生成灵活性、效率与忠实性之间的权衡。

Conclusion: 总结了RAG研究的现状，并指出未来研究方向，如自适应检索架构、实时检索集成和多跳证据的结构化推理。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to
enhance large language models (LLMs) by conditioning generation on external
evidence retrieved at inference time. While RAG addresses critical limitations
of parametric knowledge storage-such as factual inconsistency and domain
inflexibility-it introduces new challenges in retrieval quality, grounding
fidelity, pipeline efficiency, and robustness against noisy or adversarial
inputs. This survey provides a comprehensive synthesis of recent advances in
RAG systems, offering a taxonomy that categorizes architectures into
retriever-centric, generator-centric, hybrid, and robustness-oriented designs.
We systematically analyze enhancements across retrieval optimization, context
filtering, decoding control, and efficiency improvements, supported by
comparative performance analyses on short-form and multi-hop question answering
tasks. Furthermore, we review state-of-the-art evaluation frameworks and
benchmarks, highlighting trends in retrieval-aware evaluation, robustness
testing, and federated retrieval settings. Our analysis reveals recurring
trade-offs between retrieval precision and generation flexibility, efficiency
and faithfulness, and modularity and coordination. We conclude by identifying
open challenges and future research directions, including adaptive retrieval
architectures, real-time retrieval integration, structured reasoning over
multi-hop evidence, and privacy-preserving retrieval mechanisms. This survey
aims to consolidate current knowledge in RAG research and serve as a foundation
for the next generation of retrieval-augmented language modeling systems.

</details>


### [542] [GPR: Empowering Generation with Graph-Pretrained Retriever](https://arxiv.org/abs/2506.00261)
*Xiaochen Wang,Zongyu Wu,Yuan Zhong,Xiang Zhang,Suhang Wang,Fenglong Ma*

Main category: cs.IR

TL;DR: GPR是一种基于知识图谱预训练的检索器，通过LLM引导的图增强和结构感知目标，提升检索质量和下游生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有检索器依赖纯文本预训练的语言模型，存在领域不对齐和结构忽视问题，限制了其在图检索增强生成中的效果。

Method: 提出GPR，直接在知识图谱上预训练，通过LLM引导的图增强对齐自然语言问题与相关子图，并采用结构感知目标学习细粒度检索策略。

Result: 在两个数据集、三个LLM主干和五个基线上的实验表明，GPR显著提升了检索质量和下游生成效果。

Conclusion: GPR是一种有效的图检索增强生成解决方案，具有鲁棒性。

Abstract: Graph retrieval-augmented generation (GRAG) places high demands on
graph-specific retrievers. However, existing retrievers often rely on language
models pretrained on plain text, limiting their effectiveness due to domain
misalignment and structure ignorance. To address these challenges, we propose
GPR, a graph-based retriever pretrained directly on knowledge graphs. GPR
aligns natural language questions with relevant subgraphs through LLM-guided
graph augmentation and employs a structure-aware objective to learn
fine-grained retrieval strategies. Experiments on two datasets, three LLM
backbones, and five baselines show that GPR consistently improves both
retrieval quality and downstream generation, demonstrating its effectiveness as
a robust retrieval solution for GRAG.

</details>


### [543] [Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval](https://arxiv.org/abs/2506.00363)
*Yubai Wei,Jiale Han,Yi Yang*

Main category: cs.IR

TL;DR: BMEmbed是一种新方法，通过利用BM25的关键词检索技术，将通用文本嵌入模型适配到私有数据集，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 通用文本嵌入模型在私有数据集（如公司专有数据）上表现不佳，因为这些数据包含专业术语和行话。

Method: 利用BM25的关键词检索结果构建监督信号，以适配模型。

Result: 实验表明，BMEmbed在多个领域、数据集和模型上均能提升检索性能。

Conclusion: BM25信号通过促进对齐和一致性改进嵌入，证明了该方法在适配领域特定数据中的价值。

Abstract: Text embedding models play a cornerstone role in AI applications, such as
retrieval-augmented generation (RAG). While general-purpose text embedding
models demonstrate strong performance on generic retrieval benchmarks, their
effectiveness diminishes when applied to private datasets (e.g.,
company-specific proprietary data), which often contain specialized terminology
and lingo. In this work, we introduce BMEmbed, a novel method for adapting
general-purpose text embedding models to private datasets. By leveraging the
well-established keyword-based retrieval technique (BM25), we construct
supervisory signals from the ranking of keyword-based retrieval results to
facilitate model adaptation. We evaluate BMEmbed across a range of domains,
datasets, and models, showing consistent improvements in retrieval performance.
Moreover, we provide empirical insights into how BM25-based signals contribute
to improving embeddings by fostering alignment and uniformity, highlighting the
value of this approach in adapting models to domain-specific data. We release
the source code available at https://github.com/BaileyWei/BMEmbed for the
research community.

</details>


### [544] [Bridging the Gap: From Ad-hoc to Proactive Search in Conversations](https://arxiv.org/abs/2506.00983)
*Chuan Meng,Francesco Tonolini,Fengran Mo,Nikolaos Aletras,Emine Yilmaz,Gabriella Kazai*

Main category: cs.IR

TL;DR: Conv2Query框架通过将对话上下文映射为ad-hoc查询，解决了PSC中输入不匹配的问题，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: PSC中直接使用对话上下文作为ad-hoc检索器输入存在输入不匹配问题，限制了检索质量。

Method: 提出Conv2Query框架，将对话上下文映射为ad-hoc查询，适配ad-hoc检索器。

Result: 在两个PSC数据集上的实验表明，Conv2Query显著提升了检索性能。

Conclusion: Conv2Query通过解决输入不匹配问题，有效提升了PSC的检索效果。

Abstract: Proactive search in conversations (PSC) aims to reduce user effort in
formulating explicit queries by proactively retrieving useful relevant
information given conversational context. Previous work in PSC either directly
uses this context as input to off-the-shelf ad-hoc retrievers or further
fine-tunes them on PSC data. However, ad-hoc retrievers are pre-trained on
short and concise queries, while the PSC input is longer and noisier. This
input mismatch between ad-hoc search and PSC limits retrieval quality. While
fine-tuning on PSC data helps, its benefits remain constrained by this input
gap. In this work, we propose Conv2Query, a novel conversation-to-query
framework that adapts ad-hoc retrievers to PSC by bridging the input gap
between ad-hoc search and PSC. Conv2Query maps conversational context into
ad-hoc queries, which can either be used as input for off-the-shelf ad-hoc
retrievers or for further fine-tuning on PSC data. Extensive experiments on two
PSC datasets show that Conv2Query significantly improves ad-hoc retrievers'
performance, both when used directly and after fine-tuning on PSC.

</details>


### [545] [GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion](https://arxiv.org/abs/2506.01673)
*Sunkyung Lee,Minjin Choi,Eunseong Choi,Hye-young Kim,Jongwuk Lee*

Main category: cs.IR

TL;DR: GRAM是一种生成式推荐模型，通过语义感知的多粒度延迟融合解决了现有研究中隐含项目关系和丰富但冗长项目信息的利用问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型在隐含项目关系和冗长项目信息利用方面存在不足，GRAM旨在解决这些问题。

Method: GRAM设计了语义到词汇的翻译和多粒度延迟融合方法，分别编码隐含关系和高效整合丰富语义。

Result: 在四个基准数据集上，GRAM在Recall@5和NDCG@5上显著优于现有模型，提升幅度为11.5-16.0%和5.3-13.6%。

Conclusion: GRAM通过创新方法有效提升了生成式推荐的性能，为未来研究提供了新思路。

Abstract: Generative recommendation is an emerging paradigm that leverages the
extensive knowledge of large language models by formulating recommendations
into a text-to-text generation task. However, existing studies face two key
limitations in (i) incorporating implicit item relationships and (ii) utilizing
rich yet lengthy item information. To address these challenges, we propose a
Generative Recommender via semantic-Aware Multi-granular late fusion (GRAM),
introducing two synergistic innovations. First, we design semantic-to-lexical
translation to encode implicit hierarchical and collaborative item
relationships into the vocabulary space of LLMs. Second, we present
multi-granular late fusion to integrate rich semantics efficiently with minimal
information loss. It employs separate encoders for multi-granular prompts,
delaying the fusion until the decoding stage. Experiments on four benchmark
datasets show that GRAM outperforms eight state-of-the-art generative
recommendation models, achieving significant improvements of 11.5-16.0% in
Recall@5 and 5.3-13.6% in NDCG@5. The source code is available at
https://github.com/skleee/GRAM.

</details>


### [546] [When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting Out-of-Distribution Corpora Using GradNormIR](https://arxiv.org/abs/2506.01877)
*Dayoon Ko,Jinyoung Kim,Sohyeon Kim,Jinhyuk Kim,Jaehoon Lee,Seonghak Song,Minyoung Lee,Gunhee Kim*

Main category: cs.IR

TL;DR: 提出了一种名为GradNormIR的无监督方法，通过梯度范数检测语料库是否超出密集检索器的分布范围，以提前管理检索器更新，提升检索系统的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的语料库持续演变，可能导致密集检索器的训练分布发生变化，若不及时更新或重新训练，新文档的索引会降低未来查询的检索性能。因此，识别何时需要更新检索器对维护系统性能至关重要。

Method: 提出了GradNormIR方法，利用梯度范数无监督地检测语料库是否超出密集检索器的分布范围。

Result: 在BEIR基准测试中，GradNormIR能够及时更新密集检索器，显著提升了检索的鲁棒性和效率。

Conclusion: GradNormIR为管理密集检索器的更新提供了一种有效方法，能够在语料库演变时主动检测并更新检索器，从而避免潜在的检索失败。

Abstract: Dense retrievers encode texts into embeddings to efficiently retrieve
relevant documents from large databases in response to user queries. However,
real-world corpora continually evolve, leading to a shift from the original
training distribution of the retriever. Without timely updates or retraining,
indexing newly emerging documents can degrade retrieval performance for future
queries. Thus, identifying when a dense retriever requires an update is
critical for maintaining robust retrieval systems. In this paper, we propose a
novel task of predicting whether a corpus is out-of-distribution (OOD) relative
to a dense retriever before indexing. Addressing this task allows us to
proactively manage retriever updates, preventing potential retrieval failures.
We introduce GradNormIR, an unsupervised approach that leverages gradient norms
to detect OOD corpora effectively. Experiments on the BEIR benchmark
demonstrate that GradNormIR enables timely updates of dense retrievers in
evolving document collections, significantly enhancing retrieval robustness and
efficiency.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [547] [The Disparate Effects of Partial Information in Bayesian Strategic Learning](https://arxiv.org/abs/2506.00627)
*Srikanth Avasarala,Serena Wang,Juba Ziani*

Main category: cs.GT

TL;DR: 研究评分规则的部分信息如何影响战略学习中的公平性，分析不同代理模型（天真和贝叶斯）在噪声信号下的行为差异及其对群体间结果差异的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨战略学习环境中，代理对评分规则的不完全信息如何导致群体间不公平，尤其是当群体在特征修改成本或先验信念上存在差异时。

Method: 比较天真代理（直接接受噪声信号）和贝叶斯代理（基于信号更新先验信念）的行为，分析不同透明度水平下群体间效用差异的变化。

Result: 天真代理的效用差异随噪声无限增长，低成本群体可能受损；贝叶斯代理的差异有界，且差异随噪声非单调变化，常在中透明度下最小。

Conclusion: 透明度水平对公平性有重要影响，天真代理易受噪声影响，而贝叶斯代理能更稳健地应对信息不完全性；群体间成本或信念差异进一步加剧不公平性。

Abstract: We study how partial information about scoring rules affects fairness in
strategic learning settings. In strategic learning, a learner deploys a scoring
rule, and agents respond strategically by modifying their features -- at some
cost -- to improve their outcomes. However, in our work, agents do not observe
the scoring rule directly; instead, they receive a noisy signal of said rule.
We consider two different agent models: (i) naive agents, who take the noisy
signal at face value, and (ii) Bayesian agents, who update a prior belief based
on the signal.
  Our goal is to understand how disparities in outcomes arise between groups
that differ in their costs of feature modification, and how these disparities
vary with the level of transparency of the learner's rule. For naive agents, we
show that utility disparities can grow unboundedly with noise, and that the
group with lower costs can, perhaps counter-intuitively, be disproportionately
harmed under limited transparency. In contrast, for Bayesian agents,
disparities remain bounded. We provide a full characterization of disparities
across groups as a function of the level of transparency and show that they can
vary non-monotonically with noise; in particular, disparities are often
minimized at intermediate levels of transparency. Finally, we extend our
analysis to settings where groups differ not only in cost, but also in prior
beliefs, and study how this asymmetry influences fairness.

</details>


### [548] [General search techniques without common knowledge for imperfect-information games, and application to superhuman Fog of War chess](https://arxiv.org/abs/2506.01242)
*Brian Hu Zhang,Tuomas Sandholm*

Main category: cs.GT

TL;DR: Obscuro是首个在Fog of War（FoW）象棋中实现超人类水平的AI，通过改进不完全信息游戏中的搜索技术，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 不完全信息象棋变体（如FoW象棋）是AI领域的重大挑战，需要解决信息收集、对手知识推理等问题。

Method: Obscuro引入了不完全信息游戏中的搜索技术改进，实现了强大且可扩展的推理能力。

Result: 实验表明，Obscuro在对抗现有最先进AI和人类顶尖玩家时表现显著更强。

Conclusion: FoW象棋是目前最大规模的不完全信息回合制游戏，Obscuro的成功标志着AI在该领域的重大突破。

Abstract: Since the advent of AI, games have served as progress benchmarks. Meanwhile,
imperfect-information variants of chess have existed for over a century,
present extreme challenges, and have been the focus of significant AI research.
Beyond calculation needed in regular chess, they require reasoning about
information gathering, the opponent's knowledge, signaling, etc. The most
popular variant, Fog of War (FoW) chess (aka. dark chess) is a recognized
challenge problem in AI after superhuman performance was reached in no-limit
Texas hold'em poker. We present Obscuro, the first superhuman AI for FoW chess.
It introduces advances to search in imperfect-information games, enabling
strong, scalable reasoning. Experiments against the prior state-of-the-art AI
and human players -- including the world's best -- show that Obscuro is
significantly stronger. FoW chess is the largest (by amount of imperfect
information) turn-based game in which superhuman performance has been achieved
and the largest game in which imperfect-information search has been
successfully applied.

</details>


### [549] [Online Competitive Information Gathering for Partially Observable Trajectory Games](https://arxiv.org/abs/2506.01927)
*Mel Krusniak,Hang Xu,Parker Palermo,Forrest Laine*

Main category: cs.GT

TL;DR: 论文提出了一种针对部分可观测随机博弈（POSG）的有限历史/视野细化方法，通过近似计算和粒子估计实现在线轨迹规划，并在多场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决完全连续POSG中规划问题的计算复杂性，避免离线计算或强假设，实现高效的信息获取行为。

Method: 提出有限历史/视野细化的POSG模型，结合粒子估计和随机梯度下降进行在线轨迹规划，并调整以适应多玩家和复杂环境。

Result: 在连续追逃和仓库拾取等场景中，方法表现出主动信息获取能力，优于被动策略。

Conclusion: 该方法为连续POSG中的在线规划提供了可行方案，适用于多玩家和复杂环境。

Abstract: Game-theoretic agents must make plans that optimally gather information about
their opponents. These problems are modeled by partially observable stochastic
games (POSGs), but planning in fully continuous POSGs is intractable without
heavy offline computation or assumptions on the order of belief maintained by
each player. We formulate a finite history/horizon refinement of POSGs which
admits competitive information gathering behavior in trajectory space, and
through a series of approximations, we present an online method for computing
rational trajectory plans in these games which leverages particle-based
estimations of the joint state space and performs stochastic gradient play. We
also provide the necessary adjustments required to deploy this method on
individual agents. The method is tested in continuous pursuit-evasion and
warehouse-pickup scenarios (alongside extensions to $N > 2$ players and to more
complex environments with visual and physical obstacles), demonstrating
evidence of active information gathering and outperforming passive competitors.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [550] [Detection of Endangered Deer Species Using UAV Imagery: A Comparative Study Between Efficient Deep Learning Approaches](https://arxiv.org/abs/2506.00154)
*Agustín Roca,Gastón Castro,Gabriel Torre,Leonardo J. Colombo,Ignacio Mas,Javier Pereira,Juan I. Giribet*

Main category: cs.CV

TL;DR: 比较YOLOv11和RT-DETR模型在无人机图像中检测沼泽鹿的性能，加入分割头提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 提升在目标占比小且被植被遮挡场景下的检测性能，为野生动物监测和保护提供技术支持。

Method: 扩展数据集并加入精确分割掩码，训练带分割头的YOLO模型。

Result: 加入分割头显著提升检测性能。

Conclusion: 为无人机野生动物监测提供了可扩展且精确的AI检测方案。

Abstract: This study compares the performance of state-of-the-art neural networks
including variants of the YOLOv11 and RT-DETR models for detecting marsh deer
in UAV imagery, in scenarios where specimens occupy a very small portion of the
image and are occluded by vegetation. We extend previous analysis adding
precise segmentation masks for our datasets enabling a fine-grained training of
a YOLO model with a segmentation head included. Experimental results show the
effectiveness of incorporating the segmentation head achieving superior
detection performance. This work contributes valuable insights for improving
UAV-based wildlife monitoring and conservation strategies through scalable and
accurate AI-driven detection systems.

</details>


### [551] [Ctrl-Crash: Controllable Diffusion for Realistic Car Crashes](https://arxiv.org/abs/2506.00227)
*Anthony Gosselin,Ge Ya Luo,Luis Lara,Florian Golemo,Derek Nowrouzezahrai,Liam Paull,Alexia Jolicoeur-Martineau,Christopher Pal*

Main category: cs.CV

TL;DR: Ctrl-Crash是一种可控的车祸视频生成模型，通过输入边界框、碰撞类型和初始帧等信号，生成高质量的车祸视频，支持反事实场景生成。


<details>
  <summary>Details</summary>
Motivation: 由于驾驶数据集中车祸事件稀缺，现有视频扩散技术难以生成真实的车祸图像，而提升交通安全需要可控且真实的事故模拟。

Method: 提出Ctrl-Crash模型，利用分类器自由引导技术，独立调整每个输入信号的权重，实现细粒度控制。

Result: 在定量指标（如FVD和JEDi）和人类评估的物理真实性与视频质量上，Ctrl-Crash表现优于现有扩散方法。

Conclusion: Ctrl-Crash为交通安全研究提供了高质量且可控的车祸视频生成工具。

Abstract: Video diffusion techniques have advanced significantly in recent years;
however, they struggle to generate realistic imagery of car crashes due to the
scarcity of accident events in most driving datasets. Improving traffic safety
requires realistic and controllable accident simulations. To tackle the
problem, we propose Ctrl-Crash, a controllable car crash video generation model
that conditions on signals such as bounding boxes, crash types, and an initial
image frame. Our approach enables counterfactual scenario generation where
minor variations in input can lead to dramatically different crash outcomes. To
support fine-grained control at inference time, we leverage classifier-free
guidance with independently tunable scales for each conditioning signal.
Ctrl-Crash achieves state-of-the-art performance across quantitative video
quality metrics (e.g., FVD and JEDi) and qualitative measurements based on a
human-evaluation of physical realism and video quality compared to prior
diffusion-based methods.

</details>


### [552] [Latent Guidance in Diffusion Models for Perceptual Evaluations](https://arxiv.org/abs/2506.00327)
*Shreshth Saini,Ru-Ling Liao,Yan Ye,Alan C. Bovik*

Main category: cs.CV

TL;DR: 本文提出了一种名为Perceptual Manifold Guidance (PMG)的算法，利用预训练的潜在扩散模型和感知质量特征，在无参考图像质量评估（NR-IQA）任务中实现感知一致性。实验表明，该方法在IQA数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管潜在扩散模型在高维图像生成和下游任务中取得了进展，但在NR-IQA任务中感知一致性的研究较少。本文假设这些模型在数据流形中隐含表现出感知一致的局部区域，并利用这一特性进行引导采样。

Method: 提出PMG算法，利用预训练的潜在扩散模型和感知质量特征，从去噪U-Net中提取感知一致的多尺度和多时间步特征图。

Result: 实验证明，这些超特征与人类感知在IQA任务中高度相关，且方法在IQA数据集上达到了最先进的性能。

Conclusion: 本文首次将感知特征用于引导扩散模型进行NR-IQA任务，展示了扩散模型在NR-IQA任务中的优越泛化能力。

Abstract: Despite recent advancements in latent diffusion models that generate
high-dimensional image data and perform various downstream tasks, there has
been little exploration into perceptual consistency within these models on the
task of No-Reference Image Quality Assessment (NR-IQA). In this paper, we
hypothesize that latent diffusion models implicitly exhibit perceptually
consistent local regions within the data manifold. We leverage this insight to
guide on-manifold sampling using perceptual features and input measurements.
Specifically, we propose Perceptual Manifold Guidance (PMG), an algorithm that
utilizes pretrained latent diffusion models and perceptual quality features to
obtain perceptually consistent multi-scale and multi-timestep feature maps from
the denoising U-Net. We empirically demonstrate that these hyperfeatures
exhibit high correlation with human perception in IQA tasks. Our method can be
applied to any existing pretrained latent diffusion model and is
straightforward to integrate. To the best of our knowledge, this paper is the
first work on guiding diffusion model with perceptual features for NR-IQA.
Extensive experiments on IQA datasets show that our method, LGDM, achieves
state-of-the-art performance, underscoring the superior generalization
capabilities of diffusion models for NR-IQA tasks.

</details>


### [553] [Parallel Rescaling: Rebalancing Consistency Guidance for Personalized Diffusion Models](https://arxiv.org/abs/2506.00607)
*JungWoo Chae,Jiyoon Kim,Sangheum Hwang*

Main category: cs.CV

TL;DR: 提出一种并行重缩放技术，用于个性化扩散模型，通过分解一致性指导信号以改进提示对齐和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DreamBooth和Textual Inversion）在有限数据下容易过拟合，导致生成图像与文本提示不一致，尤其是在复杂或风格化提示下表现不佳。

Method: 提出并行重缩放技术，将一致性指导信号分解为与分类器自由指导（CFG）平行和正交的分量，并通过重缩放平行分量减少对CFG的干扰。

Result: 实验表明，该方法在提示对齐和视觉保真度上优于基线方法，尤其在风格化提示下表现更优。

Conclusion: 并行重缩放指导技术能更稳定、准确地实现个性化扩散模型，适用于多样化的用户输入。

Abstract: Personalizing diffusion models to specific users or concepts remains
challenging, particularly when only a few reference images are available.
Existing methods such as DreamBooth and Textual Inversion often overfit to
limited data, causing misalignment between generated images and text prompts
when attempting to balance identity fidelity with prompt adherence. While
Direct Consistency Optimization (DCO) with its consistency-guided sampling
partially alleviates this issue, it still struggles with complex or stylized
prompts. In this paper, we propose a parallel rescaling technique for
personalized diffusion models. Our approach explicitly decomposes the
consistency guidance signal into parallel and orthogonal components relative to
classifier free guidance (CFG). By rescaling the parallel component, we
minimize disruptive interference with CFG while preserving the subject's
identity. Unlike prior personalization methods, our technique does not require
additional training data or expensive annotations. Extensive experiments show
improved prompt alignment and visual fidelity compared to baseline methods,
even on challenging stylized prompts. These findings highlight the potential of
parallel rescaled guidance to yield more stable and accurate personalization
for diverse user inputs.

</details>


### [554] [Text-to-CT Generation via 3D Latent Diffusion Model with Contrastive Vision-Language Pretraining](https://arxiv.org/abs/2506.00633)
*Daniele Molino,Camillo Maria Caruso,Filippo Ruffini,Paolo Soda,Valerio Guarrasi*

Main category: cs.CV

TL;DR: 该论文提出了一种结合潜在扩散模型和3D对比视觉语言预训练方案的新架构，用于从文本生成CT图像，解决了3D医学影像生成中的高维度和解剖复杂性挑战。


<details>
  <summary>Details</summary>
Motivation: 扩展文本到图像生成技术至3D医学影像（如CT）仍面临高维度、解剖复杂性和缺乏视觉语言对齐框架的挑战。

Method: 采用双编码器CLIP风格模型和预训练的3D VAE，结合潜在扩散模型，实现高效的3D去噪扩散生成。

Result: 在CT-RATE数据集上评估，模型在图像保真度、临床相关性和语义对齐方面表现优异，显著优于基线方法，并能有效增强下游诊断性能。

Conclusion: 研究表明，特定模态的视觉语言对齐是高质量3D医学影像生成的关键，该方法为数据增强、医学教育和临床模拟提供了可控且可扩展的解决方案。

Abstract: Objective: While recent advances in text-conditioned generative models have
enabled the synthesis of realistic medical images, progress has been largely
confined to 2D modalities such as chest X-rays. Extending text-to-image
generation to volumetric Computed Tomography (CT) remains a significant
challenge, due to its high dimensionality, anatomical complexity, and the
absence of robust frameworks that align vision-language data in 3D medical
imaging. Methods: We introduce a novel architecture for Text-to-CT generation
that combines a latent diffusion model with a 3D contrastive vision-language
pretraining scheme. Our approach leverages a dual-encoder CLIP-style model
trained on paired CT volumes and radiology reports to establish a shared
embedding space, which serves as the conditioning input for generation. CT
volumes are compressed into a low-dimensional latent space via a pretrained
volumetric VAE, enabling efficient 3D denoising diffusion without requiring
external super-resolution stages. Results: We evaluate our method on the
CT-RATE dataset and conduct a comprehensive assessment of image fidelity,
clinical relevance, and semantic alignment. Our model achieves competitive
performance across all tasks, significantly outperforming prior baselines for
text-to-CT generation. Moreover, we demonstrate that CT scans synthesized by
our framework can effectively augment real data, improving downstream
diagnostic performance. Conclusion: Our results show that modality-specific
vision-language alignment is a key component for high-quality 3D medical image
generation. By integrating contrastive pretraining and volumetric diffusion,
our method offers a scalable and controllable solution for synthesizing
clinically meaningful CT volumes from text, paving the way for new applications
in data augmentation, medical education, and automated clinical simulation.

</details>


### [555] [From Local Cues to Global Percepts: Emergent Gestalt Organization in Self-Supervised Vision Models](https://arxiv.org/abs/2506.00718)
*Tianqin Li,Ziqi Wen,Leiran Song,Jun Liu,Zhi Jing,Tai Sing Lee*

Main category: cs.CV

TL;DR: 论文研究了现代视觉模型是否表现出类似人类视觉的Gestalt原则行为，并探讨了训练条件对其影响。发现自监督训练的ViTs和ConvNeXt模型表现出Gestalt感知能力，但分类微调会削弱这种能力。


<details>
  <summary>Details</summary>
Motivation: 探究现代视觉模型是否能够像人类视觉一样利用Gestalt原则（如闭合、邻近性）组织全局空间结构。

Method: 使用Masked Autoencoding（MAE）训练Vision Transformers（ViTs）和ConvNeXt模型，并引入Distorted Spatial Relationship Testbench（DiSRT）评估模型对全局空间扰动的敏感性。

Result: 自监督模型（如MAE、CLIP）在DiSRT测试中表现优于监督基线，甚至有时超过人类表现。分类微调会削弱Gestalt感知能力，但Top-K激活稀疏机制可恢复。

Conclusion: 研究确定了促进或抑制Gestalt感知的训练条件，并验证了DiSRT作为评估模型全局结构敏感性的有效工具。

Abstract: Human vision organizes local cues into coherent global forms using Gestalt
principles like closure, proximity, and figure-ground assignment -- functions
reliant on global spatial structure. We investigate whether modern vision
models show similar behaviors, and under what training conditions these emerge.
We find that Vision Transformers (ViTs) trained with Masked Autoencoding (MAE)
exhibit activation patterns consistent with Gestalt laws, including illusory
contour completion, convexity preference, and dynamic figure-ground
segregation. To probe the computational basis, we hypothesize that modeling
global dependencies is necessary for Gestalt-like organization. We introduce
the Distorted Spatial Relationship Testbench (DiSRT), which evaluates
sensitivity to global spatial perturbations while preserving local textures.
Using DiSRT, we show that self-supervised models (e.g., MAE, CLIP) outperform
supervised baselines and sometimes even exceed human performance. ConvNeXt
models trained with MAE also exhibit Gestalt-compatible representations,
suggesting such sensitivity can arise without attention architectures. However,
classification finetuning degrades this ability. Inspired by biological vision,
we show that a Top-K activation sparsity mechanism can restore global
sensitivity. Our findings identify training conditions that promote or suppress
Gestalt-like perception and establish DiSRT as a diagnostic for global
structure sensitivity across models.

</details>


### [556] [ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary](https://arxiv.org/abs/2506.00742)
*Zeqi Gu,Yin Cui,Zhaoshuo Li,Fangyin Wei,Yunhao Ge,Jinwei Gu,Ming-Yu Liu,Abe Davis,Yifan Ding*

Main category: cs.CV

TL;DR: ArtiScene利用文本生成2D图像作为中介，指导3D场景合成，无需额外训练，显著提升了布局和美学质量。


<details>
  <summary>Details</summary>
Motivation: 传统3D场景设计需要专业技能和复杂软件，而现有文本到3D生成方法受限于高质量3D数据的稀缺性。

Method: 通过文本生成2D图像，从中提取形状和外观信息构建3D模型，并基于图像信息组装场景。

Result: ArtiScene在布局和美学质量上大幅领先现有方法，用户研究胜率达74.89%，GPT-4o评估胜率达95.07%。

Conclusion: 利用2D图像作为中介的ArtiScene提供了一种高效、灵活的3D场景设计方法，具有广泛适用性。

Abstract: Designing 3D scenes is traditionally a challenging task that demands both
artistic expertise and proficiency with complex software. Recent advances in
text-to-3D generation have greatly simplified this process by letting users
create scenes based on simple text descriptions. However, as these methods
generally require extra training or in-context learning, their performance is
often hindered by the limited availability of high-quality 3D data. In
contrast, modern text-to-image models learned from web-scale images can
generate scenes with diverse, reliable spatial layouts and consistent, visually
appealing styles. Our key insight is that instead of learning directly from 3D
scenes, we can leverage generated 2D images as an intermediary to guide 3D
synthesis. In light of this, we introduce ArtiScene, a training-free automated
pipeline for scene design that integrates the flexibility of free-form
text-to-image generation with the diversity and reliability of 2D intermediary
layouts.
  First, we generate 2D images from a scene description, then extract the shape
and appearance of objects to create 3D models. These models are assembled into
the final scene using geometry, position, and pose information derived from the
same intermediary image. Being generalizable to a wide range of scenes and
styles, ArtiScene outperforms state-of-the-art benchmarks by a large margin in
layout and aesthetic quality by quantitative metrics. It also averages a 74.89%
winning rate in extensive user studies and 95.07% in GPT-4o evaluation. Project
page: https://artiscene-cvpr.github.io/

</details>


### [557] [L3A: Label-Augmented Analytic Adaptation for Multi-Label Class Incremental Learning](https://arxiv.org/abs/2506.00816)
*Xiang Zhang,Run He,Jiao Chen,Di Fang,Ming Li,Ziqian Zeng,Cen Chen,Huiping Zhuang*

Main category: cs.CV

TL;DR: 论文提出了一种名为L3A的方法，用于解决多标签增量学习中的标签缺失和类别不平衡问题，无需存储历史样本。


<details>
  <summary>Details</summary>
Motivation: 多标签增量学习（MLCIL）面临标签缺失和类别不平衡的挑战，需要一种无需存储历史样本的解决方案。

Method: L3A包含两个模块：伪标签模块（PL）通过生成伪标签解决标签缺失问题；加权分析分类器（WAC）通过样本特定权重平衡类别贡献。

Result: 在MS-COCO和PASCAL VOC数据集上的实验表明，L3A优于现有方法。

Conclusion: L3A是一种有效的多标签增量学习方法，解决了标签缺失和类别不平衡问题。

Abstract: Class-incremental learning (CIL) enables models to learn new classes
continually without forgetting previously acquired knowledge. Multi-label CIL
(MLCIL) extends CIL to a real-world scenario where each sample may belong to
multiple classes, introducing several challenges: label absence, which leads to
incomplete historical information due to missing labels, and class imbalance,
which results in the model bias toward majority classes. To address these
challenges, we propose Label-Augmented Analytic Adaptation (L3A), an
exemplar-free approach without storing past samples. L3A integrates two key
modules. The pseudo-label (PL) module implements label augmentation by
generating pseudo-labels for current phase samples, addressing the label
absence problem. The weighted analytic classifier (WAC) derives a closed-form
solution for neural networks. It introduces sample-specific weights to
adaptively balance the class contribution and mitigate class imbalance.
Experiments on MS-COCO and PASCAL VOC datasets demonstrate that L3A outperforms
existing methods in MLCIL tasks. Our code is available at
https://github.com/scut-zx/L3A.

</details>


### [558] [ZeShot-VQA: Zero-Shot Visual Question Answering Framework with Answer Mapping for Natural Disaster Damage Assessment](https://arxiv.org/abs/2506.00238)
*Ehsan Karimi,Maryam Rahnemoonfar*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型（VLM）的零样本视觉问答（ZeShot-VQA）方法，用于自然灾害后的快速响应，无需微调即可处理新数据集和未见过的答案。


<details>
  <summary>Details</summary>
Motivation: 自然灾害响应需要高效的数据驱动方法，现有视觉问答模型无法处理开放性问题且需微调，限制了灵活性。

Method: 利用大规模视觉语言模型（VLMs）的零样本学习能力，提出ZeShot-VQA方法，并在FloodNet数据集上验证性能。

Result: ZeShot-VQA无需微调即可处理新数据集，并能生成未见过的答案，展示了其灵活性。

Conclusion: ZeShot-VQA为自然灾害响应提供了一种高效且灵活的视觉问答解决方案。

Abstract: Natural disasters usually affect vast areas and devastate infrastructures.
Performing a timely and efficient response is crucial to minimize the impact on
affected communities, and data-driven approaches are the best choice. Visual
question answering (VQA) models help management teams to achieve in-depth
understanding of damages. However, recently published models do not possess the
ability to answer open-ended questions and only select the best answer among a
predefined list of answers. If we want to ask questions with new additional
possible answers that do not exist in the predefined list, the model needs to
be fin-tuned/retrained on a new collected and annotated dataset, which is a
time-consuming procedure. In recent years, large-scale Vision-Language Models
(VLMs) have earned significant attention. These models are trained on extensive
datasets and demonstrate strong performance on both unimodal and multimodal
vision/language downstream tasks, often without the need for fine-tuning. In
this paper, we propose a VLM-based zero-shot VQA (ZeShot-VQA) method, and
investigate the performance of on post-disaster FloodNet dataset. Since the
proposed method takes advantage of zero-shot learning, it can be applied on new
datasets without fine-tuning. In addition, ZeShot-VQA is able to process and
generate answers that has been not seen during the training procedure, which
demonstrates its flexibility.

</details>


### [559] [Towards Predicting Any Human Trajectory In Context](https://arxiv.org/abs/2506.00871)
*Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: TrajICL是一种基于上下文学习的行人轨迹预测框架，无需微调即可快速适应不同场景，通过时空相似性和预测引导的示例选择方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的行人轨迹预测方法通常需要针对特定场景进行微调，这在边缘设备上计算资源受限时难以实现。TrajICL旨在解决这一问题。

Method: 提出了时空相似性示例选择（STES）和预测引导示例选择（PG-ES）方法，结合大规模合成数据集训练模型。

Result: TrajICL在多个公共基准测试中表现优异，适应性强，甚至优于微调方法。

Conclusion: TrajICL通过上下文学习和示例选择方法，实现了高效的行人轨迹预测，适用于跨域场景。

Abstract: Predicting accurate future trajectories of pedestrians is essential for
autonomous systems but remains a challenging task due to the need for
adaptability in different environments and domains. A common approach involves
collecting scenario-specific data and performing fine-tuning via
backpropagation. However, this process is often impractical on edge devices due
to constrained computational resources. To address this challenge, we introduce
TrajICL, an In-Context Learning (ICL) framework for pedestrian trajectory
prediction that enables rapid adaptation without fine-tuning on the
scenario-specific data. We propose a spatio-temporal similarity-based example
selection (STES) method that selects relevant examples from previously observed
trajectories within the same scene by identifying similar motion patterns at
corresponding locations. To further refine this selection, we introduce
prediction-guided example selection (PG-ES), which selects examples based on
both the past trajectory and the predicted future trajectory, rather than
relying solely on the past trajectory. This approach allows the model to
account for long-term dynamics when selecting examples. Finally, instead of
relying on small real-world datasets with limited scenario diversity, we train
our model on a large-scale synthetic dataset to enhance its prediction ability
by leveraging in-context examples. Extensive experiments demonstrate that
TrajICL achieves remarkable adaptation across both in-domain and cross-domain
scenarios, outperforming even fine-tuned approaches across multiple public
benchmarks. The code will be released at
https://fujiry0.github.io/TrajICL-project-page.

</details>


### [560] [Uneven Event Modeling for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.00891)
*Sa Zhu,Huashan Chen,Wanqian Zhang,Jinchao Zhang,Zexian Yang,Xiaoshuai Hao,Bo Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为UEM的框架，通过PGVS模块和CAER模块解决了PRVR任务中事件边界模糊和文本-视频对齐不精确的问题，并在实验中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在部分相关视频检索（PRVR）中通常将视频分割为固定长度的片段，导致事件边界模糊，且使用平均池化计算事件表示，引入不精确的对齐。

Method: 提出UEM框架，包含PGVS模块（基于时间和语义相似性迭代分割事件）和CAER模块（通过文本交叉注意力优化事件表示）。

Result: 在两个PRVR基准测试中取得了最先进的性能。

Conclusion: UEM框架通过明确事件边界和优化事件表示，显著提升了PRVR任务的性能。

Abstract: Given a text query, partially relevant video retrieval (PRVR) aims to
retrieve untrimmed videos containing relevant moments, wherein event modeling
is crucial for partitioning the video into smaller temporal events that
partially correspond to the text. Previous methods typically segment videos
into a fixed number of equal-length clips, resulting in ambiguous event
boundaries. Additionally, they rely on mean pooling to compute event
representations, inevitably introducing undesired misalignment. To address
these, we propose an Uneven Event Modeling (UEM) framework for PRVR. We first
introduce the Progressive-Grouped Video Segmentation (PGVS) module, to
iteratively formulate events in light of both temporal dependencies and
semantic similarity between consecutive frames, enabling clear event
boundaries. Furthermore, we also propose the Context-Aware Event Refinement
(CAER) module to refine the event representation conditioned the text's
cross-attention. This enables event representations to focus on the most
relevant frames for a given text, facilitating more precise text-video
alignment. Extensive experiments demonstrate that our method achieves
state-of-the-art performance on two PRVR benchmarks.

</details>


### [561] [HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models](https://arxiv.org/abs/2506.00805)
*Songtao Jiang,Yan Zhang,Yeying Jin,Zhihang Tang,Yangyang Wu,Yang Feng,Jian Wu,Zuozhu Liu*

Main category: cs.CV

TL;DR: 提出了一种名为HSCR的新方法，通过分层自对比奖励解决Med-VLMs中的模态不对齐问题，显著提升了模型的对齐性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有Med-VLMs方法忽视了模态不对齐问题，导致临床场景中不可靠的响应。

Method: HSCR利用Med-VLMs生成不偏好响应，通过视觉标记丢弃分析模态耦合标记，并引入多级偏好优化策略。

Result: 实验表明，HSCR在多种医疗任务中提升了零样本性能，仅需2000条训练数据即可显著改善对齐性和可信度。

Conclusion: HSCR为Med-VLMs的对齐问题提供了一种高效且高质量的解决方案。

Abstract: Medical Vision-Language Models (Med-VLMs) have achieved success across
various tasks, yet most existing methods overlook the modality misalignment
issue that can lead to untrustworthy responses in clinical settings. In this
paper, we propose Hierarchical Self-Contrastive Rewarding (HSCR), a novel
approach that addresses two critical challenges in Med-VLM alignment: 1)
Cost-effective generation of high-quality preference data; 2) Capturing nuanced
and context-aware preferences for improved alignment. HSCR first leverages the
inherent capability of Med-VLMs to generate dispreferred responses with higher
sampling probability. By analyzing output logit shifts after visual token
dropout, we identify modality-coupled tokens that induce misalignment and
derive an implicit alignment reward function. This function guides token
replacement with hallucinated ones during decoding, producing high-quality
dispreferred data. Furthermore, HSCR introduces a multi-level preference
optimization strategy, which extends beyond traditional adjacent-level
optimization by incorporating nuanced implicit preferences, leveraging relative
quality in dispreferred data to capture subtle alignment cues for more precise
and context-aware optimization. Extensive experiments across multiple medical
tasks, including Med-VQA, medical image captioning and instruction following,
demonstrate that HSCR not only enhances zero-shot performance but also
significantly improves modality alignment and trustworthiness with just 2,000
training entries.

</details>


### [562] [IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection](https://arxiv.org/abs/2506.00979)
*Wayne Zhang,Changjiang Jiang,Zhonghao Zhang,Chenyang Si,Fengchang Yu,Wei Peng*

Main category: cs.CV

TL;DR: 论文提出了一种名为IVY-FAKE的统一、可解释的多模态AIGC检测数据集，并基于此设计了IVY-XDETECTOR检测架构，实现了图像和视频的统一检测与解释。


<details>
  <summary>Details</summary>
Motivation: 当前AIGC检测方法多为黑盒二分类器，缺乏可解释性，且无法统一检测图像和视频。这些问题降低了模型的透明度和可信度，限制了实际应用。

Method: 提出了IVY-FAKE数据集，包含15万标注样本和1.87万评估样本，并设计了IVY-XDETECTOR架构，结合视觉-语言模型实现统一检测与解释。

Result: IVY-XDETECTOR在多个图像和视频检测基准上达到了最先进的性能。

Conclusion: IVY-FAKE数据集和IVY-XDETECTOR架构显著提升了AIGC检测的可解释性和统一性，为实际部署提供了支持。

Abstract: The rapid advancement of Artificial Intelligence Generated Content (AIGC) in
visual domains has resulted in highly realistic synthetic images and videos,
driven by sophisticated generative frameworks such as diffusion-based
architectures. While these breakthroughs open substantial opportunities, they
simultaneously raise critical concerns about content authenticity and
integrity. Many current AIGC detection methods operate as black-box binary
classifiers, which offer limited interpretability, and no approach supports
detecting both images and videos in a unified framework. This dual limitation
compromises model transparency, reduces trustworthiness, and hinders practical
deployment. To address these challenges, we introduce IVY-FAKE , a novel,
unified, and large-scale dataset specifically designed for explainable
multimodal AIGC detection. Unlike prior benchmarks, which suffer from
fragmented modality coverage and sparse annotations, IVY-FAKE contains over
150,000 richly annotated training samples (images and videos) and 18,700
evaluation examples, each accompanied by detailed natural-language reasoning
beyond simple binary labels. Building on this, we propose Ivy Explainable
Detector (IVY-XDETECTOR), a unified AIGC detection and explainable architecture
that jointly performs explainable detection for both image and video content.
Our unified vision-language model achieves state-of-the-art performance across
multiple image and video detection benchmarks, highlighting the significant
advancements enabled by our dataset and modeling framework. Our data is
publicly available at https://huggingface.co/datasets/AI-Safeguard/Ivy-Fake.

</details>


### [563] [Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times](https://arxiv.org/abs/2506.00928)
*Olga Loginova,Sofía Ortega Loguinova*

Main category: cs.CV

TL;DR: 论文介绍了多语言数据集Perfect Times，用于评估视频-语言模型在时间推理上的表现，发现现有模型难以模拟人类的时间与因果推理。


<details>
  <summary>Details</summary>
Motivation: 人类通过语言和视觉线索区分已完成和进行中的动作，但现有模型在此类时间推理任务上表现不佳。

Method: 构建了多语言（英语、意大利语、俄语、日语）选择题数据集Perfect Times，结合视频和事件完成标签，测试模型的时间推理能力。

Result: 实验显示，尽管模型在文本任务上表现优异，但在基于视频的时间与因果推理上仍落后于人类。

Conclusion: 研究强调需整合多模态线索以提升模型对动作持续性和完成性的理解，为时间推理评估设定了新标准。

Abstract: Human perception of events is intrinsically tied to distinguishing between
completed (perfect and telic) and ongoing (durative) actions, a process
mediated by both linguistic structure and visual cues. In this work, we
introduce the \textbf{Perfect Times} dataset, a novel, quadrilingual (English,
Italian, Russian, and Japanese) multiple-choice question-answering benchmark
designed to assess video-language models (VLMs) on temporal reasoning. By
pairing everyday activity videos with event completion labels and
perfectivity-tailored distractors, our dataset probes whether models truly
comprehend temporal dynamics or merely latch onto superficial markers.
Experimental results indicate that state-of-the-art models, despite their
success on text-based tasks, struggle to mirror human-like temporal and causal
reasoning grounded in video. This study underscores the necessity of
integrating deep multimodal cues to capture the nuances of action duration and
completion within temporal and causal video dynamics, setting a new standard
for evaluating and advancing temporal reasoning in VLMs.

</details>


### [564] [Quotient Network -- A Network Similar to ResNet but Learning Quotients](https://arxiv.org/abs/2506.00992)
*Peng Hui,Jiamuyang Zhao,Changxin Li,Qingzhen Zhu*

Main category: cs.CV

TL;DR: 论文提出了一种基于商数学习的新型网络（商数网络），解决了ResNet中特征差异学习的问题，并在不增加参数的情况下显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: ResNet通过特征差异学习训练深度网络，但差异学习缺乏独立意义且对特征大小敏感。本文旨在解决这些问题，同时保留ResNet的优势。

Method: 提出商数网络，学习目标特征与现有特征的商数而非差异，并设计了相应的训练规则以确保高效学习和性能提升。

Result: 在CIFAR10、CIFAR100和SVHN数据集上的实验表明，商数网络在不增加参数的情况下显著优于ResNet。

Conclusion: 商数网络通过改进特征学习方式，稳定提升了性能，为深度网络训练提供了新思路。

Abstract: The emergence of ResNet provides a powerful tool for training extremely deep
networks. The core idea behind it is to change the learning goals of the
network. It no longer learns new features from scratch but learns the
difference between the target and existing features. However, the difference
between the two kinds of features does not have an independent and clear
meaning, and the amount of learning is based on the absolute rather than the
relative difference, which is sensitive to the size of existing features. We
propose a new network that perfectly solves these two problems while still
having the advantages of ResNet. Specifically, it chooses to learn the quotient
of the target features with the existing features, so we call it the quotient
network. In order to enable this network to learn successfully and achieve
higher performance, we propose some design rules for this network so that it
can be trained efficiently and achieve better performance than ResNet.
Experiments on the CIFAR10, CIFAR100, and SVHN datasets prove that this network
can stably achieve considerable improvements over ResNet by simply making tiny
corresponding changes to the original ResNet network without adding new
parameters.

</details>


### [565] [Motion-Aware Concept Alignment for Consistent Video Editing](https://arxiv.org/abs/2506.01004)
*Tong Zhang,Juan C Leon Alcazar,Bernard Ghanem*

Main category: cs.CV

TL;DR: MoCA-Video是一种无需训练的视频语义混合框架，通过参考图像将语义特征注入视频中的特定对象，同时保持原始运动和视觉上下文。


<details>
  <summary>Details</summary>
Motivation: 解决图像域语义混合与视频之间的差距，实现无需训练的高质量视频合成。

Method: 利用对角去噪计划和类无关分割在潜在空间中检测和跟踪对象，结合动量语义校正和伽马残差噪声稳定确保时间连贯性。

Result: 在SSIM、LPIPS和新型指标CASS上表现优异，优于现有基线，实现空间一致性和连贯运动。

Conclusion: MoCA-Video证明通过结构化操作扩散噪声轨迹可实现可控、高质量的视频合成。

Abstract: We introduce MoCA-Video (Motion-Aware Concept Alignment in Video), a
training-free framework bridging the gap between image-domain semantic mixing
and video. Given a generated video and a user-provided reference image,
MoCA-Video injects the semantic features of the reference image into a specific
object within the video, while preserving the original motion and visual
context. Our approach leverages a diagonal denoising schedule and
class-agnostic segmentation to detect and track objects in the latent space and
precisely control the spatial location of the blended objects. To ensure
temporal coherence, we incorporate momentum-based semantic corrections and
gamma residual noise stabilization for smooth frame transitions. We evaluate
MoCA's performance using the standard SSIM, image-level LPIPS, temporal LPIPS,
and introduce a novel metric CASS (Conceptual Alignment Shift Score) to
evaluate the consistency and effectiveness of the visual shifts between the
source prompt and the modified video frames. Using self-constructed dataset,
MoCA-Video outperforms current baselines, achieving superior spatial
consistency, coherent motion, and a significantly higher CASS score, despite
having no training or fine-tuning. MoCA-Video demonstrates that structured
manipulation in the diffusion noise trajectory allows for controllable,
high-quality video synthesis.

</details>


### [566] [Abstractive Visual Understanding of Multi-modal Structured Knowledge: A New Perspective for MLLM Evaluation](https://arxiv.org/abs/2506.01293)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Yajing Xu,Min Zhang,Wen Zhang,Huajun Chen*

Main category: cs.CV

TL;DR: 论文提出了一种新的评估范式M3STR，用于测试多模态大语言模型（MLLMs）对结构化视觉知识的理解能力，填补了现有评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs评估主要忽略了对结构化视觉知识的理解能力，作者希望通过M3STR填补这一空白。

Method: 设计了基于多模态知识图谱的M3STR基准，要求MLLMs识别视觉输入中的多模态实体并解析其关系拓扑。

Result: 对26种先进MLLMs的测试显示，它们在处理结构化视觉知识时仍存在明显不足。

Conclusion: M3STR为提升MLLMs的整体推理能力指明了方向，代码和数据已开源。

Abstract: Multi-modal large language models (MLLMs) incorporate heterogeneous
modalities into LLMs, enabling a comprehensive understanding of diverse
scenarios and objects. Despite the proliferation of evaluation benchmarks and
leaderboards for MLLMs, they predominantly overlook the critical capacity of
MLLMs to comprehend world knowledge with structured abstractions that appear in
visual form. To address this gap, we propose a novel evaluation paradigm and
devise M3STR, an innovative benchmark grounded in the Multi-Modal Map for
STRuctured understanding. This benchmark leverages multi-modal knowledge graphs
to synthesize images encapsulating subgraph architectures enriched with
multi-modal entities. M3STR necessitates that MLLMs not only recognize the
multi-modal entities within the visual inputs but also decipher intricate
relational topologies among them. We delineate the benchmark's statistical
profiles and automated construction pipeline, accompanied by an extensive
empirical analysis of 26 state-of-the-art MLLMs. Our findings reveal persistent
deficiencies in processing abstractive visual information with structured
knowledge, thereby charting a pivotal trajectory for advancing MLLMs' holistic
reasoning capacities. Our code and data are released at
https://github.com/zjukg/M3STR

</details>


### [567] [Fighting Fire with Fire (F3): A Training-free and Efficient Visual Adversarial Example Purification Method in LVLMs](https://arxiv.org/abs/2506.01064)
*Yudong Zhang,Ruobing Xie,Yiqing Huang,Jiansheng Chen,Xingwu Sun,Zhanhui Kang,Di Wang,Yu Wang*

Main category: cs.CV

TL;DR: F3是一种对抗性净化框架，通过引入简单扰动来减轻对抗性样本的有害影响，无需训练且高效。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）易受视觉对抗攻击影响，现有净化方法研究不足。

Method: F3采用“以火攻火”策略，通过随机扰动对抗样本并利用跨模态注意力优化注意力机制。

Result: F3显著提升了对抗性样本的净化效果，且计算效率高。

Conclusion: F3适用于大规模工业应用，兼具鲁棒性和高效性。

Abstract: Recent advances in large vision-language models (LVLMs) have showcased their
remarkable capabilities across a wide range of multimodal vision-language
tasks. However, these models remain vulnerable to visual adversarial attacks,
which can substantially compromise their performance. Despite their potential
impact, the development of effective methods for purifying such adversarial
examples has received relatively limited attention. In this paper, we introduce
F3, a novel adversarial purification framework that employs a counterintuitive
"fighting fire with fire" strategy: intentionally introducing simple
perturbations to adversarial examples to mitigate their harmful effects.
Specifically, F3 leverages cross-modal attentions derived from randomly
perturbed adversary examples as reference targets. By injecting noise into
these adversarial examples, F3 effectively refines their attention, resulting
in cleaner and more reliable model outputs. Remarkably, this seemingly
paradoxical approach of employing noise to counteract adversarial attacks
yields impressive purification results. Furthermore, F3 offers several distinct
advantages: it is training-free and straightforward to implement, and exhibits
significant computational efficiency improvements compared to existing
purification methods. These attributes render F3 particularly suitable for
large-scale industrial applications where both robust performance and
operational efficiency are critical priorities. The code will be made publicly
available.

</details>


### [568] [Revolutionizing Blood Banks: AI-Driven Fingerprint-Blood Group Correlation for Enhanced Safety](https://arxiv.org/abs/2506.01069)
*Malik A. Altayar,Muhyeeddin Alqaraleh,Mowafaq Salem Alzboon,Wesam T. Almagharbeh*

Main category: cs.CV

TL;DR: 研究探讨了指纹模式与ABO血型的关系，发现两者关联性较弱，血型数据未能显著提升指纹识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索低成本、易实施的生物识别方法，以补充现有昂贵且耗时的技术。

Method: 对200名受试者的指纹模式（环、涡、弓）和血型进行比较，使用卡方检验和皮尔逊相关性分析。

Result: 环状指纹最常见，O+血型最普遍，但指纹模式与血型无显著统计学关联。

Conclusion: 血型数据对指纹识别的改进作用有限，未来研究可结合多模态生物特征和机器学习提升识别效果。

Abstract: Identification of a person is central in forensic science, security, and
healthcare. Methods such as iris scanning and genomic profiling are more
accurate but expensive, time-consuming, and more difficult to implement. This
study focuses on the relationship between the fingerprint patterns and the ABO
blood group as a biometric identification tool. A total of 200 subjects were
included in the study, and fingerprint types (loops, whorls, and arches) and
blood groups were compared. Associations were evaluated with statistical tests,
including chi-square and Pearson correlation. The study found that the loops
were the most common fingerprint pattern and the O+ blood group was the most
prevalent. Even though there was some associative pattern, there was no
statistically significant difference in the fingerprint patterns of different
blood groups. Overall, the results indicate that blood group data do not
significantly improve personal identification when used in conjunction with
fingerprinting. Although the study shows weak correlation, it may emphasize the
efforts of multi-modal based biometric systems in enhancing the current
biometric systems. Future studies may focus on larger and more diverse samples,
and possibly machine learning and additional biometrics to improve
identification methods. This study addresses an element of the ever-changing
nature of the fields of forensic science and biometric identification,
highlighting the importance of resilient analytical methods for personal
identification.

</details>


### [569] [GThinker: Towards General Multimodal Reasoning via Cue-Guided Rethinking](https://arxiv.org/abs/2506.01078)
*Yufei Zhan,Ziheng Wu,Yousong Zhu,Rongkun Xue,Ruipu Luo,Zhenghao Chen,Can Zhang,Yifan Li,Zhentao He,Zheming Yang,Ming Tang,Minghui Qiu,Jinqiao Wang*

Main category: cs.CV

TL;DR: GThinker是一种新型多模态推理模型，通过视觉线索重新思考和两阶段训练，显著提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉中心任务中表现不佳，主要依赖逻辑和知识推理，未能有效整合视觉信息。

Method: 提出Cue-Rethinking推理模式，结合两阶段训练（模式引导冷启动和激励强化学习），并构建GThinker-11K数据集。

Result: 在M$^3$CoT基准测试中达到81.5%，优于O4-mini模型，通用场景推理提升2.1%，数学推理表现持平。

Conclusion: GThinker通过视觉线索重新思考和高效训练，显著提升多模态推理能力，填补了通用多模态推理的数据空白。

Abstract: Despite notable advancements in multimodal reasoning, leading Multimodal
Large Language Models (MLLMs) still underperform on vision-centric multimodal
reasoning tasks in general scenarios. This shortfall stems from their
predominant reliance on logic- and knowledge-based slow thinking strategies,
while effective for domains like math and science, fail to integrate visual
information effectively during reasoning. Consequently, these models often fail
to adequately ground visual cues, resulting in suboptimal performance in tasks
that require multiple plausible visual interpretations and inferences. To
address this, we present GThinker (General Thinker), a novel reasoning MLLM
excelling in multimodal reasoning across general scenarios, mathematics, and
science. GThinker introduces Cue-Rethinking, a flexible reasoning pattern that
grounds inferences in visual cues and iteratively reinterprets these cues to
resolve inconsistencies. Building on this pattern, we further propose a
two-stage training pipeline, including pattern-guided cold start and incentive
reinforcement learning, designed to enable multimodal reasoning capabilities
across domains. Furthermore, to support the training, we construct
GThinker-11K, comprising 7K high-quality, iteratively-annotated reasoning paths
and 4K curated reinforcement learning samples, filling the data gap toward
general multimodal reasoning. Extensive experiments demonstrate that GThinker
achieves 81.5% on the challenging comprehensive multimodal reasoning benchmark
M$^3$CoT, surpassing the latest O4-mini model. It also shows an average
improvement of 2.1% on general scenario multimodal reasoning benchmarks, while
maintaining on-par performance in mathematical reasoning compared to
counterpart advanced reasoning models. The code, model, and data will be
released soon at https://github.com/jefferyZhan/GThinker.

</details>


### [570] [Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models](https://arxiv.org/abs/2506.01413)
*Yulei Qin,Gang Li,Zongyi Li,Zihan Xu,Yuchen Shi,Zhekai Lin,Xiao Cui,Ke Li,Xing Sun*

Main category: cs.CV

TL;DR: 论文提出了一种系统性方法，通过激励推理提升大语言模型（LLMs）处理复杂指令的能力，解决了传统链式思维（CoT）方法在多层约束关系识别上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理具有并行、链式和分支结构的复杂指令时表现不佳，传统链式思维方法因浅层推理而效果有限。

Method: 提出基于强化学习的可验证规则奖励信号，结合样本对比和行为克隆，提升模型推理能力。

Result: 在七个基准测试中，1.5B参数的LLM性能提升11.74%，接近8B参数模型的表现。

Conclusion: 该方法有效提升了LLMs处理复杂指令的能力，代码和数据已开源。

Abstract: Existing large language models (LLMs) face challenges of following complex
instructions, especially when multiple constraints are present and organized in
paralleling, chaining, and branching structures. One intuitive solution, namely
chain-of-thought (CoT), is expected to universally improve capabilities of
LLMs. However, we find that the vanilla CoT exerts a negative impact on
performance due to its superficial reasoning pattern of simply paraphrasing the
instructions. It fails to peel back the compositions of constraints for
identifying their relationship across hierarchies of types and dimensions. To
this end, we propose a systematic method to boost LLMs in dealing with complex
instructions via incentivizing reasoning for test-time compute scaling. First,
we stem from the decomposition of complex instructions under existing
taxonomies and propose a reproducible data acquisition method. Second, we
exploit reinforcement learning (RL) with verifiable rule-centric reward signals
to cultivate reasoning specifically for instruction following. We address the
shallow, non-essential nature of reasoning under complex instructions via
sample-wise contrast for superior CoT enforcement. We also exploit behavior
cloning of experts to facilitate steady distribution shift from fast-thinking
LLMs to skillful reasoners. Extensive evaluations on seven comprehensive
benchmarks confirm the validity of the proposed method, where a 1.5B LLM
achieves 11.74% gains with performance comparable to a 8B LLM. Codes and data
are available at https://github.com/yuleiqin/RAIF.

</details>


### [571] [Learning What Matters: Prioritized Concept Learning via Relative Error-driven Sample Selection](https://arxiv.org/abs/2506.01085)
*Shivam Chandhok,Qian Yang,Oscar Manas,Kanishk Jain,Leonid Sigal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: PROGRESS是一种动态选择学习样本的高效框架，通过优先学习概念和相对误差驱动的样本选择，减少了对大规模数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉语言模型（VLMs）指令调优需要大量数据、高质量标注和高计算成本，因此需要一种更高效的方法。

Method: PROGRESS通过动态跟踪模型在不同技能上的学习进度，选择当前阶段最有益的样本（既未掌握又不过于困难），并优先学习进步最快的技能。

Result: 实验表明，PROGRESS在多个指令调优数据集上优于现有方法，且数据量和监督需求更低，同时展示了跨架构的泛化性和可扩展性。

Conclusion: PROGRESS是一种可扩展的高效学习解决方案，适用于资源有限的场景。

Abstract: Instruction tuning has been central to the success of recent vision-language
models (VLMs), but it remains expensive-requiring large-scale datasets,
high-quality annotations, and large compute budgets. We propose PRioritized
cOncept learninG via Relative Error-driven Sample Selection (PROGRESS), a data-
and compute-efficient framework that enables VLMs to dynamically select what to
learn next based on their evolving needs during training. At each stage, the
model tracks its learning progress across skills and selects the most
informative samples-those it has not already mastered and that are not too
difficult to learn at the current stage of training. This strategy effectively
controls skill acquisition and the order in which skills are learned.
Specifically, we sample from skills showing the highest learning progress,
prioritizing those with the most rapid improvement. Unlike prior methods,
PROGRESS requires no upfront answer annotations, queries answers only on a need
basis, avoids reliance on additional supervision from auxiliary VLMs, and does
not require compute-heavy gradient computations for data selection. Experiments
across multiple instruction-tuning datasets of varying scales demonstrate that
PROGRESS consistently outperforms state-of-the-art baselines with much less
data and supervision. Additionally, we show strong cross-architecture
generalization and transferability to larger models, validating PROGRESS as a
scalable solution for efficient learning.

</details>


### [572] [EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation](https://arxiv.org/abs/2506.01551)
*Bingqian Lin,Yunshuang Nie,Khun Loun Zai,Ziming Wei,Mingfei Han,Rongtao Xu,Minzhe Niu,Jianhua Han,Liang Lin,Cewu Lu,Xiaodan Liang*

Main category: cs.CV

TL;DR: EvolveNav是一个两阶段框架，通过形式化的CoT监督微调和自我反思后训练，提升基于LLM的视觉语言导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中直接输入输出映射导致的导航决策难以学习和解释的问题，同时避免纯CoT监督微调可能导致的过拟合。

Method: 1. 形式化CoT监督微调，激活模型的导航推理能力；2. 自我反思后训练，通过自我生成的CoT标签增强监督多样性。

Result: 在流行的VLN基准测试中表现优于之前的基于LLM的VLN方法。

Conclusion: EvolveNav通过结合形式化CoT和自我反思训练，显著提升了导航决策的准确性和可解释性。

Abstract: Building Vision-Language Navigation (VLN) agents which can navigate following
natural language instructions is a long-standing goal in human-robot
interaction applications. Recent studies have revealed the potential of
training open-source Large Language Models (LLMs) to unleash LLMs' reasoning
ability for improving navigation, and simultaneously mitigate the domain gap
between LLMs' training corpus and the VLN task. However, these approaches
primarily adopt direct input-output mapping paradigms, causing the mapping
learning difficult and the navigational decisions unexplainable.
Chain-of-Thought (CoT) training is a promising way to improve both navigational
decision accuracy and interpretability, while the complexity of the navigation
task makes the perfect CoT labels unavailable and may lead to overfitting
through pure CoT supervised fine-tuning. In this paper, we propose a novel
sElf-improving embodied reasoning framework for boosting LLM-based
vision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two
stages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model
with formalized CoT labels to both activate the model's navigational reasoning
capabilities and increase the reasoning speed; (2) Self-Reflective
Post-Training, where the model is iteratively trained with its own reasoning
outputs as self-enriched CoT labels to enhance the supervision diversity. A
self-reflective auxiliary task is also introduced to encourage learning correct
reasoning patterns by contrasting with wrong ones. Experimental results on the
popular VLN benchmarks demonstrate the superiority of EvolveNav over previous
LLM-based VLN approaches. Code is available at
https://github.com/expectorlin/EvolveNav.

</details>


### [573] [CountingFruit: Real-Time 3D Fruit Counting with Language-Guided Semantic Gaussian Splatting](https://arxiv.org/abs/2506.01109)
*Fengze Li,Yangle Liu,Jieming Ma,Hai-Ning Liang,Yaochun Shen,Huangxiang Li,Zhijing Wu*

Main category: cs.CV

TL;DR: FruitLangGS是一个实时3D水果计数框架，通过空间重建、语义嵌入和语言引导的实例估计解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有水果计数方法在推理速度、泛化能力和开放集语义控制方面的不足。

Method: 采用自适应高斯喷洒管道进行场景重建，结合CLIP对齐的语言嵌入实现语义控制，并通过分布感知采样和聚类估计水果数量。

Result: 在真实果园数据上，FruitLangGS在渲染速度、语义灵活性和计数准确性上优于现有方法。

Conclusion: FruitLangGS为开放世界场景下的语言驱动实时神经渲染提供了新视角。

Abstract: Accurate fruit counting in real-world agricultural environments is a
longstanding challenge due to visual occlusions, semantic ambiguity, and the
high computational demands of 3D reconstruction. Existing methods based on
neural radiance fields suffer from low inference speed, limited generalization,
and lack support for open-set semantic control. This paper presents
FruitLangGS, a real-time 3D fruit counting framework that addresses these
limitations through spatial reconstruction, semantic embedding, and
language-guided instance estimation. FruitLangGS first reconstructs
orchard-scale scenes using an adaptive Gaussian splatting pipeline with
radius-aware pruning and tile-based rasterization for efficient rendering. To
enable semantic control, each Gaussian encodes a compressed CLIP-aligned
language embedding, forming a compact and queryable 3D representation. At
inference time, prompt-based semantic filtering is applied directly in 3D
space, without relying on image-space segmentation or view-level fusion. The
selected Gaussians are then converted into dense point clouds via
distribution-aware sampling and clustered to estimate fruit counts.
Experimental results on real orchard data demonstrate that FruitLangGS achieves
higher rendering speed, semantic flexibility, and counting accuracy compared to
prior approaches, offering a new perspective for language-driven, real-time
neural rendering across open-world scenarios.

</details>


### [574] [Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination](https://arxiv.org/abs/2506.01902)
*Xinliu Zhong,Kayhan Batmanghelich,Li Sun*

Main category: cs.CV

TL;DR: 提出了一种新的生物医学视觉语言模型预训练方法，通过扰动报告区分任务和对比注意力加权子区域与子词，提升了语义表示的质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 生物医学文本具有复杂且领域特定的语义，现有对比学习方法常忽视这一点，导致预训练效果不佳。

Method: 提出扰动报告区分方法，通过文本扰动保持词汇不变但破坏语义结构，同时对比注意力加权的图像子区域和子词。

Result: 在多个下游任务中表现优于基线方法，学习到更具语义意义和鲁棒性的多模态表示。

Conclusion: 该方法有效解决了生物医学领域语义复杂性带来的挑战，提升了视觉语言模型的性能。

Abstract: Vision-language models pre-trained on large scale of unlabeled biomedical
images and associated reports learn generalizable semantic representations.
These multi-modal representations can benefit various downstream tasks in the
biomedical domain. Contrastive learning is widely used to pre-train
vision-language models for general natural images and associated captions.
Despite its popularity, we found biomedical texts have complex and
domain-specific semantics that are often neglected by common contrastive
methods. To address this issue, we propose a novel method, perturbed report
discrimination, for pre-train biomedical vision-language models. First, we
curate a set of text perturbation methods that keep the same words, but disrupt
the semantic structure of the sentence. Next, we apply different types of
perturbation to reports, and use the model to distinguish the original report
from the perturbed ones given the associated image. Parallel to this, we
enhance the sensitivity of our method to higher level of granularity for both
modalities by contrasting attention-weighted image sub-regions and sub-words in
the image-text pairs. We conduct extensive experiments on multiple downstream
tasks, and our method outperforms strong baseline methods. The results
demonstrate that our approach learns more semantic meaningful and robust
multi-modal representations.

</details>


### [575] [Dual-Process Image Generation](https://arxiv.org/abs/2506.01955)
*Grace Luo,Jonathan Granskog,Aleksander Holynski,Trevor Darrell*

Main category: cs.CV

TL;DR: 提出了一种双过程蒸馏方案，使前馈图像生成器能够从深思熟虑的视觉语言模型（VLM）中学习新任务。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成控制方法难以学习新任务，而VLM具有上下文学习能力。

Method: 使用VLM对生成图像评分，并通过反向传播梯度更新图像生成器权重。

Result: 实现了多种新控制任务，如常识推理和视觉提示，支持快速多模态控制。

Conclusion: 该方法通过文本和图像界面，实现了灵活的图像生成控制。

Abstract: Prior methods for controlling image generation are limited in their ability
to be taught new tasks. In contrast, vision-language models, or VLMs, can learn
tasks in-context and produce the correct outputs for a given input. We propose
a dual-process distillation scheme that allows feed-forward image generators to
learn new tasks from deliberative VLMs. Our scheme uses a VLM to rate the
generated images and backpropagates this gradient to update the weights of the
image generator. Our general framework enables a wide variety of new control
tasks through the same text-and-image based interface. We showcase a handful of
applications of this technique for different types of control signals, such as
commonsense inferences and visual prompts. With our method, users can implement
multimodal controls for properties such as color palette, line weight, horizon
position, and relative depth within a matter of minutes. Project page:
https://dual-process.github.io.

</details>


### [576] [A Review on Coarse to Fine-Grained Animal Action Recognition](https://arxiv.org/abs/2506.01214)
*Ali Zia,Renuka Sharma,Abdelwahed Khamis,Xuesong Li,Muhammad Husnain,Numan Shafi,Saeed Anwar,Sabine Schmoelzl,Eric Stone,Lars Petersson,Vivien Rolland*

Main category: cs.CV

TL;DR: 本文综述了动物行为识别领域的现状，重点探讨了粗粒度（CG）和细粒度（FG）技术，并分析了户外环境中识别细微动物行为的独特挑战。


<details>
  <summary>Details</summary>
Motivation: 动物行为识别面临非刚性身体结构、频繁遮挡和缺乏大规模标注数据集等挑战，与人类行为识别差异显著，需要专门研究。

Method: 通过评估时空深度学习框架（如SlowFast）和现有数据集的局限性，探讨了动物行为分析的有效方法。

Result: 综述总结了当前方法的优缺点，并介绍了新发布的数据集，为未来细粒度行为识别的发展提供了方向。

Conclusion: 未来研究应致力于提高动物行为识别的准确性和泛化能力，特别是在复杂自然环境中的细粒度分析。

Abstract: This review provides an in-depth exploration of the field of animal action
recognition, focusing on coarse-grained (CG) and fine-grained (FG) techniques.
The primary aim is to examine the current state of research in animal behaviour
recognition and to elucidate the unique challenges associated with recognising
subtle animal actions in outdoor environments. These challenges differ
significantly from those encountered in human action recognition due to factors
such as non-rigid body structures, frequent occlusions, and the lack of
large-scale, annotated datasets. The review begins by discussing the evolution
of human action recognition, a more established field, highlighting how it
progressed from broad, coarse actions in controlled settings to the demand for
fine-grained recognition in dynamic environments. This shift is particularly
relevant for animal action recognition, where behavioural variability and
environmental complexity present unique challenges that human-centric models
cannot fully address. The review then underscores the critical differences
between human and animal action recognition, with an emphasis on high
intra-species variability, unstructured datasets, and the natural complexity of
animal habitats. Techniques like spatio-temporal deep learning frameworks
(e.g., SlowFast) are evaluated for their effectiveness in animal behaviour
analysis, along with the limitations of existing datasets. By assessing the
strengths and weaknesses of current methodologies and introducing a
recently-published dataset, the review outlines future directions for advancing
fine-grained action recognition, aiming to improve accuracy and
generalisability in behaviour analysis across species.

</details>


### [577] [Fourier-Modulated Implicit Neural Representation for Multispectral Satellite Image Compression](https://arxiv.org/abs/2506.01234)
*Woojin Cho,Steve Andreas Immanuel,Junhyuk Heo,Darongsae Kwon*

Main category: cs.CV

TL;DR: ImpliSat是一个基于隐式神经表示（INR）的统一框架，用于高效压缩和重建多光谱卫星数据，解决高维度和多分辨率挑战。


<details>
  <summary>Details</summary>
Motivation: 多光谱卫星图像在农业、渔业和环境监测中至关重要，但其高维度、大数据量和多分辨率特性给数据压缩和分析带来挑战。

Method: 利用隐式神经表示（INR）将卫星图像建模为坐标空间上的连续函数，并引入傅里叶调制算法动态适应各波段的光谱和空间特性。

Result: 实现了对多光谱卫星数据的高效压缩和重建，同时保留了关键图像细节。

Conclusion: ImpliSat为多光谱卫星数据的处理提供了统一的解决方案，显著提升了压缩效率和重建质量。

Abstract: Multispectral satellite images play a vital role in agriculture, fisheries,
and environmental monitoring. However, their high dimensionality, large data
volumes, and diverse spatial resolutions across multiple channels pose
significant challenges for data compression and analysis. This paper presents
ImpliSat, a unified framework specifically designed to address these challenges
through efficient compression and reconstruction of multispectral satellite
data. ImpliSat leverages Implicit Neural Representations (INR) to model
satellite images as continuous functions over coordinate space, capturing fine
spatial details across varying spatial resolutions. Furthermore, we introduce a
Fourier modulation algorithm that dynamically adjusts to the spectral and
spatial characteristics of each band, ensuring optimal compression while
preserving critical image details.

</details>


### [578] [Visual Sparse Steering: Improving Zero-shot Image Classification with Sparsity Guided Steering Vectors](https://arxiv.org/abs/2506.01247)
*Gerasimos Chatzoudis,Zhuowei Li,Gemma E. Moran,Hao Wang,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: VS2和VS2++是轻量级测试时方法，通过稀疏特征引导视觉模型，显著提升零样本CLIP性能，PASS进一步优化稀疏特征对齐。


<details>
  <summary>Details</summary>
Motivation: 在动态或资源受限环境中，无需重新训练或大量标注数据即可引导视觉基础模型是一个重要但具有挑战性的目标。

Method: 提出VS2和VS2++，利用稀疏自编码器的稀疏特征生成引导向量；进一步提出PASS，通过原型对齐损失优化稀疏特征。

Result: VS2在多个数据集上显著超越零样本CLIP；VS2++在特定条件下性能提升更显著；PASS进一步小幅提升性能。

Conclusion: 稀疏特征引导方法有效提升模型性能，尤其对特定类别的分类效果显著，PASS展示了稀疏特征对齐的潜力。

Abstract: Steering vision foundation models at inference time without retraining or
access to large labeled datasets is a desirable yet challenging objective,
particularly in dynamic or resource-constrained settings. In this paper, we
introduce Visual Sparse Steering (VS2), a lightweight, test-time method that
guides vision models using steering vectors derived from sparse features
learned by top-$k$ Sparse Autoencoders without requiring contrastive data.
Specifically, VS2 surpasses zero-shot CLIP by 4.12% on CIFAR-100, 1.08% on
CUB-200, and 1.84% on Tiny-ImageNet. We further propose VS2++, a
retrieval-augmented variant that selectively amplifies relevant sparse features
using pseudo-labeled neighbors at inference time. With oracle positive/negative
sets, VS2++ achieves absolute top-1 gains over CLIP zero-shot of up to 21.44%
on CIFAR-100, 7.08% on CUB-200, and 20.47% on Tiny-ImageNet. Interestingly, VS2
and VS2++ raise per-class accuracy by up to 25% and 38%, respectively, showing
that sparse steering benefits specific classes by disambiguating visually or
taxonomically proximate categories rather than providing a uniform boost.
Finally, to better align the sparse features learned through the SAE
reconstruction task with those relevant for downstream performance, we propose
Prototype-Aligned Sparse Steering (PASS). By incorporating a
prototype-alignment loss during SAE training, using labels only during training
while remaining fully test-time unsupervised, PASS consistently, though
modestly, outperforms VS2, achieving a 6.12% gain over VS2 only on CIFAR-100
with ViT-B/32.

</details>


### [579] [ReFoCUS: Reinforcement-guided Frame Optimization for Contextual Understanding](https://arxiv.org/abs/2506.01274)
*Hosu Lee,Junho Kim,Hyunjun Kim,Yong Man Ro*

Main category: cs.CV

TL;DR: ReFoCUS是一种通过强化学习优化视频帧选择策略的框架，旨在提升视频问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法依赖静态启发式或外部检索模块，可能导致查询相关信息不足。

Method: 采用强化学习训练帧选择策略，利用参考LMM的奖励信号优化帧选择，并通过自回归条件选择架构降低复杂性。

Result: 在多个视频问答基准测试中显著提升了推理性能。

Conclusion: ReFoCUS通过模型内部效用对齐帧选择，无需显式监督即可提升性能。

Abstract: Recent progress in Large Multi-modal Models (LMMs) has enabled effective
vision-language reasoning, yet the ability to understand video content remains
constrained by suboptimal frame selection strategies. Existing approaches often
rely on static heuristics or external retrieval modules to feed frame
information into video-LLMs, which may fail to provide the query-relevant
information. In this work, we introduce ReFoCUS (Reinforcement-guided Frame
Optimization for Contextual UnderStanding), a novel frame-level policy
optimization framework that shifts the optimization target from textual
responses to visual input selection. ReFoCUS learns a frame selection policy
via reinforcement learning, using reward signals derived from a reference LMM
to reflect the model's intrinsic preferences for frames that best support
temporally grounded responses. To efficiently explore the large combinatorial
frame space, we employ an autoregressive, conditional selection architecture
that ensures temporal coherence while reducing complexity. Our approach does
not require explicit supervision at the frame-level and consistently improves
reasoning performance across multiple video QA benchmarks, highlighting the
benefits of aligning frame selection with model-internal utility.

</details>


### [580] [Playing with Transformer at 30+ FPS via Next-Frame Diffusion](https://arxiv.org/abs/2506.01380)
*Xinle Cheng,Tianyu He,Jiayi Xu,Junliang Guo,Di He,Jiang Bian*

Main category: cs.CV

TL;DR: 论文提出了Next-Frame Diffusion (NFD)，一种自回归扩散变换器，通过块级因果注意力和并行令牌生成实现高效推理。为解决实时视频生成的挑战，提出了两种创新：一致性蒸馏和推测采样，显著提升了采样效率和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 自回归视频模型在交互式视频内容和流媒体应用中具有优势，但实时生成仍面临高计算成本和硬件效率低下的问题。

Method: 提出了NFD模型，结合块级因果注意力和并行令牌生成；引入一致性蒸馏和推测采样以优化效率和性能。

Result: NFD在视觉质量和采样效率上优于基线模型，首次在A100 GPU上实现超过30 FPS的自回归视频生成。

Conclusion: NFD通过创新方法解决了自回归视频生成的高效性问题，为实时应用提供了可行方案。

Abstract: Autoregressive video models offer distinct advantages over bidirectional
diffusion models in creating interactive video content and supporting streaming
applications with arbitrary duration. In this work, we present Next-Frame
Diffusion (NFD), an autoregressive diffusion transformer that incorporates
block-wise causal attention, enabling iterative sampling and efficient
inference via parallel token generation within each frame. Nonetheless,
achieving real-time video generation remains a significant challenge for such
models, primarily due to the high computational cost associated with diffusion
sampling and the hardware inefficiencies inherent to autoregressive generation.
To address this, we introduce two innovations: (1) We extend consistency
distillation to the video domain and adapt it specifically for video models,
enabling efficient inference with few sampling steps; (2) To fully leverage
parallel computation, motivated by the observation that adjacent frames often
share the identical action input, we propose speculative sampling. In this
approach, the model generates next few frames using current action input, and
discard speculatively generated frames if the input action differs. Experiments
on a large-scale action-conditioned video generation benchmark demonstrate that
NFD beats autoregressive baselines in terms of both visual quality and sampling
efficiency. We, for the first time, achieves autoregressive video generation at
over 30 Frames Per Second (FPS) on an A100 GPU using a 310M model.

</details>


### [581] [VRD-IU: Lessons from Visually Rich Document Intelligence and Understanding](https://arxiv.org/abs/2506.01388)
*Yihao Ding,Soyeon Caren Han,Yan Li,Josiah Poon*

Main category: cs.CV

TL;DR: VRD-IU竞赛聚焦于从多格式表单中提取和定位关键信息，展示了多种先进方法，并为视觉丰富文档理解（VRDU）设定了新基准。


<details>
  <summary>Details</summary>
Motivation: 解决表单类文档因复杂布局、多利益相关者参与和高结构可变性带来的独特挑战。

Method: 竞赛分为两个赛道：Track A（基于实体的关键信息检索）和Track B（端到端的关键信息定位），采用分层分解、基于Transformer的检索、多模态特征融合和高级目标检测技术。

Result: 超过20个团队参与，展示了多种先进方法，并设定了VRDU领域的新基准。

Conclusion: 竞赛为文档智能提供了宝贵见解，推动了VRDU领域的发展。

Abstract: Visually Rich Document Understanding (VRDU) has emerged as a critical field
in document intelligence, enabling automated extraction of key information from
complex documents across domains such as medical, financial, and educational
applications. However, form-like documents pose unique challenges due to their
complex layouts, multi-stakeholder involvement, and high structural
variability. Addressing these issues, the VRD-IU Competition was introduced,
focusing on extracting and localizing key information from multi-format forms
within the Form-NLU dataset, which includes digital, printed, and handwritten
documents. This paper presents insights from the competition, which featured
two tracks: Track A, emphasizing entity-based key information retrieval, and
Track B, targeting end-to-end key information localization from raw document
images. With over 20 participating teams, the competition showcased various
state-of-the-art methodologies, including hierarchical decomposition,
transformer-based retrieval, multimodal feature fusion, and advanced object
detection techniques. The top-performing models set new benchmarks in VRDU,
providing valuable insights into document intelligence.

</details>


### [582] [ViTA-PAR: Visual and Textual Attribute Alignment with Attribute Prompting for Pedestrian Attribute Recognition](https://arxiv.org/abs/2506.01411)
*Minjeong Park,Hongbeen Park,Jinkyu Kim*

Main category: cs.CV

TL;DR: ViTA-PAR提出了一种基于视觉和文本属性对齐的多模态提示方法，用于行人属性识别，通过全局到局部的语义捕捉和文本嵌入增强，提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于固定水平区域的属性识别，导致属性出现在不同位置时性能下降，ViTA-PAR旨在通过多模态提示和对齐解决这一问题。

Method: 设计了视觉属性提示和可学习的文本提示模板，实现全局到局部的语义捕捉和文本嵌入增强，并通过视觉与文本特征对齐进行有效融合。

Result: 在四个PAR基准测试中表现优异，推理效率高。

Conclusion: ViTA-PAR通过多模态提示和对齐显著提升了行人属性识别的性能，具有高效性和竞争力。

Abstract: The Pedestrian Attribute Recognition (PAR) task aims to identify various
detailed attributes of an individual, such as clothing, accessories, and
gender. To enhance PAR performance, a model must capture features ranging from
coarse-grained global attributes (e.g., for identifying gender) to fine-grained
local details (e.g., for recognizing accessories) that may appear in diverse
regions. Recent research suggests that body part representation can enhance the
model's robustness and accuracy, but these methods are often restricted to
attribute classes within fixed horizontal regions, leading to degraded
performance when attributes appear in varying or unexpected body locations. In
this paper, we propose Visual and Textual Attribute Alignment with Attribute
Prompting for Pedestrian Attribute Recognition, dubbed as ViTA-PAR, to enhance
attribute recognition through specialized multimodal prompting and
vision-language alignment. We introduce visual attribute prompts that capture
global-to-local semantics, enabling diverse attribute representations. To
enrich textual embeddings, we design a learnable prompt template, termed person
and attribute context prompting, to learn person and attributes context.
Finally, we align visual and textual attribute features for effective fusion.
ViTA-PAR is validated on four PAR benchmarks, achieving competitive performance
with efficient inference. We release our code and model at
https://github.com/mlnjeongpark/ViTA-PAR.

</details>


### [583] [G4Seg: Generation for Inexact Segmentation Refinement with Diffusion Models](https://arxiv.org/abs/2506.01539)
*Tianjiao Zhang,Fei Zhang,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: 利用大规模文本到图像扩散模型解决不精确分割任务，通过生成差异实现分割细化。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖判别模型或密集视觉表示，本文探索生成模型（Stable Diffusion）的内在先验来解决不精确分割问题。

Method: 利用原始图像与掩码条件生成图像的模式差异，通过语义对齐和前景概率更新实现粗到细的分割优化。

Result: 实验验证了该方法的有效性和优越性，展示了生成差异在建模密集表示中的潜力。

Conclusion: 生成方法在解决判别任务中具有潜力，鼓励进一步探索。

Abstract: This paper considers the problem of utilizing a large-scale text-to-image
diffusion model to tackle the challenging Inexact Segmentation (IS) task.
Unlike traditional approaches that rely heavily on discriminative-model-based
paradigms or dense visual representations derived from internal attention
mechanisms, our method focuses on the intrinsic generative priors in Stable
Diffusion~(SD). Specifically, we exploit the pattern discrepancies between
original images and mask-conditional generated images to facilitate a
coarse-to-fine segmentation refinement by establishing a semantic
correspondence alignment and updating the foreground probability. Comprehensive
quantitative and qualitative experiments validate the effectiveness and
superiority of our plug-and-play design, underscoring the potential of
leveraging generation discrepancies to model dense representations and
encouraging further exploration of generative approaches for solving
discriminative tasks.

</details>


### [584] [EPFL-Smart-Kitchen-30: Densely annotated cooking dataset with 3D kinematics to challenge video and language models](https://arxiv.org/abs/2506.01608)
*Andy Bonnetto,Haozhe Qi,Franklin Leong,Matea Tashkovska,Mahdi Rad,Solaiman Shokur,Friedhelm Hummel,Silvestro Micera,Marc Pollefeys,Alexander Mathis*

Main category: cs.CV

TL;DR: EPFL-Smart-Kitchen-30数据集是一个多模态厨房行为数据集，用于研究人类复杂动作和认知功能。


<details>
  <summary>Details</summary>
Motivation: 厨房环境能自然展现人类复杂动作，适合研究运动和认知功能。

Method: 使用多视角RGB-D相机、IMU和HoloLens~2头显，捕捉16名受试者在厨房中的3D动作、眼动等数据。

Result: 数据集包含29.7小时的多模态数据，标注密集，并提出了四个行为理解基准。

Conclusion: 该数据集有望推动生态效度人类行为理解的方法和见解。

Abstract: Understanding behavior requires datasets that capture humans while carrying
out complex tasks. The kitchen is an excellent environment for assessing human
motor and cognitive function, as many complex actions are naturally exhibited
in kitchens from chopping to cleaning. Here, we introduce the
EPFL-Smart-Kitchen-30 dataset, collected in a noninvasive motion capture
platform inside a kitchen environment. Nine static RGB-D cameras, inertial
measurement units (IMUs) and one head-mounted HoloLens~2 headset were used to
capture 3D hand, body, and eye movements. The EPFL-Smart-Kitchen-30 dataset is
a multi-view action dataset with synchronized exocentric, egocentric, depth,
IMUs, eye gaze, body and hand kinematics spanning 29.7 hours of 16 subjects
cooking four different recipes. Action sequences were densely annotated with
33.78 action segments per minute. Leveraging this multi-modal dataset, we
propose four benchmarks to advance behavior understanding and modeling through
1) a vision-language benchmark, 2) a semantic text-to-motion generation
benchmark, 3) a multi-modal action recognition benchmark, 4) a pose-based
action segmentation benchmark. We expect the EPFL-Smart-Kitchen-30 dataset to
pave the way for better methods as well as insights to understand the nature of
ecologically-valid human behavior. Code and data are available at
https://github.com/amathislab/EPFL-Smart-Kitchen

</details>


### [585] [Data Pruning by Information Maximization](https://arxiv.org/abs/2506.01701)
*Haoru Tan,Sitong Wu,Wei Huang,Shizhen Zhao,Xiaojuan Qi*

Main category: cs.CV

TL;DR: InfoMax是一种新颖的数据修剪方法，通过最大化样本信息内容和最小化冗余来提升核心集的信息量。


<details>
  <summary>Details</summary>
Motivation: 传统数据修剪方法未能有效平衡信息内容和冗余，InfoMax旨在解决这一问题。

Method: 通过重要性评分衡量样本信息，利用样本相似性量化冗余，将问题建模为离散二次规划任务，并引入高效的梯度求解器和稀疏化技术。

Result: 实验表明InfoMax在图像分类、视觉语言预训练和大语言模型指令调优等任务中表现优异。

Conclusion: InfoMax是一种高效且可扩展的数据修剪方法，能够显著提升核心集的信息量。

Abstract: In this paper, we present InfoMax, a novel data pruning method, also known as
coreset selection, designed to maximize the information content of selected
samples while minimizing redundancy. By doing so, InfoMax enhances the overall
informativeness of the coreset. The information of individual samples is
measured by importance scores, which capture their influence or difficulty in
model learning. To quantify redundancy, we use pairwise sample similarities,
based on the premise that similar samples contribute similarly to the learning
process. We formalize the coreset selection problem as a discrete quadratic
programming (DQP) task, with the objective of maximizing the total information
content, represented as the sum of individual sample contributions minus the
redundancies introduced by similar samples within the coreset. To ensure
practical scalability, we introduce an efficient gradient-based solver,
complemented by sparsification techniques applied to the similarity matrix and
dataset partitioning strategies. This enables InfoMax to seamlessly scale to
datasets with millions of samples. Extensive experiments demonstrate the
superior performance of InfoMax in various data pruning tasks, including image
classification, vision-language pre-training, and instruction tuning for large
language models.

</details>


### [586] [Efficient Egocentric Action Recognition with Multimodal Data](https://arxiv.org/abs/2506.01757)
*Marco Calzavara,Ard Kastrati,Matteo Macchini,Dushan Vasilevski,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 通过分析采样频率对RGB视频和3D手部姿态输入的影响，研究发现降低RGB帧采样率并辅以高频3D手部姿态输入，可在保持高精度的同时显著降低CPU使用率。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴XR设备的普及，实现实时Egocentric Action Recognition (EAR)面临便携性、电池寿命和计算资源之间的权衡挑战。

Method: 系统分析不同输入模态（RGB视频和3D手部姿态）的采样频率对EAR性能和CPU使用的影响。

Result: 降低RGB帧采样率并辅以高频3D手部姿态输入，可实现CPU使用率降低3倍，且识别性能几乎无损。

Conclusion: 多模态输入策略是实现XR设备上高效实时EAR的可行方法。

Abstract: The increasing availability of wearable XR devices opens new perspectives for
Egocentric Action Recognition (EAR) systems, which can provide deeper human
understanding and situation awareness. However, deploying real-time algorithms
on these devices can be challenging due to the inherent trade-offs between
portability, battery life, and computational resources. In this work, we
systematically analyze the impact of sampling frequency across different input
modalities - RGB video and 3D hand pose - on egocentric action recognition
performance and CPU usage. By exploring a range of configurations, we provide a
comprehensive characterization of the trade-offs between accuracy and
computational efficiency. Our findings reveal that reducing the sampling rate
of RGB frames, when complemented with higher-frequency 3D hand pose input, can
preserve high accuracy while significantly lowering CPU demands. Notably, we
observe up to a 3x reduction in CPU usage with minimal to no loss in
recognition performance. This highlights the potential of multimodal input
strategies as a viable approach to achieving efficient, real-time EAR on XR
devices.

</details>


### [587] [unMORE: Unsupervised Multi-Object Segmentation via Center-Boundary Reasoning](https://arxiv.org/abs/2506.01778)
*Yafei Yang,Zihui Zhang,Bo Yang*

Main category: cs.CV

TL;DR: 论文提出了一种名为unMORE的两阶段无监督多目标分割方法，显著优于现有方法，在复杂真实图像中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法在分割复杂真实世界对象时效果有限，无法处理拥挤场景。

Method: unMORE通过两阶段流程：第一阶段学习三层对象中心表示，第二阶段利用网络无关的多对象推理模块发现多个对象。

Result: 在6个真实世界基准数据集（包括COCO）上表现最优，尤其在拥挤图像中显著优于基线方法。

Conclusion: unMORE为无监督多目标分割提供了高效解决方案，适用于复杂场景。

Abstract: We study the challenging problem of unsupervised multi-object segmentation on
single images. Existing methods, which rely on image reconstruction objectives
to learn objectness or leverage pretrained image features to group similar
pixels, often succeed only in segmenting simple synthetic objects or
discovering a limited number of real-world objects. In this paper, we introduce
unMORE, a novel two-stage pipeline designed to identify many complex objects in
real-world images. The key to our approach involves explicitly learning three
levels of carefully defined object-centric representations in the first stage.
Subsequently, our multi-object reasoning module utilizes these learned object
priors to discover multiple objects in the second stage. Notably, this
reasoning module is entirely network-free and does not require human labels.
Extensive experiments demonstrate that unMORE significantly outperforms all
existing unsupervised methods across 6 real-world benchmark datasets, including
the challenging COCO dataset, achieving state-of-the-art object segmentation
results. Remarkably, our method excels in crowded images where all baselines
collapse.

</details>


### [588] [Ridgeformer: Mutli-Stage Contrastive Training For Fine-grained Cross-Domain Fingerprint Recognition](https://arxiv.org/abs/2506.01806)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur*

Main category: cs.CV

TL;DR: 提出了一种基于多阶段Transformer的非接触式指纹匹配方法，解决了图像模糊、对比度低等问题，并在公开数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 非接触式指纹识别需求增长，但面临图像模糊、对比度低、手指位置变化等挑战，影响匹配准确性。

Method: 采用多阶段Transformer方法，先提取全局空间特征，再细化局部特征对齐，结合层次化特征提取与匹配流程。

Result: 在HKPolyU和RidgeBase数据集上验证，性能优于现有方法，包括商用解决方案。

Conclusion: 该方法显著提升了非接触式指纹匹配的准确性和鲁棒性。

Abstract: The increasing demand for hygienic and portable biometric systems has
underscored the critical need for advancements in contactless fingerprint
recognition. Despite its potential, this technology faces notable challenges,
including out-of-focus image acquisition, reduced contrast between fingerprint
ridges and valleys, variations in finger positioning, and perspective
distortion. These factors significantly hinder the accuracy and reliability of
contactless fingerprint matching. To address these issues, we propose a novel
multi-stage transformer-based contactless fingerprint matching approach that
first captures global spatial features and subsequently refines localized
feature alignment across fingerprint samples. By employing a hierarchical
feature extraction and matching pipeline, our method ensures fine-grained,
cross-sample alignment while maintaining the robustness of global feature
representation. We perform extensive evaluations on publicly available datasets
such as HKPolyU and RidgeBase under different evaluation protocols, such as
contactless-to-contact matching and contactless-to-contactless matching and
demonstrate that our proposed approach outperforms existing methods, including
COTS solutions.

</details>


### [589] [MoDA: Modulation Adapter for Fine-Grained Visual Grounding in Instructional MLLMs](https://arxiv.org/abs/2506.01850)
*Wayner Barrios,Andrés Villa,Juan León Alcázar,SouYoung Jin,Bernard Ghanem*

Main category: cs.CV

TL;DR: MoDA（Modulation Adapter）是一种轻量级模块，通过指令引导的调制优化预对齐视觉特征，提升多模态大语言模型（MLLMs）在复杂场景中的细粒度视觉概念理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景中难以精确关联细粒度视觉概念，MoDA旨在通过指令引导的调制解决这一问题。

Method: MoDA采用两阶段训练：1）通过冻结视觉编码器和适配层将图像特征对齐到LLMs输入空间；2）在指令调优阶段使用MoDA适配器优化特征，利用Transformer跨注意力机制生成调制掩码。

Result: 实验表明，MoDA提升了视觉定位能力，并生成更符合上下文的响应。

Conclusion: MoDA是一种通用的图像MLLMs增强方法，有效改善了视觉理解和语言生成能力。

Abstract: Recently, Multimodal Large Language Models (MLLMs) have demonstrated
impressive performance on instruction-following tasks by integrating pretrained
visual encoders with large language models (LLMs). However, existing approaches
often struggle to ground fine-grained visual concepts in complex scenes. In
this paper, we propose MoDA (Modulation Adapter), a lightweight yet effective
module designed to refine pre-aligned visual features through
instruction-guided modulation. Our approach follows the standard LLaVA training
protocol, consisting of a two-stage process: (1) aligning image features to the
LLMs input space via a frozen vision encoder and adapter layers, and (2)
refining those features using the MoDA adapter during the instructional tuning
stage. MoDA employs a Transformer-based cross-attention mechanism to generate a
modulation mask over the aligned visual tokens, thereby emphasizing
semantically relevant embedding dimensions based on the language instruction.
The modulated features are then passed to the LLM for autoregressive language
generation. Our experimental evaluation shows that MoDA improves visual
grounding and generates more contextually appropriate responses, demonstrating
its effectiveness as a general-purpose enhancement for image-based MLLMs.

</details>


### [590] [MedEBench: Revisiting Text-instructed Image Editing](https://arxiv.org/abs/2506.01921)
*Minghao Liu,Zhitao He,Zhiyuan Fan,Qingyun Wang,Yi R. Fung*

Main category: cs.CV

TL;DR: MedEBench是一个用于评估文本引导医学图像编辑的基准，包含1182个临床图像-提示对，覆盖70个任务和13个解剖区域，提供标准化评估框架和模型比较。


<details>
  <summary>Details</summary>
Motivation: 文本引导图像编辑在医学影像领域缺乏标准化评估，但具有临床潜力，如模拟手术结果和教学材料。

Method: MedEBench包括临床相关的评估框架（编辑准确性、上下文保留和视觉质量），并比较了七种先进模型。

Result: 揭示了常见失败模式，并提出基于注意力定位的失败分析协议。

Conclusion: MedEBench为开发可靠的医学图像编辑系统奠定了基础。

Abstract: Text-guided image editing has seen rapid progress in natural image domains,
but its adaptation to medical imaging remains limited and lacks standardized
evaluation. Clinically, such editing holds promise for simulating surgical
outcomes, creating personalized teaching materials, and enhancing patient
communication. To bridge this gap, we introduce \textbf{MedEBench}, a
comprehensive benchmark for evaluating text-guided medical image editing. It
consists of 1,182 clinically sourced image-prompt triplets spanning 70 tasks
across 13 anatomical regions. MedEBench offers three key contributions: (1) a
clinically relevant evaluation framework covering Editing Accuracy, Contextual
Preservation, and Visual Quality, supported by detailed descriptions of
expected change and ROI (Region of Interest) masks; (2) a systematic comparison
of seven state-of-the-art models, revealing common failure patterns; and (3) a
failure analysis protocol based on attention grounding, using IoU between
attention maps and ROIs to identify mislocalization. MedEBench provides a solid
foundation for developing and evaluating reliable, clinically meaningful
medical image editing systems.

</details>


### [591] [TaxaDiffusion: Progressively Trained Diffusion Model for Fine-Grained Species Generation](https://arxiv.org/abs/2506.01923)
*Amin Karimi Monsefi,Mridul Khurana,Rajiv Ramnath,Anuj Karpatne,Wei-Lun Chao,Cheng Zhang*

Main category: cs.CV

TL;DR: TaxaDiffusion是一种基于分类学的扩散模型训练框架，用于生成高保真度的细粒度动物图像。


<details>
  <summary>Details</summary>
Motivation: 传统方法将每个物种视为独立类别，忽略了物种间的视觉相似性。TaxaDiffusion旨在利用分类学知识，通过层次化训练提升生成图像的形态和身份准确性。

Method: TaxaDiffusion采用分层训练策略，从粗粒度分类（如纲、目）逐步细化到细粒度（如科、属、种），利用物种间的相似性进行知识迁移。

Result: 在三个细粒度动物数据集上的实验表明，TaxaDiffusion优于现有方法，生成图像具有更高的保真度。

Conclusion: TaxaDiffusion通过结合分类学知识，显著提升了细粒度动物图像生成的准确性，尤其在训练样本有限的情况下表现优异。

Abstract: We propose TaxaDiffusion, a taxonomy-informed training framework for
diffusion models to generate fine-grained animal images with high morphological
and identity accuracy. Unlike standard approaches that treat each species as an
independent category, TaxaDiffusion incorporates domain knowledge that many
species exhibit strong visual similarities, with distinctions often residing in
subtle variations of shape, pattern, and color. To exploit these relationships,
TaxaDiffusion progressively trains conditioned diffusion models across
different taxonomic levels -- starting from broad classifications such as Class
and Order, refining through Family and Genus, and ultimately distinguishing at
the Species level. This hierarchical learning strategy first captures
coarse-grained morphological traits shared by species with common ancestors,
facilitating knowledge transfer before refining fine-grained differences for
species-level distinction. As a result, TaxaDiffusion enables accurate
generation even with limited training samples per species. Extensive
experiments on three fine-grained animal datasets demonstrate that outperforms
existing approaches, achieving superior fidelity in fine-grained animal image
generation. Project page: https://amink8.github.io/TaxaDiffusion/

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [592] [Advanced Nanostructured Topical Therapeutics for Psoriasis: Strategic Synthesis, Multimodal Characterization, and Preliminary Pharmacodynamic Profiling](https://arxiv.org/abs/2506.01572)
*Iqra Yousaf,Aqsa Yousaf*

Main category: physics.med-ph

TL;DR: 开发了一种结合金属氧化物纳米颗粒和植物提取物的新型局部治疗凝胶，用于治疗银屑病，动物模型显示显著疗效。


<details>
  <summary>Details</summary>
Motivation: 银屑病是一种难以治疗的长期炎症性皮肤病，需要新的治疗方法。

Method: 结合CeO2、ZnO和Ag纳米颗粒与苦瓜、姜和印楝的植物提取物，制成鱼胶原和琼脂凝胶，并通过多种技术表征纳米颗粒。

Result: 动物模型中，治疗组表现出更快的伤口愈合和炎症减轻，结果具有统计学显著性。

Conclusion: 纳米颗粒与植物成分的组合可能为银屑病治疗提供新途径，需进一步研究长期安全性和疗效。

Abstract: Psoriasis is a long-term inflammatory skin disease that remains difficult to
treat. In this study, we developed a new topical treatment by combining metal
oxide nanoparticles: cerium oxide (CeO2), zinc oxide (ZnO), and silver (Ag),
with natural plant extracts in a gel made from fish collagen and agar. The
nanoparticles were characterized using UV-Vis spectroscopy, dynamic light
scattering (DLS), Fourier-transform infrared spectroscopy (FTIR), and scanning
electron microscopy (SEM), showing good stability and a uniform particle size
distribution (ZnO averaged 66 nm).
  To enhance therapeutic potential, the gel was enriched with plant-derived
antioxidants from bitter melon, ginger, and neem. This formulation was tested
on an animal model of psoriasis. The treated group exhibited faster wound
healing and reduced inflammation compared to both placebo and untreated groups,
with statistically significant results (p < 0.01 to p < 0.001) observed from
Day 3, becoming more pronounced by Day 14.
  These results indicate that the combination of nanoparticles with plant-based
components in a topical gel may provide a promising new approach to psoriasis
treatment. Further studies are recommended to evaluate long-term safety and
therapeutic effectiveness.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [593] [CineMA: A Foundation Model for Cine Cardiac MRI](https://arxiv.org/abs/2506.00679)
*Yunguan Fu,Weixi Yi,Charlotte Manisty,Anish N Bhuva,Thomas A Treibel,James C Moon,Matthew J Clarkson,Rhodri Huw Davies,Yipeng Hu*

Main category: eess.IV

TL;DR: CineMA是一个基于自监督学习的AI基础模型，用于自动化心脏磁共振（CMR）图像分析任务，减少标注需求并提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统CMR图像分析（如射血分数计算）耗时且主观，需要自动化解决方案。

Method: CineMA通过自监督自动编码器在74,916个CMR研究中预训练，并通过微调完成多种任务。

Result: CineMA在8个数据集上表现优于传统CNN，且标注效率更高。

Conclusion: CineMA为心脏影像分析提供了高效的基础模型，降低了标注负担并加速临床转化。

Abstract: Cardiac magnetic resonance (CMR) is a key investigation in clinical
cardiovascular medicine and has been used extensively in population research.
However, extracting clinically important measurements such as ejection fraction
for diagnosing cardiovascular diseases remains time-consuming and subjective.
We developed CineMA, a foundation AI model automating these tasks with limited
labels. CineMA is a self-supervised autoencoder model trained on 74,916 cine
CMR studies to reconstruct images from masked inputs. After fine-tuning, it was
evaluated across eight datasets on 23 tasks from four categories: ventricle and
myocardium segmentation, left and right ventricle ejection fraction
calculation, disease detection and classification, and landmark localisation.
CineMA is the first foundation model for cine CMR to match or outperform
convolutional neural networks (CNNs). CineMA demonstrated greater label
efficiency than CNNs, achieving comparable or better performance with fewer
annotations. This reduces the burden of clinician labelling and supports
replacing task-specific training with fine-tuning foundation models in future
cardiac imaging applications. Models and code for pre-training and fine-tuning
are available at https://github.com/mathpluscode/CineMA, democratising access
to high-performance models that otherwise require substantial computational
resources, promoting reproducibility and accelerating clinical translation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [594] [Supporting architecture evaluation for ATAM scenarios with LLMs](https://arxiv.org/abs/2506.00150)
*Rafael Capilla,J. Andrés Díaz-Pace,Yamid Ramírez,Jennifer Pérez,Vanessa Rodríguez-Horcajo*

Main category: cs.SE

TL;DR: 论文探讨了利用LLM（如MS Copilot）部分自动化软件架构评估活动，以提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统架构评估方法依赖人工，效率低且耗时，需要更高效的工具支持决策。

Method: 使用MS Copilot分析学生提出的质量场景，并与人工评估结果对比。

Result: LLM在大多数情况下能更准确地分析质量场景的风险、敏感点和权衡。

Conclusion: 生成式AI有潜力部分自动化架构评估任务，优化人类决策过程。

Abstract: Architecture evaluation methods have long been used to evaluate software
designs. Several evaluation methods have been proposed and used to analyze
tradeoffs between different quality attributes. Having competing qualities
leads to conflicts for selecting which quality-attribute scenarios are the most
suitable ones that an architecture should tackle and for prioritizing the
scenarios required by the stakeholders. In this context, architecture
evaluation is carried out manually, often involving long brainstorming sessions
to decide which are the most adequate quality scenarios. To reduce this effort
and make the assessment and selection of scenarios more efficient, we suggest
the usage of LLMs to partially automate evaluation activities. As a first step
to validate this hypothesis, this work studies MS Copilot as an LLM tool to
analyze quality scenarios suggested by students in a software architecture
course and compares the students' results with the assessment provided by the
LLM. Our initial study reveals that the LLM produces in most cases better and
more accurate results regarding the risks, sensitivity points and tradeoff
analysis of the quality scenarios. Overall, the use of generative AI has the
potential to partially automate and support the architecture evaluation tasks,
improving the human decision-making process.

</details>


### [595] [An LLM Agent for Functional Bug Detection in Network Protocols](https://arxiv.org/abs/2506.00714)
*Mingwei Zheng,Chengpeng Wang,Xuwei Liu,Jinyao Guo,Shiwei Feng,Xiangyu Zhang*

Main category: cs.SE

TL;DR: RFCScan是一种利用大型语言模型（LLM）检测网络协议实现与RFC规范之间功能错误的自主代理工具，具有高精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 功能错误可能导致严重后果，如路由错误和服务中断，传统静态分析工具无法满足需求。

Method: RFCScan由索引代理和检测代理组成，前者生成语义索引，后者通过需求驱动检索识别不一致。

Result: 在六个实际网络协议实现中，RFCScan检测到47个功能错误，精度达81.9%，其中20个已被开发者确认或修复。

Conclusion: RFCScan通过结合LLM和需求驱动检索，有效提升了功能错误的检测能力。

Abstract: Functional correctness is critical for ensuring the reliability and security
of network protocol implementations. Functional bugs, instances where
implementations diverge from behaviors specified in RFC documents, can lead to
severe consequences, including faulty routing, authentication bypasses, and
service disruptions. Detecting these bugs requires deep semantic analysis
across specification documents and source code, a task beyond the capabilities
of traditional static analysis tools. This paper introduces RFCScan, an
autonomous agent that leverages large language models (LLMs) to detect
functional bugs by checking conformance between network protocol
implementations and their RFC specifications. Inspired by the human auditing
procedure, RFCScan comprises two key components: an indexing agent and a
detection agent. The former hierarchically summarizes protocol code semantics,
generating semantic indexes that enable the detection agent to narrow down the
scanning scope. The latter employs demand-driven retrieval to iteratively
collect additional relevant data structures and functions, eventually
identifying potential inconsistencies with the RFC specifications effectively.
We evaluate RFCScan across six real-world network protocol implementations.
RFCScan identifies 47 functional bugs with 81.9% precision, of which 20 bugs
have been confirmed or fixed by developers.

</details>


### [596] [CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning](https://arxiv.org/abs/2506.00750)
*Monoshi Kumar Roy,Simin Chen,Benjamin Steenhoek,Jinjun Peng,Gail Kaiser,Baishakhi Ray,Wei Le*

Main category: cs.SE

TL;DR: CodeSense是一个针对真实世界代码的细粒度语义推理任务的基准测试，填补了现有基准测试的不足，并揭示了LLMs在代码语义理解上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有代码推理基准多依赖合成数据或教育性问题，且集中于粗粒度任务，无法有效评估LLMs在实际软件工程中的表现。

Method: 从真实代码库收集Python、C和Java项目，执行测试并收集执行轨迹，构建细粒度语义推理任务的数据集，并对先进LLMs进行全面评估。

Result: LLMs在细粒度推理任务上表现明显不足，提示技术如思维链和上下文学习虽有帮助，但代码语义的缺乏仍是根本限制。

Conclusion: CodeSense提供了数据集、基准和工具集，为未来基准构建和模型训练奠定了基础。

Abstract: Understanding and reasoning about code semantics is essential for enhancing
code LLMs' abilities to solve real-world software engineering (SE) tasks.
Although several code reasoning benchmarks exist, most rely on synthetic
datasets or educational coding problems and focus on coarse-grained reasoning
tasks such as input/output prediction, limiting their effectiveness in
evaluating LLMs in practical SE contexts. To bridge this gap, we propose
CodeSense, the first benchmark that makes available a spectrum of fine-grained
code reasoning tasks concerned with the software engineering of real-world
code. We collected Python, C and Java software projects from real-world
repositories. We executed tests from these repositories, collected their
execution traces, and constructed a ground truth dataset for fine-grained
semantic reasoning tasks. We then performed comprehensive evaluations on
state-of-the-art LLMs. Our results show a clear performance gap for the models
to handle fine-grained reasoning tasks. Although prompting techniques such as
chain-of-thought and in-context learning helped, the lack of code semantics in
LLMs fundamentally limit models' capabilities of code reasoning. Besides
dataset, benchmark and evaluation, our work produced an execution tracing
framework and tool set that make it easy to collect ground truth for
fine-grained SE reasoning tasks, offering a strong basis for future benchmark
construction and model post training. Our code and data are located at
https://codesense-bench.github.io/.

</details>


### [597] [Behavioral Augmentation of UML Class Diagrams: An Empirical Study of Large Language Models for Method Generation](https://arxiv.org/abs/2506.00788)
*Djaber Rouabhia,Ismail Hadjadj*

Main category: cs.SE

TL;DR: 该研究评估了九种大型语言模型（LLM）在从自然语言用例中为UML类图添加行为方法的能力，发现LLM能生成结构良好的方法，但需要人工监督以确保准确性。


<details>
  <summary>Details</summary>
Motivation: 自动化从自然语言用例中丰富UML类图的行为方法是一个重要挑战，研究旨在评估LLM在此任务中的表现。

Method: 研究使用21个结构化废物管理用例，评估了九种LLM在方法数量、签名丰富性、注释完整性等六个指标上的表现。

Result: 所有LLM均生成了符合UML规范的PlantUML图，部分模型在方法覆盖率和注释准确性上表现优异，但签名和注释存在不一致。

Conclusion: LLM可作为软件设计的协作工具，但需改进提示工程和模型选择，并辅以人工监督以确保语义对齐。

Abstract: Automating the enrichment of UML class diagrams with behavioral methods from
natural language use cases is a significant challenge. This study evaluates
nine large language models (LLMs) in augmenting a methodless UML diagram (21
classes, 17 relationships) using 21 structured waste-management use cases. A
total of 90 diagrams (3,373 methods) were assessed across six metrics: method
quantity, signature richness (visibility, names, parameters, return types),
annotation completeness (linking to use cases/actions), structural fidelity,
syntactic correctness (PlantUML compilation), and naming convergence (across
models). All LLMs produced valid PlantUML diagrams adhering to UML conventions.
Some models excelled in method coverage and annotation accuracy, while others
showed richer parameterization but weaker traceability. These results
demonstrate that LLMs can generate well-structured methods with consistent
naming, advancing automated behavioral modeling. However, inconsistencies in
annotations and signatures highlight the need for improved prompt engineering
and model selection. The rapid generation of these methods supports Agile
practices by enabling faster design iterations. Despite their capabilities,
human oversight is essential to ensure accuracy, appropriateness, and semantic
alignment. This positions LLMs as collaborative partners in software design.
All experimental artifacts (\texttt{.puml}, \texttt{.png}, \texttt{.csv}) are
publicly available for reproducibility.

</details>


### [598] [CODEMENV: Benchmarking Large Language Models on Code Migration](https://arxiv.org/abs/2506.00894)
*Keyuan Cheng,Xudong Shen,Yihao Yang,Tengyue Wang,Yang Cao,Muhammad Asif Ali,Hanbin Wang,Lijie Hu,Di Wang*

Main category: cs.SE

TL;DR: 论文介绍了CODEMENV基准，用于评估大语言模型（LLMs）在代码迁移任务中的表现，覆盖Python和Java的19个包，测试了三个核心任务。实验结果显示GPT-4O表现最佳，但LLMs在逻辑一致性上存在问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在代码迁移任务中的能力，填补现有研究的空白。

Method: 提出CODEMENV基准，包含922个示例，测试LLMs在三个核心任务上的表现。

Result: 七种LLMs的平均pass@1率为26.50%，GPT-4O最高（43.84%）。LLMs对新版本函数更擅长，但存在逻辑不一致问题。

Conclusion: CODEMENV为代码迁移任务提供了评估基准，揭示了LLMs的优势与不足。

Abstract: Large language models (LLMs) have shown remarkable capabilities across
various software engineering tasks; however, their effectiveness in code
migration, adapting code to run in different environments, remains
insufficiently studied. In this work, we introduce CODEMENV: Code Migration
Across Environment, a new benchmark specifically designed to assess LLMs'
abilities in code migration scenarios. CODEMENV consists of 922 examples
spanning 19 Python and Java packages, and covers three core tasks: (1)
identifying functions incompatible with specific versions, (2) detecting
changes in function definitions, and (3) adapting code to target environments.
Experimental evaluation with seven LLMs on CODEMENV yields an average pass@1
rate of 26.50%, with GPT-4O achieving the highest score at 43.84%. Key findings
include: (i) LLMs tend to be more proficient with newer function versions,
which aids in migrating legacy code, and (ii) LLMs sometimes exhibit logical
inconsistencies by identifying function changes irrelevant to the intended
migration environment. The datasets are available at
https://github.com/xdshen-ai/Benchmark-of-Code-Migration.

</details>


### [599] [Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models](https://arxiv.org/abs/2506.00943)
*Chanuka Wijayakoon,Hai Dong,H. M. N. Dilum Bandara,Zahir Tari,Anurag Soin*

Main category: cs.SE

TL;DR: 论文探讨了利用大型语言模型（LLM）从自然语言法律合同生成合法合规的智能合约，并提出了一套量化合规性的新指标。


<details>
  <summary>Details</summary>
Motivation: 智能合约的法律合规性验证需要法律和软件开发领域的专业知识，且现有方法依赖大量人工工作，LLM的代码生成能力为解决这一问题提供了可能。

Method: 通过将法律合同和智能合约建模为流程并比较其行为，提出了一套量化合规性的指标，并测试了四种LLM生成智能合约的合规性。

Result: 所有LLM生成的代码语法正确，但法律合规性差异显著，较大模型表现更好；提出的指标能提供细粒度区分并适用于跨领域代码。

Conclusion: LLM可在严格审查下辅助生成合规智能合约的初始代码，提出的指标为自动化开发流程奠定了基础。

Abstract: Smart contracts can implement and automate parts of legal contracts, but
ensuring their legal compliance remains challenging. Existing approaches such
as formal specification, verification, and model-based development require
expertise in both legal and software development domains, as well as extensive
manual effort. Given the recent advances of Large Language Models (LLMs) in
code generation, we investigate their ability to generate legally compliant
smart contracts directly from natural language legal contracts, addressing
these challenges. We propose a novel suite of metrics to quantify legal
compliance based on modeling both legal and smart contracts as processes and
comparing their behaviors. We select four LLMs, generate 20 smart contracts
based on five legal contracts, and analyze their legal compliance. We find that
while all LLMs generate syntactically correct code, there is significant
variance in their legal compliance with larger models generally showing higher
levels of compliance. We also evaluate the proposed metrics against properties
of software metrics, showing they provide fine-grained distinctions, enable
nuanced comparisons, and are applicable across domains for code from any
source, LLM or developer. Our results suggest that LLMs can assist in
generating starter code for legally compliant smart contracts with strict
reviews, and the proposed metrics provide a foundation for automated and
self-improving development workflows.

</details>


### [600] [Greening AI-enabled Systems with Software Engineering: A Research Agenda for Environmentally Sustainable AI Practices](https://arxiv.org/abs/2506.01774)
*Luís Cruz,João Paulo Fernandes,Maja H. Kirkeby,Silverio Martínez-Fernández,June Sallou,Hina Anwar,Enrique Barba Roque,Justus Bogner,Joel Castaño,Fernando Castor,Aadil Chasmawala,Simão Cunha,Daniel Feitosa,Alexandra González,Andreas Jedlitschka,Patricia Lago,Ana Oprescu,Pooja Rani,João Saraiva,Federica Sarro,Raghavendra Selvan,Karthik Vaidhyanathan,Roberto Verdecchia,Ivan P. Yamshchikov,Henry Muccini*

Main category: cs.SE

TL;DR: 该论文总结了2025年CECAM-Lorentz研讨会的成果，探讨了如何通过软件工程推动绿色AI的发展，提出了关键挑战和研究方向。


<details>
  <summary>Details</summary>
Motivation: AI系统的环境影响日益显著，软件工程在开发可持续解决方案中扮演重要角色。研讨会旨在促进绿色软件和AI研究的跨学科交流。

Method: 通过主题演讲、快速演讲和协作讨论，29名参与者共同识别并优先处理了绿色AI领域的关键挑战。

Result: 提出了能源评估与标准化、基准测试实践、可持续架构、运行时适应、实证方法和教育等研究方向。

Conclusion: 研讨会形成了一份研究议程，为基于软件工程原则开发环境可持续的AI系统提供了开放研究方向和实践建议。

Abstract: The environmental impact of Artificial Intelligence (AI)-enabled systems is
increasing rapidly, and software engineering plays a critical role in
developing sustainable solutions. The "Greening AI with Software Engineering"
CECAM-Lorentz workshop (no. 1358, 2025) funded by the Centre Europ\'een de
Calcul Atomique et Mol\'eculaire and the Lorentz Center, provided an
interdisciplinary forum for 29 participants, from practitioners to academics,
to share knowledge, ideas, practices, and current results dedicated to
advancing green software and AI research. The workshop was held February 3-7,
2025, in Lausanne, Switzerland. Through keynotes, flash talks, and
collaborative discussions, participants identified and prioritized key
challenges for the field. These included energy assessment and standardization,
benchmarking practices, sustainability-aware architectures, runtime adaptation,
empirical methodologies, and education. This report presents a research agenda
emerging from the workshop, outlining open research directions and practical
recommendations to guide the development of environmentally sustainable
AI-enabled systems rooted in software engineering principles.

</details>
